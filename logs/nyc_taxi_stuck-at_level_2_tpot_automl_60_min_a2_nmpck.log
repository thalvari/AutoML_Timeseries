30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   9%|▉         | 9/100 [00:10<01:49,  1.20s/pipeline]Optimization Progress:  89%|████████▉ | 89/100 [00:12<00:09,  1.18pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  1.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  1.18pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:47:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5a6e47edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5a6e58f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5a6e59cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5a6e583cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5a6e470f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f507c26b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f507c26b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f507c28327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f507c283cb4]

.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.68pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:17<00:00,  1.68pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 103/200 [00:17<00:57,  1.68pipeline/s]Optimization Progress:  52%|█████▏    | 104/200 [00:17<01:16,  1.26pipeline/s]Optimization Progress:  54%|█████▎    | 107/200 [00:25<02:06,  1.36s/pipeline]Optimization Progress:  92%|█████████▎| 185/200 [00:28<00:14,  1.04pipeline/s]
Generation 1 - Current Pareto front scores:
-1	-1085442944.7084582	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-1076018617.2372575	SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=2), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)
-3	-1035031195.2356281	RidgeCV(Normalizer(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), Normalizer__norm=l2))                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.04pipeline/s]Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.45pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:32<00:00,  1.45pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 200/200 [00:33<00:00,  1.45pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:33<00:00,  1.45pipeline/s]Optimization Progress:  68%|██████▊   | 203/300 [00:34<01:39,  1.03s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 203/300 [00:34<01:39,  1.03s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [00:49<01:38,  1.03s/pipeline]Optimization Progress:  68%|██████▊   | 205/300 [02:09<23:33, 14.88s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [02:12<02:36, 10.43s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1064889657.351911	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-3	-1035031195.2356281	RidgeCV(Normalizer(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), Normalizer__norm=l2))                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:49:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5a6e47edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5a6e58f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5a6e59cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5a6e583cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5a6e470f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f507c26b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f507c26b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f507c28327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f507c283cb4]

.
Optimization Progress: 100%|██████████| 300/300 [02:12<00:00, 10.43s/pipeline]Optimization Progress: 100%|██████████| 300/300 [02:12<00:00,  7.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 300/300 [02:13<00:00,  7.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:13<00:00,  7.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:16<00:00,  7.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [02:18<00:00,  7.30s/pipeline]Optimization Progress:  76%|███████▌  | 304/400 [02:28<10:06,  6.32s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [02:36<01:15,  4.46s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1064889657.351911	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-3	-1035031195.2356281	RidgeCV(Normalizer(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), Normalizer__norm=l2))                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 400/400 [02:36<00:00,  4.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:37<00:00,  4.46s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:37<00:00,  3.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:40<00:00,  3.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 400/400 [02:42<00:00,  3.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [02:42<00:00,  3.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:42<00:00,  3.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 400/400 [02:42<00:00,  3.14s/pipeline]Optimization Progress:  80%|████████  | 402/500 [02:43<04:58,  3.04s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 402/500 [02:43<04:58,  3.04s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 403/500 [02:43<04:55,  3.04s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 404/500 [02:43<04:52,  3.04s/pipeline]Optimization Progress:  81%|████████  | 406/500 [02:48<03:53,  2.48s/pipeline]Optimization Progress:  97%|█████████▋| 486/500 [02:52<00:24,  1.75s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1064889657.351911	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-3	-1035031195.2356281	RidgeCV(Normalizer(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), Normalizer__norm=l2))                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:53<00:00,  1.75s/pipeline]Optimization Progress: 100%|██████████| 500/500 [02:53<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:53<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:55<00:00,  1.25s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 500/500 [02:56<00:00,  1.25s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [03:06<04:26,  2.71s/pipeline]Optimization Progress:  97%|█████████▋| 581/600 [03:10<00:36,  1.92s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1064889657.351911	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-1064150768.4470737	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-1035031195.2356281	RidgeCV(Normalizer(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), Normalizer__norm=l2))                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  1.92s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  1.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 600/600 [03:12<00:00,  1.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [03:12<00:00,  1.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:16<00:00,  1.36s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [03:18<05:04,  3.08s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [03:29<08:37,  5.28s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [03:34<01:06,  3.72s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-1064200289.3301356	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-987682524.850818	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [03:35<00:00,  3.72s/pipeline]Optimization Progress: 100%|██████████| 700/700 [03:35<00:00,  2.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [03:37<00:00,  2.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 700/700 [03:38<00:00,  2.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [03:42<00:00,  2.63s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [03:42<04:45,  2.91s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [03:42<04:45,  2.91s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [03:53<05:45,  3.59s/pipeline]Optimization Progress:  98%|█████████▊| 784/800 [03:57<00:40,  2.53s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-1064139871.517355	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-987682524.850818	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-965321503.1172794	GradientBoostingRegressor(SGDRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:02<00:00,  2.53s/pipeline]Optimization Progress: 100%|██████████| 800/800 [04:02<00:00,  1.88s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [04:07<04:28,  2.71s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 801/900 [04:07<04:28,  2.71s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [04:22<06:41,  4.14s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [04:32<00:49,  2.94s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-1063900438.9843518	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-987682524.850818	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-965321503.1172794	GradientBoostingRegressor(SGDRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 900/900 [04:33<00:00,  2.94s/pipeline]Optimization Progress: 100%|██████████| 900/900 [04:33<00:00,  2.08s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [04:39<00:00,  2.08s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:40<00:00,  2.08s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [04:43<07:13,  4.38s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [04:57<12:13,  7.48s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [05:04<01:34,  5.26s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-1063900438.9843518	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-987682524.850818	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [05:06<00:00,  5.26s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [05:06<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [05:08<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [05:13<00:00,  3.71s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [05:16<05:21,  3.34s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [05:30<10:31,  6.65s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [05:37<01:10,  4.68s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-1063716483.252651	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-983107083.9925029	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1100/1100 [05:38<00:00,  4.68s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [05:38<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:43<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:43<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 1100/1100 [05:43<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [05:45<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1100/1100 [05:46<00:00,  3.30s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [05:50<09:37,  5.83s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  92%|█████████▏| 1101/1200 [05:50<09:37,  5.83s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [10:54<1:20:29, 49.79s/pipeline]                                                                                  Skipped pipeline #1172 due to time out. Continuing to the next pipeline.
Optimization Progress:  98%|█████████▊| 1172/1200 [10:54<23:14, 49.79s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  99%|█████████▊| 1184/1200 [11:00<09:17, 34.87s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-1063710284.4324362	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-983107083.9925029	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [11:02, 34.87s/pipeline]Optimization Progress: 1201pipeline [11:02, 24.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 1201pipeline [11:07, 24.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1201pipeline [11:11, 24.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1201pipeline [11:11, 24.45s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [11:11<28:52, 18.05s/pipeline]Optimization Progress:  93%|█████████▎| 1205/1300 [11:24<25:49, 16.31s/pipeline]Optimization Progress:  99%|█████████▉| 1285/1300 [11:37<02:51, 11.46s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-1063525683.5119416	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-983107083.9925029	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 1301pipeline [11:38, 11.46s/pipeline]Optimization Progress: 1301pipeline [11:38,  8.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [11:43,  8.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [11:47,  8.03s/pipeline]Optimization Progress: 1301pipeline [11:50,  8.03s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [11:51<12:14,  7.57s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [12:35<29:53, 18.68s/pipeline]Optimization Progress:  99%|█████████▉| 1384/1400 [12:42<03:29, 13.10s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-1063486673.7889858	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-983107083.9925029	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [12:44, 13.10s/pipeline]Optimization Progress: 1401pipeline [12:44,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1401pipeline [12:45,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1401pipeline [12:47,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1401pipeline [12:50,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 1401pipeline [12:51,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [12:51,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [12:51,  9.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 1401pipeline [12:52,  9.21s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [12:55<12:03,  7.54s/pipeline]Optimization Progress:  94%|█████████▎| 1405/1500 [14:04<41:08, 25.99s/pipeline]Optimization Progress:  99%|█████████▉| 1485/1500 [14:11<04:33, 18.22s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-1063486673.7889858	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-983107083.9925029	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-954258269.2776333	GradientBoostingRegressor(ElasticNetCV(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), ElasticNetCV__l1_ratio=0.35000000000000003, ElasticNetCV__tol=0.0001), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [14:13, 18.22s/pipeline]Optimization Progress: 1501pipeline [14:13, 12.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 1501pipeline [14:18, 12.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 1501pipeline [14:18, 12.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 1501pipeline [14:19, 12.78s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 1501pipeline [14:24, 12.78s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  94%|█████████▍| 1501/1600 [14:26<21:05, 12.78s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [14:26<21:05, 12.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1502/1600 [14:26<21:05, 12.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1503/1600 [14:26<20:52, 12.91s/pipeline]Optimization Progress:  94%|█████████▍| 1505/1600 [15:26<23:54, 15.10s/pipeline]Optimization Progress:  99%|█████████▉| 1585/1600 [15:35<02:38, 10.60s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-1063486673.7889858	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-956757672.5237515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-954258269.2776333	GradientBoostingRegressor(ElasticNetCV(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), ElasticNetCV__l1_ratio=0.35000000000000003, ElasticNetCV__tol=0.0001), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [15:36, 10.60s/pipeline]Optimization Progress: 1601pipeline [15:36,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 1601pipeline [15:38,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 1601pipeline [15:38,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1601pipeline [15:39,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X needs to contain only non-negative integers..
Optimization Progress: 1601pipeline [15:40,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [15:47,  7.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [15:48,  7.45s/pipeline]Optimization Progress:  94%|█████████▍| 1606/1700 [15:48<09:15,  5.91s/pipeline]Optimization Progress:  95%|█████████▍| 1607/1700 [16:01<12:31,  8.08s/pipeline]Optimization Progress:  99%|█████████▉| 1687/1700 [16:10<01:13,  5.69s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-1063486673.7889858	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-956757672.5237515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-954258269.2776333	GradientBoostingRegressor(ElasticNetCV(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), ElasticNetCV__l1_ratio=0.35000000000000003, ElasticNetCV__tol=0.0001), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1701pipeline [16:10,  5.69s/pipeline]Optimization Progress: 1701pipeline [16:10,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 1701pipeline [16:10,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [16:11,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [16:12,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [16:12,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [16:13,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [16:13,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1701pipeline [16:16,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 1701pipeline [16:17,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [16:21,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1701pipeline [16:22,  3.99s/pipeline]Optimization Progress:  95%|█████████▍| 1706/1800 [16:22<05:32,  3.54s/pipeline]Optimization Progress:  95%|█████████▍| 1707/1800 [16:33<08:54,  5.74s/pipeline]Optimization Progress:  99%|█████████▉| 1787/1800 [16:40<00:52,  4.04s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-1063404002.2868958	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-956757672.5237515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-954258269.2776333	GradientBoostingRegressor(ElasticNetCV(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), ElasticNetCV__l1_ratio=0.35000000000000003, ElasticNetCV__tol=0.0001), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1801pipeline [16:40,  4.04s/pipeline]Optimization Progress: 1801pipeline [16:40,  2.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 1801pipeline [16:40,  2.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 1801pipeline [16:42,  2.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1801pipeline [16:43,  2.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1801pipeline [16:44,  2.83s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1803/1900 [16:52<04:34,  2.83s/pipeline]Optimization Progress:  95%|█████████▍| 1804/1900 [17:00<04:32,  2.83s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [17:06<06:17,  3.97s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [17:16<00:42,  2.82s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-1063404002.2868958	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-956757672.5237515	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-954258269.2776333	GradientBoostingRegressor(ElasticNetCV(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), ElasticNetCV__l1_ratio=0.35000000000000003, ElasticNetCV__tol=0.0001), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-894804048.9730723	GradientBoostingRegressor(Binarizer(SGDRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [17:18,  2.82s/pipeline]Optimization Progress: 1901pipeline [17:18,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [17:19,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 1901pipeline [17:19,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1901pipeline [17:20,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [17:20,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 1901pipeline [17:22,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1901pipeline [17:24,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [17:26,  2.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1901pipeline [17:28,  2.00s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [17:32<09:12,  5.64s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [19:08<53:09, 32.88s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [20:01<06:34, 23.21s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-1063404002.2868958	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2001pipeline [20:01, 23.21s/pipeline]Optimization Progress: 2001pipeline [20:01, 16.25s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2001/2100 [20:15<26:49, 16.25s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [20:20<26:32, 16.25s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [21:06<34:08, 21.12s/pipeline]Optimization Progress:  99%|█████████▉| 2083/2100 [21:16<04:12, 14.82s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 2101pipeline [21:17, 14.82s/pipeline]Optimization Progress: 2101pipeline [21:17, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [21:18, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2101pipeline [21:19, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 2101pipeline [21:20, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2101pipeline [21:20, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2101pipeline [21:20, 10.39s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 2101pipeline [21:25, 10.39s/pipeline]Optimization Progress: 2101pipeline [21:30, 10.39s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [21:31<15:04,  9.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [21:31<15:04,  9.32s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [23:25<37:29, 23.68s/pipeline]Optimization Progress:  99%|█████████▉| 2185/2200 [23:36<04:09, 16.62s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2201pipeline [23:43, 16.62s/pipeline]Optimization Progress: 2201pipeline [23:43, 11.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2201pipeline [23:44, 11.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2201pipeline [23:45, 11.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [23:48, 11.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2201pipeline [23:50, 11.76s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [23:50<17:01, 10.43s/pipeline]Optimization Progress:  96%|█████████▌| 2203/2300 [24:03<17:59, 11.13s/pipeline]Optimization Progress:  99%|█████████▉| 2283/2300 [24:09<02:12,  7.81s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2301pipeline [24:12,  7.81s/pipeline]Optimization Progress: 2301pipeline [24:12,  5.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [24:18,  5.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2301pipeline [24:22,  5.52s/pipeline]Optimization Progress:  96%|█████████▌| 2303/2400 [24:23<08:54,  5.51s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [24:38<12:57,  8.10s/pipeline]Optimization Progress:  99%|█████████▉| 2384/2400 [24:47<01:31,  5.70s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [24:49,  5.70s/pipeline]Optimization Progress: 2401pipeline [24:49,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [24:50,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [24:51,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [24:51,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2401pipeline [24:53,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 2401pipeline [24:53,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2401pipeline [24:53,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [24:57,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [24:58,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [24:59,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [25:00,  4.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [25:00,  4.04s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [25:01<07:33,  4.67s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [26:25<45:24, 28.38s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [26:34<05:18, 19.90s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2501pipeline [26:35, 19.90s/pipeline]Optimization Progress: 2501pipeline [26:35, 13.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 2501pipeline [26:39, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=3 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=4 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=5 X contains negative values..
Optimization Progress: 2501pipeline [26:41, 13.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2501pipeline [26:42, 13.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [26:45, 13.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [26:45, 13.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2501pipeline [26:49, 13.95s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [26:49<23:00, 13.95s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [26:49<22:58, 14.06s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [27:31<35:56, 22.24s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [27:40<04:25, 15.60s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-1063346631.9835443	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2601pipeline [27:41, 15.60s/pipeline]Optimization Progress: 2601pipeline [27:41, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2601pipeline [27:42, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2601pipeline [27:43, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2601pipeline [27:45, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 2601pipeline [27:46, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2601pipeline [27:46, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2601pipeline [27:47, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2601pipeline [27:51, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2601pipeline [27:51, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2601pipeline [27:54, 10.94s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [27:54, 10.94s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [27:55<19:13, 11.77s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [27:55<19:13, 11.77s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [28:39<23:50, 14.90s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [28:46<02:47, 10.46s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-1063016400.3819603	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [28:50, 10.46s/pipeline]Optimization Progress: 2701pipeline [28:50,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 2701pipeline [28:53,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [28:55,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 2701pipeline [28:55,  7.40s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [28:57,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [29:00,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [29:00,  7.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2701pipeline [29:01,  7.40s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [29:02<14:05,  8.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2702/2800 [29:02<14:05,  8.63s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [29:18<13:35,  8.50s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [29:26<01:35,  5.98s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-1063016400.3819603	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2801pipeline [29:28,  5.98s/pipeline]Optimization Progress: 2801pipeline [29:28,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2801pipeline [29:28,  4.22s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2801pipeline [29:29,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2801pipeline [29:29,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 2801pipeline [29:29,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [29:31,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2801pipeline [29:31,  4.22s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2801pipeline [29:34,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2801pipeline [29:37,  4.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 2801pipeline [29:37,  4.22s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [29:42<11:41,  7.15s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [31:35<1:02:52, 38.89s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [31:46<07:43, 27.27s/pipeline]  
Generation 28 - Current Pareto front scores:
-1	-1063016400.3819603	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:46, 27.27s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:47, 27.27s/pipeline]Optimization Progress: 2901pipeline [31:47, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:48, 19.11s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:49, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:55, 19.11s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:55, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 2901pipeline [31:55, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:57, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 2901pipeline [31:57, 19.11s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2901pipeline [31:58, 19.11s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [32:01<28:52, 17.68s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [32:18<27:55, 17.27s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [32:30<03:26, 12.14s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-1063016400.3819603	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3001pipeline [32:32, 12.14s/pipeline]Optimization Progress: 3001pipeline [32:32,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3001pipeline [32:32,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [32:34,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [32:34,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3001pipeline [32:36,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [32:36,  8.52s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3001pipeline [32:37,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [32:39,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3001pipeline [32:41,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3001pipeline [32:41,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 3001pipeline [32:42,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 3001pipeline [32:43,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [32:43,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [32:43,  8.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3001pipeline [32:44,  8.52s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [33:02<24:45, 15.16s/pipeline]Optimization Progress:  99%|█████████▉| 3082/3100 [33:20<03:12, 10.68s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-1062817283.5012448	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-841664582.1467662	GradientBoostingRegressor(Binarizer(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), Binarizer__threshold=0.30000000000000004), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [33:22, 10.68s/pipeline]Optimization Progress: 3101pipeline [33:22,  7.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [33:25,  7.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [33:27,  7.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3101pipeline [33:30,  7.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3101pipeline [33:34,  7.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3101pipeline [33:36,  7.50s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [33:36<15:33,  9.53s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [35:00<51:12, 31.68s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [35:09<06:17, 22.21s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-1062817283.5012448	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-863397380.4764547	GradientBoostingRegressor(Nystroem(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), Nystroem__gamma=0.15000000000000002, Nystroem__kernel=laplacian, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:12, 22.21s/pipeline]Optimization Progress: 3201pipeline [35:12, 15.60s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:13, 15.60s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:13, 15.60s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:13, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 3201pipeline [35:15, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [35:15, 15.60s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:17, 15.60s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:18, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:19, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:20, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 3201pipeline [35:20, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 3201pipeline [35:20, 15.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [35:23, 15.60s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3201/3300 [35:24<25:44, 15.60s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [35:24<23:28, 14.37s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [35:24<23:28, 14.37s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [36:33<32:48, 20.51s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [36:45<03:50, 14.40s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-1062808461.9258773	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-863397380.4764547	GradientBoostingRegressor(Nystroem(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), Nystroem__gamma=0.15000000000000002, Nystroem__kernel=laplacian, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3301pipeline [36:48, 14.40s/pipeline]Optimization Progress: 3301pipeline [36:48, 10.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3301pipeline [36:49, 10.13s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3301pipeline [36:50, 10.13s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3301pipeline [36:55, 10.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [36:59, 10.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3301pipeline [37:01, 10.13s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [37:01<18:05, 11.08s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3302/3400 [37:01<18:05, 11.08s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [38:20<31:21, 19.60s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [38:29<03:40, 13.75s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-1062808461.9258773	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3401pipeline [38:29, 13.75s/pipeline]Optimization Progress: 3401pipeline [38:29,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [38:29,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3401pipeline [38:29,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3401pipeline [38:30,  9.64s/pipeline]Optimization Progress: 3401pipeline [38:40,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3401pipeline [38:42,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [38:47,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 3401pipeline [38:47,  9.64s/pipeline]Optimization Progress:  97%|█████████▋| 3405/3500 [38:47<12:50,  8.11s/pipeline]Optimization Progress:  97%|█████████▋| 3406/3500 [39:15<21:41, 13.84s/pipeline]Optimization Progress: 100%|█████████▉| 3486/3500 [39:26<02:16,  9.73s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-1062808461.9258773	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-7	-809739697.0610288	GradientBoostingRegressor(OneHotEncoder(SGDRegressor(PolynomialFeatures(XGBRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:28,  9.73s/pipeline]Optimization Progress: 3501pipeline [39:28,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [39:28,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3501pipeline [39:28,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:32,  6.84s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:33,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [39:37,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:39,  6.84s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:39,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 3501pipeline [39:41,  6.84s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [39:42<11:17,  6.84s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [39:42<14:58,  9.17s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [41:19<57:09, 35.36s/pipeline]Optimization Progress: 100%|█████████▉| 3583/3600 [42:56<07:06, 25.12s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-1062808461.9258773	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-7	-809739697.0610288	GradientBoostingRegressor(OneHotEncoder(SGDRegressor(PolynomialFeatures(XGBRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3601pipeline [42:56, 25.12s/pipeline]Optimization Progress: 3601pipeline [42:56, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 3601pipeline [42:56, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [42:57, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [43:04, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [43:04, 17.59s/pipeline]Optimization Progress: 3601pipeline [43:10, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 3601pipeline [43:10, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [43:12, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [43:12, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 3601pipeline [43:16, 17.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3601pipeline [43:16, 17.59s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [44:16<59:01, 36.13s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [45:29<07:40, 25.57s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-1062807635.5947374	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-7	-809739697.0610288	GradientBoostingRegressor(OneHotEncoder(SGDRegressor(PolynomialFeatures(XGBRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 3701pipeline [45:30, 25.57s/pipeline]Optimization Progress: 3701pipeline [45:30, 17.91s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3701pipeline [45:32, 17.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [45:37, 17.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [45:40, 17.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 3701pipeline [45:44, 17.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 3701pipeline [45:49, 17.91s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [47:07<1:08:08, 41.72s/pipeline]Optimization Progress: 100%|█████████▉| 3782/3800 [47:22<08:46, 29.26s/pipeline]  
Generation 37 - Current Pareto front scores:
-1	-1062807635.5947374	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-857209260.0455649	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=6), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-5	-828998482.4462569	GradientBoostingRegressor(SelectPercentile(Nystroem(PolynomialFeatures(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), SelectPercentile__percentile=9), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-7	-809739697.0610288	GradientBoostingRegressor(OneHotEncoder(SGDRegressor(PolynomialFeatures(XGBRegressor(Nystroem(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=18, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=constant, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [47:24, 29.26s/pipeline]Optimization Progress: 3801pipeline [47:24, 20.52s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 3801pipeline [47:24, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3801pipeline [47:27, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [47:28, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [47:29, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [47:32, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [47:32, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [47:35, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X needs to contain only non-negative integers..
Optimization Progress: 3801pipeline [47:35, 20.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 3801pipeline [47:35, 20.52s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [47:37<33:51, 20.52s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [47:37<29:33, 18.09s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [49:24<1:12:19, 44.74s/pipeline]Optimization Progress: 100%|█████████▉| 3883/3900 [49:33<08:52, 31.35s/pipeline]  
Generation 38 - Current Pareto front scores:
-1	-1062765245.4823501	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 3901pipeline [49:33, 31.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3901pipeline [49:33, 31.35s/pipeline]Optimization Progress: 3901pipeline [49:33, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [49:36, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3901pipeline [49:38, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [49:38, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [49:39, 21.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 3901pipeline [49:40, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [05:36:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5a6e47edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5a6e58f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5a6e59cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5a6e583cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5a6e470f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f507c26b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f507c26b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f507c28327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f507c283cb4]

.
Optimization Progress: 3901pipeline [49:43, 21.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [05:36:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5a6e47edc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5a6e58f669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5a6e59cf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5a6e583cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5a6e470f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f507c26b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f507c26b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f507c28327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f507c283cb4]

.
Optimization Progress: 3901pipeline [49:46, 21.95s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3901/4000 [49:48<36:13, 21.95s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [49:48<35:51, 21.95s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [49:48<28:24, 17.58s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [50:11<30:26, 19.03s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [50:24<03:33, 13.37s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-1062753135.0875397	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:24, 13.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [50:24, 13.37s/pipeline]Optimization Progress: 4001pipeline [50:24,  9.36s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:24,  9.36s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 4001pipeline [50:24,  9.36s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 4001pipeline [50:24,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:24,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:27,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [50:28,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [50:28,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 4001pipeline [50:28,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:29,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:30,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [50:32,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [50:34,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:34,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:35,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4001pipeline [50:36,  9.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 4001pipeline [50:37,  9.36s/pipeline]Optimization Progress: 4001pipeline [50:40,  9.36s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [52:02<58:33, 35.85s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [52:12<07:32, 25.14s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-1062753135.0875397	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-887357557.0802101	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4101pipeline [52:15, 25.14s/pipeline]Optimization Progress: 4101pipeline [52:15, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4101pipeline [52:24, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [52:26, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [52:26, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [52:26, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [52:26, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4101pipeline [52:28, 17.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 4101pipeline [52:28, 17.64s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [52:30<27:21, 16.75s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [54:16<1:10:28, 43.59s/pipeline]Optimization Progress: 100%|█████████▉| 4183/4200 [54:29<08:39, 30.56s/pipeline]  
Generation 41 - Current Pareto front scores:
-1	-1062753135.0875397	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-880714354.4379137	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 4201pipeline [54:35, 30.56s/pipeline]Optimization Progress: 4201pipeline [54:35, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4201pipeline [54:36, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4201pipeline [54:37, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [54:38, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 4201pipeline [54:40, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [54:46, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4201pipeline [54:46, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [54:47, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4201pipeline [54:48, 21.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [54:51, 21.49s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [54:52<28:22, 17.55s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [54:52<28:22, 17.55s/pipeline]Optimization Progress:  98%|█████████▊| 4205/4300 [56:21<40:43, 25.73s/pipeline]Optimization Progress: 100%|█████████▉| 4285/4300 [56:41<04:31, 18.08s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-1062753135.0875397	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-880714354.4379137	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:42, 18.08s/pipeline]Optimization Progress: 4301pipeline [56:42, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [56:43, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4301pipeline [56:45, 12.67s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:45, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:47, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:48, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [56:48, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [56:49, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:51, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4301pipeline [56:51, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 4301pipeline [56:54, 12.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [56:54, 12.67s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [56:55<21:09, 12.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4302/4400 [56:55<21:09, 12.96s/pipeline]Optimization Progress:  98%|█████████▊| 4304/4400 [57:51<27:56, 17.46s/pipeline]Optimization Progress: 100%|█████████▉| 4384/4400 [58:03<03:16, 12.27s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-1062734154.5269203	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-880714354.4379137	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4401pipeline [58:11, 12.27s/pipeline]Optimization Progress: 4401pipeline [58:11,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [58:11,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 4401pipeline [58:12,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 4401pipeline [58:18,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4401pipeline [58:19,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [58:19,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4401pipeline [58:21,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [58:21,  8.73s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [58:21<15:09,  9.28s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [58:46<22:37, 14.00s/pipeline]Optimization Progress: 100%|█████████▉| 4483/4500 [1:00:34<02:53, 10.20s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-1062703849.2553608	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-880714354.4379137	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=10), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-862128173.3135216	GradientBoostingRegressor(ZeroCount(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5)), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-4	-762183927.0510123	LassoLarsCV(MinMaxScaler(XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.25, Nystroem__kernel=additive_chi2, Nystroem__n_components=5), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=15, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001)), LassoLarsCV__normalize=False)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4501pipeline [1:00:34, 10.20s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [1:00:37, 10.20s/pipeline]Optimization Progress: 4501pipeline [1:00:37,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [1:00:37,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4501pipeline [1:00:38,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 4501pipeline [1:00:38,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [1:00:39,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4501pipeline [1:00:40,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [1:00:43,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 4501pipeline [1:00:43,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [1:00:43,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X needs to contain only non-negative integers..
Optimization Progress: 4501pipeline [1:00:45,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 4501pipeline [1:00:48,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4501pipeline [1:00:48,  7.19s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [1:00:48,  7.19s/pipeline]                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4501/4600 [1:00:50<11:51,  7.19s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [1:00:50<14:46,  9.05s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4502/4600 [1:00:50<14:46,  9.05s/pipeline]                                                                                  60.94 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 4502/4600 [1:00:50<14:46,  9.05s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4502/4600 [1:00:50<14:46,  9.05s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 4502/4600 [1:00:50<14:46,  9.05s/pipeline]                                                                                  Best pipeline:
0. Nystroem(gamma=0.25, kernel='additive_chi2', n_components=5)
1. StackingEstimator(estimator=XGBRegressor(base_score=0.5, booster='gbtree',
                                         colsample_bylevel=1,
                                         colsample_bynode=1, colsample_bytree=1,
                                         gamma=0, gpu_id=-1,
                                         importance_type='gain',
                                         interaction_constraints='',
                                         learning_rate=0.5, max_delta_step=0,
                                         max_depth=8, min_child_weight=15,
                                         missing=nan, monotone_constraints='()',
                                         n_estimators=100, n_jobs=1, nthread=1,
                                         num_parallel_tree=1, random_state=0,
                                         reg_alpha=0, reg_lambda=1,
                                         scale_pos_weight=1,
                                         subsample=0.7000000000000001,
                                         tree_method='exact',
                                         validate_parameters=1,
                                         verbosity=None))
2. MinMaxScaler()
3. LassoLarsCV(normalize=False)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
