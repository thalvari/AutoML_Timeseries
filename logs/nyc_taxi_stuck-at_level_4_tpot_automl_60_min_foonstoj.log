30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   7%|▋         | 7/100 [00:06<01:27,  1.07pipeline/s]Optimization Progress:  87%|████████▋ | 87/100 [00:12<00:08,  1.47pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.47pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:17<00:00,  1.85pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 100/100 [00:18<00:00,  1.85pipeline/s]Optimization Progress:  52%|█████▎    | 105/200 [00:18<00:53,  1.77pipeline/s]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  52%|█████▎    | 105/200 [00:18<00:53,  1.77pipeline/s]Optimization Progress:  54%|█████▎    | 107/200 [00:26<02:29,  1.61s/pipeline]Optimization Progress:  94%|█████████▎| 187/200 [00:30<00:14,  1.14s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-560866624.586766	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-544714431.9794427	GradientBoostingRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.14s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.25pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.25pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.25pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.25pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.25pipeline/s]Optimization Progress:  68%|██████▊   | 205/300 [00:39<01:44,  1.10s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  68%|██████▊   | 205/300 [00:39<01:44,  1.10s/pipeline]Optimization Progress:  69%|██████▉   | 207/300 [00:49<03:31,  2.27s/pipeline]Optimization Progress:  96%|█████████▌| 287/300 [00:56<00:21,  1.62s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-556209088.8590491	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-544714431.9794427	GradientBoostingRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 300/300 [00:56<00:00,  1.62s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:56<00:00,  1.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:57<00:00,  1.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [00:57<00:00,  1.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [00:58<00:00,  1.14s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 300/300 [00:59<00:00,  1.14s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [01:05<03:36,  2.21s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [01:20<03:36,  2.21s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [01:25<12:03,  7.46s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [03:01<01:34,  5.58s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-556209088.8590491	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-544714431.9794427	GradientBoostingRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [03:01<00:00,  5.58s/pipeline]Optimization Progress: 100%|██████████| 400/400 [03:01<00:00,  3.92s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [03:04<00:00,  3.92s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [03:07<00:00,  3.92s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 400/400 [03:07<00:00,  3.92s/pipeline]Optimization Progress:  80%|████████  | 402/500 [03:12<07:11,  4.40s/pipeline]Optimization Progress:  81%|████████  | 403/500 [03:24<10:44,  6.64s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [03:32<01:19,  4.68s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-556209088.8590491	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-544714431.9794427	GradientBoostingRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 500/500 [03:34<00:00,  4.68s/pipeline]Optimization Progress: 100%|██████████| 500/500 [03:34<00:00,  3.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 500/500 [03:42<00:00,  3.30s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [03:44<00:00,  3.30s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [03:47<05:19,  3.33s/pipeline]Optimization Progress:  84%|████████▍ | 505/600 [04:04<11:45,  7.42s/pipeline]Optimization Progress:  98%|█████████▊| 585/600 [05:42<01:23,  5.56s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-544185452.5474409	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [05:54<00:00,  5.56s/pipeline]Optimization Progress: 100%|██████████| 600/600 [05:54<00:00,  4.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [05:56<00:00,  4.13s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [05:57<06:52,  4.13s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [05:57<06:17,  3.81s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [06:12<11:45,  7.20s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [06:33<01:32,  5.12s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-537744491.2027085	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-532104893.556126	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [06:36<00:00,  5.12s/pipeline]Optimization Progress: 100%|██████████| 700/700 [06:36<00:00,  3.64s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [06:44<00:00,  3.64s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [06:45<00:00,  3.64s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [06:46<00:00,  3.64s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [06:50<00:00,  3.64s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 700/700 [06:51<00:00,  3.64s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [06:52<11:48,  7.16s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [06:52<11:48,  7.16s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [07:30<17:30, 10.82s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [08:01<02:10,  7.69s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-537744491.2027085	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-532104893.556126	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [08:06<00:00,  7.69s/pipeline]Optimization Progress: 100%|██████████| 800/800 [08:06<00:00,  5.47s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [08:14<08:10,  5.00s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 802/900 [08:14<08:10,  5.00s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 803/900 [08:14<08:05,  5.00s/pipeline]Optimization Progress:  89%|████████▉ | 805/900 [08:31<08:15,  5.22s/pipeline]Optimization Progress:  98%|█████████▊| 885/900 [08:39<00:55,  3.69s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-537744491.2027085	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-531101815.5666975	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 900/900 [08:42<00:00,  3.69s/pipeline]Optimization Progress: 100%|██████████| 900/900 [08:42<00:00,  2.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [08:46<00:00,  2.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 900/900 [08:52<00:00,  2.63s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [08:54<05:52,  3.59s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [09:32<22:46, 14.08s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  98%|█████████▊| 983/1000 [14:32<03:06, 10.98s/pipeline]                                                                               Skipped pipeline #989 due to time out. Continuing to the next pipeline.
Optimization Progress:  99%|█████████▉| 989/1000 [14:32<02:00, 10.98s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-537744491.2027085	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-528600549.44153136	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1001pipeline [14:37, 10.98s/pipeline]Optimization Progress: 1001pipeline [14:37,  7.76s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 1001pipeline [14:39,  7.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [14:41,  7.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1001pipeline [14:47,  7.76s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [14:47<12:48,  7.76s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [14:47<14:01,  8.59s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [14:47<14:01,  8.59s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1003/1100 [14:47<13:53,  8.59s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████▏| 1004/1100 [14:47<13:44,  8.59s/pipeline]Optimization Progress:  91%|█████████▏| 1006/1100 [14:59<10:47,  6.89s/pipeline]Optimization Progress:  99%|█████████▊| 1086/1100 [15:05<01:07,  4.85s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-537744491.2027085	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-528600549.44153136	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [15:19,  4.85s/pipeline]Optimization Progress: 1101pipeline [15:19,  3.67s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [15:20<04:32,  2.81s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1103/1200 [15:20<04:32,  2.81s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1104/1200 [15:20<04:29,  2.81s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1105/1200 [15:20<04:26,  2.81s/pipeline]Optimization Progress:  92%|█████████▏| 1107/1200 [15:57<07:15,  4.69s/pipeline]Optimization Progress:  99%|█████████▉| 1187/1200 [16:03<00:42,  3.31s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-533744000.85027933	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-528600549.44153136	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 1201pipeline [16:07,  3.31s/pipeline]Optimization Progress: 1201pipeline [16:07,  2.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [16:14,  2.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [16:19,  2.40s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [16:21<09:30,  5.82s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [17:00<25:24, 15.72s/pipeline]Optimization Progress:  99%|█████████▊| 1283/1300 [17:07<03:07, 11.03s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-533744000.85027933	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-526130411.95526636	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [17:09, 11.03s/pipeline]Optimization Progress: 1301pipeline [17:09,  7.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1301pipeline [17:11,  7.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1301pipeline [17:12,  7.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [17:20,  7.75s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [17:23<12:18,  7.61s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1303/1400 [17:23<12:18,  7.61s/pipeline]Optimization Progress:  93%|█████████▎| 1305/1400 [17:36<11:22,  7.18s/pipeline]Optimization Progress:  99%|█████████▉| 1385/1400 [17:45<01:15,  5.06s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-533744000.85027933	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-523635949.2161094	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [17:47,  5.06s/pipeline]Optimization Progress: 1401pipeline [17:47,  3.58s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [17:47,  3.58s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [17:47,  3.58s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [17:48,  3.58s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [17:59,  3.58s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [18:00<07:19,  4.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▎| 1403/1500 [18:00<07:19,  4.54s/pipeline]Optimization Progress:  94%|█████████▎| 1405/1500 [18:11<07:35,  4.79s/pipeline]Optimization Progress:  99%|█████████▉| 1485/1500 [18:17<00:50,  3.38s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-523635949.2161094	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-521361013.94819605	GradientBoostingRegressor(ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=1, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1501pipeline [18:22,  3.38s/pipeline]Optimization Progress: 1501pipeline [18:22,  2.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [18:22,  2.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [18:30,  2.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [18:30,  2.45s/pipeline]Optimization Progress:  94%|█████████▍| 1504/1600 [18:36<05:01,  3.14s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  94%|█████████▍| 1504/1600 [18:36<05:01,  3.14s/pipeline]Optimization Progress:  94%|█████████▍| 1506/1600 [18:48<06:16,  4.01s/pipeline]Optimization Progress:  99%|█████████▉| 1586/1600 [18:52<00:39,  2.82s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-523635949.2161094	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-519975153.0414616	GradientBoostingRegressor(SelectPercentile(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0), SelectPercentile__percentile=53), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [19:00,  2.82s/pipeline]Optimization Progress: 1601pipeline [19:00,  2.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [19:00,  2.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1601pipeline [19:09,  2.12s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [19:09<07:01,  4.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1602/1700 [19:09<07:01,  4.30s/pipeline]Optimization Progress:  94%|█████████▍| 1604/1700 [19:21<07:41,  4.80s/pipeline]Optimization Progress:  99%|█████████▉| 1684/1700 [19:30<00:54,  3.40s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-523635949.2161094	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-519975153.0414616	GradientBoostingRegressor(SelectPercentile(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0), SelectPercentile__percentile=53), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [19:32,  3.40s/pipeline]Optimization Progress: 1701pipeline [19:32,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 1701pipeline [19:32,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:37,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [19:41,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:41,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:44,  2.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [19:45,  2.41s/pipeline]Optimization Progress:  95%|█████████▍| 1704/1800 [19:46<04:58,  3.11s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1704/1800 [19:46<04:58,  3.11s/pipeline]Optimization Progress:  95%|█████████▍| 1706/1800 [19:55<05:33,  3.55s/pipeline]Optimization Progress:  99%|█████████▉| 1786/1800 [20:02<00:35,  2.51s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-523412669.91885996	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-484762995.71917284	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-478648454.0548841	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 1801pipeline [20:03,  2.51s/pipeline]Optimization Progress: 1801pipeline [20:03,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1801pipeline [20:03,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:04,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:05,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 1801pipeline [20:05,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:07,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1801pipeline [20:09,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1801pipeline [20:11,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:12,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:14,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:14,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:14,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1801pipeline [20:15,  1.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [20:16,  1.77s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [21:23<41:07, 25.18s/pipeline]Optimization Progress:  99%|█████████▉| 1882/1900 [22:10<05:20, 17.80s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-466112419.37945205	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 1901pipeline [22:10, 17.80s/pipeline]Optimization Progress: 1901pipeline [22:10, 12.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [22:11, 12.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [22:11, 12.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [22:11, 12.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 1901pipeline [22:24, 12.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 1901pipeline [22:25, 12.47s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [22:26<21:44, 13.31s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [23:20<41:39, 25.77s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [23:29<05:07, 18.07s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-466112419.37945205	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-461290900.56226957	GradientBoostingRegressor(AdaBoostRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-5	-394731778.6042472	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(ExtraTreesRegressor(OneHotEncoder(input_matrix, OneHotEncoder__minimum_fraction=0.1, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:32, 18.07s/pipeline]Optimization Progress: 2001pipeline [23:32, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:32, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2001pipeline [23:32, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:32, 12.70s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 2001pipeline [23:35, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:38, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:38, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:39, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:39, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2001pipeline [23:41, 12.70s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [23:42, 12.70s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [23:44<17:23, 10.75s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [23:56<17:44, 11.09s/pipeline]Optimization Progress:  99%|█████████▉| 2084/2100 [24:01<02:04,  7.78s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2101pipeline [24:01,  7.78s/pipeline]Optimization Progress: 2101pipeline [24:01,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2101pipeline [24:03,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 2101pipeline [24:03,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2101pipeline [24:06,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [24:07,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [24:10,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [24:10,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [24:10,  5.46s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [24:17,  5.46s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [24:18<10:06,  6.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [24:18<10:06,  6.26s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [24:29<09:42,  6.13s/pipeline]Optimization Progress:  99%|█████████▉| 2185/2200 [24:39<01:04,  4.33s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:40,  4.33s/pipeline]Optimization Progress: 2201pipeline [24:40,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [24:44,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 2201pipeline [24:44,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [24:47,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:48,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:49,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:49,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:49,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:49,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:50,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:50,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [24:50,  3.04s/pipeline]Optimization Progress:  96%|█████████▌| 2204/2300 [24:56<05:56,  3.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2204/2300 [24:56<05:56,  3.71s/pipeline]Optimization Progress:  96%|█████████▌| 2206/2300 [25:41<14:44,  9.41s/pipeline]Optimization Progress:  99%|█████████▉| 2286/2300 [25:50<01:32,  6.62s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2301pipeline [25:51,  6.62s/pipeline]Optimization Progress: 2301pipeline [25:51,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2301pipeline [25:52,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [25:54,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [26:00,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2301pipeline [26:02,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:02,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [26:03,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2301pipeline [26:04,  4.66s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 2301pipeline [26:04,  4.66s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:05,  4.66s/pipeline]Optimization Progress:  96%|█████████▌| 2306/2400 [26:08<06:42,  4.28s/pipeline]Optimization Progress:  96%|█████████▌| 2307/2400 [26:22<11:05,  7.16s/pipeline]Optimization Progress:  99%|█████████▉| 2387/2400 [26:27<01:05,  5.03s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2401pipeline [26:28,  5.03s/pipeline]Optimization Progress: 2401pipeline [26:28,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2401pipeline [26:31,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2401pipeline [26:32,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2401pipeline [26:32,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [26:33,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [26:33,  3.53s/pipeline]Optimization Progress: 2401pipeline [26:40,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2401pipeline [26:40,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [26:42,  3.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [26:42,  3.53s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [26:44<05:49,  3.53s/pipeline]Optimization Progress:  96%|█████████▌| 2402/2500 [26:44<11:51,  7.26s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [28:14<52:06, 32.23s/pipeline]Optimization Progress:  99%|█████████▉| 2483/2500 [28:24<06:24, 22.60s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521807666.3835474	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2501pipeline [28:26, 22.60s/pipeline]Optimization Progress: 2501pipeline [28:26, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 2501pipeline [28:27, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [28:28, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [28:29, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [28:29, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [28:33, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2501pipeline [28:33, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2501pipeline [28:35, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [28:38, 15.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [28:38, 15.86s/pipeline]Optimization Progress:  96%|█████████▋| 2507/2600 [28:41<18:21, 11.84s/pipeline]Optimization Progress:  96%|█████████▋| 2508/2600 [28:55<19:02, 12.41s/pipeline]Optimization Progress: 100%|█████████▉| 2588/2600 [29:20<01:45,  8.79s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521457738.3805896	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [29:24,  8.79s/pipeline]Optimization Progress: 2601pipeline [29:24,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [29:24,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2601pipeline [29:26,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 2601pipeline [29:28,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 2601pipeline [29:34,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 2601pipeline [29:34,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2601pipeline [29:35,  6.23s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [29:37,  6.23s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [29:38<09:11,  5.75s/pipeline]Optimization Progress:  96%|█████████▋| 2605/2700 [31:05<47:40, 30.11s/pipeline]Optimization Progress:  99%|█████████▉| 2685/2700 [31:25<05:17, 21.15s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-521457738.3805896	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 2701pipeline [31:30, 21.15s/pipeline]Optimization Progress: 2701pipeline [31:30, 14.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [31:33, 14.91s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [32:45<53:48, 32.94s/pipeline]Optimization Progress:  99%|█████████▉| 2782/2800 [32:55<06:55, 23.10s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [32:58, 23.10s/pipeline]Optimization Progress: 2801pipeline [32:58, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 2801pipeline [33:01, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [33:02, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [33:05, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [33:05, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [33:06, 16.21s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [33:11, 16.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [33:12, 16.21s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [33:58<48:21, 29.61s/pipeline]Optimization Progress:  99%|█████████▉| 2882/2900 [34:06<06:13, 20.75s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2901pipeline [34:08, 20.75s/pipeline]Optimization Progress: 2901pipeline [34:08, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 2901pipeline [34:08, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [35:32, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [35:35, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2901pipeline [35:38, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2901pipeline [35:38, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [35:38, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [35:39, 14.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [35:44, 14.56s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [36:25<1:23:44, 51.27s/pipeline]Optimization Progress:  99%|█████████▉| 2982/3000 [36:38<10:46, 35.94s/pipeline]  
Generation 29 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [36:41, 35.94s/pipeline]Optimization Progress: 3001pipeline [36:41, 25.20s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [36:41, 25.20s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3001pipeline [36:43, 25.20s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [36:50, 25.20s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [36:52, 25.20s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [36:53, 25.20s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [36:53, 25.20s/pipeline]Optimization Progress:  97%|█████████▋| 3004/3100 [36:54<30:13, 18.89s/pipeline]Optimization Progress:  97%|█████████▋| 3005/3100 [37:37<41:24, 26.16s/pipeline]Optimization Progress: 100%|█████████▉| 3085/3100 [37:46<04:35, 18.34s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-533523218.6320573	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [37:46, 18.34s/pipeline]Optimization Progress: 3101pipeline [37:46, 12.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3101pipeline [37:51, 12.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [37:52, 12.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3101pipeline [37:52, 12.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3101pipeline [37:59, 12.84s/pipeline]Optimization Progress: 3101pipeline [38:00, 12.84s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [38:01<21:11, 12.84s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [38:01<22:02, 13.49s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [38:19<23:49, 14.74s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [39:01<02:58, 10.47s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-533473764.1426794	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [39:02, 10.47s/pipeline]Optimization Progress: 3201pipeline [39:02,  7.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [39:06,  7.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 3201pipeline [39:10,  7.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [39:11,  7.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [39:13,  7.36s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [39:16<10:29,  6.56s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [39:31<14:18,  9.04s/pipeline]Optimization Progress: 100%|█████████▉| 3285/3300 [40:34<01:38,  6.56s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-533473764.1426794	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [40:36,  6.56s/pipeline]Optimization Progress: 3301pipeline [40:36,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 3301pipeline [40:39,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3301pipeline [40:49,  4.64s/pipeline]Optimization Progress:  97%|█████████▋| 3305/3400 [40:51<06:54,  4.36s/pipeline]Optimization Progress:  97%|█████████▋| 3306/3400 [41:21<18:44, 11.96s/pipeline]Optimization Progress: 100%|█████████▉| 3386/3400 [41:28<01:57,  8.40s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-533455331.42111874	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3401pipeline [41:39,  8.40s/pipeline]Optimization Progress: 3401pipeline [41:39,  6.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3401pipeline [41:41,  6.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3401pipeline [41:42,  6.10s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [41:46<10:34,  6.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3402/3500 [41:46<10:34,  6.47s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [42:00<10:42,  6.69s/pipeline]Optimization Progress: 100%|█████████▉| 3484/3500 [42:07<01:15,  4.71s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-533455331.42111874	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-368957619.8665776	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [42:11,  4.71s/pipeline]Optimization Progress: 3501pipeline [42:11,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3501pipeline [42:12,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [42:16,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [42:16,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3501pipeline [42:17,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [42:21,  3.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 3501pipeline [42:23,  3.37s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [42:23<06:44,  4.17s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [42:37<11:26,  7.15s/pipeline]Optimization Progress: 100%|█████████▉| 3584/3600 [42:44<01:20,  5.03s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-533455331.42111874	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-382860063.6575381	GradientBoostingRegressor(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=15), FastICA__tol=0.45), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-368957619.8665776	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [42:45,  5.03s/pipeline]Optimization Progress: 3601pipeline [42:45,  3.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 3601pipeline [42:51,  3.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3601pipeline [42:54,  3.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3601pipeline [42:56,  3.55s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [42:58<10:24,  6.38s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [44:05<39:40, 24.54s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [44:12<04:52, 17.20s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-533455331.42111874	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [44:12, 17.20s/pipeline]Optimization Progress: 3701pipeline [44:12, 12.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [44:15, 12.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [44:15, 12.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [44:15, 12.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3701pipeline [44:24, 12.05s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [44:27<17:15, 10.68s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [44:45<20:16, 12.67s/pipeline]Optimization Progress: 100%|█████████▉| 3784/3800 [44:50<02:22,  8.89s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-519109674.91916656	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 3801pipeline [44:50,  8.89s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [44:52,  8.89s/pipeline]Optimization Progress: 3801pipeline [44:52,  6.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [44:53,  6.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [44:56,  6.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3801pipeline [45:01,  6.25s/pipeline]Optimization Progress:  98%|█████████▊| 3805/3900 [45:05<08:33,  5.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3805/3900 [45:05<08:33,  5.41s/pipeline]Optimization Progress:  98%|█████████▊| 3807/3900 [46:13<21:28, 13.85s/pipeline]Optimization Progress: 100%|█████████▉| 3887/3900 [46:21<02:06,  9.73s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-518678399.1404808	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3901pipeline [46:28,  9.73s/pipeline]Optimization Progress: 3901pipeline [46:28,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3901pipeline [46:28,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 3901pipeline [46:29,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3901pipeline [46:30,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3901pipeline [46:31,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 3901pipeline [46:31,  6.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3901pipeline [46:34,  6.96s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [46:35<09:40,  5.99s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [46:47<12:22,  7.74s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [46:58<01:27,  5.46s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-518678399.1404808	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4001pipeline [47:07,  5.46s/pipeline]Optimization Progress: 4001pipeline [47:07,  3.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4001pipeline [47:08,  3.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4001pipeline [47:13,  3.97s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [47:14,  3.97s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [47:16<06:44,  4.17s/pipeline]Optimization Progress:  98%|█████████▊| 4004/4100 [47:29<11:05,  6.94s/pipeline]Optimization Progress: 100%|█████████▉| 4084/4100 [47:37<01:18,  4.88s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-518678399.1404808	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)Optimization Progress: 4101pipeline [47:52,  3.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [47:52<05:56,  3.67s/pipeline]Optimization Progress:  98%|█████████▊| 4105/4200 [48:05<05:41,  3.60s/pipeline]Optimization Progress: 100%|█████████▉| 4185/4200 [48:28<00:39,  2.60s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-518678399.1404808	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [48:28,  2.60s/pipeline]Optimization Progress: 4201pipeline [48:28,  1.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [48:29,  1.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 4201pipeline [48:31,  1.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 4201pipeline [48:37,  1.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4201pipeline [48:38,  1.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [48:39,  1.84s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [48:41<08:25,  5.16s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [49:09<19:26, 12.02s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [49:16<02:23,  8.44s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517985833.53355855	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [49:17,  8.44s/pipeline]Optimization Progress: 4301pipeline [49:17,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [49:17,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 4301pipeline [49:25,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4301pipeline [49:25,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4301pipeline [49:26,  5.92s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [50:43<49:14, 30.15s/pipeline]Optimization Progress: 100%|█████████▉| 4382/4400 [50:50<06:20, 21.13s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517985833.53355855	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4401pipeline [50:52, 21.13s/pipeline]Optimization Progress: 4401pipeline [50:52, 14.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 4401pipeline [50:53, 14.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [51:03, 14.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [51:05, 14.82s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4401/4500 [51:08<24:26, 14.82s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [51:08<24:54, 15.25s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [51:54<39:41, 24.55s/pipeline]Optimization Progress: 100%|█████████▉| 4483/4500 [52:01<04:52, 17.21s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517985833.53355855	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [52:02, 17.21s/pipeline]Optimization Progress: 4501pipeline [52:02, 12.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [52:07, 12.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [52:15, 12.06s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4502/4600 [52:18<19:41, 12.06s/pipeline]Optimization Progress:  98%|█████████▊| 4503/4600 [52:18<17:25, 10.78s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [52:30<17:58, 11.23s/pipeline]Optimization Progress: 100%|█████████▉| 4584/4600 [52:37<02:06,  7.89s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-533379377.18976307	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517985833.53355855	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [52:38,  7.89s/pipeline]Optimization Progress: 4601pipeline [52:38,  5.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4601pipeline [52:45,  5.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [52:50,  5.54s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 4601pipeline [52:51,  5.54s/pipeline]Optimization Progress:  98%|█████████▊| 4603/4700 [52:53<10:00,  6.19s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [55:10<1:12:35, 45.36s/pipeline]Optimization Progress: 100%|█████████▉| 4684/4700 [55:19<08:28, 31.79s/pipeline]  
Generation 46 - Current Pareto front scores:
-1	-533322927.336737	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517559795.0981749	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [55:25, 31.79s/pipeline]Optimization Progress: 4701pipeline [55:25, 22.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4701pipeline [55:34, 22.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [55:34, 22.37s/pipeline]Optimization Progress:  98%|█████████▊| 4703/4800 [55:35<27:41, 17.13s/pipeline]Optimization Progress:  98%|█████████▊| 4704/4800 [56:37<48:38, 30.40s/pipeline]Optimization Progress: 100%|█████████▉| 4784/4800 [58:07<05:45, 21.62s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-533322927.336737	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517559795.0981749	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [58:07, 21.62s/pipeline]Optimization Progress: 4801pipeline [58:07, 15.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [58:13, 15.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [58:15, 15.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 4801pipeline [58:16, 15.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [58:18, 15.14s/pipeline]Optimization Progress: 4801pipeline [58:20, 15.14s/pipeline]Optimization Progress:  98%|█████████▊| 4806/4900 [58:21<17:56, 11.45s/pipeline]Optimization Progress:  98%|█████████▊| 4807/4900 [59:10<35:07, 22.66s/pipeline]Optimization Progress: 100%|█████████▉| 4887/4900 [59:17<03:26, 15.89s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-533322927.336737	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517559795.0981749	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4901pipeline [59:18, 15.89s/pipeline]Optimization Progress: 4901pipeline [59:18, 11.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [59:22, 11.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4901pipeline [59:24, 11.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4901pipeline [59:25, 11.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4901pipeline [59:34, 11.14s/pipeline]Optimization Progress:  98%|█████████▊| 4902/5000 [59:34<20:33, 12.59s/pipeline]Optimization Progress:  98%|█████████▊| 4903/5000 [59:47<20:25, 12.64s/pipeline]Optimization Progress: 100%|█████████▉| 4983/5000 [59:56<02:30,  8.88s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-533292395.00775135	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-517559795.0981749	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-354672748.35623646	GradientBoostingRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-4	-341522858.0098382	GradientBoostingRegressor(PCA(ExtraTreesRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [59:56,  8.88s/pipeline]Optimization Progress: 5001pipeline [59:56,  6.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5001pipeline [1:00:00,  6.22s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 5001pipeline [1:00:03,  6.22s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [1:00:04,  6.22s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5001pipeline [1:00:04,  6.22s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 5001pipeline [1:00:04,  6.22s/pipeline]Optimization Progress: 5001pipeline [1:00:10,  6.22s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 5001pipeline [1:00:11,  6.22s/pipeline]                                                              
Optimization Progress:  98%|█████████▊| 5001/5100 [1:00:15<10:15,  6.22s/pipeline]                                                                                  60.36 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 5001/5100 [1:00:15<10:15,  6.22s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 5001/5100 [1:00:15<10:15,  6.22s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 5001/5100 [1:00:15<10:15,  6.22s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.05))
1. StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=True,
                                                max_features=0.3,
                                                min_samples_leaf=13,
                                                min_samples_split=7))
2. PCA(iterated_power=8, svd_solver='randomized')
3. GradientBoostingRegressor(alpha=0.75, learning_rate=0.5, loss='huber',
                          max_depth=4, max_features=0.4, min_samples_leaf=3,
                          min_samples_split=4, subsample=0.35000000000000003)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
