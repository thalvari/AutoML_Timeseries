30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   8%|▊         | 8/100 [00:07<01:23,  1.10pipeline/s]Optimization Progress:  88%|████████▊ | 88/100 [00:11<00:07,  1.53pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  1.53pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  1.96pipeline/s]Optimization Progress:  51%|█████     | 102/200 [00:17<01:30,  1.08pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  51%|█████     | 102/200 [00:17<01:30,  1.08pipeline/s]Optimization Progress:  52%|█████▏    | 104/200 [00:24<02:41,  1.68s/pipeline]Optimization Progress:  92%|█████████▏| 184/200 [00:29<00:19,  1.19s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-221864926.59211507	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-219673723.2345466	DecisionTreeRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.19s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.18pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.18pipeline/s]Optimization Progress:  67%|██████▋   | 202/300 [00:37<02:57,  1.81s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [00:37<02:57,  1.81s/pipeline]Optimization Progress:  68%|██████▊   | 203/300 [00:50<02:55,  1.81s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [01:04<08:33,  5.35s/pipeline]Optimization Progress:  95%|█████████▍| 284/300 [01:11<01:00,  3.77s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-220291087.50555658	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-219673723.2345466	DecisionTreeRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:13<00:00,  3.77s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:13<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 300/300 [01:14<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:14<00:00,  2.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:16<00:00,  2.68s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [01:19<04:01,  2.49s/pipeline]Optimization Progress:  76%|███████▌  | 304/400 [01:26<06:00,  3.75s/pipeline]Optimization Progress:  96%|█████████▌| 384/400 [01:30<00:42,  2.64s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-220291087.50555658	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-214589952.2011012	KNeighborsRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002), KNeighborsRegressor__n_neighbors=74, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:31<00:00,  2.64s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:31<00:00,  1.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 400/400 [01:32<00:00,  1.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:33<00:00,  1.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [01:35<00:00,  1.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:37<00:00,  1.86s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:39<00:00,  1.86s/pipeline]Optimization Progress:  81%|████████  | 404/500 [01:39<03:01,  1.89s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 404/500 [01:39<03:01,  1.89s/pipeline]Optimization Progress:  81%|████████  | 406/500 [01:46<03:44,  2.39s/pipeline]Optimization Progress:  97%|█████████▋| 486/500 [01:55<00:23,  1.70s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-220291087.50555658	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-214589952.2011012	KNeighborsRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002), KNeighborsRegressor__n_neighbors=74, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)
-3	-213386233.17948112	KNeighborsRegressor(ExtraTreesRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), KNeighborsRegressor__n_neighbors=74, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:56<00:00,  1.70s/pipeline]Optimization Progress: 100%|██████████| 500/500 [01:56<00:00,  1.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [01:56<00:00,  1.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [01:59<00:00,  1.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:00<00:00,  1.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:02<00:00,  1.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:02<00:00,  1.21s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [02:10<01:59,  1.21s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [02:13<05:44,  3.51s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [02:19<00:44,  2.48s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-220265706.8500184	XGBRegressor(input_matrix, XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=13, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-2	-214589952.2011012	KNeighborsRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002), KNeighborsRegressor__n_neighbors=74, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)
-3	-213386233.17948112	KNeighborsRegressor(ExtraTreesRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.15000000000000002), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=16, ExtraTreesRegressor__n_estimators=100), KNeighborsRegressor__n_neighbors=74, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [02:21<00:00,  2.48s/pipeline]Optimization Progress: 100%|██████████| 600/600 [02:21<00:00,  1.76s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 600/600 [02:23<00:00,  1.76s/pipeline]Optimization Progress:  86%|████████▌ | 603/700 [02:28<03:07,  1.93s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 603/700 [02:28<03:07,  1.93s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▋ | 604/700 [02:28<03:05,  1.93s/pipeline]Optimization Progress:  87%|████████▋ | 606/700 [02:38<03:41,  2.35s/pipeline]Optimization Progress:  98%|█████████▊| 686/700 [02:48<00:23,  1.69s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-211253639.16231206	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-211223713.84440923	XGBRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-3	-208313171.02118316	DecisionTreeRegressor(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.005), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:28:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 700/700 [02:49<00:00,  1.69s/pipeline]Optimization Progress: 100%|██████████| 700/700 [02:49<00:00,  1.19s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [02:55<00:00,  1.19s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [02:58<01:58,  1.19s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [02:58<03:37,  2.22s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [02:58<03:37,  2.22s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 703/800 [02:58<03:35,  2.22s/pipeline]Optimization Progress:  88%|████████▊ | 705/800 [03:05<03:36,  2.27s/pipeline]Optimization Progress:  98%|█████████▊| 785/800 [03:20<00:24,  1.65s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-211073437.24454752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-208313171.02118316	DecisionTreeRegressor(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.005), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 800/800 [03:21<00:00,  1.65s/pipeline]Optimization Progress: 100%|██████████| 800/800 [03:21<00:00,  1.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:28:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 800/800 [03:22<00:00,  1.17s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [03:29<05:45,  3.49s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 801/900 [03:29<05:45,  3.49s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 802/900 [03:29<05:41,  3.49s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [04:23<12:24,  7.76s/pipeline]Optimization Progress:  98%|█████████▊| 884/900 [04:28<01:27,  5.45s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-211073437.24454752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-208313171.02118316	DecisionTreeRegressor(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.005), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 900/900 [04:28<00:00,  5.45s/pipeline]Optimization Progress: 100%|██████████| 900/900 [04:28<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:29:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 900/900 [04:29<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 900/900 [04:29<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:31<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 900/900 [04:31<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:29:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 900/900 [04:33<00:00,  3.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:34<00:00,  3.83s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [04:40<06:18,  3.83s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [04:46<08:44,  5.35s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [05:33<01:10,  3.92s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-211073437.24454752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:33<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [05:34<00:00,  3.92s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [05:34<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [05:36<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [05:37<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:37<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:37<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:37<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [05:38<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 100%|██████████| 1000/1000 [05:40<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [05:40<00:00,  2.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1000/1100 [05:43<04:35,  2.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [05:43<04:32,  2.75s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [05:43<05:30,  3.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [05:43<05:30,  3.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1003/1100 [05:43<05:27,  3.37s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [05:52<05:09,  3.26s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [06:00<00:34,  2.31s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-211073437.24454752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-210271827.52277812	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.7500000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.8500000000000001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [06:01<00:00,  2.31s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [06:01<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [06:04<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [06:04<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [06:06<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [06:07<00:00,  1.63s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [06:08<03:40,  2.25s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [06:16<06:26,  3.98s/pipeline]Optimization Progress:  99%|█████████▊| 1183/1200 [06:22<00:47,  2.81s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-208876982.3774361	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:31:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 1200/1200 [06:23<00:00,  2.81s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [06:23<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [06:23<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [06:23<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [06:26<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 1200/1200 [06:27<00:00,  1.98s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [06:29<03:42,  2.27s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [06:35<05:34,  3.45s/pipeline]Optimization Progress:  99%|█████████▊| 1283/1300 [06:39<00:41,  2.43s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-208876982.3774361	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-206876705.4251314	GradientBoostingRegressor(RidgeCV(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [06:41<00:00,  2.43s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [06:41<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 1300/1300 [06:43<00:00,  1.74s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [06:45<02:36,  1.61s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [07:22<19:19, 12.07s/pipeline]Optimization Progress:  99%|█████████▉| 1384/1400 [07:23<02:15,  8.46s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-208876982.3774361	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-203960545.00861508	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=11, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _mate_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 1400/1400 [07:27<00:00,  8.46s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [07:27<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [07:27<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [07:29<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [07:29<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [07:29<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [07:30<00:00,  5.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [07:30<00:00,  5.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1400/1500 [07:33<09:58,  5.99s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [07:40<09:52,  5.99s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [07:42<10:37,  6.51s/pipeline]Optimization Progress:  99%|█████████▉| 1482/1500 [07:48<01:22,  4.58s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-208500611.00314173	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-203960545.00861508	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=11, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197270287.41808105	XGBRegressor(ElasticNetCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [07:48<00:00,  4.58s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [07:48<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [07:51<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 1500/1500 [07:51<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1500/1500 [07:51<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1500/1500 [07:52<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 1500/1500 [07:52<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [07:53<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [07:54<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 1500/1500 [07:54<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [07:54<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1500/1500 [07:54<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [07:54<00:00,  3.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [07:55<00:00,  3.21s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [08:00<05:18,  3.21s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [08:04<07:24,  4.53s/pipeline]Optimization Progress:  99%|█████████▉| 1582/1600 [08:07<00:57,  3.19s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-207842511.60211784	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-203360299.86640364	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197270287.41808105	XGBRegressor(ElasticNetCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-197024882.72753388	XGBRegressor(ElasticNetCV(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  3.19s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [08:08<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [08:11<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [08:11<00:00,  2.25s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [08:16<06:41,  4.05s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [08:37<14:35,  8.94s/pipeline]Optimization Progress:  99%|█████████▉| 1682/1700 [08:53<01:53,  6.31s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-206697581.90601188	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-203360299.86640364	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197270287.41808105	XGBRegressor(ElasticNetCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-197024882.72753388	XGBRegressor(ElasticNetCV(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [08:54<00:00,  6.31s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [08:54<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [08:55<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 1700/1700 [08:58<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1700/1700 [08:59<00:00,  4.44s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [09:01<06:10,  3.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1703/1800 [09:01<06:10,  3.82s/pipeline]Optimization Progress:  95%|█████████▍| 1705/1800 [09:19<08:24,  5.31s/pipeline]Optimization Progress:  99%|█████████▉| 1785/1800 [09:24<00:56,  3.73s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-205152971.39777264	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-203360299.86640364	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197109480.9195726	XGBRegressor(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-197024882.72753388	XGBRegressor(ElasticNetCV(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1800/1800 [09:24<00:00,  3.73s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [09:24<00:00,  2.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [09:25<00:00,  2.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 1800/1800 [09:27<00:00,  2.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [09:28<00:00,  2.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 1800/1800 [09:31<00:00,  2.62s/pipeline]Optimization Progress:  95%|█████████▌| 1807/1900 [09:33<03:26,  2.22s/pipeline]Optimization Progress:  95%|█████████▌| 1810/1900 [09:40<03:22,  2.25s/pipeline]Optimization Progress:  99%|█████████▉| 1888/1900 [09:42<00:18,  1.58s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-205152971.39777264	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-202216477.56354648	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=13, DecisionTreeRegressor__min_samples_split=12), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197109480.9195726	XGBRegressor(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-197024882.72753388	XGBRegressor(ElasticNetCV(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [09:46<00:00,  1.58s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [09:46<00:00,  1.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 1900/1900 [09:47<00:00,  1.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1900/1900 [09:50<00:00,  1.20s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [09:59<04:38,  2.85s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [10:05<00:36,  2.01s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-205152971.39777264	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-202216477.56354648	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=13, DecisionTreeRegressor__min_samples_split=12), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-197422337.3773953	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-197109480.9195726	XGBRegressor(SelectFwe(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), SelectFwe__alpha=0.035), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-184652700.03779948	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(VarianceThreshold(input_matrix, VarianceThreshold__threshold=0.0005), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [10:13<00:00,  2.01s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [10:13<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [10:15<00:00,  1.54s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [10:15<02:22,  1.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2002/2100 [10:15<02:22,  1.46s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [10:21<03:06,  1.95s/pipeline]Optimization Progress:  99%|█████████▉| 2084/2100 [10:26<00:22,  1.38s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-205152971.39777264	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-202216477.56354648	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=13, DecisionTreeRegressor__min_samples_split=12), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-184612822.38238424	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [10:26<00:00,  1.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [10:26<00:00,  1.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:35:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 2100/2100 [10:29<00:00,  1.38s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [10:29<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [10:29<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [10:32<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [10:32<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [10:33<00:00,  1.03s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [10:38<02:31,  1.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [10:38<02:31,  1.56s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [10:43<03:06,  1.96s/pipeline]Optimization Progress:  99%|█████████▉| 2185/2200 [10:50<00:20,  1.40s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-204710659.00039798	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-202216477.56354648	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=13, DecisionTreeRegressor__min_samples_split=12), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-184612822.38238424	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [10:51<00:00,  1.40s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [10:51<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [10:53<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:36:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 2200/2200 [10:59<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [11:01<00:00,  1.01pipeline/s]Optimization Progress:  96%|█████████▌| 2202/2300 [11:08<05:24,  3.31s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [11:12<00:41,  2.33s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-204205243.2378491	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-197614086.05383506	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-184612822.38238424	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2300/2300 [11:14<00:00,  2.33s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [11:14<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [11:15<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 2300/2300 [11:16<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [11:16<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 2300/2300 [11:18<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [11:19<00:00,  1.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 100%|██████████| 2300/2300 [11:19<00:00,  1.67s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [11:29<09:29,  5.75s/pipeline]Optimization Progress:  99%|█████████▉| 2381/2400 [11:36<01:16,  4.05s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-197614086.05383506	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-184612822.38238424	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [11:40<00:00,  4.05s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [11:40<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [11:43<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 2400/2400 [11:43<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 2400/2400 [11:45<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [11:46<00:00,  2.91s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [11:54<10:26,  6.32s/pipeline]Optimization Progress:  99%|█████████▉| 2481/2500 [11:57<01:24,  4.44s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-184612822.38238424	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:37:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 2500/2500 [11:57<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [11:59<00:00,  4.44s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [11:59<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [12:04<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [12:04<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [12:04<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 2500/2500 [12:04<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 100%|██████████| 2500/2500 [12:06<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2500/2500 [12:08<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [12:08<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [12:08<00:00,  3.13s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [12:09<05:07,  3.17s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [12:15<06:29,  4.06s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [12:19<00:45,  2.86s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [12:25<00:00,  2.86s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [12:25<00:00,  2.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [12:25<00:00,  2.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [12:26<00:00,  2.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 2600/2600 [12:29<00:00,  2.10s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [12:31<03:56,  2.42s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [12:37<05:27,  3.38s/pipeline]Optimization Progress:  99%|█████████▉| 2683/2700 [12:41<00:40,  2.38s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2700/2700 [12:46<00:00,  2.38s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [12:46<00:00,  1.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [12:46<00:00,  1.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [12:46<00:00,  1.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [12:47<00:00,  1.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 100%|██████████| 2700/2700 [12:48<00:00,  1.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [12:51<00:00,  1.75s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [12:54<03:21,  2.08s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [13:01<05:26,  3.40s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [13:06<00:38,  2.40s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 2800/2800 [13:06<00:00,  2.40s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [13:06<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2800/2800 [13:07<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 2800/2800 [13:08<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [13:08<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [13:13<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 2800/2800 [13:14<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 2800/2800 [13:15<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [13:16<00:00,  1.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [13:17<00:00,  1.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2801/2900 [13:18<02:47,  1.69s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [13:18<04:43,  2.90s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [13:24<06:15,  3.87s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [13:27<00:46,  2.72s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-204145345.16284472	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [13:27<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [13:32<00:00,  2.72s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [13:32<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [13:32<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [13:35<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [13:36<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [13:38<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [13:38<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [13:38<00:00,  1.99s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [13:39<03:52,  2.38s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [13:45<05:44,  3.55s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [13:47<00:42,  2.50s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3000/3000 [13:49<00:00,  2.50s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [13:49<00:00,  1.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [13:50<00:00,  1.78s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [14:00<02:55,  1.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3001/3100 [14:00<02:55,  1.78s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [14:00<04:37,  2.83s/pipeline]Optimization Progress:  97%|█████████▋| 3003/3100 [14:07<06:31,  4.04s/pipeline]Optimization Progress:  99%|█████████▉| 3083/3100 [14:12<00:48,  2.85s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-166812668.3982853	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [14:13<00:00,  2.85s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [14:13<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [14:14<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [14:17<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [14:17<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 3100/3100 [14:17<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 3100/3100 [14:18<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 3100/3100 [14:22<00:00,  2.02s/pipeline]Optimization Progress:  97%|█████████▋| 3104/3200 [14:23<03:27,  2.16s/pipeline]Optimization Progress:  97%|█████████▋| 3105/3200 [14:34<07:23,  4.67s/pipeline]Optimization Progress: 100%|█████████▉| 3185/3200 [14:39<00:49,  3.29s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-166812668.3982853	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 3200/3200 [14:39<00:00,  3.29s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [14:39<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:39:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 3200/3200 [14:42<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [14:47<00:00,  2.31s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [14:50<00:00,  2.31s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [14:52<04:06,  2.57s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [14:58<05:47,  3.66s/pipeline]Optimization Progress: 100%|█████████▉| 3285/3300 [15:04<00:38,  2.58s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-166812668.3982853	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [15:06<00:00,  2.58s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [15:06<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [15:07<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [15:07<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [15:07<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [15:12<00:00,  1.83s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [15:16<07:20,  4.45s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [15:24<09:03,  5.54s/pipeline]Optimization Progress:  99%|█████████▉| 3382/3400 [15:29<01:10,  3.90s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-166812668.3982853	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3400/3400 [15:33<00:00,  3.90s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [15:33<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [15:38<00:00,  2.80s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [15:49<11:12,  6.80s/pipeline]Optimization Progress:  99%|█████████▉| 3481/3500 [15:52<01:30,  4.77s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-166812668.3982853	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 3500/3500 [15:54<00:00,  4.77s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [15:54<00:00,  3.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [15:55<00:00,  3.36s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [16:11<12:35,  7.63s/pipeline]Optimization Progress:  99%|█████████▉| 3581/3600 [16:14<01:41,  5.35s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [16:16<00:00,  5.35s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [16:16<00:00,  3.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [16:17<00:00,  3.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [16:24<00:00,  3.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 3600/3600 [16:26<00:00,  3.78s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [17:06<28:58, 17.56s/pipeline]Optimization Progress:  99%|█████████▉| 3681/3700 [17:11<03:53, 12.31s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [17:14<00:00, 12.31s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [17:14<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3700/3700 [17:14<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 3700/3700 [17:16<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [17:19<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [17:20<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 3700/3700 [17:21<00:00,  8.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 3700/3700 [17:22<00:00,  8.66s/pipeline]Optimization Progress:  98%|█████████▊| 3706/3800 [17:23<10:12,  6.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3706/3800 [17:23<10:12,  6.52s/pipeline]Optimization Progress:  98%|█████████▊| 3708/3800 [17:29<08:13,  5.37s/pipeline]Optimization Progress: 100%|█████████▉| 3788/3800 [17:32<00:45,  3.77s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 3800/3800 [17:34<00:00,  3.77s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [17:34<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [17:34<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 3800/3800 [17:35<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [17:35<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [17:35<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 3800/3800 [17:36<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [17:37<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 3800/3800 [17:39<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [17:39<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [17:42<00:00,  2.67s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [17:43<04:09,  2.60s/pipeline]Optimization Progress:  98%|█████████▊| 3805/3900 [17:53<07:39,  4.83s/pipeline]Optimization Progress: 100%|█████████▉| 3885/3900 [17:58<00:50,  3.40s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [18:00<00:00,  3.40s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [18:00<00:00,  2.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [18:00<00:00,  2.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 3900/3900 [18:01<00:00,  2.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3900/3900 [18:02<00:00,  2.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [18:04<00:00,  2.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 3900/3900 [18:08<00:00,  2.42s/pipeline]Optimization Progress:  98%|█████████▊| 3901/4000 [18:19<12:09,  7.36s/pipeline]Optimization Progress: 100%|█████████▉| 3981/4000 [18:29<01:38,  5.19s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 4000/4000 [18:32<00:00,  5.19s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [18:32<00:00,  3.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 4000/4000 [18:36<00:00,  3.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 4000/4000 [18:38<00:00,  3.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 100%|██████████| 4000/4000 [18:38<00:00,  3.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 4000/4000 [18:39<00:00,  3.68s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [18:41<06:15,  3.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4002/4100 [18:41<06:15,  3.83s/pipeline]Optimization Progress:  98%|█████████▊| 4004/4100 [18:53<07:14,  4.52s/pipeline]Optimization Progress: 100%|█████████▉| 4084/4100 [18:58<00:50,  3.18s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [19:00<00:00,  3.18s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [19:00<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 4100/4100 [19:02<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4100/4100 [19:02<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [19:02<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [19:02<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [19:03<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:44:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 4100/4100 [19:03<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [19:03<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [19:04<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4100/4100 [19:04<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 4100/4100 [19:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [19:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [19:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [19:06<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [19:08<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 4100/4100 [19:09<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [19:09<00:00,  2.28s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [19:10<07:08,  4.33s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [19:19<09:31,  5.83s/pipeline]Optimization Progress: 100%|█████████▉| 4182/4200 [19:23<01:13,  4.10s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [19:24<00:00,  4.10s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [19:24<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [19:30<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [19:35<00:00,  2.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4201/4300 [19:35<04:45,  2.89s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [19:35<05:58,  3.66s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [19:41<07:11,  4.45s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [19:46<00:53,  3.13s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [19:48<00:00,  3.13s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [19:48<00:00,  2.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 4300/4300 [19:53<00:00,  2.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [19:53<00:00,  2.23s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [19:57<03:58,  2.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4303/4400 [19:57<03:58,  2.46s/pipeline]Optimization Progress:  98%|█████████▊| 4305/4400 [20:05<04:36,  2.91s/pipeline]Optimization Progress: 100%|█████████▉| 4385/4400 [20:15<00:31,  2.07s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 4400/4400 [20:17<00:00,  2.07s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [20:17<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [20:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 4400/4400 [20:20<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [20:21<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4400/4400 [20:23<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [20:26<00:00,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4400/4500 [20:27<02:28,  1.49s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [20:27<06:33,  3.97s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [20:33<07:38,  4.67s/pipeline]Optimization Progress: 100%|█████████▉| 4482/4500 [20:44<00:59,  3.31s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [20:46<00:00,  3.31s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [20:46<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 4500/4500 [20:47<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [20:50<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 4500/4500 [20:50<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [20:51<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [20:54<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 4500/4500 [20:54<00:00,  2.36s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [20:55<03:41,  2.31s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [21:06<07:47,  4.92s/pipeline]Optimization Progress: 100%|█████████▉| 4585/4600 [21:11<00:51,  3.46s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 4600/4600 [21:12<00:00,  3.46s/pipeline]Optimization Progress: 100%|██████████| 4600/4600 [21:12<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 4600/4600 [21:12<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 4600/4600 [21:14<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4600/4600 [21:17<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 4600/4600 [21:18<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4600/4600 [21:21<00:00,  2.44s/pipeline]Optimization Progress:  98%|█████████▊| 4602/4700 [21:21<05:03,  3.09s/pipeline]Optimization Progress:  98%|█████████▊| 4603/4700 [21:33<09:33,  5.91s/pipeline]Optimization Progress: 100%|█████████▉| 4683/4700 [21:38<01:10,  4.15s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 4700/4700 [21:39<00:00,  4.15s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [21:39<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [21:39<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:46:56] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 4700/4700 [21:41<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 4700/4700 [21:42<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [21:43<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [21:45<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [21:45<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [21:46<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [21:47<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 4700/4700 [21:48<00:00,  2.92s/pipeline]Optimization Progress:  98%|█████████▊| 4703/4800 [21:49<05:02,  3.12s/pipeline]Optimization Progress:  98%|█████████▊| 4704/4800 [21:56<06:40,  4.17s/pipeline]Optimization Progress: 100%|█████████▉| 4784/4800 [22:21<00:48,  3.01s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4800/4800 [22:22<00:00,  3.01s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [22:22<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [06:47:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 4800/4800 [22:22<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [22:23<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [22:24<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 4800/4800 [22:29<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:47:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 4800/4800 [22:30<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 4800/4800 [22:30<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [22:31<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 4800/4800 [22:31<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [22:32<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [22:32<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 4800/4800 [22:33<00:00,  2.13s/pipeline]Optimization Progress:  98%|█████████▊| 4801/4900 [22:34<08:28,  5.14s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [22:34<08:28,  5.14s/pipeline]Optimization Progress:  98%|█████████▊| 4803/4900 [22:46<08:37,  5.34s/pipeline]Optimization Progress: 100%|█████████▉| 4883/4900 [22:58<01:04,  3.78s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-162951922.02124828	XGBRegressor(StandardScaler(ElasticNetCV(FeatureAgglomeration(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FeatureAgglomeration__affinity=l2, FeatureAgglomeration__linkage=average), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-161404720.31606647	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(OneHotEncoder(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), OneHotEncoder__minimum_fraction=0.25, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [22:58<00:00,  3.78s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [22:58<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [22:59<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [06:48:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 4900/4900 [22:59<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [23:01<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [23:02<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4900/4900 [23:03<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [23:03<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [23:04<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [23:04<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [23:04<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [23:04<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 4900/4900 [23:06<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 4900/4900 [23:08<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [23:08<00:00,  2.65s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [23:10<00:00,  2.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4900/4900 [23:10<00:00,  2.65s/pipeline]Optimization Progress:  98%|█████████▊| 4907/5000 [23:10<03:40,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4907/5000 [23:10<03:40,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4908/5000 [23:10<03:38,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4909/5000 [23:10<03:36,  2.37s/pipeline]Optimization Progress:  98%|█████████▊| 4911/5000 [23:23<03:54,  2.63s/pipeline]Optimization Progress: 100%|█████████▉| 4991/5000 [23:28<00:16,  1.86s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:29<00:00,  1.86s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [23:29<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:29<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:30<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 5000/5000 [23:31<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 5000/5000 [23:31<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:33<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:33<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 5000/5000 [23:33<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [23:34<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:35<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:35<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:35<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:38<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 5000/5000 [23:38<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:38<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [23:38<00:00,  1.35s/pipeline]Optimization Progress:  98%|█████████▊| 5003/5100 [23:39<03:00,  1.87s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5003/5100 [23:39<03:00,  1.87s/pipeline]Optimization Progress:  98%|█████████▊| 5005/5100 [23:47<03:57,  2.50s/pipeline]Optimization Progress: 100%|█████████▉| 5085/5100 [23:58<00:26,  1.79s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [23:59<00:00,  1.79s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [23:59<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [23:59<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 5100/5100 [23:59<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [24:00<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [24:00<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 5100/5100 [24:00<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:49:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 5100/5100 [24:02<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [24:04<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 5100/5100 [24:04<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [24:04<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5100/5100 [24:07<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [24:08<00:00,  1.28s/pipeline]Optimization Progress:  98%|█████████▊| 5101/5200 [24:09<06:28,  3.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5101/5200 [24:09<06:28,  3.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5102/5200 [24:09<06:24,  3.93s/pipeline]Optimization Progress:  98%|█████████▊| 5104/5200 [25:01<12:41,  7.93s/pipeline]Optimization Progress: 100%|█████████▉| 5184/5200 [25:13<01:29,  5.60s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:13<00:00,  5.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:13<00:00,  5.60s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [25:13<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:13<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 5200/5200 [25:16<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:16<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:16<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:50:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 5200/5200 [25:19<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 5200/5200 [25:19<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 5200/5200 [25:20<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:21<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 5200/5200 [25:22<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [25:23<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:50:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 5200/5200 [25:23<00:00,  3.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5200/5300 [25:24<06:32,  3.93s/pipeline]Optimization Progress:  98%|█████████▊| 5201/5300 [25:30<06:28,  3.93s/pipeline]Optimization Progress:  98%|█████████▊| 5202/5300 [25:32<09:05,  5.57s/pipeline]Optimization Progress: 100%|█████████▉| 5282/5300 [25:36<01:10,  3.91s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-182787910.3955392	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  3.91s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 5300/5300 [25:37<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 5300/5300 [25:38<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:40<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:40<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:41<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:41<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 5300/5300 [25:42<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:42<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 5300/5300 [25:44<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:51:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 5300/5300 [25:45<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 5300/5300 [25:45<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [25:47<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [25:48<00:00,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5300/5400 [25:49<04:34,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5301/5400 [25:49<04:31,  2.74s/pipeline]Optimization Progress:  98%|█████████▊| 5302/5400 [25:50<04:28,  2.74s/pipeline]Optimization Progress:  98%|█████████▊| 5303/5400 [25:56<06:18,  3.91s/pipeline]Optimization Progress: 100%|█████████▉| 5383/5400 [26:02<00:46,  2.75s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 5400/5400 [26:02<00:00,  2.75s/pipeline]Optimization Progress: 100%|██████████| 5400/5400 [26:02<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [26:02<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5400/5400 [26:04<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5400/5400 [26:06<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 5400/5400 [26:09<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 5400/5400 [26:09<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [26:10<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [26:10<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [26:10<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [26:10<00:00,  1.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5400/5500 [26:13<03:13,  1.93s/pipeline]Optimization Progress:  98%|█████████▊| 5403/5500 [26:19<05:00,  3.10s/pipeline]Optimization Progress: 100%|█████████▉| 5482/5500 [26:25<00:39,  2.19s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:25<00:00,  2.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:27<00:00,  2.19s/pipeline]Optimization Progress: 100%|██████████| 5500/5500 [26:27<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:27<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:28<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:29<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:31<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:31<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5500/5500 [26:32<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [26:33<00:00,  1.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5500/5500 [26:35<00:00,  1.56s/pipeline]Optimization Progress:  98%|█████████▊| 5501/5600 [26:36<06:08,  3.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5501/5600 [26:36<06:08,  3.72s/pipeline]Optimization Progress:  98%|█████████▊| 5503/5600 [26:45<06:33,  4.05s/pipeline]Optimization Progress: 100%|█████████▉| 5583/5600 [26:49<00:48,  2.85s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:50<00:00,  2.85s/pipeline]Optimization Progress: 100%|██████████| 5600/5600 [26:50<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:50<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:50<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:51<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:51<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [26:51<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [26:53<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:54<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:54<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 5600/5600 [26:56<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:52:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 5600/5600 [26:56<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:56<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [26:57<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5600/5600 [26:57<00:00,  2.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [26:58<00:00,  2.01s/pipeline]Optimization Progress:  98%|█████████▊| 5604/5700 [26:59<03:15,  2.04s/pipeline]Optimization Progress:  98%|█████████▊| 5605/5700 [27:09<07:06,  4.49s/pipeline]Optimization Progress: 100%|█████████▉| 5685/5700 [27:13<00:47,  3.16s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 5700/5700 [27:15<00:00,  3.16s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [27:15<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [27:15<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:16<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:17<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:17<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:18<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 5700/5700 [27:18<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [27:19<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:20<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [27:21<00:00,  2.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [27:23<00:00,  2.26s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5700/5800 [27:23<03:45,  2.26s/pipeline]Optimization Progress:  98%|█████████▊| 5701/5800 [27:23<06:18,  3.83s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [27:35<10:08,  6.21s/pipeline]Optimization Progress: 100%|█████████▉| 5782/5800 [27:45<01:18,  4.39s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165432622.84388304	XGBRegressor(StandardScaler(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:45<00:00,  4.39s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [27:45<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:45<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:46<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:46<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:46<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:48<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:49<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:51<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [27:51<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:51<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 5800/5800 [27:51<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [27:53<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5800/5800 [27:53<00:00,  3.07s/pipeline]Optimization Progress:  98%|█████████▊| 5803/5900 [27:55<05:00,  3.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5803/5900 [27:55<05:00,  3.10s/pipeline]Optimization Progress:  98%|█████████▊| 5805/5900 [28:04<05:44,  3.63s/pipeline]Optimization Progress: 100%|█████████▉| 5885/5900 [28:08<00:38,  2.55s/pipeline]
Generation 58 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:08<00:00,  2.55s/pipeline]Optimization Progress: 100%|██████████| 5900/5900 [28:08<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:09<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:09<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:09<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:10<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:10<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:11<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:11<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:11<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:11<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:14<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:15<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:15<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 5900/5900 [28:15<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 5900/5900 [28:15<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:16<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:16<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:16<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:16<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [28:16<00:00,  1.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5900/6000 [28:16<02:59,  1.79s/pipeline]Optimization Progress:  98%|█████████▊| 5901/6000 [28:20<02:57,  1.79s/pipeline]Optimization Progress:  98%|█████████▊| 5902/6000 [28:22<05:35,  3.43s/pipeline]Optimization Progress: 100%|█████████▉| 5982/6000 [28:32<00:43,  2.43s/pipeline]
Generation 59 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6000/6000 [28:32<00:00,  2.43s/pipeline]Optimization Progress: 100%|██████████| 6000/6000 [28:32<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:33<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:36<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:36<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:36<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6000/6000 [28:37<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [28:38<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6000/6000 [28:38<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 6000/6000 [28:39<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:39<00:00,  1.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [28:39<00:00,  1.71s/pipeline]Optimization Progress:  98%|█████████▊| 6001/6100 [28:50<02:48,  1.71s/pipeline]Optimization Progress:  98%|█████████▊| 6002/6100 [28:52<06:55,  4.24s/pipeline]Optimization Progress: 100%|█████████▉| 6082/6100 [28:56<00:53,  2.98s/pipeline]
Generation 60 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:58<00:00,  2.98s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [28:58<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:58<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:59<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:59<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:59<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:59<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [28:59<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 6100/6100 [29:00<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:00<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:00<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6100/6100 [29:00<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:01<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:01<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6100/6100 [29:03<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:03<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:03<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:04<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:04<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:05<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:05<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:05<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [29:05<00:00,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6100/6200 [29:05<03:31,  2.12s/pipeline]Optimization Progress:  98%|█████████▊| 6101/6200 [29:05<06:11,  3.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6101/6200 [29:05<06:11,  3.75s/pipeline]Optimization Progress:  98%|█████████▊| 6103/6200 [29:18<07:10,  4.44s/pipeline]Optimization Progress: 100%|█████████▉| 6183/6200 [29:21<00:53,  3.12s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:22<00:00,  3.12s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [29:22<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:22<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [29:23<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:24<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:25<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:25<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:26<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [29:27<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:54:43] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 6200/6200 [29:27<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 6200/6200 [29:27<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:28<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [29:30<00:00,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6201/6300 [29:30<03:37,  2.20s/pipeline]Optimization Progress:  98%|█████████▊| 6202/6300 [29:30<04:33,  2.79s/pipeline]Optimization Progress:  98%|█████████▊| 6203/6300 [29:37<06:18,  3.91s/pipeline]Optimization Progress: 100%|█████████▉| 6283/6300 [29:46<00:47,  2.77s/pipeline]
Generation 62 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [29:47<00:00,  2.77s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [29:47<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 6300/6300 [29:48<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:48<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:48<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:49<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:50<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:50<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 6300/6300 [29:50<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6300/6300 [29:51<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:51<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:51<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:51<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 6300/6300 [29:51<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:52<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:53<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:53<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:53<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [29:54<00:00,  1.96s/pipeline]Optimization Progress:  98%|█████████▊| 6302/6400 [29:55<04:05,  2.50s/pipeline]Optimization Progress:  98%|█████████▊| 6303/6400 [30:24<17:10, 10.62s/pipeline]Optimization Progress: 100%|█████████▉| 6383/6400 [30:27<02:06,  7.44s/pipeline]
Generation 63 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:27<00:00,  7.44s/pipeline]Optimization Progress: 100%|██████████| 6400/6400 [30:27<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:27<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:31<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:32<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:32<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:55:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [30:33<00:00,  5.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6402/6500 [30:36<08:31,  5.21s/pipeline]Optimization Progress:  99%|█████████▊| 6403/6500 [30:40<08:25,  5.21s/pipeline]Optimization Progress:  99%|█████████▊| 6404/6500 [30:46<08:06,  5.06s/pipeline]Optimization Progress: 100%|█████████▉| 6484/6500 [30:50<00:56,  3.56s/pipeline]
Generation 64 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 6500/6500 [30:51<00:00,  3.56s/pipeline]Optimization Progress: 100%|██████████| 6500/6500 [30:51<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:51<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:52<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [30:52<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:52<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6500/6500 [30:52<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:53<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:53<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:53<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:53<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 6500/6500 [30:54<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:55<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 6500/6500 [30:55<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:55<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:55<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:55<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 6500/6500 [30:56<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:56<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:56<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [30:56<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:56<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6500/6500 [30:57<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:57<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:57<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [30:58<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [31:00<00:00,  2.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6501/6600 [31:02<04:07,  2.50s/pipeline]Optimization Progress:  99%|█████████▊| 6502/6600 [31:02<05:31,  3.39s/pipeline]Optimization Progress:  99%|█████████▊| 6503/6600 [31:12<09:05,  5.63s/pipeline]Optimization Progress: 100%|█████████▉| 6583/6600 [31:18<01:07,  3.96s/pipeline]
Generation 65 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6600/6600 [31:18<00:00,  3.96s/pipeline]Optimization Progress: 100%|██████████| 6600/6600 [31:18<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:19<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6600/6600 [31:20<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [06:56:35] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 6600/6600 [31:20<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:22<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:22<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:22<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:22<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:23<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:24<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:24<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6600/6600 [31:24<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:25<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:25<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:25<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:25<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:26<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:27<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:27<00:00,  2.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [31:28<00:00,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6602/6700 [31:29<04:31,  2.78s/pipeline]Optimization Progress:  99%|█████████▊| 6603/6700 [31:29<04:51,  3.00s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6603/6700 [31:29<04:51,  3.00s/pipeline]Optimization Progress:  99%|█████████▊| 6605/6700 [31:37<05:18,  3.35s/pipeline]Optimization Progress: 100%|█████████▉| 6685/6700 [31:40<00:35,  2.36s/pipeline]
Generation 66 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  2.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  2.36s/pipeline]Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:40<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:41<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:41<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:41<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:41<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:42<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:42<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:42<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:42<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:42<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:56:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 6700/6700 [31:43<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:43<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:43<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6700/6700 [31:43<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6700/6700 [31:44<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:44<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:45<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:46<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 6700/6700 [31:47<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6700/6700 [31:47<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:49<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [31:50<00:00,  1.66s/pipeline]Optimization Progress:  99%|█████████▊| 6701/6800 [32:00<02:44,  1.66s/pipeline]Optimization Progress:  99%|█████████▊| 6702/6800 [32:51<19:17, 11.81s/pipeline]Optimization Progress: 100%|█████████▉| 6782/6800 [33:01<02:29,  8.31s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:02<00:00,  8.31s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [33:02<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [33:02<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:02<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 6800/6800 [33:03<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:04<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:06<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:06<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:06<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:06<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 6800/6800 [33:06<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:07<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 6800/6800 [33:08<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:08<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:08<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:08<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 6800/6800 [33:09<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [33:10<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 6800/6800 [33:10<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [06:58:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 6800/6800 [33:11<00:00,  5.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 6800/6800 [33:11<00:00,  5.83s/pipeline]Optimization Progress:  99%|█████████▊| 6801/6900 [33:11<11:12,  6.79s/pipeline]Optimization Progress:  99%|█████████▊| 6802/6900 [33:49<26:18, 16.11s/pipeline]Optimization Progress: 100%|█████████▉| 6882/6900 [33:53<03:23, 11.29s/pipeline]
Generation 68 - Current Pareto front scores:
-1	-202643864.49425378	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [33:53<00:00, 11.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 6900/6900 [33:53<00:00, 11.29s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [33:53<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [33:55<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [33:56<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 6900/6900 [33:57<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6900/6900 [33:58<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6900/6900 [33:58<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 6900/6900 [33:59<00:00,  7.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6900/6900 [33:59<00:00,  7.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6901/7000 [34:03<13:02,  7.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6902/7000 [34:03<12:54,  7.91s/pipeline]Optimization Progress:  99%|█████████▊| 6903/7000 [34:10<12:46,  7.91s/pipeline]Optimization Progress:  99%|█████████▊| 6904/7000 [34:13<11:11,  6.99s/pipeline]Optimization Progress: 100%|█████████▉| 6984/7000 [34:20<01:18,  4.92s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [34:21<00:00,  4.92s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [34:21<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7000/7000 [34:21<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:21<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 7000/7000 [34:21<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7000/7000 [34:22<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:22<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:22<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:22<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:22<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7000/7000 [34:23<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 7000/7000 [34:24<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:24<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [34:25<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:28<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:29<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7000/7000 [34:29<00:00,  3.45s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [34:29<00:00,  3.45s/pipeline]Optimization Progress:  99%|█████████▊| 7000/7100 [34:40<05:45,  3.45s/pipeline]Optimization Progress:  99%|█████████▊| 7001/7100 [34:45<16:07,  9.77s/pipeline]Optimization Progress: 100%|█████████▉| 7081/7100 [34:50<02:10,  6.86s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:50<00:00,  6.86s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [34:50<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:50<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:50<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:52<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:53<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:53<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:53<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:53<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7100/7100 [34:53<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:54<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 7100/7100 [34:55<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7100/7100 [34:56<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [07:00:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 7100/7100 [34:56<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:57<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [34:57<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 7100/7100 [34:58<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [34:59<00:00,  4.81s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [35:00<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [35:00<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [35:00<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [35:00<00:00,  4.81s/pipeline]Optimization Progress:  99%|█████████▊| 7101/7200 [35:00<10:42,  6.49s/pipeline]Optimization Progress:  99%|█████████▊| 7102/7200 [35:10<12:01,  7.36s/pipeline]Optimization Progress: 100%|█████████▉| 7182/7200 [35:15<01:33,  5.17s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:16<00:00,  5.17s/pipeline]Optimization Progress: 100%|██████████| 7200/7200 [35:16<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [35:16<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:18<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:18<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 7200/7200 [35:19<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:19<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:19<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7200/7200 [35:19<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:19<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7200/7200 [35:21<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:21<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:22<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:22<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:23<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:23<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:23<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:23<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [35:24<00:00,  3.64s/pipeline]Optimization Progress:  99%|█████████▊| 7202/7300 [35:24<06:12,  3.80s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7202/7300 [35:25<06:12,  3.80s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7203/7300 [35:25<06:08,  3.80s/pipeline]Optimization Progress:  99%|█████████▊| 7205/7300 [35:36<06:04,  3.84s/pipeline]Optimization Progress: 100%|█████████▉| 7285/7300 [36:05<00:41,  2.79s/pipeline]
Generation 72 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [36:06<00:00,  2.79s/pipeline]Optimization Progress: 100%|██████████| 7300/7300 [36:06<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [36:06<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:01:23] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 7300/7300 [36:07<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 7300/7300 [36:08<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [36:08<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 7300/7300 [36:08<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [36:09<00:00,  1.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [36:14<00:00,  1.98s/pipeline]Optimization Progress:  99%|█████████▊| 7301/7400 [36:22<10:31,  6.38s/pipeline]Optimization Progress: 100%|█████████▉| 7381/7400 [36:26<01:25,  4.48s/pipeline]
Generation 73 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:28<00:00,  4.48s/pipeline]Optimization Progress: 100%|██████████| 7400/7400 [36:28<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:28<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:29<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7400/7400 [36:32<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [36:32<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 7400/7400 [36:33<00:00,  3.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [36:34<00:00,  3.16s/pipeline]Optimization Progress:  99%|█████████▊| 7403/7500 [36:38<05:09,  3.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7403/7500 [36:38<05:09,  3.19s/pipeline]Optimization Progress:  99%|█████████▊| 7405/7500 [36:50<06:28,  4.09s/pipeline]Optimization Progress: 100%|█████████▉| 7485/7500 [36:55<00:43,  2.88s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [36:56<00:00,  2.88s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [36:56<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7500/7500 [37:03<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:03<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:02:21] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 7500/7500 [37:05<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:07<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:09<00:00,  2.03s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [37:10<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:10<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:10<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:11<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [37:11<00:00,  2.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7500/7600 [37:11<03:22,  2.03s/pipeline]Optimization Progress:  99%|█████████▊| 7501/7600 [37:11<10:04,  6.11s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7501/7600 [37:11<10:04,  6.11s/pipeline]Optimization Progress:  99%|█████████▊| 7503/7600 [37:21<09:20,  5.78s/pipeline]Optimization Progress: 100%|█████████▉| 7583/7600 [37:25<01:09,  4.06s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [37:26<00:00,  4.06s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [37:26<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [37:26<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 7600/7600 [37:26<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 7600/7600 [37:27<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [37:28<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7600/7600 [37:28<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [37:28<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:02:45] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 7600/7600 [37:30<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [37:30<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [37:31<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:02:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 7600/7600 [37:36<00:00,  2.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7600/7700 [37:37<04:45,  2.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7601/7700 [37:37<04:42,  2.86s/pipeline]Optimization Progress:  99%|█████████▊| 7602/7700 [37:37<06:01,  3.69s/pipeline]Optimization Progress:  99%|█████████▊| 7603/7700 [38:05<17:31, 10.84s/pipeline]Optimization Progress: 100%|█████████▉| 7683/7700 [38:23<02:10,  7.66s/pipeline]
Generation 76 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:24<00:00,  7.66s/pipeline]Optimization Progress: 100%|██████████| 7700/7700 [38:24<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:25<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:25<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:27<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 7700/7700 [38:27<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 7700/7700 [38:28<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 7700/7700 [38:28<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:28<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:31<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7700/7700 [38:31<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:32<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 7700/7700 [38:32<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [38:33<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7700/7700 [38:33<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 7700/7700 [38:33<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 7700/7700 [38:34<00:00,  5.37s/pipeline]Optimization Progress:  99%|█████████▉| 7703/7800 [38:34<07:43,  4.77s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7703/7800 [38:34<07:43,  4.77s/pipeline]Optimization Progress:  99%|█████████▉| 7705/7800 [38:40<06:51,  4.33s/pipeline]Optimization Progress: 100%|█████████▉| 7785/7800 [38:44<00:45,  3.04s/pipeline]
Generation 77 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7800/7800 [38:46<00:00,  3.04s/pipeline]Optimization Progress: 100%|██████████| 7800/7800 [38:46<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:46<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:47<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:47<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 7800/7800 [38:48<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:48<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:48<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:48<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:49<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:49<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:50<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:52<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:52<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 7800/7800 [38:53<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:54<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:54<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:55<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [38:55<00:00,  2.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7800/7900 [38:56<03:36,  2.17s/pipeline]Optimization Progress:  99%|█████████▊| 7801/7900 [38:56<07:23,  4.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7801/7900 [38:56<07:23,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 7803/7900 [39:34<14:22,  8.89s/pipeline]Optimization Progress: 100%|█████████▉| 7883/7900 [39:39<01:46,  6.24s/pipeline]
Generation 78 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:39<00:00,  6.24s/pipeline]Optimization Progress: 100%|██████████| 7900/7900 [39:39<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:40<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:40<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:42<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7900/7900 [39:42<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:42<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7900/7900 [39:43<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 7900/7900 [39:43<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:44<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [39:46<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:48<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [39:48<00:00,  4.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [39:50<00:00,  4.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7902/8000 [39:50<07:08,  4.37s/pipeline]Optimization Progress:  99%|█████████▉| 7903/8000 [39:50<07:04,  4.37s/pipeline]Optimization Progress:  99%|█████████▉| 7904/8000 [40:36<11:42,  7.31s/pipeline]Optimization Progress: 100%|█████████▉| 7984/8000 [40:45<01:22,  5.15s/pipeline]
Generation 79 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:45<00:00,  5.15s/pipeline]Optimization Progress: 100%|██████████| 8000/8000 [40:45<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 8000/8000 [40:45<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 8000/8000 [40:47<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:47<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8000/8000 [40:48<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:48<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:49<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:49<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:49<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 8000/8000 [40:50<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:51<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:51<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:06:07] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 8000/8000 [40:52<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [40:55<00:00,  3.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8000/8000 [40:56<00:00,  3.61s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8001/8100 [40:56<05:57,  3.61s/pipeline]Optimization Progress:  99%|█████████▉| 8002/8100 [41:00<05:53,  3.61s/pipeline]Optimization Progress:  99%|█████████▉| 8003/8100 [41:08<07:48,  4.83s/pipeline]Optimization Progress: 100%|█████████▉| 8083/8100 [41:13<00:57,  3.40s/pipeline]
Generation 80 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:16<00:00,  3.40s/pipeline]Optimization Progress: 100%|██████████| 8100/8100 [41:16<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:16<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:16<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:16<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:17<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:17<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:18<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:19<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:20<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:21<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:22<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:23<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:23<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [41:23<00:00,  2.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 8100/8100 [41:24<00:00,  2.43s/pipeline]Optimization Progress:  99%|█████████▉| 8101/8200 [41:25<07:29,  4.54s/pipeline]Optimization Progress:  99%|█████████▉| 8102/8200 [42:02<23:02, 14.11s/pipeline]Optimization Progress: 100%|█████████▉| 8182/8200 [42:07<02:58,  9.89s/pipeline]
Generation 81 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:07<00:00,  9.89s/pipeline]Optimization Progress: 100%|██████████| 8200/8200 [42:07<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:08<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:08<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:11<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:12<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 8200/8200 [42:12<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [42:13<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [42:15<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [42:15<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 8200/8200 [42:15<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 8200/8200 [42:16<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8200/8200 [42:16<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8200/8200 [42:16<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 8200/8200 [42:16<00:00,  6.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 8200/8200 [42:17<00:00,  6.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8200/8300 [42:17<11:33,  6.93s/pipeline]Optimization Progress:  99%|█████████▉| 8201/8300 [42:20<11:26,  6.93s/pipeline]Optimization Progress:  99%|█████████▉| 8202/8300 [42:29<13:16,  8.13s/pipeline]Optimization Progress: 100%|█████████▉| 8282/8300 [42:34<01:42,  5.71s/pipeline]
Generation 82 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:35<00:00,  5.71s/pipeline]Optimization Progress: 100%|██████████| 8300/8300 [42:35<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:35<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:35<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8300/8300 [42:38<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [42:39<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 8300/8300 [42:40<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 8300/8300 [42:40<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:40<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:40<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 8300/8300 [42:41<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:42<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [42:42<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [42:42<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 8300/8300 [42:43<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 8300/8300 [42:44<00:00,  4.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8300/8300 [42:44<00:00,  4.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8301/8400 [42:45<06:36,  4.01s/pipeline]Optimization Progress:  99%|█████████▉| 8302/8400 [42:45<07:09,  4.39s/pipeline]Optimization Progress:  99%|█████████▉| 8303/8400 [42:54<08:57,  5.54s/pipeline]Optimization Progress: 100%|█████████▉| 8383/8400 [43:03<01:06,  3.92s/pipeline]
Generation 83 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-176609080.71024007	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 8400/8400 [43:04<00:00,  3.92s/pipeline]Optimization Progress: 100%|██████████| 8400/8400 [43:04<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:04<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:05<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:05<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [43:06<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 8400/8400 [43:06<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 8400/8400 [43:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:08<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:08<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 8400/8400 [43:09<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 8400/8400 [43:11<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 8400/8400 [43:11<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 8400/8400 [43:11<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8400/8400 [43:12<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [43:14<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 8400/8400 [43:14<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:15<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:15<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:15<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:15<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [43:15<00:00,  2.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8401/8500 [43:15<04:32,  2.75s/pipeline]Optimization Progress:  99%|█████████▉| 8402/8500 [43:15<05:55,  3.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8402/8500 [43:15<05:55,  3.63s/pipeline]Optimization Progress:  99%|█████████▉| 8404/8500 [43:43<10:46,  6.74s/pipeline]Optimization Progress: 100%|█████████▉| 8484/8500 [43:53<01:16,  4.75s/pipeline]
Generation 84 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8500/8500 [43:53<00:00,  4.75s/pipeline]Optimization Progress: 100%|██████████| 8500/8500 [43:53<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8500/8500 [43:54<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:58<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 8500/8500 [43:58<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 8500/8500 [43:58<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 8500/8500 [43:58<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 8500/8500 [43:58<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [43:59<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [44:00<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [44:00<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8500/8500 [44:00<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 8500/8500 [44:01<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [44:02<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 8500/8500 [44:02<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [44:02<00:00,  3.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [44:02<00:00,  3.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8500/8600 [44:03<05:34,  3.34s/pipeline]Optimization Progress:  99%|█████████▉| 8501/8600 [44:03<08:28,  5.13s/pipeline]Optimization Progress:  99%|█████████▉| 8502/8600 [44:09<08:45,  5.36s/pipeline]Optimization Progress: 100%|█████████▉| 8582/8600 [44:18<01:08,  3.79s/pipeline]
Generation 85 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 8600/8600 [44:19<00:00,  3.79s/pipeline]Optimization Progress: 100%|██████████| 8600/8600 [44:19<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:19<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8600/8600 [44:19<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8600/8600 [44:19<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:20<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 8600/8600 [44:20<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 8600/8600 [44:21<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:21<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:21<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:23<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:24<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:24<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8600/8600 [44:25<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:25<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:25<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:26<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:27<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:27<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:27<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:27<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [44:28<00:00,  2.66s/pipeline]Optimization Progress:  99%|█████████▉| 8602/8700 [44:30<04:20,  2.66s/pipeline]Optimization Progress:  99%|█████████▉| 8603/8700 [44:34<05:30,  3.40s/pipeline]Optimization Progress: 100%|█████████▉| 8683/8700 [44:38<00:40,  2.40s/pipeline]
Generation 86 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8700/8700 [44:41<00:00,  2.40s/pipeline]Optimization Progress: 100%|██████████| 8700/8700 [44:41<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 8700/8700 [44:41<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:42<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [44:43<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 8700/8700 [44:43<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:43<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:43<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:44<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:44<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 8700/8700 [44:44<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:45<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 8700/8700 [44:47<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 8700/8700 [44:47<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [44:48<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 8700/8700 [44:49<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8700/8700 [44:49<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8700/8700 [44:49<00:00,  1.72s/pipeline]Optimization Progress:  99%|█████████▉| 8701/8800 [44:50<06:22,  3.86s/pipeline]Optimization Progress:  99%|█████████▉| 8702/8800 [45:02<10:16,  6.29s/pipeline]Optimization Progress: 100%|█████████▉| 8782/8800 [45:23<01:20,  4.48s/pipeline]
Generation 87 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  4.48s/pipeline]Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [07:10:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:25<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:26<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:27<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:28<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 8800/8800 [45:30<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:32<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:32<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:32<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:32<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8800/8800 [45:32<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:33<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:33<00:00,  3.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [45:33<00:00,  3.17s/pipeline]Optimization Progress:  99%|█████████▉| 8801/8900 [45:45<13:29,  8.18s/pipeline]Optimization Progress: 100%|█████████▉| 8881/8900 [45:49<01:49,  5.74s/pipeline]
Generation 88 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:49<00:00,  5.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:49<00:00,  5.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:49<00:00,  5.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:50<00:00,  5.74s/pipeline]Optimization Progress: 100%|██████████| 8900/8900 [45:50<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8900/8900 [45:50<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:52<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:53<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 8900/8900 [45:53<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:54<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:54<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:54<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:57<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 8900/8900 [45:57<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:57<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:57<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:57<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 8900/8900 [45:58<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:58<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:58<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [45:59<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [46:00<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 8900/8900 [46:01<00:00,  4.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [46:01<00:00,  4.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8901/9000 [46:01<06:39,  4.03s/pipeline]Optimization Progress:  99%|█████████▉| 8902/9000 [46:01<07:19,  4.49s/pipeline]Optimization Progress:  99%|█████████▉| 8903/9000 [46:13<10:55,  6.76s/pipeline]Optimization Progress: 100%|█████████▉| 8983/9000 [46:18<01:20,  4.75s/pipeline]
Generation 89 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:18<00:00,  4.75s/pipeline]Optimization Progress: 100%|██████████| 9000/9000 [46:18<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:19<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:19<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:19<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:19<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 9000/9000 [46:21<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9000/9000 [46:21<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:11:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9000/9000 [46:21<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:23<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:23<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:23<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:23<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:24<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9000/9000 [46:24<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 9000/9000 [46:24<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:24<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:25<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:25<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:25<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 9000/9000 [46:25<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:26<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [46:27<00:00,  3.33s/pipeline]Optimization Progress:  99%|█████████▉| 9001/9100 [46:30<05:29,  3.33s/pipeline]Optimization Progress:  99%|█████████▉| 9002/9100 [46:37<08:26,  5.17s/pipeline]Optimization Progress: 100%|█████████▉| 9082/9100 [46:45<01:05,  3.65s/pipeline]
Generation 90 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9100/9100 [46:45<00:00,  3.65s/pipeline]Optimization Progress: 100%|██████████| 9100/9100 [46:45<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:45<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:45<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:45<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [46:46<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 9100/9100 [46:46<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:46<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 9100/9100 [46:46<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:46<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 9100/9100 [46:47<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:47<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:47<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:48<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:48<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:48<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:48<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:49<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:49<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 9100/9100 [46:49<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9100/9100 [46:50<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9100/9100 [46:50<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:50<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:50<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 9100/9100 [46:50<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9100/9100 [46:51<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:51<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:51<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 9100/9100 [46:51<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:52<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:53<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:53<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:53<00:00,  2.56s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [46:54<00:00,  2.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9101/9200 [46:55<04:13,  2.56s/pipeline]Optimization Progress:  99%|█████████▉| 9102/9200 [46:55<05:17,  3.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9102/9200 [46:55<05:17,  3.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9103/9200 [46:55<05:14,  3.24s/pipeline]Optimization Progress:  99%|█████████▉| 9105/9200 [47:02<04:40,  2.95s/pipeline]Optimization Progress: 100%|█████████▉| 9185/9200 [47:08<00:31,  2.09s/pipeline]
Generation 91 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:10<00:00,  2.09s/pipeline]Optimization Progress: 100%|██████████| 9200/9200 [47:10<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:11<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:11<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:12<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 9200/9200 [47:14<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:14<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:14<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 9200/9200 [47:14<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:16<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:17<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [47:18<00:00,  1.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9200/9200 [47:19<00:00,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9200/9300 [47:19<02:29,  1.49s/pipeline]Optimization Progress:  99%|█████████▉| 9201/9300 [47:19<06:25,  3.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9201/9300 [47:19<06:25,  3.89s/pipeline]Optimization Progress:  99%|█████████▉| 9203/9300 [47:32<07:27,  4.62s/pipeline]Optimization Progress: 100%|█████████▉| 9283/9300 [47:37<00:55,  3.25s/pipeline]
Generation 92 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:38<00:00,  3.25s/pipeline]Optimization Progress: 100%|██████████| 9300/9300 [47:38<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:39<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:54] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9300/9300 [47:39<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:39<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:41<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:42<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:43<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:44<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:44<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 9300/9300 [47:44<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:45<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:46<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:47<00:00,  2.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [47:47<00:00,  2.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9300/9400 [47:48<03:49,  2.29s/pipeline]Optimization Progress:  99%|█████████▉| 9301/9400 [47:48<07:18,  4.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9301/9400 [47:48<07:18,  4.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9302/9400 [47:48<07:14,  4.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9303/9400 [47:48<07:10,  4.43s/pipeline]Optimization Progress:  99%|█████████▉| 9305/9400 [48:35<10:33,  6.67s/pipeline]Optimization Progress: 100%|█████████▉| 9385/9400 [48:41<01:10,  4.69s/pipeline]
Generation 93 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:41<00:00,  4.69s/pipeline]Optimization Progress: 100%|██████████| 9400/9400 [48:41<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9400/9400 [48:42<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:13:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9400/9400 [48:42<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:42<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:42<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:43<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:44<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 9400/9400 [48:45<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:45<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:45<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:14:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9400/9400 [48:45<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9400/9400 [48:46<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:46<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:46<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 9400/9400 [48:47<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:47<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:47<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9400/9400 [48:47<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:47<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 9400/9400 [48:49<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:50<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:50<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:50<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [48:52<00:00,  3.29s/pipeline]Optimization Progress:  99%|█████████▉| 9400/9500 [49:00<05:28,  3.29s/pipeline]Optimization Progress:  99%|█████████▉| 9401/9500 [49:04<15:00,  9.10s/pipeline]Optimization Progress: 100%|█████████▉| 9481/9500 [49:08<02:01,  6.38s/pipeline]
Generation 94 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 9500/9500 [49:08<00:00,  6.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9500/9500 [49:08<00:00,  6.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:08<00:00,  6.38s/pipeline]Optimization Progress: 100%|██████████| 9500/9500 [49:08<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 9500/9500 [49:09<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:09<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:09<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:10<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 9500/9500 [49:12<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:12<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9500/9500 [49:12<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:13<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:13<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:14<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:14<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:14<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:15<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 9500/9500 [49:15<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:15<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:15<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:16<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:17<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:17<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 9500/9500 [49:17<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [49:17<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [49:18<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9500/9500 [49:18<00:00,  4.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [49:19<00:00,  4.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9500/9600 [49:19<07:27,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 9501/9600 [49:20<07:23,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 9502/9600 [49:28<10:00,  6.13s/pipeline]Optimization Progress: 100%|█████████▉| 9582/9600 [49:47<01:18,  4.36s/pipeline]
Generation 95 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:48<00:00,  4.36s/pipeline]Optimization Progress: 100%|██████████| 9600/9600 [49:48<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:49<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:49<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:49<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:49<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:49<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:50<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:51<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:53<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:53<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9600/9600 [49:54<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9600/9600 [49:54<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:54<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:55<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:55<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:55<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9600/9600 [49:55<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [49:56<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:15:12] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9600/9600 [49:57<00:00,  3.08s/pipeline]Optimization Progress:  99%|█████████▉| 9601/9700 [49:57<07:48,  4.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9601/9700 [49:57<07:48,  4.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9602/9700 [49:57<07:43,  4.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9603/9700 [49:57<07:39,  4.73s/pipeline]Optimization Progress:  99%|█████████▉| 9605/9700 [50:07<06:26,  4.07s/pipeline]Optimization Progress: 100%|█████████▉| 9685/9700 [50:17<00:43,  2.89s/pipeline]
Generation 96 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:17<00:00,  2.89s/pipeline]Optimization Progress: 100%|██████████| 9700/9700 [50:17<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:17<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:18<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:18<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:24<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:24<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:24<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:26<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:26<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9700/9700 [50:26<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:26<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:27<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:27<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:27<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:27<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9700/9700 [50:27<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 9700/9700 [50:28<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:29<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:29<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9700/9700 [50:29<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:29<00:00,  2.03s/pipeline]Optimization Progress: 100%|██████████| 9700/9700 [50:30<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:30<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:30<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:31<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [50:32<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:32<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:32<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:32<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:33<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:33<00:00,  2.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [50:33<00:00,  2.03s/pipeline]Optimization Progress:  99%|█████████▉| 9701/9800 [50:35<11:11,  6.79s/pipeline]Optimization Progress:  99%|█████████▉| 9702/9800 [50:44<11:59,  7.34s/pipeline]Optimization Progress: 100%|█████████▉| 9782/9800 [51:28<01:35,  5.31s/pipeline]
Generation 97 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  5.31s/pipeline]Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:30<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:31<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:31<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 9800/9800 [51:31<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:31<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9800/9800 [51:31<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:32<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:33<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 9800/9800 [51:33<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 9800/9800 [51:33<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9800/9800 [51:34<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:35<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:35<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:35<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 9800/9800 [51:36<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:38<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:39<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:39<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:39<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:39<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 9800/9800 [51:39<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:16:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 9800/9800 [51:40<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [51:40<00:00,  3.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9800/9900 [51:40<06:13,  3.73s/pipeline]Optimization Progress:  99%|█████████▉| 9801/9900 [51:40<09:35,  5.81s/pipeline]Optimization Progress:  99%|█████████▉| 9802/9900 [52:28<30:11, 18.48s/pipeline]Optimization Progress: 100%|█████████▉| 9882/9900 [52:33<03:53, 12.96s/pipeline]
Generation 98 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:33<00:00, 12.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:33<00:00, 12.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:34<00:00, 12.96s/pipeline]Optimization Progress: 100%|██████████| 9900/9900 [52:34<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:34<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 9900/9900 [52:35<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 9900/9900 [52:36<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:37<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:37<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:38<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 9900/9900 [52:39<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:39<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9900/9900 [52:39<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:39<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:39<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:40<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:40<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:41<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 9900/9900 [52:41<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:42<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9900/9900 [52:42<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:42<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:43<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9900/9900 [52:43<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:43<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:43<00:00,  9.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9900/9900 [52:43<00:00,  9.08s/pipeline]Optimization Progress:  99%|█████████▉| 9900/10000 [52:50<15:07,  9.08s/pipeline]Optimization Progress:  99%|█████████▉| 9901/10000 [52:54<20:37, 12.50s/pipeline]Optimization Progress: 100%|█████████▉| 9981/10000 [52:59<02:46,  8.77s/pipeline]
Generation 99 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                 _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 10000/10000 [52:59<00:00,  8.77s/pipeline]Optimization Progress: 100%|██████████| 10000/10000 [52:59<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [52:59<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [52:59<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:00<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:00<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:01<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10000/10000 [53:02<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:02<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:02<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=7 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:03<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:04<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:04<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:04<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:05<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10000/10000 [53:05<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:06<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:07<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10000/10000 [53:08<00:00,  6.14s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10000/10100 [53:09<10:14,  6.14s/pipeline]Optimization Progress:  99%|█████████▉| 10001/10100 [53:10<10:08,  6.14s/pipeline]Optimization Progress:  99%|█████████▉| 10002/10100 [53:20<12:04,  7.40s/pipeline]Optimization Progress: 100%|█████████▉| 10082/10100 [53:24<01:33,  5.19s/pipeline]
Generation 100 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  5.19s/pipeline]Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:25<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:26<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:27<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:28<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:29<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:31<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:31<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:31<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:32<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:33<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:34<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:34<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:34<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:34<00:00,  3.65s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10100/10100 [53:34<00:00,  3.65s/pipeline]Optimization Progress:  99%|█████████▉| 10103/10200 [53:34<05:37,  3.48s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10103/10200 [53:34<05:37,  3.48s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10104/10200 [53:34<05:34,  3.48s/pipeline]Optimization Progress:  99%|█████████▉| 10106/10200 [53:44<05:26,  3.48s/pipeline]Optimization Progress: 100%|█████████▉| 10186/10200 [53:48<00:34,  2.45s/pipeline]
Generation 101 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:48<00:00,  2.45s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  2.45s/pipeline]Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:49<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:50<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:51<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10200/10200 [53:51<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:51<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 10200/10200 [53:51<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:52<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:53<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:54<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 10200/10200 [53:55<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:55<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:56<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:56<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:57<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10200/10200 [53:57<00:00,  1.72s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10200/10200 [53:57<00:00,  1.72s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10200/10300 [53:57<02:51,  1.72s/pipeline]Optimization Progress:  99%|█████████▉| 10201/10300 [54:00<02:50,  1.72s/pipeline]Optimization Progress:  99%|█████████▉| 10202/10300 [54:09<07:05,  4.34s/pipeline]Optimization Progress: 100%|█████████▉| 10282/10300 [54:14<00:54,  3.05s/pipeline]
Generation 102 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 10300/10300 [54:15<00:00,  3.05s/pipeline]Optimization Progress: 100%|██████████| 10300/10300 [54:15<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [07:19:30] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 10300/10300 [54:15<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10300/10300 [54:16<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:16<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:16<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:17<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:17<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:17<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:18<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:18<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 10300/10300 [54:18<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:21<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:21<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:21<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:21<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:22<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:22<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:22<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10300/10300 [54:22<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:23<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 10300/10300 [54:23<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:23<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [07:19:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10300/10300 [54:26<00:00,  2.15s/pipeline]Optimization Progress:  99%|█████████▉| 10300/10400 [54:30<03:34,  2.15s/pipeline]Optimization Progress:  99%|█████████▉| 10301/10400 [54:40<15:00,  9.09s/pipeline]Optimization Progress: 100%|█████████▉| 10381/10400 [54:44<02:01,  6.38s/pipeline]
Generation 103 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:44<00:00,  6.38s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:45<00:00,  6.38s/pipeline]Optimization Progress: 100%|██████████| 10400/10400 [54:45<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:45<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:46<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 10400/10400 [54:47<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 10400/10400 [54:49<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 10400/10400 [54:49<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:51<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:52<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:53<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:53<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:53<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:53<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:54<00:00,  4.48s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10400/10400 [54:54<00:00,  4.48s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10400/10500 [54:54<07:27,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 10401/10500 [55:00<07:23,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 10402/10500 [55:03<09:39,  5.91s/pipeline]Optimization Progress: 100%|█████████▉| 10482/10500 [55:48<01:17,  4.30s/pipeline]
Generation 104 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:48<00:00,  4.30s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10500/10500 [55:48<00:00,  4.30s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:49<00:00,  4.30s/pipeline]Optimization Progress: 100%|██████████| 10500/10500 [55:49<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:49<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:49<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:51<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:51<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:51<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:51<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:51<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:52<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10500/10500 [55:53<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:54<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:55<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:56<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:56<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:57<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:57<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:57<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:58<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 10500/10500 [55:58<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:58<00:00,  3.04s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10500/10500 [55:58<00:00,  3.04s/pipeline]Optimization Progress:  99%|█████████▉| 10501/10600 [56:09<13:20,  8.08s/pipeline]Optimization Progress: 100%|█████████▉| 10581/10600 [56:15<01:47,  5.68s/pipeline]
Generation 105 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:15<00:00,  5.68s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:16<00:00,  5.68s/pipeline]Optimization Progress: 100%|██████████| 10600/10600 [56:16<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 10600/10600 [56:17<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:17<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:17<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 10600/10600 [56:18<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:18<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:18<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:18<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:19<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:19<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:20<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:20<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:20<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:20<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:21<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:21<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:21<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:21<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:21<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:22<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 10600/10600 [56:22<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:23<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:25<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:25<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:25<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:26<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10600/10600 [56:26<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10600/10600 [56:26<00:00,  3.99s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 10600/10600 [56:27<00:00,  3.99s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10600/10700 [56:27<06:38,  3.99s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10601/10700 [56:27<06:34,  3.99s/pipeline]Optimization Progress:  99%|█████████▉| 10602/10700 [56:27<07:10,  4.39s/pipeline]Optimization Progress:  99%|█████████▉| 10603/10700 [56:54<18:21, 11.36s/pipeline]Optimization Progress: 100%|█████████▉| 10683/10700 [56:59<02:15,  7.97s/pipeline]
Generation 106 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 10700/10700 [56:59<00:00,  7.97s/pipeline]Optimization Progress: 100%|██████████| 10700/10700 [56:59<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:00<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:00<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:00<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:00<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 10700/10700 [57:00<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:01<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:01<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:01<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:02<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:02<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:02<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10700/10700 [57:02<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 10700/10700 [57:03<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:03<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 10700/10700 [57:04<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:05<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:05<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:05<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:06<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:06<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:07<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10700/10700 [57:07<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:08<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 10700/10700 [57:09<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 10700/10700 [57:09<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10700/10700 [57:10<00:00,  5.59s/pipeline]Optimization Progress: 100%|██████████| 10700/10700 [57:10<00:00,  5.59s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 10700/10700 [57:10<00:00,  5.59s/pipeline]Optimization Progress:  99%|█████████▉| 10701/10800 [57:11<12:04,  7.32s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10701/10800 [57:11<12:04,  7.32s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10702/10800 [57:11<11:57,  7.32s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10703/10800 [57:11<11:49,  7.32s/pipeline]Optimization Progress:  99%|█████████▉| 10705/10800 [57:21<09:17,  5.87s/pipeline]Optimization Progress: 100%|█████████▉| 10785/10800 [57:24<01:01,  4.12s/pipeline]
Generation 107 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  4.12s/pipeline]Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 10800/10800 [57:25<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:26<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=7 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:27<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:29<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:29<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:30<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:31<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:31<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:31<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:31<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:32<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:33<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 10800/10800 [57:33<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:34<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:34<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:35<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 10800/10800 [57:35<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:35<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:35<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:35<00:00,  2.90s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10800/10800 [57:36<00:00,  2.90s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10800/10900 [57:36<04:49,  2.90s/pipeline]Optimization Progress:  99%|█████████▉| 10801/10900 [57:40<04:46,  2.90s/pipeline]Optimization Progress:  99%|█████████▉| 10802/10900 [57:44<08:07,  4.97s/pipeline]Optimization Progress: 100%|█████████▉| 10882/10900 [57:54<01:03,  3.52s/pipeline]
Generation 108 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  3.52s/pipeline]Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:56<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:57<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:58<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 10900/10900 [57:59<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:00<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10900/10900 [58:00<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 10900/10900 [58:00<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:00<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 10900/10900 [58:00<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:01<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:02<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:02<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:02<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:02<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:02<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:03<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:03<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:03<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:04<00:00,  2.50s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 10900/10900 [58:04<00:00,  2.50s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10900/11000 [58:04<04:09,  2.50s/pipeline]Optimization Progress:  99%|█████████▉| 10901/11000 [58:04<06:39,  4.04s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 10901/11000 [58:04<06:39,  4.04s/pipeline]Optimization Progress:  99%|█████████▉| 10903/11000 [58:16<07:32,  4.66s/pipeline]Optimization Progress: 100%|█████████▉| 10983/11000 [58:26<00:56,  3.30s/pipeline]
Generation 109 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  3.30s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  3.30s/pipeline]Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11000/11000 [58:26<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:28<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 11000/11000 [58:29<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:30<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:30<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:30<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:30<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:31<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:31<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:32<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 11000/11000 [58:33<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11000/11000 [58:34<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:35<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:35<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:36<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:36<00:00,  2.31s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11000/11000 [58:36<00:00,  2.31s/pipeline]Optimization Progress:  99%|█████████▉| 11001/11100 [58:40<03:48,  2.31s/pipeline]Optimization Progress:  99%|█████████▉| 11002/11100 [58:46<07:30,  4.60s/pipeline]Optimization Progress: 100%|█████████▉| 11082/11100 [58:49<00:58,  3.23s/pipeline]
Generation 110 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  3.23s/pipeline]Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:50<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:52<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11100/11100 [58:52<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:52<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:53<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:53<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:53<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 11100/11100 [58:53<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:53<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:54<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:55<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:55<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:55<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:55<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:56<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11100/11100 [58:57<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:57<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:57<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:57<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11100/11100 [58:58<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:58<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:58<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:58<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:59<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:59<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:59<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:59<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [58:59<00:00,  2.27s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11100/11100 [59:00<00:00,  2.27s/pipeline]Optimization Progress:  99%|█████████▉| 11102/11200 [59:00<05:02,  3.08s/pipeline]Optimization Progress:  99%|█████████▉| 11104/11200 [59:07<05:16,  3.29s/pipeline]Optimization Progress: 100%|█████████▉| 11183/11200 [59:11<00:39,  2.32s/pipeline]
Generation 111 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:12<00:00,  2.32s/pipeline]Optimization Progress: 100%|██████████| 11200/11200 [59:12<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 11200/11200 [59:12<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:12<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 11200/11200 [59:13<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:14<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:15<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:16<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 11200/11200 [59:16<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:17<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:17<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 11200/11200 [59:18<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:18<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:18<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:18<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:33] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f5afc1c7dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f5afc2d8669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f5afc2e5f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f5afc2cccbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f5afc1b9f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f5109f749dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f5109f74067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f5109f8c27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f5109f8ccb4]

.
Optimization Progress: 100%|██████████| 11200/11200 [59:18<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 11200/11200 [59:19<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:20<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:20<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:20<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:20<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:22<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:22<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11200/11200 [59:22<00:00,  1.63s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 11200/11200 [59:23<00:00,  1.63s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 11200/11300 [59:23<02:42,  1.63s/pipeline]Optimization Progress:  99%|█████████▉| 11201/11300 [59:30<02:41,  1.63s/pipeline]Optimization Progress:  99%|█████████▉| 11202/11300 [59:34<07:21,  4.50s/pipeline]Optimization Progress: 100%|█████████▉| 11282/11300 [59:40<00:57,  3.17s/pipeline]
Generation 112 - Current Pareto front scores:
-1	-199072549.9776324	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-196482916.26191294	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.1, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-175107735.79792425	XGBRegressor(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.01), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-4	-165396581.01927927	XGBRegressor(StandardScaler(ElasticNetCV(CombineDFs(input_matrix, KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform)), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.001)), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-5	-150755918.4415935	XGBRegressor(ExtraTreesRegressor(SelectFromModel(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=1e-05), SelectFromModel__ExtraTreesRegressor__max_features=0.3, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)
-7	-137271605.88523144	XGBRegressor(ElasticNetCV(XGBRegressor(KNeighborsRegressor(ElasticNetCV(SelectFwe(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), SelectFwe__alpha=0.019), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.01), KNeighborsRegressor__n_neighbors=42, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), XGBRegressor__learning_rate=0.001, XGBRegressor__max_depth=2, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8), ElasticNetCV__l1_ratio=0.5, ElasticNetCV__tol=0.1), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.2)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  3.17s/pipeline]Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:40<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:41<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:41<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:41<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:41<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:42<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:42<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:42<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:42<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 11300/11300 [59:42<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:43<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:43<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:44<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 11300/11300 [59:44<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:44<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:44<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:46<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:46<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 11300/11300 [59:46<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11300/11300 [59:46<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:47<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 11300/11300 [59:48<00:00,  2.22s/pipeline]Optimization Progress:  99%|█████████▉| 11302/11400 [59:50<03:37,  2.22s/pipeline]Optimization Progress:  99%|█████████▉| 11303/11400 [1:00:00<05:51,  3.62s/pipeline]                                                                                    
Optimization Progress: 100%|█████████▉| 11382/11400 [1:00:00<01:05,  3.62s/pipeline]                                                                                    60.13 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 11382/11400 [1:00:00<01:05,  3.62s/pipeline]                                                                                    
Optimization Progress: 100%|█████████▉| 11382/11400 [1:00:00<01:05,  3.62s/pipeline]                                                                                    
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 11382/11400 [1:00:00<01:05,  3.62s/pipeline]                                                                                    Best pipeline:
0. StackingEstimator(estimator=KNeighborsRegressor(n_neighbors=42, p=1))
1. SelectFwe(alpha=0.019, score_func=<function f_regression at 0x7f46e29eab90>)
2. StackingEstimator(estimator=ElasticNetCV(tol=0.01))
3. StackingEstimator(estimator=KNeighborsRegressor(n_neighbors=42))
4. StackingEstimator(estimator=XGBRegressor(base_score=0.5, booster='gbtree',
                                         colsample_bylevel=1,
                                         colsample_bynode=1, colsample_bytree=1,
                                         gamma=0, gpu_id=-1,
                                         importance_type='gain',
                                         interaction_constraints='',
                                         learning_rate=0.001, max_delta_step=0,
                                         max_depth=2, min_child_weight=3,
                                         missing=nan, monotone_constraints='()',
                                         n_estimators=100, n_jobs=1, nthread=1,
                                         num_parallel_tree=1, random_state=0,
                                         reg_alpha=0, reg_lambda=1,
                                         scale_pos_weight=1, subsample=0.8,
                                         tree_method='exact',
                                         validate_parameters=1,
                                         verbosity=None))
5. StackingEstimator(estimator=ElasticNetCV(tol=0.1))
6. XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
             importance_type='gain', interaction_constraints='',
             learning_rate=1.0, max_delta_step=0, max_depth=5,
             min_child_weight=12, missing=nan, monotone_constraints='()',
             n_estimators=100, n_jobs=1, nthread=1, num_parallel_tree=1,
             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
             subsample=0.2, tree_method='exact', validate_parameters=1,
             verbosity=None)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
