30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  13%|█▎        | 13/100 [00:09<01:03,  1.38pipeline/s]Optimization Progress:  93%|█████████▎| 93/100 [00:13<00:03,  1.92pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  1.92pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.24pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.24pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.24pipeline/s]Optimization Progress:  51%|█████     | 102/200 [00:19<01:35,  1.02pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  51%|█████     | 102/200 [00:19<01:35,  1.02pipeline/s]Optimization Progress:  52%|█████▏    | 104/200 [00:27<03:04,  1.93s/pipeline]Optimization Progress:  92%|█████████▏| 184/200 [00:33<00:21,  1.37s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:49:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa9b8a34dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa9b8b45669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa9b8b52f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa9b8b39cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa9b8a26f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9fc68219dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9fc6821067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9fc683927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9fc6839cb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.37s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 200/200 [00:35<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:35<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:49:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa9b8a34dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa9b8b45669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa9b8b52f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa9b8b39cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa9b8a26f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9fc68219dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9fc6821067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9fc683927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9fc6839cb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:36<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.03pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:50:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa9b8a34dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa9b8b45669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa9b8b52f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa9b8b39cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa9b8a26f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9fc68219dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9fc6821067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9fc683927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9fc6839cb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:40<00:00,  1.03pipeline/s]Optimization Progress:  68%|██████▊   | 203/300 [00:42<02:22,  1.47s/pipeline]Optimization Progress:  68%|██████▊   | 203/300 [01:00<02:22,  1.47s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [01:10<15:28,  9.67s/pipeline]Optimization Progress:  95%|█████████▍| 284/300 [01:16<01:48,  6.79s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:20<00:00,  6.79s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:20<00:00,  4.84s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 300/300 [01:22<00:00,  4.84s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [01:24<07:40,  4.65s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [01:33<09:26,  5.78s/pipeline]Optimization Progress:  96%|█████████▌| 382/400 [02:04<01:14,  4.17s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:07<00:00,  4.17s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:07<00:00,  2.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:10<00:00,  2.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:16<00:00,  2.96s/pipeline]Optimization Progress:  80%|████████  | 401/500 [02:37<18:25, 11.17s/pipeline]Optimization Progress:  96%|█████████▌| 481/500 [02:41<02:28,  7.83s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-539533638.1886883	GradientBoostingRegressor(DecisionTreeRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=19, DecisionTreeRegressor__min_samples_split=7), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 500/500 [02:43<00:00,  7.83s/pipeline]Optimization Progress: 100%|██████████| 500/500 [02:43<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 500/500 [02:43<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 500/500 [02:45<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 500/500 [02:47<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:51<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:55<00:00,  5.51s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:55<00:00,  5.51s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [02:55<12:28,  7.56s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [03:12<17:03, 10.45s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [03:18<02:12,  7.34s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-536543239.6125393	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:23<00:00,  7.34s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:23<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:27<00:00,  5.21s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [03:34<11:39,  7.07s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 601/700 [03:34<11:39,  7.07s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 602/700 [03:34<11:32,  7.07s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [05:02<22:00, 13.76s/pipeline]Optimization Progress:  98%|█████████▊| 684/700 [05:05<02:34,  9.64s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-533020095.0461151	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [04:54:29] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fa9b8a34dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fa9b8b45669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fa9b8b52f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fa9b8b39cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fa9b8a26f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f9fc68219dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f9fc6821067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f9fc683927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f9fc6839cb4]

.
Optimization Progress: 100%|██████████| 700/700 [05:07<00:00,  9.64s/pipeline]Optimization Progress: 100%|██████████| 700/700 [05:07<00:00,  6.79s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [05:11<00:00,  6.79s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [05:14<00:00,  6.79s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [05:17<00:00,  6.79s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [05:17<00:00,  6.79s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [05:21<09:15,  5.78s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 704/800 [05:21<09:15,  5.78s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 705/800 [05:21<09:09,  5.78s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 706/800 [05:21<09:03,  5.78s/pipeline]Optimization Progress:  88%|████████▊ | 708/800 [06:22<13:14,  8.64s/pipeline]Optimization Progress:  98%|█████████▊| 788/800 [07:45<01:16,  6.36s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-540146946.7598554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-533020095.0461151	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [07:45<00:00,  6.36s/pipeline]Optimization Progress: 100%|██████████| 800/800 [07:45<00:00,  4.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 800/800 [07:46<00:00,  4.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 800/800 [07:49<00:00,  4.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [07:49<00:00,  4.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:57<00:00,  4.46s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [08:00<07:21,  4.46s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [09:38<32:49, 20.09s/pipeline]Optimization Progress:  98%|█████████▊| 882/900 [09:44<04:13, 14.09s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-537868900.7079103	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-532934171.5996682	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 900/900 [09:48<00:00, 14.09s/pipeline]Optimization Progress: 100%|██████████| 900/900 [09:48<00:00,  9.92s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [10:00<17:31, 10.62s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [11:48<1:04:38, 39.58s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [11:57<08:19, 27.74s/pipeline]  
Generation 9 - Current Pareto front scores:
-1	-536235630.45522577	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-532934171.5996682	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 1000/1000 [12:02<00:00, 27.74s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [12:02<00:00, 19.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [12:04<00:00, 19.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [12:06<00:00, 19.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [12:14<00:00, 19.51s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [12:16<29:19, 17.77s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [12:56<39:47, 24.37s/pipeline]Optimization Progress:  98%|█████████▊| 1082/1100 [13:09<05:07, 17.11s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-536147203.2131486	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-532934171.5996682	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [13:10<00:00, 17.11s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [13:10<00:00, 11.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [13:12<00:00, 11.99s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [13:30<19:46, 11.99s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [15:19<45:12, 27.68s/pipeline]Optimization Progress:  98%|█████████▊| 1182/1200 [15:26<05:49, 19.40s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-532934171.5996682	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:31<00:00, 19.40s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [15:31<00:00, 13.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [15:32<00:00, 13.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:32<00:00, 13.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [15:40<00:00, 13.67s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [15:44<17:32, 10.85s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [18:36<1:34:29, 59.06s/pipeline]Optimization Progress:  99%|█████████▉| 1284/1300 [19:09<11:03, 41.47s/pipeline]  
Generation 12 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-532934171.5996682	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)Optimization Progress: 100%|██████████| 1300/1300 [19:29<00:00, 29.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1301/1400 [19:29<48:31, 29.41s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [19:46<36:00, 22.28s/pipeline]Optimization Progress:  99%|█████████▉| 1383/1400 [20:18<04:27, 15.71s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [20:24<00:00, 15.71s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [20:24<00:00, 11.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [20:27<00:00, 11.10s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [20:39<20:15, 12.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1401/1500 [20:39<20:15, 12.28s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [21:49<30:51, 19.09s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [21:55<03:47, 13.39s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [22:00<00:00, 13.39s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [22:00<00:00,  9.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [22:01<00:00,  9.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [22:07<00:00,  9.46s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [23:16<48:34, 29.44s/pipeline]Optimization Progress:  99%|█████████▉| 1581/1600 [23:29<06:32, 20.66s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [23:34<00:00, 20.66s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [23:34<00:00, 14.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1600/1600 [23:35<00:00, 14.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [23:46<00:00, 14.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [23:46<00:00, 14.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [23:46<00:00, 14.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 1600/1600 [23:46<00:00, 14.53s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [23:48<20:13, 12.38s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [24:48<42:50, 26.49s/pipeline]Optimization Progress:  99%|█████████▉| 1683/1700 [24:54<05:15, 18.57s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-535258101.797537	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1700/1700 [25:02<00:00, 18.57s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [25:02<00:00, 13.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:02<00:00, 13.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [25:06<00:00, 13.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:06<00:00, 13.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:06<00:00, 13.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [25:11<00:00, 13.14s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [25:15<21:42, 13.16s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [27:31<1:21:54, 50.15s/pipeline]Optimization Progress:  99%|█████████▉| 1782/1800 [27:38<10:32, 35.13s/pipeline]  
Generation 17 - Current Pareto front scores:
-1	-534069174.52550495	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-514256975.74541205	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=8, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [27:38<00:00, 35.13s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [27:38<00:00, 24.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1800/1800 [27:41<00:00, 24.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 1800/1800 [27:43<00:00, 24.59s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [27:50<00:00, 24.59s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [27:59<29:15, 18.47s/pipeline]Optimization Progress:  95%|█████████▌| 1806/1900 [28:10<25:38, 16.37s/pipeline]Optimization Progress:  99%|█████████▉| 1886/1900 [28:21<02:40, 11.50s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-534069174.52550495	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-505082836.11878407	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [28:24<00:00, 11.50s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [28:24<00:00,  8.11s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [28:24<00:00,  8.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1900/1900 [28:35<00:00,  8.11s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [28:41<17:56, 10.87s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [28:52<17:50, 10.92s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [29:47<02:21,  7.85s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-534069174.52550495	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-503742901.10646963	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [29:49<00:00,  7.85s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [29:49<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [29:51<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 2000/2000 [29:52<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [29:54<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [30:03<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [30:05<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [30:07<00:00,  5.52s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [30:07<09:12,  5.70s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [31:35<48:46, 30.49s/pipeline]Optimization Progress:  99%|█████████▉| 2084/2100 [31:40<05:41, 21.36s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-533664673.98669565	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [31:45<00:00, 21.36s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [31:45<00:00, 15.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [31:45<00:00, 15.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [31:49<00:00, 15.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [31:49<00:00, 15.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [31:52<00:00, 15.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 2100/2100 [31:56<00:00, 15.04s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [33:13<1:01:06, 37.04s/pipeline]Optimization Progress:  99%|█████████▉| 2181/2200 [33:19<08:13, 25.95s/pipeline]  
Generation 21 - Current Pareto front scores:
-1	-533664673.98669565	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [33:30<00:00, 25.95s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [33:30<00:00, 18.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [33:33<00:00, 18.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 2200/2200 [33:33<00:00, 18.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [33:35<00:00, 18.34s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [33:52<32:09, 19.49s/pipeline]Optimization Progress:  99%|█████████▉| 2281/2300 [34:01<04:19, 13.68s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-533664673.98669565	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-529554938.73331296	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=5, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:06<00:00, 13.68s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [34:06<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:08<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:12<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 2300/2300 [34:12<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [34:13<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:14<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:19<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [34:19<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [34:20<00:00,  9.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [34:21<00:00,  9.65s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [34:23<19:15, 11.67s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [34:34<18:45, 11.48s/pipeline]Optimization Progress:  99%|█████████▉| 2382/2400 [36:24<02:32,  8.45s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-533664673.98669565	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-528770235.1457596	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [36:27<00:00,  8.45s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [36:27<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [36:37<00:00,  5.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [36:38<00:00,  5.97s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [36:42<09:06,  5.63s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [36:51<10:52,  6.80s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [36:56<01:16,  4.78s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-533409132.4975084	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-528770235.1457596	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [36:56<00:00,  4.78s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [36:59<00:00,  4.78s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [36:59<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [37:04<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [37:04<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [37:06<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [37:10<00:00,  3.39s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [37:15<07:49,  4.80s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [37:23<09:26,  5.84s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [37:28<01:09,  4.10s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-533404021.68637574	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2600/2600 [37:44<00:00,  4.10s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [37:44<00:00,  3.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [37:45<00:00,  3.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [37:45<00:00,  3.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 2600/2600 [37:46<00:00,  3.15s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [37:47<04:09,  2.57s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [37:57<07:27,  4.66s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [38:02<00:52,  3.28s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-533404021.68637574	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)Optimization Progress: 100%|██████████| 2700/2700 [38:22<00:00,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2703/2800 [38:22<04:18,  2.67s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [39:32<09:37,  6.08s/pipeline]Optimization Progress:  99%|█████████▉| 2785/2800 [39:37<01:04,  4.27s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-533404021.68637574	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00100.
Optimization Progress: 100%|██████████| 2800/2800 [39:39<00:00,  4.27s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [39:39<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [39:40<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [39:44<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2800/2800 [39:47<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 2800/2800 [39:48<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [39:55<00:00,  3.04s/pipeline]Optimization Progress:  97%|█████████▋| 2801/2900 [39:56<11:47,  7.15s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [40:12<15:46,  9.66s/pipeline]Optimization Progress:  99%|█████████▉| 2882/2900 [40:17<02:02,  6.78s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-533404021.68637574	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 2900/2900 [40:18<00:00,  6.78s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [40:18<00:00,  4.76s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [40:36<08:15,  5.11s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [40:44<09:54,  6.19s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [40:53<01:09,  4.37s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-488469659.99010074	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)
-4	-465344634.5405628	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [40:54<00:00,  4.37s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [40:54<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [40:55<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3000/3000 [41:00<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 3000/3000 [41:02<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 3000/3000 [41:03<00:00,  3.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [41:04<00:00,  3.08s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [43:27<1:19:12, 48.00s/pipeline]Optimization Progress:  99%|█████████▉| 3081/3100 [43:34<10:38, 33.63s/pipeline]  
Generation 30 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487777994.7523085	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [43:39<00:00, 33.63s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [43:39<00:00, 23.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [43:43<00:00, 23.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [43:46<00:00, 23.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [43:48<00:00, 23.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3100/3200 [43:52<39:21, 23.62s/pipeline]Optimization Progress:  97%|█████████▋| 3101/3200 [43:52<34:04, 20.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [43:52<34:04, 20.65s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [44:52<37:55, 23.46s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [44:58<04:39, 16.44s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487777994.7523085	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [44:59<00:00, 16.44s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [44:59<00:00, 11.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 3200/3200 [45:04<00:00, 11.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [45:04<00:00, 11.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 3200/3200 [45:11<00:00, 11.53s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [45:14<16:55, 10.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [45:14<16:55, 10.36s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [47:07<38:39, 24.17s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [47:13<04:31, 16.94s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487777994.7523085	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [47:18<00:00, 16.94s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [47:18<00:00, 11.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3300/3300 [47:30<00:00, 11.95s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [49:03<1:05:35, 39.75s/pipeline]Optimization Progress:  99%|█████████▉| 3381/3400 [49:23<08:50, 27.90s/pipeline]  
Generation 33 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487777994.7523085	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 3400/3400 [49:26<00:00, 27.90s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [49:26<00:00, 19.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [49:34<00:00, 19.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [49:41<00:00, 19.58s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3400/3500 [49:41<32:37, 19.58s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [49:41<30:15, 18.34s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [51:05<1:01:45, 37.81s/pipeline]Optimization Progress:  99%|█████████▉| 3482/3500 [51:13<07:56, 26.50s/pipeline]  
Generation 34 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487777994.7523085	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [51:15<00:00, 26.50s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [51:15<00:00, 18.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [51:23<00:00, 18.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3500/3500 [51:26<00:00, 18.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 3500/3500 [51:29<00:00, 18.59s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [51:56<41:43, 25.28s/pipeline]Optimization Progress:  99%|█████████▉| 3581/3600 [52:06<05:36, 17.73s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-487270673.84635127	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), input_matrix), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [52:06<00:00, 17.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [52:06<00:00, 17.73s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [52:06<00:00, 12.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 3600/3600 [52:12<00:00, 12.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3600/3600 [52:20<00:00, 12.43s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [52:20<21:18, 12.91s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3601/3700 [52:20<21:18, 12.91s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [53:20<29:04, 17.99s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [53:26<03:34, 12.61s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-484724473.938964	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=4, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100)
-4	-460418949.79918635	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.15000000000000002, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100)
-5	-453759481.1051903	ExtraTreesRegressor(PCA(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=7, PCA__svd_solver=randomized), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [53:27<00:00, 12.61s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [53:27<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [53:28<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [53:32<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [53:32<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [53:33<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 3700/3700 [53:36<00:00,  8.85s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [53:43<00:00,  8.85s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [53:45<12:52,  7.96s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [54:58<44:01, 27.52s/pipeline]Optimization Progress: 100%|█████████▉| 3784/3800 [55:03<05:08, 19.28s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-484724473.938964	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=4, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100)
-4	-446809459.9709994	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), Normalizer(input_matrix, Normalizer__norm=max)), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [55:08<00:00, 19.28s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [55:08<00:00, 13.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 3800/3800 [55:10<00:00, 13.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 3800/3800 [55:18<00:00, 13.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3800/3800 [55:18<00:00, 13.58s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [55:20<18:27, 11.30s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [57:25<1:13:20, 45.37s/pipeline]Optimization Progress: 100%|█████████▉| 3883/3900 [57:30<09:00, 31.78s/pipeline]  
Generation 38 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-484724473.938964	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=4, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100)
-4	-446809459.9709994	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), Normalizer(input_matrix, Normalizer__norm=max)), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [57:33<00:00, 31.78s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [57:33<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [57:33<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [57:33<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [57:38<00:00, 22.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 3900/3900 [57:47<00:00, 22.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3900/4000 [57:48<37:08, 22.28s/pipeline]Optimization Progress:  98%|█████████▊| 3901/4000 [57:48<33:14, 20.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3901/4000 [57:48<33:14, 20.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [57:48<32:54, 20.15s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [58:00<24:36, 15.38s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [59:32<02:57, 11.11s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-533070379.38876855	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-519628662.3758338	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-484724473.938964	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=4, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100)
-4	-446809459.9709994	ExtraTreesRegressor(PCA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=1.0, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), Normalizer(input_matrix, Normalizer__norm=max)), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100)Optimization Progress: 100%|██████████| 4000/4000 [59:49<00:00,  8.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4000/4100 [59:49<13:29,  8.10s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [1:02:00<41:19, 25.30s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4081/4100 [1:02:00<08:00, 25.30s/pipeline]                                                                                  62.09 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 4081/4100 [1:02:00<08:00, 25.30s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4081/4100 [1:02:00<08:00, 25.30s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 4081/4100 [1:02:00<08:00, 25.30s/pipeline]                                                                                  Best pipeline:
0. FeatureUnion(transformer_list=[('stackingestimator',
                                StackingEstimator(estimator=ExtraTreesRegressor(max_features=1.0,
                                                                                min_samples_leaf=18,
                                                                                min_samples_split=15))),
                               ('normalizer', Normalizer(norm='max'))])
1. PCA(iterated_power=8, svd_solver='randomized')
2. ExtraTreesRegressor(max_features=0.35000000000000003, min_samples_split=15)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
