30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   8%|▊         | 8/100 [00:22<04:17,  2.80s/pipeline]Optimization Progress:  88%|████████▊ | 88/100 [00:24<00:23,  1.97s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 100/100 [00:24<00:00,  1.97s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:24<00:00,  1.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:25<00:00,  1.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:17:32] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f49a0535dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f49a0646669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f49a0653f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f49a063acbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f49a0527f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3fae2e29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3fae2e2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3fae2fa27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3fae2facb4]

.
Optimization Progress: 100%|██████████| 100/100 [00:27<00:00,  1.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:28<00:00,  1.39s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [00:29<02:23,  1.48s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 103/200 [00:29<02:23,  1.48s/pipeline]Optimization Progress:  52%|█████▎    | 105/200 [00:35<02:56,  1.86s/pipeline]Optimization Progress:  92%|█████████▎| 185/200 [00:37<00:19,  1.31s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-1067676605.3963003	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-1066529895.0455841	GradientBoostingRegressor(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.31s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:39<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:41<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:41<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:43<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:45<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:17:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f49a0535dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f49a0646669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f49a0653f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f49a063acbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f49a0527f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3fae2e29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3fae2e2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3fae2fa27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3fae2facb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:45<00:00,  1.07pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:45<00:00,  1.07pipeline/s]Optimization Progress:  68%|██████▊   | 204/300 [00:45<01:55,  1.20s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 204/300 [00:45<01:55,  1.20s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 205/300 [00:46<01:54,  1.20s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  69%|██████▊   | 206/300 [00:46<01:53,  1.20s/pipeline]Optimization Progress:  69%|██████▉   | 207/300 [01:00<01:51,  1.20s/pipeline]Optimization Progress:  69%|██████▉   | 208/300 [01:40<07:32,  4.92s/pipeline]Optimization Progress:  96%|█████████▌| 288/300 [01:46<00:41,  3.47s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1067676605.3963003	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-1066529895.0455841	GradientBoostingRegressor(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:47<00:00,  3.47s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:47<00:00,  2.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:47<00:00,  2.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:47<00:00,  2.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:47<00:00,  2.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:48<00:00,  2.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:48<00:00,  2.44s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [01:53<05:56,  3.60s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [02:30<22:28, 13.76s/pipeline]Optimization Progress:  96%|█████████▌| 382/400 [02:36<02:53,  9.65s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1067676605.3963003	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-1066529895.0455841	GradientBoostingRegressor(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:37<00:00,  9.65s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:37<00:00,  6.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 400/400 [02:39<00:00,  6.78s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:40<00:00,  6.78s/pipeline]Optimization Progress:  80%|████████  | 401/500 [02:41<09:38,  5.85s/pipeline]Optimization Progress:  80%|████████  | 402/500 [03:17<24:24, 14.94s/pipeline]Optimization Progress:  96%|█████████▋| 482/500 [03:21<03:08, 10.47s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1067121726.7252502	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-1066529895.0455841	GradientBoostingRegressor(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [03:21<00:00, 10.47s/pipeline]Optimization Progress: 100%|██████████| 500/500 [03:21<00:00,  7.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [16:20:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f49a0535dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f49a0646669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f49a0653f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f49a063acbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f49a0527f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3fae2e29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3fae2e2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3fae2fa27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3fae2facb4]

.
Optimization Progress: 100%|██████████| 500/500 [03:21<00:00,  7.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 500/500 [03:24<00:00,  7.34s/pipeline]Optimization Progress:  83%|████████▎ | 500/600 [03:40<12:13,  7.34s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [03:48<21:56, 13.30s/pipeline]Optimization Progress:  97%|█████████▋| 581/600 [04:11<02:58,  9.40s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1067102175.8841251	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-1065730516.2538607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [04:15<00:00,  9.40s/pipeline]Optimization Progress: 100%|██████████| 600/600 [04:15<00:00,  6.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 600/600 [04:15<00:00,  6.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [04:15<00:00,  6.63s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [04:15<00:00,  6.63s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [04:18<09:02,  5.48s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [04:26<10:11,  6.24s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [04:31<01:19,  4.39s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-1066064441.3031375	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-1065730516.2538607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 700/700 [04:34<00:00,  4.39s/pipeline]Optimization Progress: 100%|██████████| 700/700 [04:34<00:00,  3.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [04:34<00:00,  3.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:35<00:00,  3.13s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:36<00:00,  3.13s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [04:38<04:05,  2.53s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 703/800 [04:38<04:05,  2.53s/pipeline]Optimization Progress:  88%|████████▊ | 705/800 [04:44<04:17,  2.71s/pipeline]Optimization Progress:  98%|█████████▊| 785/800 [04:49<00:28,  1.92s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-1066064441.3031375	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-1065730516.2538607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=11, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:53<00:00,  1.92s/pipeline]Optimization Progress: 100%|██████████| 800/800 [04:53<00:00,  1.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:57<00:00,  1.43s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [04:57<02:40,  1.64s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [05:07<06:25,  3.97s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [05:10<00:47,  2.79s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-1064876718.8190126	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-1061901042.5002697	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=7, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:11<00:00,  2.79s/pipeline]Optimization Progress: 100%|██████████| 900/900 [05:11<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:11<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 900/900 [05:11<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:13<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 900/900 [05:14<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:15<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [05:16<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 900/900 [05:17<00:00,  1.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 900/900 [05:19<00:00,  1.97s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [05:28<06:27,  3.96s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [05:32<00:50,  2.78s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-1063566246.969319	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1061502847.0889482	GradientBoostingRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [05:35<00:00,  2.78s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [05:35<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:37<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [05:40<00:00,  2.00s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [05:41<05:25,  3.29s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [05:48<06:58,  4.27s/pipeline]Optimization Progress:  98%|█████████▊| 1082/1100 [05:53<00:54,  3.01s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-1063566246.969319	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1061457956.4827635	GradientBoostingRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7000000000000001, RandomForestRegressor__min_samples_leaf=1, RandomForestRegressor__min_samples_split=12, RandomForestRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [05:54<00:00,  3.01s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [05:54<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [05:55<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [05:55<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [05:55<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:57<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [05:58<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [05:58<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [06:01<00:00,  2.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [06:04<00:00,  2.13s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [06:04<07:11,  4.36s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [07:10<37:08, 22.74s/pipeline]Optimization Progress:  98%|█████████▊| 1182/1200 [07:15<04:46, 15.94s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-1063566246.969319	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1059935907.7740736	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 1200/1200 [07:18<00:00, 15.94s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [07:18<00:00, 11.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [07:20<00:00, 11.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [07:20<00:00, 11.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [07:22<00:00, 11.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [16:24:27] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f49a0535dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f49a0646669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f49a0653f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f49a063acbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f49a0527f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f3fae2e29dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f3fae2e2067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f3fae2fa27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f3fae2facb4]

.
Optimization Progress: 100%|██████████| 1200/1200 [07:22<00:00, 11.20s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [07:27<13:37,  8.52s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  93%|█████████▎| 1204/1300 [07:27<13:37,  8.52s/pipeline]Optimization Progress:  93%|█████████▎| 1206/1300 [07:36<11:29,  7.33s/pipeline]Optimization Progress:  99%|█████████▉| 1286/1300 [07:44<01:12,  5.16s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-1063566246.969319	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1059935907.7740736	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:44<00:00,  5.16s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [07:44<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [07:45<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:46<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:46<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:46<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [07:46<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [07:48<00:00,  3.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [07:50<00:00,  3.62s/pipeline]Optimization Progress:  93%|█████████▎| 1300/1400 [08:00<06:02,  3.62s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [08:28<25:50, 15.66s/pipeline]Optimization Progress:  99%|█████████▊| 1381/1400 [08:33<03:28, 10.98s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-1063366141.2780364	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-1059935907.7740736	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:35<00:00, 10.98s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [08:35<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1400/1400 [08:39<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [08:40<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:43<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [08:45<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:46<00:00,  7.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [08:47<00:00,  7.71s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [08:47<10:07,  6.33s/pipeline]Optimization Progress:  94%|█████████▎| 1405/1500 [09:09<17:27, 11.02s/pipeline]Optimization Progress:  99%|█████████▉| 1485/1500 [09:19<01:56,  7.75s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059935907.7740736	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [09:31<00:00,  7.75s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [09:31<00:00,  5.68s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [09:34<06:48,  4.21s/pipeline]Optimization Progress:  94%|█████████▍| 1504/1600 [09:52<13:21,  8.35s/pipeline]Optimization Progress:  99%|█████████▉| 1584/1600 [10:06<01:34,  5.90s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059815601.6994553	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:07<00:00,  5.90s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [10:07<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:07<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:09<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1600/1600 [10:12<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [10:14<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [10:15<00:00,  4.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 1600/1600 [10:17<00:00,  4.14s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [10:19<07:38,  4.68s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [10:28<09:57,  6.16s/pipeline]Optimization Progress:  99%|█████████▉| 1683/1700 [10:36<01:13,  4.34s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059815601.6994553	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [10:37<00:00,  4.34s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [10:37<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 1700/1700 [10:37<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [10:44<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [10:44<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [10:44<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [10:44<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 1700/1700 [10:47<00:00,  3.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1700/1700 [10:48<00:00,  3.05s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [10:50<09:59,  6.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1701/1800 [10:50<09:59,  6.06s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [11:01<09:31,  5.89s/pipeline]Optimization Progress:  99%|█████████▉| 1783/1800 [11:06<01:10,  4.14s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059815601.6994553	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-1040576860.9946012	LinearSVR(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [11:07<00:00,  4.14s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [11:07<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [11:09<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [11:10<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [11:11<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [11:17<00:00,  2.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1800/1800 [11:17<00:00,  2.91s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [11:20<04:48,  2.91s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [11:28<08:23,  5.14s/pipeline]Optimization Progress:  99%|█████████▉| 1882/1900 [11:36<01:05,  3.63s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059271711.6813921	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 1900/1900 [11:41<00:00,  3.63s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [11:41<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 1900/1900 [11:42<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [11:43<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [11:43<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 1900/1900 [11:43<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 1900/1900 [11:48<00:00,  2.63s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [11:49<04:13,  2.61s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [11:59<07:47,  4.87s/pipeline]Optimization Progress:  99%|█████████▉| 1984/2000 [12:05<00:54,  3.43s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059271711.6813921	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 2000/2000 [12:05<00:00,  3.43s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [12:05<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [12:09<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [12:09<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [12:11<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [12:11<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [12:13<00:00,  2.40s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [12:15<03:52,  2.40s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [12:20<03:50,  2.40s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [12:43<06:18,  3.99s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [12:49<00:42,  2.81s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1059247857.7461355	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:50<00:00,  2.81s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [12:50<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:53<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:53<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [12:53<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [12:53<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2100/2100 [12:55<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2100/2100 [12:57<00:00,  2.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:58<00:00,  2.00s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [12:59<04:34,  2.80s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2102/2200 [12:59<04:34,  2.80s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [12:59<04:31,  2.80s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [13:39<09:26,  5.97s/pipeline]Optimization Progress:  99%|█████████▉| 2185/2200 [13:46<01:03,  4.20s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1058910948.0935482	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:47<00:00,  4.20s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [13:47<00:00,  2.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 2200/2200 [13:47<00:00,  2.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [13:48<00:00,  2.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:51<00:00,  2.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:53<00:00,  2.95s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 2200/2200 [13:54<00:00,  2.95s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2200/2300 [13:57<04:54,  2.95s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [14:00<04:51,  2.95s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [14:05<07:53,  4.83s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [14:17<01:01,  3.42s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1058910948.0935482	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2300/2300 [14:17<00:00,  3.42s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [14:17<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [14:17<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [14:17<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [14:17<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [14:18<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [14:18<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [14:20<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [14:24<00:00,  2.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [14:24<00:00,  2.40s/pipeline]Optimization Progress:  96%|█████████▌| 2303/2400 [14:27<04:19,  2.68s/pipeline]Optimization Progress:  96%|█████████▌| 2303/2400 [14:40<04:19,  2.68s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [14:54<15:50,  9.90s/pipeline]Optimization Progress:  99%|█████████▉| 2384/2400 [15:01<01:51,  6.96s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1058910948.0935482	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2400/2400 [15:02<00:00,  6.96s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [15:02<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2400/2400 [15:02<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 2400/2400 [15:06<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 2400/2400 [15:07<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [15:08<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [15:08<00:00,  4.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 2400/2400 [15:12<00:00,  4.89s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [15:13<11:03,  6.70s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [15:13<11:03,  6.70s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [15:13<10:56,  6.70s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [15:42<12:11,  7.62s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [15:50<01:25,  5.37s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-1058910948.0935482	GradientBoostingRegressor(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=5, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7500000000000001)
-3	-1026748725.4029859	LinearSVR(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-4	-916963548.4037994	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2500/2500 [15:51<00:00,  5.37s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [15:51<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [15:52<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [15:52<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 2500/2500 [15:53<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [15:54<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [15:54<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 2500/2500 [15:54<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 2500/2500 [15:54<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [15:55<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [15:56<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2500/2500 [15:57<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [15:59<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [15:59<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [16:00<00:00,  3.76s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [16:00<06:12,  3.76s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [16:00<06:36,  4.05s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2502/2600 [16:00<06:36,  4.05s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [16:12<07:25,  4.64s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [16:19<00:52,  3.27s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:19<00:00,  3.27s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [16:19<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:21<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 2600/2600 [16:23<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [16:24<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [16:27<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 2600/2600 [16:27<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [16:28<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [16:29<00:00,  2.30s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [16:30<00:00,  2.30s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [16:31<05:31,  3.39s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [16:31<05:31,  3.39s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [18:03<25:45, 16.10s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [18:13<03:00, 11.31s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:14<00:00, 11.31s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [18:14<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 2700/2700 [18:15<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [18:16<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:16<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [18:19<00:00,  7.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [18:21<00:00,  7.93s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [18:25<10:46,  6.66s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2703/2800 [18:25<10:46,  6.66s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [19:57<29:18, 18.51s/pipeline]Optimization Progress:  99%|█████████▉| 2785/2800 [20:06<03:14, 12.99s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)Optimization Progress: 100%|██████████| 2800/2800 [20:18<00:00,  9.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2803/2900 [20:18<15:03,  9.32s/pipeline]Optimization Progress:  97%|█████████▋| 2805/2900 [20:32<11:40,  7.37s/pipeline]Optimization Progress:  99%|█████████▉| 2885/2900 [20:39<01:17,  5.19s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-6	-793230019.2264118	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 2900/2900 [20:39<00:00,  5.19s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [20:39<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [20:40<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2900/2900 [20:41<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [20:42<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [20:45<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [20:45<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [20:46<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [20:47<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [20:48<00:00,  3.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [20:48<00:00,  3.64s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [20:49<05:40,  3.51s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [20:57<07:53,  4.93s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [21:02<00:55,  3.47s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-6	-793230019.2264118	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-785150648.3117179	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(FastICA(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [21:07<00:00,  3.47s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [21:07<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [21:10<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [21:12<00:00,  2.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [21:12<00:00,  2.52s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [21:12<04:11,  2.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3002/3100 [21:12<04:11,  2.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3003/3100 [21:12<04:08,  2.56s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3004/3100 [21:12<04:06,  2.56s/pipeline]Optimization Progress:  97%|█████████▋| 3006/3100 [21:22<03:58,  2.54s/pipeline]Optimization Progress: 100%|█████████▉| 3086/3100 [22:36<00:28,  2.05s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-6	-793230019.2264118	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-753665128.963226	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [22:40<00:00,  2.05s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [22:40<00:00,  1.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3100/3100 [22:40<00:00,  1.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [22:42<00:00,  1.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [22:44<00:00,  1.51s/pipeline]Optimization Progress:  97%|█████████▋| 3101/3200 [22:49<05:59,  3.63s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [22:49<05:59,  3.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3102/3200 [22:49<05:55,  3.63s/pipeline]Optimization Progress:  97%|█████████▋| 3104/3200 [27:50<52:20, 32.71s/pipeline]                                                                                Skipped pipeline #3106 due to time out. Continuing to the next pipeline.
Optimization Progress:  97%|█████████▋| 3106/3200 [27:50<51:14, 32.71s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 3185/3200 [29:25<05:48, 23.25s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-6	-748219012.0334934	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 3201pipeline [29:25, 23.25s/pipeline]Optimization Progress: 3201pipeline [29:25, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 3201pipeline [29:26, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [29:26, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [29:28, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [29:28, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [29:29, 16.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [29:33, 16.29s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [29:33<19:00, 12.00s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3205/3300 [29:33<19:00, 12.00s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3206/3300 [29:33<18:48, 12.00s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3207/3300 [29:33<18:36, 12.00s/pipeline]Optimization Progress:  97%|█████████▋| 3209/3300 [29:46<14:08,  9.33s/pipeline]Optimization Progress: 100%|█████████▉| 3289/3300 [29:49<01:11,  6.54s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-814469458.4081918	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-748219012.0334934	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-7	-675305793.4054568	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [29:50,  6.54s/pipeline]Optimization Progress: 3301pipeline [29:50,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 3301pipeline [29:50,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3301pipeline [29:51,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 3301pipeline [29:51,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3301pipeline [29:54,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [29:55,  4.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 3301pipeline [29:56,  4.62s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [29:57<06:11,  3.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3304/3400 [29:57<06:11,  3.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3305/3400 [29:57<06:07,  3.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3306/3400 [29:57<06:03,  3.87s/pipeline]Optimization Progress:  97%|█████████▋| 3308/3400 [30:38<08:51,  5.78s/pipeline]Optimization Progress: 100%|█████████▉| 3388/3400 [30:40<00:48,  4.05s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-814469458.4081918	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-727987436.0259789	LinearSVR(SelectPercentile(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), SelectPercentile__percentile=70), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-7	-675305793.4054568	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3401pipeline [30:43,  4.05s/pipeline]Optimization Progress: 3401pipeline [30:43,  2.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3401pipeline [30:44,  2.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3401pipeline [30:44,  2.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3401pipeline [30:46,  2.92s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [30:48<05:46,  3.53s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3402/3500 [30:48<05:46,  3.53s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [30:58<06:20,  3.97s/pipeline]Optimization Progress: 100%|█████████▉| 3484/3500 [31:17<00:45,  2.85s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-814469458.4081918	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-727987436.0259789	LinearSVR(SelectPercentile(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), SelectPercentile__percentile=70), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-7	-675305793.4054568	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-624604965.0495975	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(SelectFwe(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001), SelectFwe__alpha=0.027), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3501pipeline [31:20,  2.85s/pipeline]Optimization Progress: 3501pipeline [31:20,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3501pipeline [31:20,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [31:21,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [31:21,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 3501pipeline [31:24,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 3501pipeline [31:25,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3501pipeline [31:25,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3501pipeline [31:25,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3501pipeline [31:26,  2.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3501pipeline [31:27,  2.04s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [31:27<06:08,  3.76s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [31:27<06:08,  3.76s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [31:36<06:18,  3.94s/pipeline]Optimization Progress: 100%|█████████▉| 3584/3600 [31:39<00:44,  2.77s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-814469458.4081918	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-727987436.0259789	LinearSVR(SelectPercentile(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), SelectPercentile__percentile=70), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-7	-675305793.4054568	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-624604965.0495975	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(SelectFwe(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001), SelectFwe__alpha=0.027), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [31:40,  2.77s/pipeline]Optimization Progress: 3601pipeline [31:40,  1.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3601pipeline [31:40,  1.95s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3601pipeline [31:42,  1.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3601pipeline [31:43,  1.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 3601pipeline [31:43,  1.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [31:45,  1.95s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [31:50<03:12,  1.95s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [32:49<36:04, 22.09s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [34:21<04:44, 15.81s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-814469458.4081918	LinearSVR(MinMaxScaler(PolynomialFeatures(RobustScaler(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-662028706.9814379	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(CombineDFs(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), input_matrix), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-624604965.0495975	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(SelectFwe(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001), SelectFwe__alpha=0.027), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [34:24, 15.81s/pipeline]Optimization Progress: 3701pipeline [34:24, 11.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 3701pipeline [34:24, 11.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 3701pipeline [34:27, 11.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [34:29, 11.12s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [34:30<13:19,  8.33s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [34:30<13:19,  8.33s/pipeline]Optimization Progress:  98%|█████████▊| 3706/3800 [34:41<11:47,  7.53s/pipeline]Optimization Progress: 100%|█████████▉| 3786/3800 [34:46<01:14,  5.29s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-1063192830.0559868	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-662028706.9814379	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(CombineDFs(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), input_matrix), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-624604965.0495975	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(SelectFwe(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001), SelectFwe__alpha=0.027), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3801pipeline [34:47,  5.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3801pipeline [34:47,  5.29s/pipeline]Optimization Progress: 3801pipeline [34:47,  3.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [34:48,  3.71s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3801pipeline [34:55,  3.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3801pipeline [34:55,  3.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 3801pipeline [34:59,  3.71s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [34:59<06:03,  3.71s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [34:59<07:11,  4.45s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3803/3900 [34:59<07:11,  4.45s/pipeline]Optimization Progress:  98%|█████████▊| 3805/3900 [35:10<07:30,  4.75s/pipeline]Optimization Progress: 100%|█████████▉| 3885/3900 [35:14<00:50,  3.34s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [35:15,  3.34s/pipeline]Optimization Progress: 3901pipeline [35:15,  2.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [35:16,  2.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [35:17,  2.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [35:19,  2.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3901pipeline [35:23,  2.35s/pipeline]Optimization Progress:  98%|█████████▊| 3902/4000 [35:26<07:47,  4.77s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [35:26<07:47,  4.77s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [35:34<07:22,  4.61s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [36:40<00:55,  3.47s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4001pipeline [36:41,  3.47s/pipeline]Optimization Progress: 4001pipeline [36:41,  2.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 4001pipeline [36:43,  2.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 4001pipeline [36:50,  2.44s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4002/4100 [36:51<03:58,  2.44s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [36:51<05:21,  3.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4003/4100 [36:51<05:21,  3.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4004/4100 [36:51<05:18,  3.32s/pipeline]Optimization Progress:  98%|█████████▊| 4006/4100 [38:33<19:31, 12.46s/pipeline]Optimization Progress: 100%|█████████▉| 4086/4100 [38:36<02:02,  8.74s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 4101pipeline [38:37,  8.74s/pipeline]Optimization Progress: 4101pipeline [38:37,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:42,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4101pipeline [38:42,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:44,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 4101pipeline [38:45,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:45,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [38:45,  6.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [38:45,  6.13s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [38:47<09:23,  5.81s/pipeline]Optimization Progress:  98%|█████████▊| 4104/4200 [38:59<12:01,  7.52s/pipeline]Optimization Progress: 100%|█████████▉| 4184/4200 [40:26<01:29,  5.59s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [40:26,  5.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [40:26,  5.59s/pipeline]Optimization Progress: 4201pipeline [40:26,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 4201pipeline [40:26,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4201pipeline [40:26,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [40:27,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [40:28,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 4201pipeline [40:28,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [40:36,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [40:37,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [40:39,  3.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [40:39,  3.92s/pipeline]Optimization Progress: 4201pipeline [40:40,  3.92s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [40:40<07:47,  4.82s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [40:40<07:47,  4.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4204/4300 [40:40<07:42,  4.82s/pipeline]Optimization Progress:  98%|█████████▊| 4206/4300 [40:52<07:05,  4.53s/pipeline]Optimization Progress: 100%|█████████▉| 4286/4300 [42:25<00:49,  3.52s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-4	-846358597.1057171	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [42:30,  3.52s/pipeline]Optimization Progress: 4301pipeline [42:30,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4301pipeline [42:31,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [42:32,  2.57s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4301/4400 [42:36<04:14,  2.57s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [42:36<05:47,  3.54s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [42:48<09:52,  6.11s/pipeline]Optimization Progress: 100%|█████████▉| 4383/4400 [42:52<01:12,  4.29s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-4	-846358597.1057171	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [42:54,  4.29s/pipeline]Optimization Progress: 4401pipeline [42:54,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4401pipeline [42:55,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [42:55,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4401pipeline [42:57,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4401pipeline [42:57,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [42:58,  3.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [42:59,  3.04s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4401/4500 [43:03<05:00,  3.04s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [43:03<08:04,  4.95s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4402/4500 [43:03<08:04,  4.95s/pipeline]Optimization Progress:  98%|█████████▊| 4404/4500 [47:10<1:04:48, 40.51s/pipeline]Optimization Progress: 100%|█████████▉| 4484/4500 [47:14<07:33, 28.37s/pipeline]  
Generation 44 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-4	-846358597.1057171	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [47:29, 28.37s/pipeline]Optimization Progress: 4501pipeline [47:29, 20.12s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [47:29<22:35, 14.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4504/4600 [47:29<22:35, 14.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4505/4600 [47:29<22:21, 14.12s/pipeline]Optimization Progress:  98%|█████████▊| 4507/4600 [47:43<17:23, 11.22s/pipeline]Optimization Progress: 100%|█████████▉| 4587/4600 [47:50<01:42,  7.88s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-4	-846358597.1057171	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [47:51,  7.88s/pipeline]Optimization Progress: 4601pipeline [47:51,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4601pipeline [47:52,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [47:55,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4601pipeline [47:55,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [47:55,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4601pipeline [47:58,  5.53s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4601pipeline [48:02,  5.53s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [48:04<08:15,  5.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4604/4700 [48:04<08:15,  5.17s/pipeline]Optimization Progress:  98%|█████████▊| 4606/4700 [52:23<1:06:33, 42.48s/pipeline]Optimization Progress: 100%|█████████▉| 4686/4700 [52:26<06:56, 29.75s/pipeline]  
Generation 46 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-913593603.024291	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-4	-846358597.1057171	RandomForestRegressor(AdaBoostRegressor(RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.8500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=5, RandomForestRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=6, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [52:28, 29.75s/pipeline]Optimization Progress: 4701pipeline [52:28, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [52:32, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [52:32, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [52:34, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [52:34, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [52:34, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4701pipeline [52:37, 20.86s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [52:37, 20.86s/pipeline]Optimization Progress:  98%|█████████▊| 4703/4800 [52:40<26:31, 16.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4703/4800 [52:40<26:31, 16.41s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [52:40<26:15, 16.41s/pipeline]Optimization Progress:  98%|█████████▊| 4706/4800 [54:32<35:35, 22.71s/pipeline]Optimization Progress:  98%|█████████▊| 4707/4800 [55:05<39:50, 25.71s/pipeline]Optimization Progress: 100%|█████████▉| 4786/4800 [55:10<04:12, 18.02s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-811721879.4945809	KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), KNeighborsRegressor__n_neighbors=9, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform)
-5	-707995936.3816866	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [55:11, 18.02s/pipeline]Optimization Progress: 4801pipeline [55:11, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4801pipeline [55:12, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4801pipeline [55:17, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [55:17, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [55:19, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4801pipeline [55:22, 12.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4801pipeline [55:23, 12.63s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [55:24<20:50, 12.63s/pipeline]Optimization Progress:  98%|█████████▊| 4802/4900 [55:24<20:47, 12.73s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [55:24<20:47, 12.73s/pipeline]Optimization Progress:  98%|█████████▊| 4804/4900 [56:58<36:40, 22.92s/pipeline]Optimization Progress: 100%|█████████▉| 4884/4900 [58:57<04:23, 16.49s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-1063037650.8995701	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-811721879.4945809	KNeighborsRegressor(Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=4), KNeighborsRegressor__n_neighbors=9, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform)
-5	-666560579.1702563	LinearSVR(PolynomialFeatures(RobustScaler(FastICA(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-630661241.7442046	LinearSVR(RobustScaler(PolynomialFeatures(FastICA(LinearSVR(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), FastICA__tol=0.7000000000000001), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-8	-512679989.45019513	LinearSVR(RobustScaler(PolynomialFeatures(RobustScaler(FastICA(LinearSVR(GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.1), FastICA__tol=0.7000000000000001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4901pipeline [58:58, 16.49s/pipeline]Optimization Progress: 4901pipeline [58:58, 11.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4901pipeline [59:00, 11.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 4901pipeline [59:04, 11.55s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4901/5000 [59:08<19:03, 11.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4902/5000 [59:08<18:51, 11.55s/pipeline]Optimization Progress:  98%|█████████▊| 4903/5000 [59:08<15:38,  9.68s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4903/5000 [59:08<15:38,  9.68s/pipeline]Optimization Progress:  98%|█████████▊| 4905/5000 [1:00:43<33:16, 21.01s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4984/5000 [1:00:43<05:36, 21.01s/pipeline]                                                                                  60.87 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 4984/5000 [1:00:43<05:36, 21.01s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4984/5000 [1:00:43<05:36, 21.01s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 4984/5000 [1:00:43<05:36, 21.01s/pipeline]                                                                                  Best pipeline:
0. PCA(iterated_power=8, svd_solver='randomized')
1. StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.85,
                                                      learning_rate=0.001,
                                                      max_depth=5,
                                                      max_features=0.2,
                                                      min_samples_leaf=16,
                                                      subsample=0.1))
2. StackingEstimator(estimator=LinearSVR(C=0.5, epsilon=0.001,
                                      loss='squared_epsilon_insensitive',
                                      tol=0.1))
3. FastICA(tol=0.7000000000000001)
4. RobustScaler()
5. PolynomialFeatures(include_bias=False)
6. RobustScaler()
7. LinearSVR(C=10.0, epsilon=0.001, tol=0.001)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
