30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   7%|▋         | 7/100 [00:30<06:44,  4.35s/pipeline]Optimization Progress:  87%|████████▋ | 87/100 [00:34<00:39,  3.06s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:34<00:00,  3.06s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:34<00:00,  3.06s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:34<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:36<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 100/100 [00:36<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:37<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:37<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:38<00:00,  2.15s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:38<00:00,  2.15s/pipeline]Optimization Progress:  52%|█████▏    | 104/200 [00:40<03:02,  1.90s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 104/200 [00:40<03:02,  1.90s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▎    | 105/200 [00:40<03:00,  1.90s/pipeline]Optimization Progress:  54%|█████▎    | 107/200 [00:54<04:19,  2.79s/pipeline]Optimization Progress:  94%|█████████▎| 187/200 [01:49<00:28,  2.15s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-552271810.0162525	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-530849407.1431993	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 200/200 [01:50<00:00,  2.15s/pipeline]Optimization Progress: 100%|██████████| 200/200 [01:50<00:00,  1.54s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:55<00:00,  1.54s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [01:56<02:24,  1.51s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 204/300 [01:56<02:24,  1.51s/pipeline]Optimization Progress:  69%|██████▊   | 206/300 [03:25<22:46, 14.53s/pipeline]Optimization Progress:  95%|█████████▌| 286/300 [03:29<02:22, 10.19s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-552271810.0162525	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-530849407.1431993	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [03:31<00:00, 10.19s/pipeline]Optimization Progress: 100%|██████████| 300/300 [03:31<00:00,  7.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 300/300 [03:32<00:00,  7.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [03:34<00:00,  7.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [03:34<00:00,  7.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 300/300 [03:35<00:00,  7.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [03:35<00:00,  7.17s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [03:37<10:58,  6.65s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [05:22<58:58, 36.11s/pipeline]Optimization Progress:  96%|█████████▌| 382/400 [05:28<07:35, 25.30s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-552271810.0162525	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-2	-530849407.1431993	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [05:29<00:00, 25.30s/pipeline]Optimization Progress: 100%|██████████| 400/400 [05:29<00:00, 17.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 400/400 [05:34<00:00, 17.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [05:35<00:00, 17.74s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 400/500 [05:36<29:33, 17.74s/pipeline]Optimization Progress:  80%|████████  | 401/500 [05:36<23:38, 14.33s/pipeline]Optimization Progress:  80%|████████  | 402/500 [05:42<19:22, 11.86s/pipeline]Optimization Progress:  96%|█████████▋| 482/500 [05:47<02:29,  8.32s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-544092720.7886204	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-530849407.1431993	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [05:48<00:00,  8.32s/pipeline]Optimization Progress: 100%|██████████| 500/500 [05:48<00:00,  5.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [05:49<00:00,  5.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [05:52<00:00,  5.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [05:52<00:00,  5.83s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [05:54<00:00,  5.83s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [06:00<09:37,  5.83s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [06:01<10:03,  6.16s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [07:48<01:24,  4.71s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-541293400.2216107	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-530849407.1431993	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=20, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-507676269.1971943	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [07:54<00:00,  4.71s/pipeline]Optimization Progress: 100%|██████████| 600/600 [07:54<00:00,  3.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [07:55<00:00,  3.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 600/600 [07:55<00:00,  3.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [07:56<00:00,  3.39s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [07:57<04:09,  2.60s/pipeline]Optimization Progress:  86%|████████▋ | 605/700 [08:13<10:31,  6.65s/pipeline]Optimization Progress:  98%|█████████▊| 685/700 [08:17<01:10,  4.67s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-541293400.2216107	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-520767215.69951546	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-507676269.1971943	ExtraTreesRegressor(PCA(ExtraTreesRegressor(CombineDFs(input_matrix, input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [08:19<00:00,  4.67s/pipeline]Optimization Progress: 100%|██████████| 700/700 [08:19<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 700/700 [08:19<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [08:20<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 700/700 [08:21<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [08:22<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [08:22<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [08:25<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 700/700 [08:25<00:00,  3.32s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [08:25<06:54,  4.19s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [08:25<06:54,  4.19s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [08:25<06:50,  4.19s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [09:18<13:07,  8.21s/pipeline]Optimization Progress:  98%|█████████▊| 784/800 [09:22<01:32,  5.76s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-540677888.8525566	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-520767215.69951546	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-498277073.41973054	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [09:26<00:00,  5.76s/pipeline]Optimization Progress: 100%|██████████| 800/800 [09:26<00:00,  4.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 800/800 [09:28<00:00,  4.09s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 800/800 [09:31<00:00,  4.09s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [09:33<06:25,  3.93s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [12:54<1:42:15, 63.26s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [13:00<12:33, 44.30s/pipeline]  
Generation 8 - Current Pareto front scores:
-1	-536787122.55144995	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-520767215.69951546	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [13:02<00:00, 44.30s/pipeline]Optimization Progress: 100%|██████████| 900/900 [13:02<00:00, 31.06s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 900/900 [13:04<00:00, 31.06s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [13:09<36:14, 22.42s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 903/1000 [13:09<36:14, 22.42s/pipeline]Optimization Progress:  90%|█████████ | 905/1000 [13:37<31:25, 19.85s/pipeline]Optimization Progress:  98%|█████████▊| 985/1000 [13:42<03:28, 13.92s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-536787122.55144995	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-518844005.5724495	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [13:42<00:00, 13.92s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [13:42<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [13:43<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [13:44<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [13:45<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1000/1000 [13:46<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [13:50<00:00,  9.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 1000/1000 [13:51<00:00,  9.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [13:52<16:05,  9.75s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [13:52<13:32,  8.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [13:52<13:32,  8.30s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [14:02<11:41,  7.31s/pipeline]Optimization Progress:  99%|█████████▊| 1084/1100 [14:38<01:24,  5.25s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-536787122.55144995	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-518844005.5724495	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [14:39<00:00,  5.25s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [14:39<00:00,  3.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [14:43<00:00,  3.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [14:49<00:00,  3.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 1100/1100 [14:49<00:00,  3.70s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [14:49<05:48,  3.59s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [15:00<09:02,  5.65s/pipeline]Optimization Progress:  99%|█████████▊| 1184/1200 [15:05<01:03,  3.97s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-518844005.5724495	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1200/1200 [15:05<00:00,  3.97s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [15:06<00:00,  3.97s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [15:06<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [15:06<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [15:06<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:11<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [15:11<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:13<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [15:13<00:00,  2.79s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [15:20<04:36,  2.79s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [16:03<17:19, 10.61s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [16:08<02:14,  7.45s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [16:09<00:00,  7.45s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [16:09<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [16:10<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [16:12<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [16:15<00:00,  5.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1300/1300 [16:16<00:00,  5.23s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1300/1400 [16:18<08:42,  5.23s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [16:18<10:32,  6.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1301/1400 [16:19<10:32,  6.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1302/1400 [16:19<10:26,  6.39s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [16:35<09:51,  6.17s/pipeline]Optimization Progress:  99%|█████████▉| 1384/1400 [16:49<01:09,  4.37s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [16:58<00:00,  4.37s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [16:58<00:00,  3.23s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [17:00<04:07,  2.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1402/1500 [17:00<04:07,  2.52s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [17:12<05:38,  3.52s/pipeline]Optimization Progress:  99%|█████████▉| 1484/1500 [17:23<00:40,  2.51s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1500/1500 [17:24<00:00,  2.51s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [17:24<00:00,  1.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [17:25<00:00,  1.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 1500/1500 [17:25<00:00,  1.77s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 1500/1500 [17:34<00:00,  1.77s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [17:35<04:53,  2.99s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [17:50<10:39,  6.59s/pipeline]Optimization Progress:  99%|█████████▉| 1583/1600 [17:58<01:18,  4.64s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [18:06<00:00,  4.64s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [18:06<00:00,  3.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 1600/1600 [18:06<00:00,  3.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1600/1600 [18:06<00:00,  3.40s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [18:09<05:09,  3.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1601/1700 [18:09<05:09,  3.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1602/1700 [18:09<05:06,  3.13s/pipeline]Optimization Progress:  94%|█████████▍| 1604/1700 [18:20<05:21,  3.35s/pipeline]Optimization Progress:  99%|█████████▉| 1684/1700 [18:27<00:37,  2.37s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-536641903.96187097	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [18:30<00:00,  2.37s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [18:30<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [18:31<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1700/1700 [18:35<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [18:37<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [18:38<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:30:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 1700/1700 [18:38<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [18:38<00:00,  1.70s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [18:38<06:23,  3.87s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1701/1800 [18:38<06:23,  3.87s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [19:31<17:07, 10.60s/pipeline]Optimization Progress:  99%|█████████▉| 1783/1800 [19:40<02:06,  7.45s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-534355371.4051013	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 1800/1800 [19:45<00:00,  7.45s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [19:45<00:00,  5.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 1800/1800 [19:46<00:00,  5.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 1800/1800 [19:47<00:00,  5.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:31:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 1800/1800 [19:47<00:00,  5.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [22:31:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 1800/1800 [19:47<00:00,  5.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [19:50<00:00,  5.30s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [20:03<15:17,  9.26s/pipeline]Optimization Progress:  99%|█████████▉| 1881/1900 [20:11<02:03,  6.51s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-534014423.7257652	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 1900/1900 [20:12<00:00,  6.51s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [20:12<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1900/1900 [20:17<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [20:20<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [20:21<00:00,  4.59s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [20:22<06:45,  4.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1903/2000 [20:22<06:45,  4.18s/pipeline]Optimization Progress:  95%|█████████▌| 1905/2000 [22:08<29:52, 18.86s/pipeline]Optimization Progress:  99%|█████████▉| 1985/2000 [23:33<03:22, 13.52s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-534014423.7257652	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [23:38<00:00, 13.52s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [23:38<00:00,  9.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [23:40<00:00,  9.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2000/2000 [23:42<00:00,  9.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [23:42<00:00,  9.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [23:45<00:00,  9.55s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [23:45<12:49,  7.86s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [23:56<14:12,  8.79s/pipeline]Optimization Progress:  99%|█████████▉| 2083/2100 [24:05<01:45,  6.18s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-534014423.7257652	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [24:06<00:00,  6.18s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [24:06<00:00,  4.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [24:08<00:00,  4.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [24:09<00:00,  4.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [24:11<00:00,  4.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2100/2200 [24:17<07:14,  4.34s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [24:17<10:27,  6.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2101/2200 [24:17<10:27,  6.34s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [24:27<09:31,  5.89s/pipeline]Optimization Progress:  99%|█████████▉| 2183/2200 [24:35<01:10,  4.16s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-534014423.7257652	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 2200/2200 [24:36<00:00,  4.16s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [24:36<00:00,  2.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [24:38<00:00,  2.92s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [24:47<08:34,  5.20s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [25:06<15:38,  9.58s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [25:15<02:01,  6.74s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-534014423.7257652	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-481160551.58915377	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [25:19<00:00,  6.74s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [25:19<00:00,  4.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [25:19<00:00,  4.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:37:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 2300/2300 [25:20<00:00,  4.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 2300/2300 [25:21<00:00,  4.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 2300/2300 [25:26<00:00,  4.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2300/2400 [25:27<07:58,  4.79s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [25:27<09:32,  5.79s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [25:37<11:29,  7.04s/pipeline]Optimization Progress:  99%|█████████▉| 2382/2400 [25:46<01:29,  4.96s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-534008518.6061514	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2400/2400 [25:47<00:00,  4.96s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [25:47<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [25:49<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [25:49<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 2400/2400 [25:50<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [25:52<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [25:54<00:00,  3.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [25:55<00:00,  3.48s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [26:00<00:00,  3.48s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [26:00<10:39,  6.46s/pipeline]Optimization Progress:  96%|█████████▌| 2402/2500 [26:25<19:22, 11.86s/pipeline]Optimization Progress:  99%|█████████▉| 2482/2500 [26:30<02:29,  8.32s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-534008518.6061514	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:38:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 2500/2500 [26:31<00:00,  8.32s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [26:31<00:00,  5.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [26:32<00:00,  5.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [26:34<00:00,  5.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [26:37<00:00,  5.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:38:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 2500/2500 [26:39<00:00,  5.84s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [26:42<12:20,  7.48s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [26:50<12:39,  7.75s/pipeline]Optimization Progress:  99%|█████████▉| 2582/2600 [26:56<01:38,  5.45s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-533830668.22290134	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:01<00:00,  5.45s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [27:01<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:03<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:05<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2600/2600 [27:07<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:07<00:00,  3.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:09<00:00,  3.90s/pipeline]Optimization Progress:  96%|█████████▋| 2601/2700 [27:10<08:48,  5.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2601/2700 [27:10<08:48,  5.34s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [27:37<12:35,  7.79s/pipeline]Optimization Progress:  99%|█████████▉| 2683/2700 [27:43<01:33,  5.48s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-533830668.22290134	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 2700/2700 [27:52<00:00,  5.48s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [27:52<00:00,  3.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2700/2700 [27:55<00:00,  3.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [27:55<00:00,  3.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 2700/2700 [27:56<00:00,  3.98s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2700/2700 [27:57<00:00,  3.98s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [27:58<05:27,  3.38s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [28:44<26:10, 16.36s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [29:12<03:04, 11.55s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-533830668.22290134	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 100%|██████████| 2800/2800 [29:15<00:00, 11.55s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [29:15<00:00,  8.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:41:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 2800/2800 [29:15<00:00,  8.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [29:19<00:00,  8.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [29:22<00:00,  8.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 2800/2800 [29:22<00:00,  8.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [29:23<00:00,  8.15s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [29:28<12:31,  7.67s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [29:28<12:31,  7.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2803/2900 [29:28<12:23,  7.67s/pipeline]Optimization Progress:  97%|█████████▋| 2805/2900 [30:01<13:45,  8.69s/pipeline]Optimization Progress:  99%|█████████▉| 2885/2900 [30:15<01:32,  6.13s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-533830668.22290134	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-515326546.5508193	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2900/2900 [30:15<00:00,  6.13s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [30:15<00:00,  4.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [30:18<00:00,  4.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2900/2900 [30:19<00:00,  4.30s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [30:30<00:00,  4.30s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2900/3000 [30:30<07:09,  4.30s/pipeline]Optimization Progress:  97%|█████████▋| 2901/3000 [30:30<12:24,  7.52s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2901/3000 [30:30<12:24,  7.52s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [30:43<11:34,  7.16s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [30:50<01:25,  5.04s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-533830668.22290134	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [30:51<00:00,  5.04s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [30:51<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [30:51<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [30:52<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 3000/3000 [30:53<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [30:59<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 3000/3000 [30:59<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [31:04<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 3000/3000 [31:06<00:00,  3.54s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [31:21<18:54, 11.46s/pipeline]Optimization Progress:  99%|█████████▉| 3081/3100 [31:26<02:32,  8.04s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-468682704.31139076	ExtraTreesRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-467261665.7044724	ExtraTreesRegressor(RobustScaler(VarianceThreshold(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), VarianceThreshold__threshold=0.1)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-7	-466624333.1044776	ExtraTreesRegressor(SelectPercentile(ExtraTreesRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), SelectPercentile__percentile=35), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [31:29<00:00,  8.04s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [31:29<00:00,  5.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [31:32<00:00,  5.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [31:34<00:00,  5.68s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [31:41<09:23,  5.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3102/3200 [31:41<09:23,  5.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [31:41<09:17,  5.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3104/3200 [31:41<09:11,  5.75s/pipeline]Optimization Progress:  97%|█████████▋| 3106/3200 [31:49<07:17,  4.66s/pipeline]Optimization Progress: 100%|█████████▉| 3186/3200 [31:55<00:45,  3.28s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-7	-452663311.8603009	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.5), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [31:55<00:00,  3.28s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [31:55<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 3200/3200 [31:56<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [32:02<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [32:03<00:00,  2.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [22:44:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f87a80fbdc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f87a820c669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f87a8219f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f87a8200cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f87a80edf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f7db5ee89dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f7db5ee8067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f7db5f0027e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f7db5f00cb4]

.
Optimization Progress: 100%|██████████| 3200/3200 [32:05<00:00,  2.30s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [32:10<00:00,  2.30s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [32:11<10:24,  6.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3201/3300 [32:11<10:24,  6.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [32:11<10:17,  6.30s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [32:27<09:36,  6.00s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [32:32<01:07,  4.22s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-434106229.6457737	ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 3300/3300 [32:32<00:00,  4.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 3300/3300 [32:45<00:00,  4.22s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [32:45<00:00,  3.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [32:46<00:00,  3.20s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [32:47<04:43,  2.86s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3301/3400 [32:47<04:43,  2.86s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [34:09<23:04, 14.27s/pipeline]Optimization Progress: 100%|█████████▉| 3383/3400 [34:14<02:50, 10.01s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-434106229.6457737	ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 3400/3400 [34:22<00:00, 10.01s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [34:22<00:00,  7.15s/pipeline]Optimization Progress:  97%|█████████▋| 3404/3500 [34:29<08:51,  5.53s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3404/3500 [34:29<08:51,  5.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3405/3500 [34:29<08:45,  5.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3406/3500 [34:29<08:40,  5.53s/pipeline]Optimization Progress:  97%|█████████▋| 3408/3500 [36:12<17:44, 11.57s/pipeline]Optimization Progress: 100%|█████████▉| 3488/3500 [36:21<01:37,  8.13s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-514575552.50159585	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-434106229.6457737	ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-6	-431707333.16358966	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [36:21<00:00,  8.13s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [36:21<00:00,  5.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3500/3500 [36:29<00:00,  5.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [36:30<00:00,  5.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [36:31<00:00,  5.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3500/3500 [36:33<00:00,  5.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [36:35<00:00,  5.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [36:37<09:24,  5.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [36:37<09:18,  5.70s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [36:37<08:55,  5.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [36:37<08:55,  5.52s/pipeline]Optimization Progress:  97%|█████████▋| 3505/3600 [37:01<11:54,  7.52s/pipeline]Optimization Progress: 100%|█████████▉| 3585/3600 [37:08<01:19,  5.29s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 3600/3600 [37:08<00:00,  5.29s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [37:09<00:00,  5.29s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [37:09<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3600/3600 [37:13<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 3600/3600 [37:14<00:00,  3.71s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3600/3600 [37:16<00:00,  3.71s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [37:20<00:00,  3.71s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3600/3700 [37:22<06:11,  3.71s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [37:22<11:02,  6.69s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [37:36<14:27,  8.85s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [37:43<01:52,  6.22s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-533767293.6008872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=10, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [37:44<00:00,  6.22s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [37:44<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [37:51<00:00,  4.36s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [37:55<07:40,  4.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3702/3800 [37:55<07:40,  4.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3703/3800 [37:55<07:35,  4.70s/pipeline]Optimization Progress:  98%|█████████▊| 3705/3800 [38:08<07:15,  4.59s/pipeline]Optimization Progress: 100%|█████████▉| 3785/3800 [38:15<00:48,  3.24s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [38:16<00:00,  3.24s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [38:16<00:00,  2.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 3800/3800 [38:22<00:00,  2.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [38:24<00:00,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [38:27<03:45,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [38:27<03:42,  2.27s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [38:27<04:19,  2.68s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [39:31<33:46, 21.11s/pipeline]Optimization Progress: 100%|█████████▉| 3884/3900 [39:39<03:56, 14.80s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3900/3900 [39:40<00:00, 14.80s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [39:40<00:00, 10.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 3900/3900 [39:40<00:00, 10.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [39:41<00:00, 10.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [39:43<00:00, 10.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [39:45<00:00, 10.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [39:47<00:00, 10.39s/pipeline]Optimization Progress:  98%|█████████▊| 3902/4000 [39:50<14:22,  8.80s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [39:50<14:22,  8.80s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3903/4000 [39:50<14:13,  8.80s/pipeline]Optimization Progress:  98%|█████████▊| 3905/4000 [40:01<11:34,  7.31s/pipeline]Optimization Progress: 100%|█████████▉| 3985/4000 [41:40<01:22,  5.49s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-458203491.5846664	ExtraTreesRegressor(PCA(ExtraTreesRegressor(ZeroCount(input_matrix), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4000/4000 [41:48<00:00,  5.49s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [41:48<00:00,  4.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [41:48<00:00,  4.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [41:48<00:00,  4.00s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4000/4100 [41:50<06:39,  4.00s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [41:50<05:48,  3.52s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [42:07<12:18,  7.54s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [44:24<01:44,  5.79s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-441371808.8579494	GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [44:29<00:00,  5.79s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [44:29<00:00,  4.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [44:29<00:00,  4.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [44:31<00:00,  4.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4100/4100 [44:33<00:00,  4.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 4100/4100 [44:36<00:00,  4.13s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [44:36<08:08,  4.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4101/4200 [44:36<08:08,  4.94s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4102/4200 [44:36<08:03,  4.94s/pipeline]Optimization Progress:  98%|█████████▊| 4104/4200 [44:48<07:34,  4.73s/pipeline]Optimization Progress: 100%|█████████▉| 4184/4200 [46:28<00:58,  3.69s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-441371808.8579494	GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [46:28<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 4200/4200 [46:28<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [46:30<00:00,  3.69s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [46:30<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4200/4200 [46:34<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [46:38<00:00,  2.63s/pipeline]Optimization Progress:  98%|█████████▊| 4201/4300 [46:52<13:37,  8.25s/pipeline]Optimization Progress: 100%|█████████▉| 4281/4300 [46:59<01:50,  5.81s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-441371808.8579494	GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-5	-410179389.4305891	DecisionTreeRegressor(RobustScaler(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized)), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=9)
-6	-407714260.47679293	ExtraTreesRegressor(ExtraTreesRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9000000000000001, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=17, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7000000000000001, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [47:00<00:00,  5.81s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [47:00<00:00,  4.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [47:09<00:00,  4.07s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [47:10<00:00,  4.07s/pipeline]Optimization Progress:  98%|█████████▊| 4301/4400 [47:28<18:41, 11.33s/pipeline]Optimization Progress: 100%|█████████▉| 4381/4400 [47:34<02:31,  7.95s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-441371808.8579494	GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [47:34<00:00,  7.95s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [47:34<00:00,  5.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [47:41<00:00,  5.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [47:44<00:00,  5.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [47:44<00:00,  5.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [47:44<00:00,  5.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [47:45<00:00,  5.57s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [47:50<09:11,  5.57s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [47:58<12:13,  7.49s/pipeline]Optimization Progress: 100%|█████████▉| 4482/4500 [48:05<01:34,  5.27s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [48:07<00:00,  5.27s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [48:07<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [48:08<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4500/4500 [48:10<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [48:17<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [48:17<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [48:19<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [48:19<00:00,  3.72s/pipeline]Optimization Progress:  98%|█████████▊| 4501/4600 [48:19<10:09,  6.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4501/4600 [48:19<10:09,  6.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4502/4600 [48:19<10:02,  6.15s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [49:04<14:04,  8.79s/pipeline]Optimization Progress: 100%|█████████▉| 4584/4600 [49:12<01:38,  6.19s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)Optimization Progress: 100%|██████████| 4600/4600 [49:24<00:00,  4.55s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [49:24<07:25,  4.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [49:24<07:21,  4.55s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [51:34<17:20, 10.95s/pipeline]Optimization Progress: 100%|█████████▉| 4685/4700 [51:40<01:55,  7.69s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [51:41<00:00,  7.69s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [51:41<00:00,  5.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 4700/4700 [51:43<00:00,  5.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [51:45<00:00,  5.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4700/4700 [51:47<00:00,  5.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 4700/4700 [51:51<00:00,  5.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4700/4800 [51:53<08:59,  5.40s/pipeline]Optimization Progress:  98%|█████████▊| 4701/4800 [51:53<12:20,  7.48s/pipeline]Optimization Progress:  98%|█████████▊| 4702/4800 [52:04<13:57,  8.55s/pipeline]Optimization Progress: 100%|█████████▉| 4782/4800 [53:46<01:54,  6.36s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 4800/4800 [53:50<00:00,  6.36s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [53:50<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [53:50<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [53:52<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4800/4800 [53:52<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 4800/4800 [53:52<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 4800/4800 [53:55<00:00,  4.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [53:55<00:00,  4.53s/pipeline]Optimization Progress:  98%|█████████▊| 4801/4900 [53:55<07:47,  4.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [53:55<07:47,  4.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [53:55<07:43,  4.72s/pipeline]Optimization Progress:  98%|█████████▊| 4804/4900 [55:04<16:13, 10.14s/pipeline]Optimization Progress: 100%|█████████▉| 4884/4900 [55:11<01:54,  7.13s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-508073740.4254028	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4900/4900 [55:12<00:00,  7.13s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [55:12<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [55:15<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 4900/4900 [55:19<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4900/4900 [55:20<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [55:20<00:00,  5.01s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [55:23<11:19,  6.86s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4901/5000 [55:23<11:19,  6.86s/pipeline]Optimization Progress:  98%|█████████▊| 4903/5000 [56:20<21:30, 13.31s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 4983/5000 [1:01:20<02:57, 10.44s/pipeline]                                                                                  Skipped pipeline #5000 due to time out. Continuing to the next pipeline.
Optimization Progress: 100%|██████████| 5000/5000 [1:01:20<00:00, 10.44s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-533689891.78369606	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0)
-2	-504516831.2362839	LassoLarsCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=3, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.7000000000000001), LassoLarsCV__normalize=True)
-3	-480160101.8671296	ExtraTreesRegressor(PCA(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=10, PCA__svd_solver=randomized), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100)
-4	-426628748.50041974	DecisionTreeRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)
-5	-383936752.3239225	DecisionTreeRegressor(GradientBoostingRegressor(PCA(ExtraTreesRegressor(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=11, ExtraTreesRegressor__min_samples_split=5, ExtraTreesRegressor__n_estimators=100), PCA__iterated_power=1, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001), DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=8)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [1:01:22, 10.44s/pipeline]Optimization Progress: 5001pipeline [1:01:22,  7.33s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [1:01:22,  7.33s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [1:01:26,  7.33s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [1:01:31,  7.33s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5001pipeline [1:01:32,  7.33s/pipeline]Optimization Progress:  98%|█████████▊| 5003/5100 [1:01:32<10:53,  6.74s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5003/5100 [1:01:32<10:53,  6.74s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 5004/5100 [1:01:32<10:47,  6.74s/pipeline]                                                                                  61.66 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 5004/5100 [1:01:32<10:47,  6.74s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 5004/5100 [1:01:32<10:47,  6.74s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 5004/5100 [1:01:32<10:47,  6.74s/pipeline]                                                                                  /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
