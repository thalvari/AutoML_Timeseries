30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   2%|▏         | 2/100 [00:06<05:29,  3.36s/pipeline]Optimization Progress:  82%|████████▏ | 82/100 [00:21<00:43,  2.41s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 100/100 [00:25<00:00,  2.41s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:25<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:25<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:25<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:26<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:59:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 100/100 [00:27<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 [06:59:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 100/100 [00:27<00:00,  1.75s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:27<00:00,  1.75s/pipeline]Optimization Progress:  53%|█████▎    | 106/200 [00:27<02:04,  1.32s/pipeline]Optimization Progress:  54%|█████▎    | 107/200 [00:32<03:41,  2.38s/pipeline]Optimization Progress:  94%|█████████▎| 187/200 [01:00<00:23,  1.77s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-554204588.4935791	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:02<00:00,  1.77s/pipeline]Optimization Progress: 100%|██████████| 200/200 [01:02<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:02<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:02<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:05<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [01:05<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:07<00:00,  1.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:08<00:00,  1.28s/pipeline]Optimization Progress:  67%|██████▋   | 202/300 [01:09<03:07,  1.91s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [01:09<03:07,  1.91s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [01:17<04:01,  2.52s/pipeline]Optimization Progress:  95%|█████████▍| 284/300 [01:57<00:30,  1.91s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-554204588.4935791	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)
-2	-545006490.8771359	GradientBoostingRegressor(SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 300/300 [01:59<00:00,  1.91s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:59<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:59<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 300/300 [02:04<00:00,  1.37s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [02:05<02:36,  1.62s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  76%|███████▌  | 303/400 [02:05<02:36,  1.62s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  76%|███████▌  | 304/400 [02:05<02:35,  1.62s/pipeline]Optimization Progress:  76%|███████▋  | 306/400 [02:20<04:09,  2.66s/pipeline]Optimization Progress:  96%|█████████▋| 386/400 [02:25<00:26,  1.88s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [02:28<00:00,  1.88s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:28<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:29<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [02:30<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=3 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=4 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=5 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=6 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=7 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=8 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=9 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:31<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:32<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:32<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 400/400 [02:33<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [02:33<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:34<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:34<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:35<00:00,  1.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:35<00:00,  1.37s/pipeline]Optimization Progress:  80%|████████  | 401/500 [02:35<05:05,  3.09s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 401/500 [02:35<05:05,  3.09s/pipeline]Optimization Progress:  81%|████████  | 403/500 [02:42<05:14,  3.24s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [02:48<00:38,  2.29s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 500/500 [02:49<00:00,  2.29s/pipeline]Optimization Progress: 100%|██████████| 500/500 [02:49<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [02:49<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 500/500 [02:49<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 500/500 [02:50<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:50<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 500/500 [02:50<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:52<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:52<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:52<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 500/500 [02:52<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:53<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:54<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:56<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:57<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:57<00:00,  1.62s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:57<00:00,  1.62s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [02:58<04:03,  2.48s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▎ | 502/600 [02:58<04:03,  2.48s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [03:04<04:10,  2.61s/pipeline]Optimization Progress:  97%|█████████▋| 584/600 [03:08<00:29,  1.85s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 600/600 [03:09<00:00,  1.85s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:09<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [03:09<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 [07:01:44] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:14<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:14<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:14<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:15<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:15<00:00,  1.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:17<00:00,  1.31s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [03:18<02:10,  1.31s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 601/700 [03:18<02:09,  1.31s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [03:18<03:42,  2.27s/pipeline]Optimization Progress:  86%|████████▌ | 603/700 [03:50<17:50, 11.04s/pipeline]Optimization Progress:  98%|█████████▊| 683/700 [04:04<02:12,  7.78s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:06<00:00,  7.78s/pipeline]Optimization Progress: 100%|██████████| 700/700 [04:06<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:06<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 700/700 [04:06<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:09<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 700/700 [04:09<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 700/700 [04:09<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:11<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:12<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:13<00:00,  5.48s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 700/700 [04:14<00:00,  5.48s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [04:16<11:19,  6.86s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [04:16<11:19,  6.86s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [04:16<11:12,  6.86s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [04:36<10:52,  6.80s/pipeline]Optimization Progress:  98%|█████████▊| 784/800 [04:43<01:16,  4.79s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:44<00:00,  4.79s/pipeline]Optimization Progress: 100%|██████████| 800/800 [04:44<00:00,  3.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 800/800 [04:53<00:00,  3.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:53<00:00,  3.37s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [06:14<48:22, 29.31s/pipeline]Optimization Progress:  98%|█████████▊| 881/900 [06:35<06:31, 20.60s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-544841579.8459235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [06:36<00:00, 20.60s/pipeline]Optimization Progress: 100%|██████████| 900/900 [06:36<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:37<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [06:37<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:37<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:37<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [06:38<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [06:38<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 900/900 [06:39<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [06:39<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [06:40<00:00, 14.45s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 900/900 [06:43<00:00, 14.45s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [06:48<22:32, 13.66s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 901/1000 [06:48<22:32, 13.66s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 902/1000 [06:48<22:18, 13.66s/pipeline]Optimization Progress:  90%|█████████ | 904/1000 [07:20<20:23, 12.74s/pipeline]Optimization Progress:  98%|█████████▊| 984/1000 [07:25<02:22,  8.94s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [07:28<00:00,  8.94s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [07:28<00:00,  6.32s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [07:38<09:41,  5.93s/pipeline]Optimization Progress:  91%|█████████ | 1003/1100 [07:47<10:50,  6.70s/pipeline]Optimization Progress:  98%|█████████▊| 1083/1100 [07:53<01:20,  4.71s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:53<00:00,  4.71s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [07:53<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:54<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:56<00:00,  3.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1100/1100 [08:01<00:00,  3.30s/pipeline]Optimization Progress:  92%|█████████▏| 1106/1200 [08:03<04:22,  2.80s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1106/1200 [08:03<04:22,  2.80s/pipeline]Optimization Progress:  92%|█████████▏| 1107/1200 [08:19<04:20,  2.80s/pipeline]Optimization Progress:  92%|█████████▏| 1108/1200 [08:36<10:45,  7.01s/pipeline]Optimization Progress:  99%|█████████▉| 1188/1200 [09:08<01:00,  5.03s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-540480791.3670999	DecisionTreeRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [09:09<00:00,  5.03s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [09:09<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:10<00:00,  3.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [09:14<00:00,  3.54s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [09:15<04:43,  2.95s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1204/1300 [09:15<04:43,  2.95s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1205/1300 [09:15<04:40,  2.95s/pipeline]Optimization Progress:  93%|█████████▎| 1207/1300 [09:22<04:15,  2.74s/pipeline]Optimization Progress:  99%|█████████▉| 1287/1300 [09:24<00:25,  1.93s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-540480791.3670999	DecisionTreeRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:27<00:00,  1.93s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [09:27<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [09:28<00:00,  1.43s/pipeline]Optimization Progress:  93%|█████████▎| 1302/1400 [09:30<02:17,  1.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1302/1400 [09:30<02:17,  1.40s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [09:34<02:38,  1.65s/pipeline]Optimization Progress:  99%|█████████▉| 1384/1400 [09:38<00:18,  1.17s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-540480791.3670999	DecisionTreeRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1400/1400 [09:40<00:00,  1.17s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [09:40<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [09:43<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [09:43<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:43<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:43<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:43<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:44<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 1400/1400 [09:45<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:45<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [09:45<00:00,  1.18pipeline/s]Optimization Progress:  94%|█████████▎| 1403/1500 [09:46<01:51,  1.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▎| 1403/1500 [09:46<01:51,  1.15s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  94%|█████████▎| 1404/1500 [09:46<01:50,  1.15s/pipeline]Optimization Progress:  94%|█████████▎| 1406/1500 [09:51<02:10,  1.39s/pipeline]Optimization Progress:  99%|█████████▉| 1486/1500 [09:57<00:13,  1.00pipeline/s]
Generation 14 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-537629151.9505799	DecisionTreeRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=4, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=13)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [09:57<00:00,  1.00pipeline/s]Optimization Progress: 100%|██████████| 1500/1500 [09:57<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1500/1500 [09:59<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [10:00<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [10:02<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [10:03<00:00,  1.42pipeline/s]Optimization Progress:  94%|█████████▍| 1503/1600 [10:03<01:42,  1.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1503/1600 [10:03<01:42,  1.06s/pipeline]Optimization Progress:  94%|█████████▍| 1505/1600 [10:08<02:19,  1.46s/pipeline]Optimization Progress:  99%|█████████▉| 1585/1600 [10:11<00:15,  1.03s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-540481405.5237596	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-537030216.9369998	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-517869326.05846834	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-4	-512669748.0501504	ExtraTreesRegressor(FastICA(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.35000000000000003), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:11<00:00,  1.03s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [10:11<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [10:12<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [10:12<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:12<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [10:15<00:00,  1.36pipeline/s]Optimization Progress:  94%|█████████▍| 1603/1700 [10:18<01:55,  1.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1603/1700 [10:18<01:55,  1.19s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [10:22<02:18,  1.46s/pipeline]Optimization Progress:  99%|█████████▉| 1685/1700 [10:26<00:15,  1.04s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-540415234.6109641	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-507082403.81588876	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=3, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [10:28<00:00,  1.04s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [10:28<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [10:28<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 1700/1700 [10:29<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [10:30<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1700/1700 [10:31<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1700/1700 [10:31<00:00,  1.32pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 1700/1700 [10:32<00:00,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1700/1800 [10:34<01:15,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1701/1800 [10:34<01:14,  1.32pipeline/s]Optimization Progress:  95%|█████████▍| 1702/1800 [10:34<02:21,  1.44s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [10:40<04:32,  2.81s/pipeline]Optimization Progress:  99%|█████████▉| 1783/1800 [10:44<00:33,  1.98s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-540415234.6109641	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-507082403.81588876	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=3, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 1800/1800 [10:45<00:00,  1.98s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [10:45<00:00,  1.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:46<00:00,  1.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:46<00:00,  1.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [10:47<00:00,  1.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [10:49<00:00,  1.41s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [10:52<03:11,  1.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1802/1900 [10:52<03:11,  1.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1803/1900 [10:52<03:09,  1.96s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [10:58<03:10,  2.00s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [11:00<00:21,  1.41s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-540415234.6109641	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-507082403.81588876	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=3, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-4	-505010883.29374564	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [11:01<00:00,  1.41s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [11:01<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 1900/1900 [11:02<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [11:03<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 1900/1900 [11:05<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [11:05<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [11:06<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:09:42] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 1900/1900 [11:08<00:00,  1.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1901/2000 [11:09<01:39,  1.01s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [11:09<02:56,  1.80s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1902/2000 [11:09<02:56,  1.80s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [11:13<03:01,  1.89s/pipeline]Optimization Progress:  99%|█████████▉| 1984/2000 [11:16<00:21,  1.33s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-540415234.6109641	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-507082403.81588876	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=3, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-4	-505010883.29374564	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [11:18<00:00,  1.33s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [11:18<00:00,  1.04pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [11:19<00:00,  1.04pipeline/s]Optimization Progress:  95%|█████████▌| 2002/2100 [11:22<02:12,  1.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2002/2100 [11:22<02:12,  1.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [11:22<02:11,  1.35s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [12:26<11:39,  7.37s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [12:31<01:17,  5.17s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-536081786.58441705	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-503284397.52587664	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 2100/2100 [12:31<00:00,  5.17s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [12:31<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [12:31<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:31<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:31<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [12:33<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [12:34<00:00,  3.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [12:36<00:00,  3.63s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [12:37<05:32,  3.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2102/2200 [12:37<05:32,  3.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [12:37<05:28,  3.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2104/2200 [12:37<05:25,  3.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2105/2200 [12:37<05:21,  3.39s/pipeline]Optimization Progress:  96%|█████████▌| 2106/2200 [12:49<05:18,  3.39s/pipeline]Optimization Progress:  96%|█████████▌| 2107/2200 [13:06<06:22,  4.11s/pipeline]Optimization Progress:  99%|█████████▉| 2187/2200 [13:08<00:37,  2.89s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-536081786.58441705	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-535723644.5350526	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), input_matrix), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-3	-503284397.52587664	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-498965185.93317163	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(MinMaxScaler(input_matrix), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2200/2200 [13:08<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2200/2200 [13:10<00:00,  2.89s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [13:10<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [13:11<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2200/2200 [13:11<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 2200/2200 [13:12<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [13:12<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:13<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 2200/2200 [13:14<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [13:15<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [13:15<00:00,  2.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [13:15<00:00,  2.06s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [13:16<03:42,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2202/2300 [13:16<03:42,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2203/2300 [13:16<03:40,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2204/2300 [13:16<03:38,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2205/2300 [13:16<03:36,  2.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2206/2300 [13:16<03:33,  2.27s/pipeline]Optimization Progress:  96%|█████████▌| 2208/2300 [13:22<02:55,  1.91s/pipeline]Optimization Progress:  99%|█████████▉| 2288/2300 [13:25<00:16,  1.35s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-503284397.52587664	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-498965185.93317163	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(MinMaxScaler(input_matrix), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 2300/2300 [13:25<00:00,  1.35s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [13:25<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [13:26<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2300/2300 [13:26<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [13:27<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [13:28<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 2300/2300 [13:29<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [13:30<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [13:30<00:00,  1.05pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 2300/2300 [13:30<00:00,  1.05pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2301/2400 [13:30<01:34,  1.05pipeline/s]Optimization Progress:  96%|█████████▌| 2302/2400 [13:30<02:21,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2302/2400 [13:30<02:21,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2303/2400 [13:30<02:19,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2304/2400 [13:30<02:18,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2305/2400 [13:30<02:16,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2306/2400 [13:30<02:15,  1.44s/pipeline]Optimization Progress:  96%|█████████▌| 2308/2400 [13:35<01:55,  1.25s/pipeline]Optimization Progress: 100%|█████████▉| 2388/2400 [13:40<00:10,  1.12pipeline/s]
Generation 23 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-503284397.52587664	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-498965185.93317163	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(MinMaxScaler(input_matrix), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [13:40<00:00,  1.12pipeline/s]Optimization Progress: 100%|██████████| 2400/2400 [13:40<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [13:41<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 2400/2400 [13:41<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2400/2400 [13:43<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 2400/2400 [13:43<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [07:12:17] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 2400/2400 [13:43<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [13:43<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [13:46<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [13:46<00:00,  1.58pipeline/s]Optimization Progress:  96%|█████████▌| 2404/2500 [13:47<01:35,  1.00pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2404/2500 [13:47<01:35,  1.00pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2405/2500 [13:47<01:34,  1.00pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2406/2500 [13:47<01:33,  1.00pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2407/2500 [13:47<01:32,  1.00pipeline/s]Optimization Progress:  96%|█████████▋| 2409/2500 [13:57<01:54,  1.25s/pipeline]Optimization Progress: 100%|█████████▉| 2489/2500 [14:01<00:09,  1.12pipeline/s]
Generation 24 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-490864881.6732367	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 2500/2500 [14:01<00:00,  1.12pipeline/s]Optimization Progress: 100%|██████████| 2500/2500 [14:01<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [14:02<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [14:03<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2500/2500 [14:03<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [14:04<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 2500/2500 [14:05<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [14:05<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [14:06<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:12:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 2500/2500 [14:06<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 2500/2500 [14:06<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 2500/2500 [14:06<00:00,  1.58pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [14:07<00:00,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2500/2600 [14:08<01:03,  1.58pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [14:08<01:02,  1.58pipeline/s]Optimization Progress:  96%|█████████▋| 2503/2600 [14:13<02:40,  1.65s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [14:28<00:20,  1.21s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-490864881.6732367	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [14:29<00:00,  1.21s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [14:29<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [14:29<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [14:29<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:13:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 2600/2600 [14:30<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 2600/2600 [14:30<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2600/2600 [14:32<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [14:32<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [14:32<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [14:34<00:00,  1.14pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [14:34<00:00,  1.14pipeline/s]Optimization Progress:  96%|█████████▋| 2604/2700 [14:35<01:40,  1.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2604/2700 [14:35<01:40,  1.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2605/2700 [14:35<01:38,  1.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2606/2700 [14:35<01:37,  1.04s/pipeline]Optimization Progress:  97%|█████████▋| 2608/2700 [14:54<03:16,  2.14s/pipeline]Optimization Progress: 100%|█████████▉| 2688/2700 [14:56<00:18,  1.50s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-494374308.5514582	ExtraTreesRegressor(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-5	-490864881.6732367	ExtraTreesRegressor(FastICA(FastICA(ExtraTreesRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=2, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.4), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=6, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), FastICA__tol=0.0), FastICA__tol=0.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [14:56<00:00,  1.50s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [14:56<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [14:58<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:13:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 2700/2700 [15:00<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 2700/2700 [15:02<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [15:02<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [15:02<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [15:03<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 2700/2700 [15:04<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2700/2700 [15:04<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [15:04<00:00,  1.06s/pipeline]Optimization Progress:  96%|█████████▋| 2701/2800 [15:09<01:45,  1.06s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [15:13<05:21,  3.28s/pipeline]Optimization Progress:  99%|█████████▉| 2782/2800 [15:15<00:41,  2.31s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [15:17<00:00,  2.31s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [15:17<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [15:18<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 2800/2800 [15:19<00:00,  1.65s/pipeline]Optimization Progress:  97%|█████████▋| 2801/2900 [15:24<05:07,  3.10s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2801/2900 [15:24<05:07,  3.10s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [15:28<04:38,  2.87s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [15:31<00:34,  2.02s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [15:31<00:00,  2.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2900/2900 [15:36<00:00,  2.02s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [15:36<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [15:36<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2900/2900 [15:37<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [15:37<00:00,  1.50s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [15:39<02:35,  1.58s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2902/3000 [15:39<02:35,  1.58s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2903/3000 [15:39<02:33,  1.58s/pipeline]Optimization Progress:  97%|█████████▋| 2905/3000 [15:56<04:29,  2.84s/pipeline]Optimization Progress: 100%|█████████▉| 2985/3000 [16:00<00:30,  2.00s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [16:00<00:00,  2.00s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [16:00<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [16:00<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [16:02<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 3000/3000 [16:05<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [16:05<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [16:06<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [16:09<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [16:09<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [16:10<00:00,  1.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3000/3100 [16:11<02:20,  1.40s/pipeline]Optimization Progress:  97%|█████████▋| 3004/3100 [16:18<03:48,  2.38s/pipeline]Optimization Progress:  99%|█████████▉| 3082/3100 [16:22<00:30,  1.68s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [16:24<00:00,  1.68s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [16:24<00:00,  1.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [16:27<00:00,  1.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [16:29<00:00,  1.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [16:29<00:00,  1.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [16:29<00:00,  1.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:15:03] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 3100/3100 [16:30<00:00,  1.21s/pipeline]Optimization Progress:  97%|█████████▋| 3105/3200 [16:33<02:14,  1.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3105/3200 [16:33<02:14,  1.41s/pipeline]Optimization Progress:  97%|█████████▋| 3107/3200 [17:26<13:48,  8.91s/pipeline]Optimization Progress: 100%|█████████▉| 3187/3200 [18:22<01:23,  6.44s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-501447422.2352781	ExtraTreesRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), FastICA__tol=0.6000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [18:24<00:00,  6.44s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [18:24<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [18:25<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [18:26<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [18:26<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 3200/3200 [18:27<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [18:27<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 3200/3200 [18:28<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:17:02] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 3200/3200 [18:28<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [18:30<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 3200/3200 [18:30<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 3200/3200 [18:30<00:00,  4.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [18:31<00:00,  4.57s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [18:32<07:00,  4.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [18:32<07:00,  4.29s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [19:16<15:31,  9.70s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [19:20<01:48,  6.81s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [19:24<00:00,  6.81s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [19:24<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [19:24<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 3300/3300 [19:26<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [19:27<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 3300/3300 [19:28<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [19:29<00:00,  4.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3300/3300 [19:29<00:00,  4.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3300/3400 [19:29<08:03,  4.83s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [19:29<08:23,  5.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3301/3400 [19:29<08:23,  5.09s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [19:48<10:20,  6.40s/pipeline]Optimization Progress: 100%|█████████▉| 3383/3400 [19:53<01:16,  4.49s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:18:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 3400/3400 [20:02<00:00,  4.49s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [20:02<00:00,  3.31s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [20:41<22:47, 13.81s/pipeline]Optimization Progress:  99%|█████████▉| 3481/3500 [20:44<03:03,  9.68s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 3500/3500 [20:44<00:00,  9.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3500/3500 [20:45<00:00,  9.68s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [20:45<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [20:47<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3500/3500 [20:47<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [20:50<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [20:51<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3500/3500 [20:53<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3500/3500 [20:53<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [20:55<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [20:56<00:00,  6.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [20:57<00:00,  6.79s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [20:57<11:12,  6.79s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [20:57<10:40,  6.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [20:57<10:40,  6.53s/pipeline]Optimization Progress:  97%|█████████▋| 3504/3600 [21:04<09:01,  5.64s/pipeline]Optimization Progress: 100%|█████████▉| 3584/3600 [21:10<01:03,  3.97s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3600/3600 [21:16<00:00,  3.97s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [21:16<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [21:16<00:00,  2.89s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [21:21<04:42,  2.88s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [21:40<12:12,  7.55s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [21:44<01:30,  5.30s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 3700/3700 [21:48<00:00,  5.30s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [21:48<00:00,  3.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [21:49<00:00,  3.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3700/3700 [21:52<00:00,  3.79s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [21:53<06:44,  4.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3701/3800 [21:53<06:44,  4.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3702/3800 [21:53<06:40,  4.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3703/3800 [21:53<06:36,  4.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [21:53<06:32,  4.09s/pipeline]Optimization Progress:  98%|█████████▊| 3706/3800 [22:03<05:28,  3.49s/pipeline]Optimization Progress: 100%|█████████▉| 3786/3800 [22:08<00:34,  2.46s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [22:09<00:00,  2.46s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [22:09<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [22:09<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 3800/3800 [22:10<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 3800/3800 [22:11<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 3800/3800 [22:13<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 3800/3800 [22:13<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [22:15<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [22:15<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [22:19<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [22:20<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3800/3800 [22:21<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [22:21<00:00,  1.74s/pipeline]Optimization Progress:  97%|█████████▋| 3801/3900 [22:21<08:04,  4.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [22:21<08:04,  4.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [22:21<07:59,  4.89s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [23:17<14:19,  8.95s/pipeline]Optimization Progress: 100%|█████████▉| 3884/3900 [23:21<01:40,  6.28s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [23:22<00:00,  6.28s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [23:22<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [23:24<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [23:25<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [23:26<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [23:26<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3900/3900 [23:27<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [23:28<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [23:29<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [23:30<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [23:32<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [23:32<00:00,  4.41s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [23:33<06:48,  4.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3903/4000 [23:33<06:48,  4.21s/pipeline]Optimization Progress:  98%|█████████▊| 3905/4000 [24:25<17:03, 10.77s/pipeline]Optimization Progress: 100%|█████████▉| 3985/4000 [24:31<01:53,  7.56s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:32<00:00,  7.56s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [24:32<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:33<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [24:35<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4000/4000 [24:37<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [24:37<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 4000/4000 [24:38<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4000/4000 [24:38<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:38<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 4000/4000 [24:40<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:41<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:41<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [24:41<00:00,  5.31s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4000/4100 [24:42<08:51,  5.31s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [24:42<10:53,  6.60s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [25:30<31:28, 19.27s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [25:33<04:02, 13.50s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [25:34<00:00, 13.50s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [25:34<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [25:35<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:36<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [25:36<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:10] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 4100/4100 [25:36<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4100/4100 [25:36<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:36<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:37<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4100/4100 [25:37<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:39<00:00,  9.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:42<00:00,  9.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4101/4200 [25:44<15:37,  9.47s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [25:44<13:10,  8.07s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4102/4200 [25:44<13:10,  8.07s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [25:44<13:02,  8.07s/pipeline]Optimization Progress:  98%|█████████▊| 4105/4200 [25:48<09:38,  6.09s/pipeline]Optimization Progress: 100%|█████████▉| 4185/4200 [25:51<01:04,  4.27s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [25:52<00:00,  4.27s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [25:52<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 4200/4200 [25:55<00:00,  3.02s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [25:56<00:00,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4201/4300 [26:03<04:58,  3.02s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [26:03<05:57,  3.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4202/4300 [26:03<05:57,  3.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [26:03<05:53,  3.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4204/4300 [26:03<05:50,  3.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4205/4300 [26:03<05:46,  3.65s/pipeline]Optimization Progress:  98%|█████████▊| 4207/4300 [26:11<04:46,  3.08s/pipeline]Optimization Progress: 100%|█████████▉| 4287/4300 [26:15<00:28,  2.17s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [26:16<00:00,  2.17s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [26:16<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:52] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 4300/4300 [26:19<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [26:19<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [26:21<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4300/4300 [26:22<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 4300/4300 [26:22<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4300/4300 [26:22<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [26:24<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [26:25<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:24:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 4300/4300 [26:26<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [26:27<00:00,  1.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [26:28<00:00,  1.54s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [26:28<03:36,  2.23s/pipeline]Optimization Progress:  98%|█████████▊| 4304/4400 [26:40<08:32,  5.34s/pipeline]Optimization Progress: 100%|█████████▉| 4384/4400 [26:44<01:00,  3.75s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [26:46<00:00,  3.75s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [26:46<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [26:46<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:25:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 4400/4400 [26:47<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4400/4400 [26:49<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [26:50<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4400/4400 [26:54<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [26:55<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [26:55<00:00,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4400/4500 [26:57<04:26,  2.66s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [26:57<08:25,  5.11s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [27:03<08:58,  5.50s/pipeline]Optimization Progress: 100%|█████████▉| 4482/4500 [27:09<01:09,  3.87s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:09<00:00,  3.87s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [27:09<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [27:10<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [27:10<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [27:11<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:14<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:17<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [27:19<00:00,  2.72s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4500/4500 [27:20<00:00,  2.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:21<00:00,  2.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4500/4600 [27:21<04:31,  2.72s/pipeline]Optimization Progress:  98%|█████████▊| 4501/4600 [27:21<09:01,  5.47s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [27:28<09:42,  5.94s/pipeline]Optimization Progress: 100%|█████████▉| 4582/4600 [27:33<01:15,  4.18s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [27:33<00:00,  4.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [27:33<00:00,  4.18s/pipeline]Optimization Progress: 100%|██████████| 4600/4600 [27:33<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [27:35<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4600/4600 [27:35<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 4600/4600 [27:37<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 4600/4600 [27:39<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [27:42<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4600/4600 [27:45<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4600/4600 [27:46<00:00,  2.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [27:47<04:46,  2.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [27:47<04:43,  2.93s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [27:50<04:40,  2.93s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [27:54<05:13,  3.30s/pipeline]Optimization Progress: 100%|█████████▉| 4685/4700 [28:00<00:35,  2.33s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [28:01<00:00,  2.33s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [28:01<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [28:02<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [28:05<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4700/4700 [28:06<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4700/4700 [28:10<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4700/4700 [28:11<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4700/4700 [28:11<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4700/4700 [28:11<00:00,  1.66s/pipeline]Optimization Progress:  98%|█████████▊| 4704/4800 [28:12<03:05,  1.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [28:12<03:05,  1.93s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4705/4800 [28:12<03:03,  1.93s/pipeline]Optimization Progress:  98%|█████████▊| 4707/4800 [28:30<04:53,  3.16s/pipeline]Optimization Progress: 100%|█████████▉| 4787/4800 [28:33<00:28,  2.23s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [28:36<00:00,  2.23s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [28:36<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [28:38<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [28:39<00:00,  1.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [28:41<00:00,  1.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4800/4900 [28:46<02:42,  1.63s/pipeline]Optimization Progress:  98%|█████████▊| 4801/4900 [28:46<06:54,  4.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [28:46<06:54,  4.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [28:46<06:50,  4.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4803/4900 [28:46<06:46,  4.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4804/4900 [28:46<06:42,  4.19s/pipeline]Optimization Progress:  98%|█████████▊| 4806/4900 [29:16<07:20,  4.69s/pipeline]Optimization Progress: 100%|█████████▉| 4886/4900 [29:20<00:46,  3.30s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [29:20<00:00,  3.30s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [29:20<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [29:23<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [29:24<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [29:26<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [29:28<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [29:28<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [29:29<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4900/4900 [29:30<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 4900/4900 [29:31<00:00,  2.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [29:31<00:00,  2.32s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [29:40<03:49,  2.32s/pipeline]Optimization Progress:  98%|█████████▊| 4902/5000 [29:40<07:34,  4.64s/pipeline]Optimization Progress: 100%|█████████▉| 4982/5000 [29:50<00:59,  3.28s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  3.28s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=5 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5000/5000 [29:51<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [29:52<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 5000/5000 [29:53<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [29:54<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5000/5000 [29:59<00:00,  2.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [30:00<00:00,  2.31s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5001/5100 [30:01<03:48,  2.31s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [30:01<05:04,  3.11s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5002/5100 [30:01<05:04,  3.11s/pipeline]Optimization Progress:  98%|█████████▊| 5004/5100 [30:20<08:07,  5.08s/pipeline]Optimization Progress: 100%|█████████▉| 5084/5100 [30:25<00:57,  3.57s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [30:27<00:00,  3.57s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [30:27<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [30:27<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [30:28<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [30:29<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [30:31<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 5100/5100 [30:31<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [30:32<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:29:08] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 5100/5100 [30:35<00:00,  2.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5100/5100 [30:36<00:00,  2.54s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [30:36<05:06,  3.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5102/5200 [30:36<05:06,  3.13s/pipeline]Optimization Progress:  98%|█████████▊| 5104/5200 [31:31<16:41, 10.43s/pipeline]Optimization Progress: 100%|█████████▉| 5184/5200 [31:37<01:57,  7.33s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5200/5200 [31:39<00:00,  7.33s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [31:39<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:30:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 5200/5200 [31:41<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 5200/5200 [31:41<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5200/5200 [31:42<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5200/5200 [31:44<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5200/5200 [31:45<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5200/5200 [31:46<00:00,  5.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:30:20] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 5200/5200 [31:46<00:00,  5.16s/pipeline]Optimization Progress:  98%|█████████▊| 5202/5300 [31:48<08:08,  4.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5202/5300 [31:48<08:08,  4.99s/pipeline]Optimization Progress:  98%|█████████▊| 5204/5300 [31:53<06:46,  4.24s/pipeline]Optimization Progress: 100%|█████████▉| 5284/5300 [31:59<00:47,  2.99s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-534576053.12375164	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-2	-533432685.52596056	GradientBoostingRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=7, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5300/5300 [32:03<00:00,  2.99s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [32:03<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 5300/5300 [32:05<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 5300/5300 [32:07<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5300/5300 [32:09<00:00,  2.16s/pipeline]Optimization Progress:  98%|█████████▊| 5301/5400 [32:16<08:57,  5.43s/pipeline]Optimization Progress: 100%|█████████▉| 5381/5400 [32:20<01:12,  3.82s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-475388103.81888264	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 5400/5400 [32:21<00:00,  3.82s/pipeline]Optimization Progress: 100%|██████████| 5400/5400 [32:21<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 5400/5400 [32:21<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 5400/5400 [32:23<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5400/5400 [32:24<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 5400/5400 [32:26<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5400/5400 [32:26<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 5400/5400 [32:28<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5400/5400 [32:28<00:00,  2.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5400/5400 [32:28<00:00,  2.69s/pipeline]Optimization Progress:  98%|█████████▊| 5402/5500 [32:37<07:08,  4.37s/pipeline]Optimization Progress: 100%|█████████▉| 5482/5500 [32:41<00:55,  3.07s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [32:41<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [32:41<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 5500/5500 [32:41<00:00,  3.07s/pipeline]Optimization Progress: 100%|██████████| 5500/5500 [32:41<00:00,  2.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [32:42<00:00,  2.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [32:42<00:00,  2.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [32:45<00:00,  2.15s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [32:46<00:00,  2.15s/pipeline]Optimization Progress:  98%|█████████▊| 5501/5600 [33:00<03:33,  2.15s/pipeline]Optimization Progress:  98%|█████████▊| 5502/5600 [33:08<09:09,  5.61s/pipeline]Optimization Progress: 100%|█████████▉| 5582/5600 [33:14<01:11,  3.95s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [33:16<00:00,  3.95s/pipeline]Optimization Progress: 100%|██████████| 5600/5600 [33:16<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 5600/5600 [33:16<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5600/5600 [33:17<00:00,  2.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5600/5600 [33:23<00:00,  2.79s/pipeline]Optimization Progress:  98%|█████████▊| 5601/5700 [33:24<07:25,  4.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5601/5700 [33:24<07:25,  4.50s/pipeline]Optimization Progress:  98%|█████████▊| 5603/5700 [33:43<09:35,  5.93s/pipeline]Optimization Progress: 100%|█████████▉| 5683/5700 [33:48<01:10,  4.17s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [33:50<00:00,  4.17s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [33:50<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [33:50<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5700/5700 [33:53<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [33:54<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5700/5700 [33:56<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [33:56<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 5700/5700 [33:56<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5700/5700 [33:57<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5700/5700 [33:57<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5700/5700 [33:57<00:00,  2.96s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [33:58<05:18,  3.25s/pipeline]Optimization Progress:  98%|█████████▊| 5703/5800 [34:05<07:01,  4.35s/pipeline]Optimization Progress: 100%|█████████▉| 5783/5800 [34:09<00:52,  3.06s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [34:09<00:00,  3.06s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [34:09<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5800/5800 [34:12<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:32:48] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 5800/5800 [34:14<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [34:15<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [34:15<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [34:17<00:00,  2.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5800/5800 [34:17<00:00,  2.14s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5803/5900 [34:18<03:28,  2.14s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5804/5900 [34:18<03:25,  2.14s/pipeline]Optimization Progress:  98%|█████████▊| 5805/5900 [34:20<03:23,  2.14s/pipeline]Optimization Progress:  98%|█████████▊| 5806/5900 [34:49<05:27,  3.49s/pipeline]Optimization Progress: 100%|█████████▉| 5886/5900 [34:53<00:34,  2.45s/pipeline]
Generation 58 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5900/5900 [34:54<00:00,  2.45s/pipeline]Optimization Progress: 100%|██████████| 5900/5900 [34:54<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [34:57<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 5900/5900 [34:57<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [34:57<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [34:57<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 5900/5900 [35:00<00:00,  1.74s/pipeline]Optimization Progress:  98%|█████████▊| 5901/6000 [35:03<06:29,  3.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5901/6000 [35:03<06:29,  3.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5902/6000 [35:03<06:25,  3.94s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5903/6000 [35:03<06:21,  3.94s/pipeline]Optimization Progress:  98%|█████████▊| 5905/6000 [35:17<06:02,  3.82s/pipeline]Optimization Progress: 100%|█████████▉| 5985/6000 [35:22<00:40,  2.69s/pipeline]
Generation 59 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:33:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 6000/6000 [35:23<00:00,  2.69s/pipeline]Optimization Progress: 100%|██████████| 6000/6000 [35:23<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [35:26<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [35:26<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:34:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 6000/6000 [35:27<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [35:27<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6000/6000 [35:28<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [35:30<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [35:31<00:00,  1.92s/pipeline]Optimization Progress:  98%|█████████▊| 6002/6100 [35:31<04:10,  2.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6002/6100 [35:31<04:10,  2.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6003/6100 [35:31<04:07,  2.55s/pipeline]Optimization Progress:  98%|█████████▊| 6005/6100 [36:01<07:27,  4.71s/pipeline]Optimization Progress: 100%|█████████▉| 6085/6100 [36:05<00:49,  3.31s/pipeline]
Generation 60 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 6100/6100 [36:05<00:00,  3.31s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [36:05<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [36:06<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 6100/6100 [36:06<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [36:06<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6100/6100 [36:06<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6100/6100 [36:07<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [36:07<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6100/6100 [36:08<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [36:10<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [36:14<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6100/6100 [36:15<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [36:15<00:00,  2.33s/pipeline]Optimization Progress:  98%|█████████▊| 6102/6200 [36:16<05:12,  3.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6102/6200 [36:16<05:12,  3.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6103/6200 [36:16<05:09,  3.19s/pipeline]Optimization Progress:  98%|█████████▊| 6105/6200 [37:14<12:41,  8.01s/pipeline]Optimization Progress: 100%|█████████▉| 6185/6200 [37:18<01:24,  5.62s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6200/6200 [37:18<00:00,  5.62s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [37:18<00:00,  3.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 6200/6200 [37:19<00:00,  3.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [37:21<00:00,  3.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [37:22<00:00,  3.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:35:57] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 6200/6200 [37:23<00:00,  3.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6200/6200 [37:28<00:00,  3.94s/pipeline]Optimization Progress:  98%|█████████▊| 6201/6300 [37:30<06:30,  3.94s/pipeline]Optimization Progress:  98%|█████████▊| 6202/6300 [37:36<08:47,  5.38s/pipeline]Optimization Progress: 100%|█████████▉| 6282/6300 [37:38<01:07,  3.77s/pipeline]
Generation 62 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-488319839.3297583	DecisionTreeRegressor(CombineDFs(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45), Nystroem(input_matrix, Nystroem__gamma=0.30000000000000004, Nystroem__kernel=additive_chi2, Nystroem__n_components=8)), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=12)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-470549648.15578765	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(MaxAbsScaler(input_matrix), KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.7000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6300/6300 [37:40<00:00,  3.77s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [37:40<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [37:40<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6300/6300 [37:43<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [37:43<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [37:45<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 6300/6300 [37:46<00:00,  2.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [37:48<00:00,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6300/6400 [37:48<04:26,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6301/6400 [37:48<04:24,  2.67s/pipeline]Optimization Progress:  98%|█████████▊| 6302/6400 [37:48<05:03,  3.10s/pipeline]Optimization Progress:  98%|█████████▊| 6303/6400 [37:56<07:25,  4.59s/pipeline]Optimization Progress: 100%|█████████▉| 6383/6400 [37:59<00:54,  3.23s/pipeline]
Generation 63 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [38:00<00:00,  3.23s/pipeline]Optimization Progress: 100%|██████████| 6400/6400 [38:00<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [38:00<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [38:00<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [38:02<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [38:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6400/6400 [38:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6400/6400 [38:05<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [38:07<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6400/6400 [38:07<00:00,  2.28s/pipeline]Optimization Progress:  99%|█████████▊| 6405/6500 [38:09<03:20,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6405/6500 [38:09<03:20,  2.12s/pipeline]Optimization Progress:  99%|█████████▊| 6407/6500 [38:29<06:52,  4.44s/pipeline]Optimization Progress: 100%|█████████▉| 6487/6500 [38:34<00:40,  3.13s/pipeline]
Generation 64 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [38:36<00:00,  3.13s/pipeline]Optimization Progress: 100%|██████████| 6500/6500 [38:36<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [38:36<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [38:39<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [38:39<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [38:39<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6500/6500 [38:39<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [38:40<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6500/6500 [38:40<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [38:41<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [38:42<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [38:42<00:00,  2.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6500/6500 [38:44<00:00,  2.24s/pipeline]Optimization Progress:  99%|█████████▊| 6503/6600 [38:44<03:47,  2.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6503/6600 [38:44<03:47,  2.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6504/6600 [38:44<03:45,  2.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6505/6600 [38:44<03:43,  2.35s/pipeline]Optimization Progress:  99%|█████████▊| 6507/6600 [39:43<09:24,  6.06s/pipeline]Optimization Progress: 100%|█████████▉| 6587/6600 [39:46<00:55,  4.26s/pipeline]
Generation 65 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [39:49<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 6600/6600 [39:49<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [39:50<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 6600/6600 [39:53<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [39:54<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [39:56<00:00,  3.04s/pipeline]Optimization Progress:  99%|█████████▊| 6601/6700 [39:57<07:18,  4.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6601/6700 [39:57<07:18,  4.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6602/6700 [39:57<07:13,  4.43s/pipeline]Optimization Progress:  99%|█████████▊| 6604/6700 [40:04<06:04,  3.80s/pipeline]Optimization Progress: 100%|█████████▉| 6684/6700 [40:07<00:42,  2.67s/pipeline]
Generation 66 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 6700/6700 [40:09<00:00,  2.67s/pipeline]Optimization Progress: 100%|██████████| 6700/6700 [40:09<00:00,  1.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6700/6700 [40:10<00:00,  1.90s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 6700/6700 [40:17<00:00,  1.90s/pipeline]Optimization Progress:  99%|█████████▊| 6701/6800 [40:17<06:08,  3.72s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6701/6800 [40:17<06:08,  3.72s/pipeline]Optimization Progress:  99%|█████████▊| 6703/6800 [41:14<18:09, 11.23s/pipeline]Optimization Progress: 100%|█████████▉| 6783/6800 [41:18<02:13,  7.87s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [41:19<00:00,  7.87s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [41:19<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [41:20<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [41:20<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [41:22<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 6800/6800 [41:22<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [41:25<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [41:25<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6800/6800 [41:27<00:00,  5.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [41:27<00:00,  5.53s/pipeline]Optimization Progress:  99%|█████████▊| 6802/6900 [41:27<08:23,  5.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6802/6900 [41:27<08:23,  5.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6803/6900 [41:27<08:17,  5.13s/pipeline]Optimization Progress:  99%|█████████▊| 6805/6900 [41:36<07:02,  4.45s/pipeline]Optimization Progress: 100%|█████████▉| 6885/6900 [41:53<00:47,  3.18s/pipeline]
Generation 68 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 6900/6900 [41:54<00:00,  3.18s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [41:54<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [41:54<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 6900/6900 [41:56<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [41:57<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [41:57<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 6900/6900 [41:59<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [42:00<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 6900/6900 [42:00<00:00,  2.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [42:01<00:00,  2.25s/pipeline]Optimization Progress:  99%|█████████▊| 6901/7000 [42:03<07:21,  4.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6901/7000 [42:03<07:21,  4.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6902/7000 [42:03<07:16,  4.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6903/7000 [42:03<07:12,  4.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6904/7000 [42:03<07:08,  4.46s/pipeline]Optimization Progress:  99%|█████████▊| 6906/7000 [42:22<06:41,  4.27s/pipeline]Optimization Progress: 100%|█████████▉| 6986/7000 [42:29<00:42,  3.01s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 7000/7000 [42:29<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [42:30<00:00,  3.01s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [42:30<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [42:31<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [42:31<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [42:31<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [42:32<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 7000/7000 [42:32<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [42:32<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7000/7000 [42:33<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7000/7000 [42:34<00:00,  2.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:41:11] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 7000/7000 [42:37<00:00,  2.11s/pipeline]Optimization Progress:  99%|█████████▊| 7004/7100 [42:39<03:30,  2.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7004/7100 [42:39<03:30,  2.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7005/7100 [42:39<03:27,  2.19s/pipeline]Optimization Progress:  99%|█████████▊| 7007/7100 [42:47<03:40,  2.37s/pipeline]Optimization Progress: 100%|█████████▉| 7087/7100 [42:51<00:21,  1.68s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 7100/7100 [42:52<00:00,  1.68s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [42:52<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7100/7100 [42:53<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7100/7100 [42:53<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7100/7100 [42:54<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [42:56<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [42:56<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7100/7100 [42:57<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [42:59<00:00,  1.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7101/7200 [43:01<01:57,  1.19s/pipeline]Optimization Progress:  99%|█████████▊| 7102/7200 [43:01<03:39,  2.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7102/7200 [43:01<03:39,  2.24s/pipeline]Optimization Progress:  99%|█████████▊| 7103/7200 [43:20<03:37,  2.24s/pipeline]Optimization Progress:  99%|█████████▊| 7104/7200 [43:29<09:18,  5.82s/pipeline]Optimization Progress: 100%|█████████▉| 7184/7200 [43:37<01:05,  4.10s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 7200/7200 [43:38<00:00,  4.10s/pipeline]Optimization Progress: 100%|██████████| 7200/7200 [43:38<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [43:40<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:42:14] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 7200/7200 [43:40<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7200/7200 [43:42<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7200/7200 [43:43<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [43:43<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [43:44<00:00,  2.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 7200/7200 [43:45<00:00,  2.89s/pipeline]Optimization Progress:  99%|█████████▊| 7203/7300 [43:48<04:54,  3.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7203/7300 [43:48<04:54,  3.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7204/7300 [43:48<04:51,  3.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7205/7300 [43:48<04:48,  3.03s/pipeline]Optimization Progress:  99%|█████████▊| 7207/7300 [44:07<05:28,  3.53s/pipeline]Optimization Progress: 100%|█████████▉| 7287/7300 [44:24<00:32,  2.54s/pipeline]
Generation 72 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 7300/7300 [44:25<00:00,  2.54s/pipeline]Optimization Progress: 100%|██████████| 7300/7300 [44:25<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [44:27<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 7300/7300 [44:32<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7300/7300 [44:33<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [44:33<00:00,  1.79s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7300/7300 [44:34<00:00,  1.79s/pipeline]Optimization Progress:  99%|█████████▊| 7302/7400 [44:35<04:24,  2.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7302/7400 [44:35<04:24,  2.70s/pipeline]Optimization Progress:  99%|█████████▊| 7304/7400 [45:03<09:44,  6.09s/pipeline]Optimization Progress: 100%|█████████▉| 7384/7400 [45:07<01:08,  4.28s/pipeline]
Generation 73 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-481658601.2948017	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 7400/7400 [45:08<00:00,  4.28s/pipeline]Optimization Progress: 100%|██████████| 7400/7400 [45:08<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [45:08<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 7400/7400 [45:09<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 7400/7400 [45:09<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [45:10<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7400/7400 [45:11<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7400/7400 [45:13<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [45:15<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7400/7400 [45:15<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [45:16<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [45:18<00:00,  3.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7400/7500 [45:18<05:00,  3.01s/pipeline]Optimization Progress:  99%|█████████▊| 7401/7500 [45:18<08:22,  5.07s/pipeline]Optimization Progress:  99%|█████████▊| 7402/7500 [45:41<17:12, 10.53s/pipeline]Optimization Progress: 100%|█████████▉| 7482/7500 [45:47<02:13,  7.39s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [45:49<00:00,  7.39s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [45:49<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7500/7500 [45:50<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:44:25] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 7500/7500 [45:52<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [45:52<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [45:52<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7500/7500 [45:53<00:00,  5.21s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7500/7500 [45:56<00:00,  5.21s/pipeline]Optimization Progress:  99%|█████████▊| 7501/7600 [45:57<10:11,  6.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7501/7600 [45:57<10:11,  6.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7502/7600 [45:57<10:05,  6.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7503/7600 [45:57<09:59,  6.18s/pipeline]Optimization Progress:  99%|█████████▉| 7505/7600 [46:16<09:05,  5.74s/pipeline]Optimization Progress: 100%|█████████▉| 7585/7600 [46:48<01:02,  4.14s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [46:50<00:00,  4.14s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [46:50<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7600/7600 [46:51<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [46:56<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [46:57<00:00,  2.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [47:00<00:00,  2.93s/pipeline]Optimization Progress:  99%|█████████▉| 7604/7700 [47:00<04:31,  2.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7604/7700 [47:00<04:31,  2.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7605/7700 [47:00<04:28,  2.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7606/7700 [47:00<04:26,  2.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7607/7700 [47:00<04:23,  2.83s/pipeline]Optimization Progress:  99%|█████████▉| 7609/7700 [47:06<03:32,  2.34s/pipeline]Optimization Progress: 100%|█████████▉| 7689/7700 [47:55<00:20,  1.82s/pipeline]
Generation 76 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7700/7700 [47:56<00:00,  1.82s/pipeline]Optimization Progress: 100%|██████████| 7700/7700 [47:56<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [48:00<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [48:02<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 7700/7700 [48:02<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 7700/7700 [48:02<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [48:08<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 7700/7700 [48:08<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7700/7700 [48:09<00:00,  1.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7700/7800 [48:09<02:07,  1.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7701/7800 [48:09<02:06,  1.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7702/7800 [48:09<02:05,  1.28s/pipeline]Optimization Progress:  99%|█████████▉| 7703/7800 [48:09<03:33,  2.21s/pipeline]Optimization Progress:  99%|█████████▉| 7704/7800 [48:27<11:13,  7.02s/pipeline]Optimization Progress: 100%|█████████▉| 7784/7800 [48:34<01:19,  4.94s/pipeline]
Generation 77 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:37<00:00,  4.94s/pipeline]Optimization Progress: 100%|██████████| 7800/7800 [48:37<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7800/7800 [48:37<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 7800/7800 [48:37<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [48:38<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7800/7800 [48:39<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:40<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:40<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [48:44<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7800/7800 [48:45<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:46<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:46<00:00,  3.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [48:46<00:00,  3.50s/pipeline]Optimization Progress:  99%|█████████▉| 7802/7900 [48:46<06:22,  3.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7802/7900 [48:46<06:22,  3.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7803/7900 [48:46<06:18,  3.90s/pipeline]Optimization Progress:  99%|█████████▉| 7805/7900 [48:53<05:20,  3.38s/pipeline]Optimization Progress: 100%|█████████▉| 7885/7900 [48:59<00:35,  2.39s/pipeline]
Generation 78 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [49:00<00:00,  2.39s/pipeline]Optimization Progress: 100%|██████████| 7900/7900 [49:00<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 7900/7900 [49:00<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [49:03<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [49:04<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [49:05<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7900/7900 [49:06<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [49:10<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 7900/7900 [49:11<00:00,  1.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7900/7900 [49:12<00:00,  1.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7900/8000 [49:13<02:47,  1.68s/pipeline]Optimization Progress:  99%|█████████▉| 7901/8000 [49:20<02:46,  1.68s/pipeline]Optimization Progress:  99%|█████████▉| 7902/8000 [49:22<07:16,  4.46s/pipeline]Optimization Progress: 100%|█████████▉| 7982/8000 [49:25<00:56,  3.13s/pipeline]
Generation 79 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [49:26<00:00,  3.13s/pipeline]Optimization Progress: 100%|██████████| 8000/8000 [49:26<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [49:27<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [49:27<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8000/8000 [49:35<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 8000/8000 [49:35<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8000/8000 [49:36<00:00,  2.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 8000/8000 [49:37<00:00,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8001/8100 [49:38<03:37,  2.20s/pipeline]Optimization Progress:  99%|█████████▉| 8002/8100 [49:38<05:31,  3.38s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8002/8100 [49:38<05:31,  3.38s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8003/8100 [49:38<05:28,  3.38s/pipeline]Optimization Progress:  99%|█████████▉| 8005/8100 [49:46<05:02,  3.18s/pipeline]Optimization Progress: 100%|█████████▉| 8085/8100 [49:49<00:33,  2.24s/pipeline]
Generation 80 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [49:50<00:00,  2.24s/pipeline]Optimization Progress: 100%|██████████| 8100/8100 [49:50<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8100/8100 [49:50<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8100/8100 [49:52<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [49:54<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 8100/8100 [49:54<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8100/8100 [49:56<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 8100/8100 [50:00<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8100/8100 [50:01<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 8100/8100 [50:03<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 8100/8100 [50:03<00:00,  1.59s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8101/8200 [50:04<02:37,  1.59s/pipeline]Optimization Progress:  99%|█████████▉| 8102/8200 [50:04<05:14,  3.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8102/8200 [50:04<05:14,  3.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8103/8200 [50:04<05:11,  3.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8104/8200 [50:04<05:08,  3.21s/pipeline]Optimization Progress:  99%|█████████▉| 8106/8200 [50:27<06:16,  4.00s/pipeline]Optimization Progress: 100%|█████████▉| 8186/8200 [50:32<00:39,  2.82s/pipeline]
Generation 81 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-472845511.96765155	ExtraTreesRegressor(SGDRegressor(FastICA(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), FastICA__tol=0.0), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=50.0), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)
-5	-468352820.65183794	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=complete), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8200/8200 [50:33<00:00,  2.82s/pipeline]Optimization Progress: 100%|██████████| 8200/8200 [50:33<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:35<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8200/8200 [50:35<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8200/8200 [50:36<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:38<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:41<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:42<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:43<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [50:43<00:00,  1.99s/pipeline]Optimization Progress:  99%|█████████▉| 8204/8300 [50:46<03:47,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8204/8300 [50:46<03:47,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8205/8300 [50:46<03:44,  2.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8206/8300 [50:46<03:42,  2.37s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  99%|█████████▉| 8207/8300 [50:46<03:39,  2.37s/pipeline]Optimization Progress:  99%|█████████▉| 8209/8300 [50:56<03:27,  2.28s/pipeline]Optimization Progress: 100%|█████████▉| 8289/8300 [51:04<00:17,  1.62s/pipeline]
Generation 82 - Current Pareto front scores:
-1	-512192521.2226795	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-456717824.6161378	GradientBoostingRegressor(ElasticNetCV(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8300/8300 [51:04<00:00,  1.62s/pipeline]Optimization Progress: 100%|██████████| 8300/8300 [51:04<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:06<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:07<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [51:08<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8300/8300 [51:08<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:08<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8300/8300 [51:11<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8300/8300 [51:11<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:12<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:14<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:15<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [51:15<00:00,  1.14s/pipeline]Optimization Progress:  99%|█████████▉| 8302/8400 [51:15<03:54,  2.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8302/8400 [51:15<03:54,  2.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8303/8400 [51:15<03:51,  2.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8304/8400 [51:15<03:49,  2.39s/pipeline]Optimization Progress:  99%|█████████▉| 8306/8400 [51:22<03:25,  2.18s/pipeline]Optimization Progress: 100%|█████████▉| 8386/8400 [51:28<00:21,  1.55s/pipeline]
Generation 83 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-456717824.6161378	GradientBoostingRegressor(ElasticNetCV(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-456369034.8628376	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=average), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [51:28<00:00,  1.55s/pipeline]Optimization Progress: 100%|██████████| 8400/8400 [51:28<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 8400/8400 [51:28<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [51:29<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [51:30<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8400/8400 [51:31<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 8400/8400 [51:32<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [51:32<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 8400/8400 [51:35<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 8400/8400 [51:37<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 8400/8400 [51:37<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [51:37<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 8400/8400 [51:38<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [51:39<00:00,  1.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [51:39<00:00,  1.09s/pipeline]Optimization Progress:  99%|█████████▉| 8403/8500 [51:40<03:04,  1.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8403/8500 [51:40<03:04,  1.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8404/8500 [51:40<03:02,  1.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8405/8500 [51:40<03:00,  1.90s/pipeline]Optimization Progress:  99%|█████████▉| 8407/8500 [52:39<09:01,  5.82s/pipeline]Optimization Progress: 100%|█████████▉| 8487/8500 [52:43<00:53,  4.09s/pipeline]
Generation 84 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-481718221.49880016	ExtraTreesRegressor(FastICA(CombineDFs(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.25, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), input_matrix), FastICA__tol=0.55), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=19, ExtraTreesRegressor__n_estimators=100)
-4	-456717824.6161378	GradientBoostingRegressor(ElasticNetCV(MinMaxScaler(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-456369034.8628376	ExtraTreesRegressor(FeatureAgglomeration(FastICA(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=36, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.30000000000000004, ElasticNetCV__tol=1e-05), FastICA__tol=0.55), FeatureAgglomeration__affinity=manhattan, FeatureAgglomeration__linkage=average), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6500000000000001, ExtraTreesRegressor__min_samples_leaf=4, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 8500/8500 [52:44<00:00,  4.09s/pipeline]Optimization Progress: 100%|██████████| 8500/8500 [52:44<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [52:45<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [52:45<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [52:45<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [52:48<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 8500/8500 [52:48<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 8500/8500 [52:48<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [52:53<00:00,  2.88s/pipeline]Optimization Progress:  99%|█████████▉| 8503/8600 [52:57<05:18,  3.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8503/8600 [52:57<05:18,  3.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8504/8600 [52:57<05:15,  3.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8505/8600 [52:57<05:12,  3.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8506/8600 [52:57<05:08,  3.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8507/8600 [52:57<05:05,  3.29s/pipeline]Optimization Progress:  99%|█████████▉| 8509/8600 [53:08<04:21,  2.87s/pipeline]Optimization Progress: 100%|█████████▉| 8589/8600 [53:15<00:22,  2.04s/pipeline]
Generation 85 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-503690869.29244363	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.3, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=4, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:15<00:00,  2.04s/pipeline]Optimization Progress: 100%|██████████| 8600/8600 [53:15<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:19<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8600/8600 [53:19<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8600/8600 [53:20<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8600/8600 [53:20<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 8600/8600 [53:21<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8600/8600 [53:21<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [53:22<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8600/8600 [53:23<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 8600/8600 [53:25<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:26<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8600/8600 [53:26<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:27<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:28<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8600/8600 [53:28<00:00,  1.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [53:29<00:00,  1.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8600/8700 [53:29<02:23,  1.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8601/8700 [53:29<02:22,  1.43s/pipeline]Optimization Progress:  99%|█████████▉| 8602/8700 [53:29<04:59,  3.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8602/8700 [53:29<04:59,  3.06s/pipeline]Optimization Progress:  99%|█████████▉| 8604/8700 [53:38<05:26,  3.40s/pipeline]Optimization Progress: 100%|█████████▉| 8684/8700 [53:41<00:38,  2.40s/pipeline]
Generation 86 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-502272673.94694537	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8700/8700 [53:42<00:00,  2.40s/pipeline]Optimization Progress: 100%|██████████| 8700/8700 [53:42<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:42<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:43<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:44<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [53:45<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:46<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8700/8700 [53:47<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8700/8700 [53:48<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 8700/8700 [53:49<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [53:49<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8700/8700 [53:50<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:50<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 8700/8700 [53:51<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:53<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8700/8700 [53:53<00:00,  1.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [53:54<00:00,  1.70s/pipeline]Optimization Progress:  99%|█████████▉| 8704/8800 [53:54<03:23,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8704/8800 [53:54<03:23,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8705/8800 [53:54<03:21,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8706/8800 [53:54<03:18,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8707/8800 [53:54<03:16,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8708/8800 [53:54<03:14,  2.12s/pipeline]Optimization Progress:  99%|█████████▉| 8710/8800 [54:07<03:08,  2.09s/pipeline]Optimization Progress: 100%|█████████▉| 8790/8800 [54:15<00:14,  1.50s/pipeline]
Generation 87 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-502272673.94694537	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:16<00:00,  1.50s/pipeline]Optimization Progress: 100%|██████████| 8800/8800 [54:16<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:21<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:22<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:24<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [54:26<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8800/8800 [54:26<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:26<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:27<00:00,  1.06s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [54:27<00:00,  1.06s/pipeline]Optimization Progress:  99%|█████████▉| 8809/8900 [54:29<01:49,  1.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8809/8900 [54:29<01:49,  1.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8810/8900 [54:29<01:47,  1.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8811/8900 [54:29<01:46,  1.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8812/8900 [54:29<01:45,  1.20s/pipeline]Optimization Progress:  99%|█████████▉| 8814/8900 [54:38<01:58,  1.38s/pipeline]Optimization Progress: 100%|█████████▉| 8894/8900 [54:53<00:06,  1.02s/pipeline]
Generation 88 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-502272673.94694537	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8900/8900 [54:57<00:00,  1.02s/pipeline]Optimization Progress: 100%|██████████| 8900/8900 [54:57<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 8900/8900 [54:57<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 8900/8900 [54:58<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8900/8900 [55:01<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 8900/8900 [55:03<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [55:07<00:00,  1.11pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 8900/8900 [55:07<00:00,  1.11pipeline/s]Optimization Progress:  99%|█████████▉| 8904/9000 [55:09<02:23,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8904/9000 [55:09<02:23,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8905/9000 [55:09<02:21,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8906/9000 [55:09<02:20,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8907/9000 [55:09<02:18,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8908/9000 [55:09<02:17,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8909/9000 [55:09<02:15,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8910/9000 [55:09<02:14,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8911/9000 [55:09<02:12,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8912/9000 [55:09<02:11,  1.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8913/9000 [55:09<02:09,  1.49s/pipeline]Optimization Progress:  99%|█████████▉| 8915/9000 [55:18<01:49,  1.29s/pipeline]Optimization Progress: 100%|█████████▉| 8995/9000 [55:21<00:04,  1.09pipeline/s]
Generation 89 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-502272673.94694537	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [55:23<00:00,  1.09pipeline/s]Optimization Progress: 100%|██████████| 9000/9000 [55:23<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [55:24<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9000/9000 [55:24<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9000/9000 [55:24<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9000/9000 [55:25<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9000/9000 [55:26<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9000/9000 [55:27<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9000/9000 [55:28<00:00,  1.27pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9000/9000 [55:34<00:00,  1.27pipeline/s]Optimization Progress:  99%|█████████▉| 9003/9100 [55:35<02:47,  1.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9003/9100 [55:35<02:47,  1.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9004/9100 [55:35<02:45,  1.73s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9005/9100 [55:35<02:43,  1.73s/pipeline]Optimization Progress:  99%|█████████▉| 9007/9100 [55:45<03:01,  1.95s/pipeline]Optimization Progress: 100%|█████████▉| 9087/9100 [55:50<00:18,  1.39s/pipeline]
Generation 90 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-502272673.94694537	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [55:51<00:00,  1.39s/pipeline]Optimization Progress: 100%|██████████| 9100/9100 [55:51<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [55:54<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [55:54<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [55:55<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [55:57<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9100/9100 [55:58<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9100/9100 [56:02<00:00,  1.02pipeline/s]Optimization Progress:  99%|█████████▉| 9103/9200 [56:02<02:59,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9103/9200 [56:02<02:59,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9104/9200 [56:02<02:57,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9105/9200 [56:02<02:55,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9106/9200 [56:02<02:54,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9107/9200 [56:02<02:52,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9108/9200 [56:02<02:50,  1.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9109/9200 [56:02<02:48,  1.85s/pipeline]Optimization Progress:  99%|█████████▉| 9111/9200 [56:11<02:23,  1.61s/pipeline]Optimization Progress: 100%|█████████▉| 9191/9200 [56:14<00:10,  1.14s/pipeline]
Generation 91 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9200/9200 [56:14<00:00,  1.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 9200/9200 [56:16<00:00,  1.14s/pipeline]Optimization Progress: 100%|██████████| 9200/9200 [56:16<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9200/9200 [56:16<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 9200/9200 [56:17<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [56:20<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9200/9200 [56:22<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9200/9200 [56:25<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9200/9200 [56:25<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9200/9200 [56:25<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9200/9200 [56:25<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9200/9200 [56:26<00:00,  1.18pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 9200/9200 [56:27<00:00,  1.18pipeline/s]Optimization Progress:  99%|█████████▉| 9204/9300 [56:28<02:26,  1.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9204/9300 [56:28<02:26,  1.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9205/9300 [56:28<02:25,  1.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9206/9300 [56:28<02:23,  1.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9207/9300 [56:28<02:22,  1.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9208/9300 [56:28<02:20,  1.53s/pipeline]Optimization Progress:  99%|█████████▉| 9210/9300 [56:51<03:18,  2.21s/pipeline]Optimization Progress: 100%|█████████▉| 9290/9300 [56:56<00:15,  1.57s/pipeline]
Generation 92 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9300/9300 [56:59<00:00,  1.57s/pipeline]Optimization Progress: 100%|██████████| 9300/9300 [56:59<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [57:02<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 9300/9300 [57:04<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9300/9300 [57:04<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 9300/9300 [57:06<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9300/9300 [57:07<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 9300/9300 [57:07<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [57:08<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9300/9300 [57:08<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 9300/9300 [57:09<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9300/9300 [57:11<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9300/9300 [57:11<00:00,  1.17s/pipeline]Optimization Progress:  99%|█████████▉| 9302/9400 [57:11<04:28,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9302/9400 [57:11<04:28,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9303/9400 [57:11<04:25,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9304/9400 [57:11<04:23,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9305/9400 [57:11<04:20,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9306/9400 [57:11<04:17,  2.74s/pipeline]Optimization Progress:  99%|█████████▉| 9308/9400 [57:20<03:35,  2.34s/pipeline]Optimization Progress: 100%|█████████▉| 9388/9400 [57:24<00:19,  1.65s/pipeline]
Generation 93 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 9400/9400 [57:25<00:00,  1.65s/pipeline]Optimization Progress: 100%|██████████| 9400/9400 [57:25<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [57:27<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [57:27<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [57:30<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9400/9400 [57:33<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9400/9400 [57:35<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 9400/9400 [57:37<00:00,  1.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9400/9400 [57:38<00:00,  1.18s/pipeline]Optimization Progress:  99%|█████████▉| 9402/9500 [57:38<04:31,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9402/9500 [57:38<04:31,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9403/9500 [57:38<04:29,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9404/9500 [57:38<04:26,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9405/9500 [57:38<04:23,  2.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9406/9500 [57:38<04:20,  2.78s/pipeline]Optimization Progress:  99%|█████████▉| 9408/9500 [57:52<03:58,  2.60s/pipeline]Optimization Progress: 100%|█████████▉| 9488/9500 [57:56<00:22,  1.83s/pipeline]
Generation 94 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [57:57<00:00,  1.83s/pipeline]Optimization Progress: 100%|██████████| 9500/9500 [57:57<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 9500/9500 [57:59<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 9500/9500 [57:59<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 9500/9500 [58:00<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9500/9500 [58:00<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 9500/9500 [58:00<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 9500/9500 [58:02<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9500/9500 [58:03<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 9500/9500 [58:03<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [07:56:38] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fbebc8cedc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fbebc9df669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fbebc9ecf8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fbebc9d3cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fbebc8c0f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fb4ca67b9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fb4ca67b067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fb4ca69327e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fb4ca693cb4]

.
Optimization Progress: 100%|██████████| 9500/9500 [58:04<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [58:05<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 9500/9500 [58:07<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9500/9500 [58:07<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [58:07<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9500/9500 [58:09<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9500/9500 [58:10<00:00,  1.31s/pipeline]Optimization Progress:  99%|█████████▉| 9501/9600 [58:10<08:01,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9501/9600 [58:10<08:01,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9502/9600 [58:10<07:56,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9503/9600 [58:10<07:51,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9504/9600 [58:10<07:46,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9505/9600 [58:10<07:42,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9506/9600 [58:10<07:37,  4.86s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9507/9600 [58:10<07:32,  4.86s/pipeline]Optimization Progress:  99%|█████████▉| 9509/9600 [58:23<05:53,  3.89s/pipeline]Optimization Progress: 100%|█████████▉| 9589/9600 [58:29<00:30,  2.74s/pipeline]
Generation 95 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:29<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 9600/9600 [58:30<00:00,  2.74s/pipeline]Optimization Progress: 100%|██████████| 9600/9600 [58:30<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9600/9600 [58:32<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:34<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:35<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9600/9600 [58:35<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 9600/9600 [58:35<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 9600/9600 [58:37<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9600/9600 [58:37<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:39<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:40<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 9600/9600 [58:42<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 9600/9600 [58:42<00:00,  1.94s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9600/9600 [58:43<00:00,  1.94s/pipeline]Optimization Progress:  99%|█████████▉| 9605/9700 [58:44<03:28,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9605/9700 [58:44<03:28,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9606/9700 [58:44<03:26,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9607/9700 [58:44<03:24,  2.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9608/9700 [58:44<03:22,  2.20s/pipeline]Optimization Progress:  99%|█████████▉| 9610/9700 [58:55<03:18,  2.21s/pipeline]Optimization Progress: 100%|█████████▉| 9690/9700 [59:01<00:15,  1.57s/pipeline]
Generation 96 - Current Pareto front scores:
-1	-510988564.30172235	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [59:01<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [59:04<00:00,  1.57s/pipeline]Optimization Progress: 100%|██████████| 9700/9700 [59:04<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9700/9700 [59:05<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 9700/9700 [59:07<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9700/9700 [59:07<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 9700/9700 [59:09<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9700/9700 [59:10<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9700/9700 [59:14<00:00,  1.19s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9700/9700 [59:15<00:00,  1.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9700/9800 [59:17<01:58,  1.19s/pipeline]Optimization Progress:  99%|█████████▉| 9701/9800 [59:17<07:37,  4.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9701/9800 [59:17<07:37,  4.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9702/9800 [59:17<07:33,  4.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9703/9800 [59:17<07:28,  4.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9704/9800 [59:17<07:24,  4.63s/pipeline]Optimization Progress:  99%|█████████▉| 9706/9800 [59:26<05:56,  3.79s/pipeline]Optimization Progress: 100%|█████████▉| 9786/9800 [59:33<00:37,  2.68s/pipeline]
Generation 97 - Current Pareto front scores:
-1	-489451582.613022	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-421770306.2034668	GradientBoostingRegressor(Nystroem(input_matrix, Nystroem__gamma=0.1, Nystroem__kernel=additive_chi2, Nystroem__n_components=8), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-411385253.58354044	GradientBoostingRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.001), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9800/9800 [59:35<00:00,  2.68s/pipeline]Optimization Progress: 100%|██████████| 9800/9800 [59:35<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 9800/9800 [59:37<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [59:39<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9800/9800 [59:39<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 9800/9800 [59:40<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 9800/9800 [59:41<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 9800/9800 [59:43<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 9800/9800 [59:44<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 9800/9800 [59:45<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 9800/9800 [59:46<00:00,  1.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 9800/9800 [59:47<00:00,  1.92s/pipeline]Optimization Progress:  99%|█████████▉| 9802/9900 [59:50<05:42,  3.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9802/9900 [59:50<05:42,  3.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9803/9900 [59:50<05:39,  3.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 9804/9900 [59:50<05:35,  3.50s/pipeline]Optimization Progress:  99%|█████████▉| 9806/9900 [1:00:40<09:43,  6.21s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 9885/9900 [1:00:40<01:33,  6.21s/pipeline]                                                                                  60.79 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 9885/9900 [1:00:40<01:33,  6.21s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 9885/9900 [1:00:40<01:33,  6.21s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 9885/9900 [1:00:40<01:33,  6.21s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001,
                                              loss='exponential',
                                              n_estimators=100))
1. StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.05, tol=0.001))
2. GradientBoostingRegressor(learning_rate=1.0, loss='huber', max_depth=7,
                          max_features=0.1, min_samples_leaf=3,
                          min_samples_split=3, subsample=0.25)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
