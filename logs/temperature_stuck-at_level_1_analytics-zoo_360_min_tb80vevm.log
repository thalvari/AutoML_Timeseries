Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
Adding /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.1-jar-with-dependencies.jar to BIGDL_JARS
Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
Current pyspark location is : /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/__init__.py
Start to getOrCreate SparkContext
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.11-2.4.3.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2021-01-17 12:36:38 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

User settings:

   KMP_AFFINITY=granularity=fine,compact,1,0
   KMP_BLOCKTIME=0
   KMP_DUPLICATE_LIB_OK=True
   KMP_INIT_AT_FORK=FALSE
   KMP_SETTINGS=1
   OMP_NUM_THREADS=40

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=160
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_HAND_THREAD=false
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=40
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='40'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_TOOL=enabled
   OMP_TOOL_LIBRARIES: value is not defined
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'

cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
Successfully got a SparkContext
2021-01-17 12:36:40,596	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2021-01-17 12:36:40,596	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-17_12-36-40_596600_6674/logs.
2021-01-17 12:36:40,711	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:32616 to respond...
2021-01-17 12:36:40,826	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:45105 to respond...
2021-01-17 12:36:40,827	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2021-01-17 12:36:40,850	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2021-01-17_12-36-40_596600_6674/logs.
2021-01-17 12:36:40,850	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2021-01-17 12:36:40,850	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2021-01-17 12:36:41,623	WARNING bayesopt.py:69 -- `reward_attr` is deprecated and will be removed in a future version of Tune. Setting `metric=reward_metric` and `mode=max`.
2021-01-17 12:36:41,697	INFO tune.py:65 -- Did not find checkpoint file in /scratch/project_2003107/ray_results_tskax4i3/automl.
2021-01-17 12:36:41,697	INFO tune.py:233 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.4/200.9 GB

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	PENDING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	PENDING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	PENDING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	PENDING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	PENDING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	PENDING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	PENDING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	PENDING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	PENDING
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING

[2m[36m(pid=7024)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7006)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7029)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7027)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7003)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7001)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7040)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7022)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7015)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7019)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7034)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7005)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7004)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7033)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7023)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7008)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7018)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7007)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7024)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7016)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7016)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7006)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7029)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7036)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7036)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7031)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7031)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7027)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7003)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7018)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7010)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7010)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7001)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7002)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7002)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7040)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7026)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7026)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7028)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7028)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7038)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7038)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7022)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7015)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7014)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7014)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7000)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7000)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7019)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7007)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7032)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7032)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7037)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7037)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7035)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7035)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7025)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7025)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7034)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7005)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7004)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7021)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7021)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7012)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7012)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7013)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7013)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7017)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7017)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7020)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7020)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7030)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7030)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7033)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7039)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7039)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7023)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7011)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=7011)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7008)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8797)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8801)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8786)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8798)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8795)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8795)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8783)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8783)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8790)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8790)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8797)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8801)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8786)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8798)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8806)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8806)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8781)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8781)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=8808)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=8808)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7034)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7034)[0m   agg_primitives: ['count']
[2m[36m(pid=7034)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7034)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7005)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7005)[0m   agg_primitives: ['count']
[2m[36m(pid=7005)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7005)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7004)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7004)[0m   agg_primitives: ['count']
[2m[36m(pid=7004)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7004)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7021)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7021)[0m   agg_primitives: ['count']
[2m[36m(pid=7021)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7021)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7012)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7012)[0m   agg_primitives: ['count']
[2m[36m(pid=7012)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7012)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7013)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7013)[0m   agg_primitives: ['count']
[2m[36m(pid=7013)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7013)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7017)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7017)[0m   agg_primitives: ['count']
[2m[36m(pid=7017)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7017)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7020)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7020)[0m   agg_primitives: ['count']
[2m[36m(pid=7020)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7020)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7030)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7030)[0m   agg_primitives: ['count']
[2m[36m(pid=7030)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7030)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7033)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7033)[0m   agg_primitives: ['count']
[2m[36m(pid=7033)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7033)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7034)[0m LSTM is selected.
[2m[36m(pid=7005)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7005)[0m Instructions for updating:
[2m[36m(pid=7005)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7005)[0m LSTM is selected.
[2m[36m(pid=7004)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7004)[0m Instructions for updating:
[2m[36m(pid=7004)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7004)[0m LSTM is selected.
[2m[36m(pid=7021)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7021)[0m Instructions for updating:
[2m[36m(pid=7021)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7012)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7012)[0m Instructions for updating:
[2m[36m(pid=7012)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7021)[0m LSTM is selected.
[2m[36m(pid=7012)[0m LSTM is selected.
[2m[36m(pid=7013)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7013)[0m Instructions for updating:
[2m[36m(pid=7013)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7013)[0m LSTM is selected.
[2m[36m(pid=7017)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7017)[0m Instructions for updating:
[2m[36m(pid=7017)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7017)[0m LSTM is selected.
[2m[36m(pid=7020)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7020)[0m Instructions for updating:
[2m[36m(pid=7020)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7020)[0m LSTM is selected.
[2m[36m(pid=7030)[0m LSTM is selected.
[2m[36m(pid=7033)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7033)[0m Instructions for updating:
[2m[36m(pid=7033)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7033)[0m LSTM is selected.
[2m[36m(pid=7034)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7034)[0m Instructions for updating:
[2m[36m(pid=7034)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7030)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7030)[0m Instructions for updating:
[2m[36m(pid=7030)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7005)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7005)[0m Instructions for updating:
[2m[36m(pid=7005)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7004)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7004)[0m Instructions for updating:
[2m[36m(pid=7004)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7021)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7021)[0m Instructions for updating:
[2m[36m(pid=7021)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7012)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7012)[0m Instructions for updating:
[2m[36m(pid=7012)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7013)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7013)[0m Instructions for updating:
[2m[36m(pid=7013)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7017)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7017)[0m Instructions for updating:
[2m[36m(pid=7017)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7020)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7020)[0m Instructions for updating:
[2m[36m(pid=7020)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7033)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7033)[0m Instructions for updating:
[2m[36m(pid=7033)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7034)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7034)[0m Instructions for updating:
[2m[36m(pid=7034)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7030)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7030)[0m Instructions for updating:
[2m[36m(pid=7030)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7005)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7005)[0m 2021-01-17 12:36:52.050511: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7021)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7021)[0m 2021-01-17 12:36:52.047911: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7013)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7013)[0m 2021-01-17 12:36:52.047597: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7013)[0m 2021-01-17 12:36:52.054943: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7017)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7017)[0m 2021-01-17 12:36:52.048748: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7020)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7020)[0m 2021-01-17 12:36:52.034971: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7020)[0m 2021-01-17 12:36:52.042613: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7020)[0m 2021-01-17 12:36:52.044623: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe5090e6400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7020)[0m 2021-01-17 12:36:52.044643: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7033)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7033)[0m 2021-01-17 12:36:52.045774: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7033)[0m 2021-01-17 12:36:52.053487: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7021)[0m 2021-01-17 12:36:52.055606: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7012)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7012)[0m 2021-01-17 12:36:52.056486: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7017)[0m 2021-01-17 12:36:52.055901: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7033)[0m 2021-01-17 12:36:52.055631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f50850b1fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7033)[0m 2021-01-17 12:36:52.055655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7013)[0m 2021-01-17 12:36:52.057050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f52390fda90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7013)[0m 2021-01-17 12:36:52.057073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7005)[0m 2021-01-17 12:36:52.058105: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7021)[0m 2021-01-17 12:36:52.057820: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f367511cfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7021)[0m 2021-01-17 12:36:52.057842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7017)[0m 2021-01-17 12:36:52.058061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f41510e8a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7017)[0m 2021-01-17 12:36:52.058084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7034)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7034)[0m 2021-01-17 12:36:52.087878: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7034)[0m 2021-01-17 12:36:52.095830: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7034)[0m 2021-01-17 12:36:52.098094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f29bd0e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7034)[0m 2021-01-17 12:36:52.098117: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7005)[0m 2021-01-17 12:36:52.060395: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5551026c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7005)[0m 2021-01-17 12:36:52.060419: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7004)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7004)[0m 2021-01-17 12:36:52.085026: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7004)[0m 2021-01-17 12:36:52.093423: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7004)[0m 2021-01-17 12:36:52.095703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6225103400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7004)[0m 2021-01-17 12:36:52.095732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7012)[0m 2021-01-17 12:36:52.064341: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7012)[0m 2021-01-17 12:36:52.066511: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89b10e66c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7012)[0m 2021-01-17 12:36:52.066534: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7030)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7030)[0m 2021-01-17 12:36:52.071542: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7030)[0m 2021-01-17 12:36:52.079299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7030)[0m 2021-01-17 12:36:52.081496: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f559d0cefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7030)[0m 2021-01-17 12:36:52.081521: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:119: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 21.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 10 ({'RUNNING': 10})
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	RUNNING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	RUNNING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	RUNNING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7033], 5 s, 1 iter

[2m[36m(pid=7005)[0m 2021-01-17 12:36:55,283	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7005)[0m Traceback (most recent call last):
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7005)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7005)[0m     param_dset[:] = val
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7005)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7005)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7005)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7005)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7005)[0m , filename = '/tmp/thalvari/4571140/automl_save_nm7bn52d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc5566d23a4, total write size = 148012, bytes this sub-write = 148012, bytes actually written = 18446744073709551615, offset = 905216)
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m Traceback (most recent call last):
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7005)[0m     self._entrypoint()
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7005)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7005)[0m     output = train_func(config, reporter)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7005)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7005)[0m     config=config)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7005)[0m     model.save(model_path, config_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7005)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7005)[0m     self.model.save(model_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7005)[0m     signatures)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7005)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7005)[0m     f.close()
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7005)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7005)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7005)[0m , filename = '/tmp/thalvari/4571140/automl_save_nm7bn52d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc5563ef370, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7005)[0m Exception in thread Thread-1:
[2m[36m(pid=7005)[0m Traceback (most recent call last):
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7005)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7005)[0m     param_dset[:] = val
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7005)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7005)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7005)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7005)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7005)[0m , filename = '/tmp/thalvari/4571140/automl_save_nm7bn52d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc5566d23a4, total write size = 148012, bytes this sub-write = 148012, bytes actually written = 18446744073709551615, offset = 905216)
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m Traceback (most recent call last):
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7005)[0m     self._entrypoint()
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7005)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7005)[0m     output = train_func(config, reporter)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7005)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7005)[0m     config=config)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7005)[0m     model.save(model_path, config_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7005)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7005)[0m     self.model.save(model_path)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7005)[0m     signatures)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7005)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7005)[0m     f.close()
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7005)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7005)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7005)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7005)[0m , filename = '/tmp/thalvari/4571140/automl_save_nm7bn52d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc5563ef370, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7017)[0m 2021-01-17 12:36:55,312	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7017)[0m Traceback (most recent call last):
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=7017)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=7017)[0m     param_dset[:] = val
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7017)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7017)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7017)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7017)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7017)[0m , filename = '/tmp/thalvari/4571140/automl_save_fk2pcpih/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4152923988, total write size = 269036, bytes this sub-write = 269036, bytes actually written = 18446744073709551615, offset = 1409024)
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m Traceback (most recent call last):
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7017)[0m     self._entrypoint()
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7017)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7017)[0m     output = train_func(config, reporter)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7017)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7017)[0m     config=config)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7017)[0m     model.save(model_path, config_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7017)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7017)[0m     self.model.save(model_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7017)[0m     signatures)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7017)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7017)[0m     f.close()
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7017)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7017)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7017)[0m , filename = '/tmp/thalvari/4571140/automl_save_fk2pcpih/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41521b65b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7017)[0m Exception in thread Thread-1:
[2m[36m(pid=7017)[0m Traceback (most recent call last):
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=7017)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=7017)[0m     param_dset[:] = val
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7017)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7017)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7017)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7017)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7017)[0m , filename = '/tmp/thalvari/4571140/automl_save_fk2pcpih/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4152923988, total write size = 269036, bytes this sub-write = 269036, bytes actually written = 18446744073709551615, offset = 1409024)
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m Traceback (most recent call last):
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7017)[0m     self._entrypoint()
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7017)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7017)[0m     output = train_func(config, reporter)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7017)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7017)[0m     config=config)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7017)[0m     model.save(model_path, config_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7017)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7017)[0m     self.model.save(model_path)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7017)[0m     signatures)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7017)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7017)[0m     f.close()
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7017)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7017)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7017)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:36:55 2021
[2m[36m(pid=7017)[0m , filename = '/tmp/thalvari/4571140/automl_save_fk2pcpih/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f41521b65b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m Traceback (most recent call last):
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7005)[0m     self.run()
[2m[36m(pid=7005)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7005)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7005)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m Traceback (most recent call last):
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7017)[0m     self.run()
[2m[36m(pid=7017)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7017)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7017)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7017)[0m 
2021-01-17 12:36:56,651	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7017, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:36:56,661	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-17 12:36:56,706	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7005, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:36:56,711	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7017)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7017)[0m 
[2m[36m(pid=7017)[0m Stack (most recent call first):
[2m[36m(pid=7005)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7005)[0m 
[2m[36m(pid=7005)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 13 ({'RUNNING': 9, 'ERROR': 2, 'TERMINATED': 2})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7030], 10 s, 2 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7013], 10 s, 4 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7012], 9 s, 1 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7004], 9 s, 2 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7021], 9 s, 4 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7034], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7033], 9 s, 5 iter

[2m[36m(pid=8790)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8790)[0m   agg_primitives: ['count']
[2m[36m(pid=8790)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8790)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8806)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8806)[0m   agg_primitives: ['count']
[2m[36m(pid=8806)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8806)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8790)[0m LSTM is selected.
[2m[36m(pid=8790)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8790)[0m Instructions for updating:
[2m[36m(pid=8790)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8806)[0m LSTM is selected.
[2m[36m(pid=8806)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8806)[0m Instructions for updating:
[2m[36m(pid=8806)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8790)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8790)[0m Instructions for updating:
[2m[36m(pid=8790)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8806)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8806)[0m Instructions for updating:
[2m[36m(pid=8806)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8790)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8790)[0m 2021-01-17 12:37:03.525592: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8801)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8801)[0m   agg_primitives: ['count']
[2m[36m(pid=8801)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8801)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8790)[0m 2021-01-17 12:37:03.539079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8790)[0m 2021-01-17 12:37:03.541462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f614d0b1a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8790)[0m 2021-01-17 12:37:03.541486: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8806)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8806)[0m 2021-01-17 12:37:03.568143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8806)[0m 2021-01-17 12:37:03.577189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8806)[0m 2021-01-17 12:37:03.579224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcac50fd900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8806)[0m 2021-01-17 12:37:03.579248: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8801)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8801)[0m Instructions for updating:
[2m[36m(pid=8801)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8801)[0m LSTM is selected.
[2m[36m(pid=8797)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8797)[0m   agg_primitives: ['count']
[2m[36m(pid=8797)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8797)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8798)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8798)[0m   agg_primitives: ['count']
[2m[36m(pid=8798)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8798)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8801)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8801)[0m Instructions for updating:
[2m[36m(pid=8801)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8797)[0m LSTM is selected.
[2m[36m(pid=8798)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8798)[0m Instructions for updating:
[2m[36m(pid=8798)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8798)[0m LSTM is selected.
[2m[36m(pid=8797)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8797)[0m Instructions for updating:
[2m[36m(pid=8797)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8801)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8801)[0m 2021-01-17 12:37:05.595200: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8801)[0m 2021-01-17 12:37:05.608705: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8801)[0m 2021-01-17 12:37:05.613637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f37e10dc900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8801)[0m 2021-01-17 12:37:05.613699: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8798)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8798)[0m Instructions for updating:
[2m[36m(pid=8798)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8797)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8797)[0m Instructions for updating:
[2m[36m(pid=8797)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 16 ({'RUNNING': 9, 'ERROR': 2, 'TERMINATED': 5})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7030], 15 s, 4 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7020], 11 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7012], 13 s, 2 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7004], 16 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7021], 11 s, 5 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7034], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7033], 9 s, 5 iter

[2m[36m(pid=8795)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8795)[0m   agg_primitives: ['count']
[2m[36m(pid=8795)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8795)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8797)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8797)[0m 2021-01-17 12:37:06.680445: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8798)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8798)[0m 2021-01-17 12:37:06.666513: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8798)[0m 2021-01-17 12:37:06.675928: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8798)[0m 2021-01-17 12:37:06.679197: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1010e2fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8798)[0m 2021-01-17 12:37:06.679232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8797)[0m 2021-01-17 12:37:06.689051: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8797)[0m 2021-01-17 12:37:06.691887: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f46b111a6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8797)[0m 2021-01-17 12:37:06.691915: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8795)[0m LSTM is selected.
[2m[36m(pid=8795)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8795)[0m Instructions for updating:
[2m[36m(pid=8795)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8795)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8795)[0m Instructions for updating:
[2m[36m(pid=8795)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8795)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8795)[0m 2021-01-17 12:37:08.680019: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8795)[0m 2021-01-17 12:37:08.698170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8795)[0m 2021-01-17 12:37:08.703899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f19e9094fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8795)[0m 2021-01-17 12:37:08.703952: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7039)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7039)[0m   agg_primitives: ['count']
[2m[36m(pid=7039)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7039)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7039)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7039)[0m Instructions for updating:
[2m[36m(pid=7039)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7039)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 18 ({'TERMINATED': 6, 'ERROR': 2, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7020], 18 s, 2 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7012], 17 s, 3 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8806], 9 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 10 s, 1 iter
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8801], 7 s, 2 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8797], 6 s, 1 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8798], 6 s, 1 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	RUNNING
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7004], 16 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7021], 11 s, 5 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7034], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7033], 9 s, 5 iter

[2m[36m(pid=7039)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7039)[0m Instructions for updating:
[2m[36m(pid=7039)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7039)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7039)[0m 2021-01-17 12:37:12.639255: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7039)[0m 2021-01-17 12:37:12.650095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7039)[0m 2021-01-17 12:37:12.655007: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c350c8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7039)[0m 2021-01-17 12:37:12.655053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7011)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7011)[0m   agg_primitives: ['count']
[2m[36m(pid=7011)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7011)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7011)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7011)[0m Instructions for updating:
[2m[36m(pid=7011)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7011)[0m LSTM is selected.
[2m[36m(pid=7011)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7011)[0m Instructions for updating:
[2m[36m(pid=7011)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7011)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7011)[0m 2021-01-17 12:37:15.505489: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7011)[0m 2021-01-17 12:37:15.516710: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7011)[0m 2021-01-17 12:37:15.520941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7ed0fdf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7011)[0m 2021-01-17 12:37:15.520979: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 19 ({'TERMINATED': 7, 'ERROR': 2, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7020], 26 s, 3 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7012], 22 s, 4 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 10 s, 1 iter
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8801], 11 s, 4 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8797], 10 s, 3 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8798], 9 s, 3 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7039], 5 s, 1 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7004], 16 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(datetime)=0.8082,bayes_feature_HOUR(datetime)=0.91831,bayes_feature_IS_AWAKE(datetime)=0.73657,bayes_feature_IS_BUSY_HOURS(datetime)=0.82566,bayes_feature_IS_WEEKEND(datetime)=0.54423,bayes_feature_MONTH(datetime)=0.48895,bayes_feature_WEEKDAY(datetime)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7021], 11 s, 5 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(datetime)=0.73635,bayes_feature_HOUR(datetime)=0.31107,bayes_feature_IS_AWAKE(datetime)=0.95061,bayes_feature_IS_BUSY_HOURS(datetime)=0.78363,bayes_feature_IS_WEEKEND(datetime)=0.99813,bayes_feature_MONTH(datetime)=0.42064,bayes_feature_WEEKDAY(datetime)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7034], 11 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(datetime)=0.79807,bayes_feature_HOUR(datetime)=0.38699,bayes_feature_IS_AWAKE(datetime)=0.31392,bayes_feature_IS_BUSY_HOURS(datetime)=0.31835,bayes_feature_IS_WEEKEND(datetime)=0.31981,bayes_feature_MONTH(datetime)=0.47235,bayes_feature_WEEKDAY(datetime)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7033], 9 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8806], 12 s, 5 iter

[2m[36m(pid=7008)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7008)[0m   agg_primitives: ['count']
[2m[36m(pid=7008)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7008)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7008)[0m LSTM is selected.
[2m[36m(pid=7008)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7008)[0m Instructions for updating:
[2m[36m(pid=7008)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7008)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7008)[0m Instructions for updating:
[2m[36m(pid=7008)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7008)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7008)[0m 2021-01-17 12:37:21.390072: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7008)[0m 2021-01-17 12:37:21.400028: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7008)[0m 2021-01-17 12:37:21.403005: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6f1095900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7008)[0m 2021-01-17 12:37:21.403047: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 23 ({'TERMINATED': 11, 'ERROR': 2, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7020], 26 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 16 s, 2 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 13 s, 1 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7039], 9 s, 3 iter
  ... 2 not shown
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=32.545,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7012], 26 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7004], 16 s, 5 iter
  ... 3 not shown
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(datetime)=0.97872,bayes_feature_HOUR(datetime)=0.69272,bayes_feature_IS_AWAKE(datetime)=0.31305,bayes_feature_IS_BUSY_HOURS(datetime)=0.86044,bayes_feature_IS_WEEKEND(datetime)=0.46308,bayes_feature_MONTH(datetime)=0.86497,bayes_feature_WEEKDAY(datetime)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8806], 12 s, 5 iter
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8801], 13 s, 5 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter

[2m[36m(pid=7024)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7024)[0m   agg_primitives: ['count']
[2m[36m(pid=7024)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7024)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8808)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8808)[0m   agg_primitives: ['count']
[2m[36m(pid=8808)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8808)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7024)[0m LSTM is selected.
[2m[36m(pid=7024)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7024)[0m Instructions for updating:
[2m[36m(pid=7024)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8808)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8808)[0m Instructions for updating:
[2m[36m(pid=8808)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8808)[0m LSTM is selected.
[2m[36m(pid=7024)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7024)[0m Instructions for updating:
[2m[36m(pid=7024)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8808)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8808)[0m Instructions for updating:
[2m[36m(pid=8808)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7016)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7016)[0m   agg_primitives: ['count']
[2m[36m(pid=7016)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7016)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7024)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7024)[0m 2021-01-17 12:37:23.985539: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7024)[0m 2021-01-17 12:37:23.997288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7024)[0m 2021-01-17 12:37:24.000269: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1a8d095400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7024)[0m 2021-01-17 12:37:24.000303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7016)[0m LSTM is selected.
[2m[36m(pid=7016)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7016)[0m Instructions for updating:
[2m[36m(pid=7016)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8808)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8808)[0m 2021-01-17 12:37:24.073536: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8808)[0m 2021-01-17 12:37:24.082804: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8808)[0m 2021-01-17 12:37:24.086535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0d10e5c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8808)[0m 2021-01-17 12:37:24.086575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7016)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7016)[0m Instructions for updating:
[2m[36m(pid=7016)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7016)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7016)[0m 2021-01-17 12:37:25.667499: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7016)[0m 2021-01-17 12:37:25.681384: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7016)[0m 2021-01-17 12:37:25.686516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9d50e9300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7016)[0m 2021-01-17 12:37:25.686568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7023)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7023)[0m   agg_primitives: ['count']
[2m[36m(pid=7023)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7023)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7023)[0m LSTM is selected.
[2m[36m(pid=7023)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7023)[0m Instructions for updating:
[2m[36m(pid=7023)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7023)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7023)[0m Instructions for updating:
[2m[36m(pid=7023)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7006)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7006)[0m   agg_primitives: ['count']
[2m[36m(pid=7006)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7006)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 24 ({'TERMINATED': 12, 'ERROR': 2, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7020], 32 s, 4 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 22 s, 3 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 21 s, 2 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7011], 11 s, 1 iter
  ... 2 not shown
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=32.545,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7012], 26 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(datetime)=0.76466,bayes_feature_HOUR(datetime)=0.66042,bayes_feature_IS_AWAKE(datetime)=0.96122,bayes_feature_IS_BUSY_HOURS(datetime)=0.71059,bayes_feature_IS_WEEKEND(datetime)=0.93238,bayes_feature_MONTH(datetime)=0.39623,bayes_feature_WEEKDAY(datetime)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7004], 16 s, 5 iter
  ... 4 not shown
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8801], 13 s, 5 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7023)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7023)[0m 2021-01-17 12:37:27.962825: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7023)[0m 2021-01-17 12:37:27.975746: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7023)[0m 2021-01-17 12:37:27.983364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83c111ce80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7023)[0m 2021-01-17 12:37:27.983418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7006)[0m LSTM is selected.
[2m[36m(pid=7006)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7006)[0m Instructions for updating:
[2m[36m(pid=7006)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7006)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7006)[0m Instructions for updating:
[2m[36m(pid=7006)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7006)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7006)[0m 2021-01-17 12:37:29.890180: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7006)[0m 2021-01-17 12:37:29.902333: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7006)[0m 2021-01-17 12:37:29.908117: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7a50cefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7006)[0m 2021-01-17 12:37:29.908161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 25 ({'TERMINATED': 13, 'ERROR': 2, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 28 s, 4 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 21 s, 2 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7011], 11 s, 1 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7008], 13 s, 1 iter
  ... 2 not shown
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7012], 26 s, 5 iter
  ... 5 not shown
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8801], 13 s, 5 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=8781)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8781)[0m   agg_primitives: ['count']
[2m[36m(pid=8781)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8781)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8781)[0m LSTM is selected.
[2m[36m(pid=8781)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8781)[0m Instructions for updating:
[2m[36m(pid=8781)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=7024)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfbea94, total write size = 1312, bytes this sub-write = 1312, bytes actually written = 18446744073709551615, offset = 2895872)
[2m[36m(pid=7024)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=7024)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfbea94, total write size = 1312, bytes this sub-write = 1312, bytes actually written = 18446744073709551615, offset = 2895872)
[2m[36m(pid=7024)[0m 2021-01-17 12:37:35,866	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=7024)[0m     f.flush()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=7024)[0m     h5f.flush(self.id)
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=7024)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfe3300, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7024)[0m     self._entrypoint()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7024)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7024)[0m     output = train_func(config, reporter)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7024)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7024)[0m     config=config)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7024)[0m     model.save(model_path, config_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7024)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7024)[0m     self.model.save(model_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7024)[0m     signatures)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7024)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7024)[0m     f.close()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7024)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7024)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfe3300, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7024)[0m Exception in thread Thread-1:
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=7024)[0m     f.flush()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=7024)[0m     h5f.flush(self.id)
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=7024)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfe3300, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7024)[0m     self._entrypoint()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7024)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7024)[0m     output = train_func(config, reporter)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7024)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7024)[0m     config=config)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7024)[0m     model.save(model_path, config_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7024)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7024)[0m     self.model.save(model_path)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7024)[0m     signatures)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7024)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7024)[0m     f.close()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7024)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7024)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7024)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:35 2021
[2m[36m(pid=7024)[0m , filename = '/tmp/thalvari/4571140/automl_save_kjky49um/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1a8dfe3300, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m Traceback (most recent call last):
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7024)[0m     self.run()
[2m[36m(pid=7024)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7024)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7024)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7024)[0m 
[2m[36m(pid=8781)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8781)[0m Instructions for updating:
[2m[36m(pid=8781)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8808)[0m 2021-01-17 12:37:36,015	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=8808)[0m Traceback (most recent call last):
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8808)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8808)[0m     param_dset[:] = val
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8808)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8808)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8808)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8808)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:36 2021
[2m[36m(pid=8808)[0m , filename = '/tmp/thalvari/4571140/automl_save_bwnxxoeb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0d28dca2c, total write size = 99908, bytes this sub-write = 99908, bytes actually written = 18446744073709551615, offset = 2920448)
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m Traceback (most recent call last):
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8808)[0m     self._entrypoint()
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8808)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8808)[0m     output = train_func(config, reporter)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8808)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8808)[0m     config=config)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8808)[0m     model.save(model_path, config_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8808)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8808)[0m     self.model.save(model_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8808)[0m     signatures)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8808)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8808)[0m     f.close()
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8808)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8808)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:36 2021
[2m[36m(pid=8808)[0m , filename = '/tmp/thalvari/4571140/automl_save_bwnxxoeb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0d15cdc80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8808)[0m Exception in thread Thread-1:
[2m[36m(pid=8808)[0m Traceback (most recent call last):
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8808)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8808)[0m     param_dset[:] = val
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8808)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8808)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8808)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8808)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:36 2021
[2m[36m(pid=8808)[0m , filename = '/tmp/thalvari/4571140/automl_save_bwnxxoeb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0d28dca2c, total write size = 99908, bytes this sub-write = 99908, bytes actually written = 18446744073709551615, offset = 2920448)
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m Traceback (most recent call last):
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8808)[0m     self._entrypoint()
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8808)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8808)[0m     output = train_func(config, reporter)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8808)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8808)[0m     config=config)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8808)[0m     model.save(model_path, config_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8808)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8808)[0m     self.model.save(model_path)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8808)[0m     signatures)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8808)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8808)[0m     f.close()
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8808)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8808)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8808)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:36 2021
[2m[36m(pid=8808)[0m , filename = '/tmp/thalvari/4571140/automl_save_bwnxxoeb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0d15cdc80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m Traceback (most recent call last):
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=8808)[0m     self.run()
[2m[36m(pid=8808)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=8808)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=8808)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=8808)[0m 
2021-01-17 12:37:36,915	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7024, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:36,919	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=8781)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8781)[0m 2021-01-17 12:37:37.013826: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8781)[0m 2021-01-17 12:37:37.025885: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8781)[0m 2021-01-17 12:37:37.032437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc60d0e8620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8781)[0m 2021-01-17 12:37:37.032485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7024)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7024)[0m 
[2m[36m(pid=7024)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 26 ({'TERMINATED': 13, 'ERROR': 3, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-17uu9lzqo7/error_2021-01-17_12-37-36.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(datetime)=0.33119,bayes_feature_HOUR(datetime)=0.37525,bayes_feature_IS_AWAKE(datetime)=0.458,bayes_feature_IS_BUSY_HOURS(datetime)=0.79909,bayes_feature_IS_WEEKEND(datetime)=0.6918,bayes_feature_MONTH(datetime)=0.30879,bayes_feature_WEEKDAY(datetime)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8790], 28 s, 4 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 21 s, 2 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7011], 20 s, 2 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7008], 13 s, 1 iter
  ... 2 not shown
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(datetime)=0.48588,bayes_feature_HOUR(datetime)=0.6441,bayes_feature_IS_AWAKE(datetime)=0.33735,bayes_feature_IS_BUSY_HOURS(datetime)=0.70188,bayes_feature_IS_WEEKEND(datetime)=0.40271,bayes_feature_MONTH(datetime)=0.71251,bayes_feature_WEEKDAY(datetime)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7012], 26 s, 5 iter
  ... 5 not shown
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(datetime)=0.8626,bayes_feature_HOUR(datetime)=0.46466,bayes_feature_IS_AWAKE(datetime)=0.5369,bayes_feature_IS_BUSY_HOURS(datetime)=0.37391,bayes_feature_IS_WEEKEND(datetime)=0.92007,bayes_feature_MONTH(datetime)=0.46177,bayes_feature_WEEKDAY(datetime)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8801], 13 s, 5 iter
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7006)[0m 2021-01-17 12:37:38,329	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7006)[0m Traceback (most recent call last):
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7006)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7006)[0m     param_dset[:] = val
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7006)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7006)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7006)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7006)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7006)[0m , filename = '/tmp/thalvari/4571140/automl_save_c7n89bpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7a6a70678, total write size = 971100, bytes this sub-write = 971100, bytes actually written = 18446744073709551615, offset = 2904064)
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m Traceback (most recent call last):
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7006)[0m     self._entrypoint()
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7006)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7006)[0m     output = train_func(config, reporter)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7006)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7006)[0m     config=config)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7006)[0m     model.save(model_path, config_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7006)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7006)[0m     self.model.save(model_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7006)[0m     signatures)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7006)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7006)[0m     f.close()
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7006)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7006)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7006)[0m , filename = '/tmp/thalvari/4571140/automl_save_c7n89bpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7a6233aa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7006)[0m Exception in thread Thread-1:
[2m[36m(pid=7006)[0m Traceback (most recent call last):
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7006)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7006)[0m     param_dset[:] = val
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7006)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7006)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7006)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7006)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7006)[0m , filename = '/tmp/thalvari/4571140/automl_save_c7n89bpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7a6a70678, total write size = 971100, bytes this sub-write = 971100, bytes actually written = 18446744073709551615, offset = 2904064)
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m Traceback (most recent call last):
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7006)[0m     self._entrypoint()
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7006)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7006)[0m     output = train_func(config, reporter)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7006)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7006)[0m     config=config)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7006)[0m     model.save(model_path, config_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7006)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7006)[0m     self.model.save(model_path)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7006)[0m     signatures)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7006)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7006)[0m     f.close()
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7006)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7006)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7006)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7006)[0m , filename = '/tmp/thalvari/4571140/automl_save_c7n89bpx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7a6233aa0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m Traceback (most recent call last):
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7006)[0m     self.run()
[2m[36m(pid=7006)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7006)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7006)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7016)[0m 2021-01-17 12:37:38,622	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7016)[0m Traceback (most recent call last):
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7016)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7016)[0m     param_dset[:] = val
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7016)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7016)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7016)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7016)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7016)[0m , filename = '/tmp/thalvari/4571140/automl_save_ccf3tk3n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9d6a88b6c, total write size = 1015540, bytes this sub-write = 1015540, bytes actually written = 18446744073709551615, offset = 2908160)
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m Traceback (most recent call last):
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7016)[0m     self._entrypoint()
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7016)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7016)[0m     output = train_func(config, reporter)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7016)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7016)[0m     config=config)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7016)[0m     model.save(model_path, config_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7016)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7016)[0m     self.model.save(model_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7016)[0m     signatures)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7016)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7016)[0m     f.close()
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7016)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7016)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7016)[0m , filename = '/tmp/thalvari/4571140/automl_save_ccf3tk3n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9d6258310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7016)[0m Exception in thread Thread-1:
[2m[36m(pid=7016)[0m Traceback (most recent call last):
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7016)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7016)[0m     param_dset[:] = val
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7016)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7016)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7016)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7016)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7016)[0m , filename = '/tmp/thalvari/4571140/automl_save_ccf3tk3n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9d6a88b6c, total write size = 1015540, bytes this sub-write = 1015540, bytes actually written = 18446744073709551615, offset = 2908160)
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m Traceback (most recent call last):
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7016)[0m     self._entrypoint()
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7016)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7016)[0m     output = train_func(config, reporter)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7016)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7016)[0m     config=config)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7016)[0m     model.save(model_path, config_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7016)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7016)[0m     self.model.save(model_path)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7016)[0m     signatures)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7016)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7016)[0m     f.close()
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7016)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7016)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7016)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:38 2021
[2m[36m(pid=7016)[0m , filename = '/tmp/thalvari/4571140/automl_save_ccf3tk3n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9d6258310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m Traceback (most recent call last):
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7016)[0m     self.run()
[2m[36m(pid=7016)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7016)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7016)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7016)[0m 
2021-01-17 12:37:39,458	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7006, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:39,462	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7006)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7006)[0m 
[2m[36m(pid=7006)[0m Stack (most recent call first):
[2m[36m(pid=7023)[0m 2021-01-17 12:37:39,899	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7023)[0m Traceback (most recent call last):
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7023)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7023)[0m     param_dset[:] = val
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7023)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7023)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7023)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7023)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:39 2021
[2m[36m(pid=7023)[0m , filename = '/tmp/thalvari/4571140/automl_save__xvmb778/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83c290e2c8, total write size = 987388, bytes this sub-write = 987388, bytes actually written = 18446744073709551615, offset = 2899968)
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m Traceback (most recent call last):
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7023)[0m     self._entrypoint()
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7023)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7023)[0m     output = train_func(config, reporter)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7023)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7023)[0m     config=config)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7023)[0m     model.save(model_path, config_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7023)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7023)[0m     self.model.save(model_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7023)[0m     signatures)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7023)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7023)[0m     f.close()
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7023)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7023)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:39 2021
[2m[36m(pid=7023)[0m , filename = '/tmp/thalvari/4571140/automl_save__xvmb778/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83c2314900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7023)[0m Exception in thread Thread-1:
[2m[36m(pid=7023)[0m Traceback (most recent call last):
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7023)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7023)[0m     param_dset[:] = val
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7023)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7023)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7023)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7023)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:39 2021
[2m[36m(pid=7023)[0m , filename = '/tmp/thalvari/4571140/automl_save__xvmb778/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83c290e2c8, total write size = 987388, bytes this sub-write = 987388, bytes actually written = 18446744073709551615, offset = 2899968)
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m Traceback (most recent call last):
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7023)[0m     self._entrypoint()
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7023)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7023)[0m     output = train_func(config, reporter)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7023)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7023)[0m     config=config)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7023)[0m     model.save(model_path, config_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7023)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7023)[0m     self.model.save(model_path)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7023)[0m     signatures)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7023)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7023)[0m     f.close()
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7023)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7023)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7023)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:39 2021
[2m[36m(pid=7023)[0m , filename = '/tmp/thalvari/4571140/automl_save__xvmb778/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83c2314900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m Traceback (most recent call last):
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7023)[0m     self.run()
[2m[36m(pid=7023)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7023)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7023)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7023)[0m 
2021-01-17 12:37:41,103	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7023, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:41,106	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7023)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7023)[0m 
[2m[36m(pid=7023)[0m Stack (most recent call first):
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=7008)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f15713c8, total write size = 8892, bytes this sub-write = 8892, bytes actually written = 18446744073709551615, offset = 2888292)
[2m[36m(pid=7008)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=7008)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f15713c8, total write size = 8892, bytes this sub-write = 8892, bytes actually written = 18446744073709551615, offset = 2888292)
[2m[36m(pid=7008)[0m 2021-01-17 12:37:41,388	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=7008)[0m     f.flush()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=7008)[0m     h5f.flush(self.id)
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=7008)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f22b99b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7008)[0m     self._entrypoint()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7008)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7008)[0m     output = train_func(config, reporter)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7008)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7008)[0m     config=config)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7008)[0m     model.save(model_path, config_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7008)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7008)[0m     self.model.save(model_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7008)[0m     signatures)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7008)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7008)[0m     f.close()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7008)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7008)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f22b99b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7008)[0m Exception in thread Thread-1:
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=7008)[0m     f.flush()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=7008)[0m     h5f.flush(self.id)
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=7008)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f22b99b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7008)[0m     self._entrypoint()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7008)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7008)[0m     output = train_func(config, reporter)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7008)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7008)[0m     config=config)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7008)[0m     model.save(model_path, config_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7008)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7008)[0m     self.model.save(model_path)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7008)[0m     signatures)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7008)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7008)[0m     f.close()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7008)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7008)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7008)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:41 2021
[2m[36m(pid=7008)[0m , filename = '/tmp/thalvari/4571140/automl_save_j68xu2ky/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd6f22b99b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m Traceback (most recent call last):
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7008)[0m     self.run()
[2m[36m(pid=7008)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7008)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7008)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7029)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7029)[0m   agg_primitives: ['count']
[2m[36m(pid=7029)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7029)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7022)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7022)[0m   agg_primitives: ['count']
[2m[36m(pid=7022)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7022)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:37:42,093	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7016, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:42,096	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7016)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7016)[0m 
[2m[36m(pid=7016)[0m Stack (most recent call first):
[2m[36m(pid=7029)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7029)[0m Instructions for updating:
[2m[36m(pid=7029)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7029)[0m LSTM is selected.
[2m[36m(pid=7022)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7022)[0m Instructions for updating:
[2m[36m(pid=7022)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7022)[0m LSTM is selected.
[2m[36m(pid=7029)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7029)[0m Instructions for updating:
[2m[36m(pid=7029)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7022)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7022)[0m Instructions for updating:
[2m[36m(pid=7022)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 30 ({'TERMINATED': 14, 'ERROR': 6, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_20_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-17uu9lzqo7/error_2021-01-17_12-37-36.txt
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_22_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-19_x4by2ee/error_2021-01-17_12-37-42.txt
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAK_2021-01-17_12-37-215c44cgnt/error_2021-01-17_12-37-41.txt
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAK_2021-01-17_12-37-23ykywtvcx/error_2021-01-17_12-37-39.txt
RUNNING trials:
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 21 s, 2 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7011], 20 s, 2 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7008], 13 s, 1 iter
  ... 4 not shown
 - train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAKE(datetime)=0.69567,bayes_feature_IS_BUSY_HOURS(datetime)=0.97691,bayes_feature_IS_WEEKEND(datetime)=0.67976,bayes_feature_MONTH(datetime)=0.32582,bayes_feature_WEEKDAY(datetime)=0.58246,dropout_1=0.41655,dropout_2=0.41658,epochs=5,lr=0.0094211,lstm_1_units_float=126.24,lstm_2_units_float=127.19,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:37:43,134	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7008, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:43,139	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7008)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7008)[0m 
[2m[36m(pid=7008)[0m Stack (most recent call first):
[2m[36m(pid=7029)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7029)[0m 2021-01-17 12:37:44.088433: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7029)[0m 2021-01-17 12:37:44.098498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7029)[0m 2021-01-17 12:37:44.102033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f50190e9230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7029)[0m 2021-01-17 12:37:44.102058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7022)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7022)[0m 2021-01-17 12:37:44.089332: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7022)[0m 2021-01-17 12:37:44.099074: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7022)[0m 2021-01-17 12:37:44.102872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f44050e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7022)[0m 2021-01-17 12:37:44.102907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:37:44,428	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=8808, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:44,432	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_21_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=32.545,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7035)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7035)[0m   agg_primitives: ['count']
[2m[36m(pid=7035)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7035)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8808)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=8808)[0m 
[2m[36m(pid=8808)[0m Stack (most recent call first):
[2m[36m(pid=7035)[0m LSTM is selected.
[2m[36m(pid=7035)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7035)[0m Instructions for updating:
[2m[36m(pid=7035)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7007)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7007)[0m   agg_primitives: ['count']
[2m[36m(pid=7007)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7007)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7035)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7035)[0m Instructions for updating:
[2m[36m(pid=7035)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7007)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7007)[0m Instructions for updating:
[2m[36m(pid=7007)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7007)[0m LSTM is selected.
[2m[36m(pid=7007)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7007)[0m Instructions for updating:
[2m[36m(pid=7007)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8781)[0m 2021-01-17 12:37:46,623	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=8781)[0m Traceback (most recent call last):
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8781)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8781)[0m     param_dset[:] = val
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8781)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8781)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8781)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8781)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:46 2021
[2m[36m(pid=8781)[0m , filename = '/tmp/thalvari/4571140/automl_save_7ztwt57d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc60e873a7c, total write size = 1040116, bytes this sub-write = 1040116, bytes actually written = 18446744073709551615, offset = 2883584)
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m Traceback (most recent call last):
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8781)[0m     self._entrypoint()
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8781)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8781)[0m     output = train_func(config, reporter)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8781)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8781)[0m     config=config)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8781)[0m     model.save(model_path, config_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8781)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8781)[0m     self.model.save(model_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8781)[0m     signatures)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8781)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8781)[0m     f.close()
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8781)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8781)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:46 2021
[2m[36m(pid=8781)[0m , filename = '/tmp/thalvari/4571140/automl_save_7ztwt57d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc60e77f4c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8781)[0m Exception in thread Thread-1:
[2m[36m(pid=8781)[0m Traceback (most recent call last):
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8781)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8781)[0m     param_dset[:] = val
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8781)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8781)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8781)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8781)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:46 2021
[2m[36m(pid=8781)[0m , filename = '/tmp/thalvari/4571140/automl_save_7ztwt57d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc60e873a7c, total write size = 1040116, bytes this sub-write = 1040116, bytes actually written = 18446744073709551615, offset = 2883584)
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m Traceback (most recent call last):
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8781)[0m     self._entrypoint()
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8781)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8781)[0m     output = train_func(config, reporter)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8781)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8781)[0m     config=config)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8781)[0m     model.save(model_path, config_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8781)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8781)[0m     self.model.save(model_path)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8781)[0m     signatures)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8781)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8781)[0m     f.close()
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8781)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8781)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8781)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:46 2021
[2m[36m(pid=8781)[0m , filename = '/tmp/thalvari/4571140/automl_save_7ztwt57d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc60e77f4c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m Traceback (most recent call last):
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=8781)[0m     self.run()
[2m[36m(pid=8781)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=8781)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=8781)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=8781)[0m 
[2m[36m(pid=7035)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7035)[0m 2021-01-17 12:37:46.659519: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7035)[0m 2021-01-17 12:37:46.670112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7035)[0m 2021-01-17 12:37:46.673284: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3d9111ca90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7035)[0m 2021-01-17 12:37:46.673318: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7000)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7000)[0m   agg_primitives: ['count']
[2m[36m(pid=7000)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7000)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7007)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7007)[0m 2021-01-17 12:37:47.489822: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7007)[0m 2021-01-17 12:37:47.500096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7007)[0m 2021-01-17 12:37:47.503169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f63b10e9220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7007)[0m 2021-01-17 12:37:47.503201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:37:47,648	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=8781, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:47,652	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7000)[0m LSTM is selected.
[2m[36m(pid=8781)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=8781)[0m 
[2m[36m(pid=8781)[0m Stack (most recent call first):
[2m[36m(pid=7000)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7000)[0m Instructions for updating:
[2m[36m(pid=7000)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7000)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7000)[0m Instructions for updating:
[2m[36m(pid=7000)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7019)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7019)[0m   agg_primitives: ['count']
[2m[36m(pid=7019)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7019)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 33 ({'TERMINATED': 14, 'ERROR': 9, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_19_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-14t_02ifs6/error_2021-01-17_12-37-43.txt, [4 CPUs, 0 GPUs], [pid=7008], 13 s, 1 iter
  ... 3 not shown
 - train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAKE(datetime)=0.58292,bayes_feature_IS_BUSY_HOURS(datetime)=0.91189,bayes_feature_IS_WEEKEND(datetime)=0.87302,bayes_feature_MONTH(datetime)=0.33893,bayes_feature_WEEKDAY(datetime)=0.60995,dropout_1=0.29682,dropout_2=0.33001,epochs=5,lr=0.0022571,lstm_1_units_float=127.67,lstm_2_units_float=127.78,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_23_batch_size_log=5.1433,bayes_feature_DAY(datetime)=0.77874,bayes_feature_HOUR(datetime)=0.89523,bayes_feature_IS_AWAK_2021-01-17_12-37-215c44cgnt/error_2021-01-17_12-37-41.txt
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAK_2021-01-17_12-37-23ykywtvcx/error_2021-01-17_12-37-39.txt
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-29781sms92/error_2021-01-17_12-37-47.txt
RUNNING trials:
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
 - train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=7011], 28 s, 3 iter
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAKE(datetime)=0.9359,bayes_feature_IS_BUSY_HOURS(datetime)=0.81544,bayes_feature_IS_WEEKEND(datetime)=0.74263,bayes_feature_MONTH(datetime)=0.88698,bayes_feature_WEEKDAY(datetime)=0.96113,dropout_1=0.32115,dropout_2=0.3297,epochs=5,lr=0.0070948,lstm_1_units_float=127.81,lstm_2_units_float=125.13,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7019)[0m LSTM is selected.
[2m[36m(pid=7019)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7019)[0m Instructions for updating:
[2m[36m(pid=7019)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8786)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8786)[0m   agg_primitives: ['count']
[2m[36m(pid=8786)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8786)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7011)[0m 2021-01-17 12:37:49,458	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7011)[0m Traceback (most recent call last):
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7011)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7011)[0m     param_dset[:] = val
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7011)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7011)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7011)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7011)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:49 2021
[2m[36m(pid=7011)[0m , filename = '/tmp/thalvari/4571140/automl_save_b5fj8j0g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7eeaa76a8, total write size = 5004, bytes this sub-write = 5004, bytes actually written = 18446744073709551615, offset = 2871296)
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m Traceback (most recent call last):
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7011)[0m     self._entrypoint()
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7011)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7011)[0m     output = train_func(config, reporter)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7011)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7011)[0m     config=config)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7011)[0m     model.save(model_path, config_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7011)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7011)[0m     self.model.save(model_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7011)[0m     signatures)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7011)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7011)[0m     f.close()
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7011)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7011)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:49 2021
[2m[36m(pid=7011)[0m , filename = '/tmp/thalvari/4571140/automl_save_b5fj8j0g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7ed4f27a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7011)[0m Exception in thread Thread-1:
[2m[36m(pid=7011)[0m Traceback (most recent call last):
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7011)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7011)[0m     param_dset[:] = val
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7011)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7011)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7011)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7011)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:49 2021
[2m[36m(pid=7011)[0m , filename = '/tmp/thalvari/4571140/automl_save_b5fj8j0g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7eeaa76a8, total write size = 5004, bytes this sub-write = 5004, bytes actually written = 18446744073709551615, offset = 2871296)
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m Traceback (most recent call last):
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7011)[0m     self._entrypoint()
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7011)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7011)[0m     output = train_func(config, reporter)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7011)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7011)[0m     config=config)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7011)[0m     model.save(model_path, config_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7011)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7011)[0m     self.model.save(model_path)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7011)[0m     signatures)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7011)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7011)[0m     f.close()
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7011)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7011)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7011)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:49 2021
[2m[36m(pid=7011)[0m , filename = '/tmp/thalvari/4571140/automl_save_b5fj8j0g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7ed4f27a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m Traceback (most recent call last):
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7011)[0m     self.run()
[2m[36m(pid=7011)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7011)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7011)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7000)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7000)[0m 2021-01-17 12:37:49.510463: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7000)[0m 2021-01-17 12:37:49.521379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7000)[0m 2021-01-17 12:37:49.526065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f959d0b4a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7000)[0m 2021-01-17 12:37:49.526114: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7019)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7019)[0m Instructions for updating:
[2m[36m(pid=7019)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8786)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8786)[0m Instructions for updating:
[2m[36m(pid=8786)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8786)[0m LSTM is selected.
[2m[36m(pid=8786)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8786)[0m Instructions for updating:
[2m[36m(pid=8786)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:37:50,536	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7011, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:50,540	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_18_batch_size_log=5.2357,bayes_feature_DAY(datetime)=0.85556,bayes_feature_HOUR(datetime)=0.96413,bayes_feature_IS_AWAKE(datetime)=0.60629,bayes_feature_IS_BUSY_HOURS(datetime)=0.86898,bayes_feature_IS_WEEKEND(datetime)=0.42538,bayes_feature_MONTH(datetime)=0.30247,bayes_feature_WEEKDAY(datetime)=0.60144,dropout_1=0.32902,dropout_2=0.47937,epochs=5,lr=0.0063213,lstm_1_units_float=11.317,lstm_2_units_float=127.7,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7035)[0m 2021-01-17 12:37:50,572	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7035)[0m Traceback (most recent call last):
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7035)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7035)[0m     param_dset[:] = val
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7035)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7035)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7035)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7035)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=7035)[0m , filename = '/tmp/thalvari/4571140/automl_save_sq3ybsaj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3d92575948, total write size = 1011868, bytes this sub-write = 1011868, bytes actually written = 18446744073709551615, offset = 2863104)
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m Traceback (most recent call last):
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7035)[0m     self._entrypoint()
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7035)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7035)[0m     output = train_func(config, reporter)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7035)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7035)[0m     config=config)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7035)[0m     model.save(model_path, config_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7035)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7035)[0m     self.model.save(model_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7035)[0m     signatures)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7035)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7035)[0m     f.close()
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7035)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7035)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=7035)[0m , filename = '/tmp/thalvari/4571140/automl_save_sq3ybsaj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3d915bd4f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7035)[0m Exception in thread Thread-1:
[2m[36m(pid=7035)[0m Traceback (most recent call last):
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7035)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7035)[0m     param_dset[:] = val
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7035)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7035)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7035)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7035)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=7035)[0m , filename = '/tmp/thalvari/4571140/automl_save_sq3ybsaj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3d92575948, total write size = 1011868, bytes this sub-write = 1011868, bytes actually written = 18446744073709551615, offset = 2863104)
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m Traceback (most recent call last):
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7035)[0m     self._entrypoint()
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7035)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7035)[0m     output = train_func(config, reporter)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7035)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7035)[0m     config=config)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7035)[0m     model.save(model_path, config_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7035)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7035)[0m     self.model.save(model_path)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7035)[0m     signatures)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7035)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7035)[0m     f.close()
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7035)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7035)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7035)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=7035)[0m , filename = '/tmp/thalvari/4571140/automl_save_sq3ybsaj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3d915bd4f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m Traceback (most recent call last):
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7035)[0m     self.run()
[2m[36m(pid=7035)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7035)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7035)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7011)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7011)[0m 
[2m[36m(pid=7011)[0m Stack (most recent call first):
[2m[36m(pid=7019)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7019)[0m 2021-01-17 12:37:50.843558: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7019)[0m 2021-01-17 12:37:50.854402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7019)[0m 2021-01-17 12:37:50.857217: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0c1136ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7019)[0m 2021-01-17 12:37:50.857249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=8795)[0m 2021-01-17 12:37:50,914	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=8795)[0m Traceback (most recent call last):
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8795)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8795)[0m     param_dset[:] = val
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8795)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8795)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8795)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8795)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=8795)[0m , filename = '/tmp/thalvari/4571140/automl_save_57wvorus/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f19ea891a2c, total write size = 31332, bytes this sub-write = 31332, bytes actually written = 18446744073709551615, offset = 2854912)
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m Traceback (most recent call last):
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8795)[0m     self._entrypoint()
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8795)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8795)[0m     output = train_func(config, reporter)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8795)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8795)[0m     config=config)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8795)[0m     model.save(model_path, config_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8795)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8795)[0m     self.model.save(model_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8795)[0m     signatures)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8795)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8795)[0m     f.close()
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8795)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8795)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=8795)[0m , filename = '/tmp/thalvari/4571140/automl_save_57wvorus/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f19ea6da490, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8795)[0m Exception in thread Thread-1:
[2m[36m(pid=8795)[0m Traceback (most recent call last):
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8795)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8795)[0m     param_dset[:] = val
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8795)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8795)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8795)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8795)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=8795)[0m , filename = '/tmp/thalvari/4571140/automl_save_57wvorus/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f19ea891a2c, total write size = 31332, bytes this sub-write = 31332, bytes actually written = 18446744073709551615, offset = 2854912)
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m Traceback (most recent call last):
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8795)[0m     self._entrypoint()
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8795)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8795)[0m     output = train_func(config, reporter)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8795)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8795)[0m     config=config)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8795)[0m     model.save(model_path, config_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8795)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8795)[0m     self.model.save(model_path)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8795)[0m     signatures)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8795)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8795)[0m     f.close()
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8795)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8795)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8795)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:50 2021
[2m[36m(pid=8795)[0m , filename = '/tmp/thalvari/4571140/automl_save_57wvorus/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f19ea6da490, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m Traceback (most recent call last):
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=8795)[0m     self.run()
[2m[36m(pid=8795)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=8795)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=8795)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8786)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8786)[0m 2021-01-17 12:37:51.454876: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8786)[0m 2021-01-17 12:37:51.464765: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8786)[0m 2021-01-17 12:37:51.468149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eec150ceee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8786)[0m 2021-01-17 12:37:51.468195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:37:52,065	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7035, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:52,069	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAKE(datetime)=0.69567,bayes_feature_IS_BUSY_HOURS(datetime)=0.97691,bayes_feature_IS_WEEKEND(datetime)=0.67976,bayes_feature_MONTH(datetime)=0.32582,bayes_feature_WEEKDAY(datetime)=0.58246,dropout_1=0.41655,dropout_2=0.41658,epochs=5,lr=0.0094211,lstm_1_units_float=126.24,lstm_2_units_float=127.19,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7035)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7035)[0m 
[2m[36m(pid=7035)[0m Stack (most recent call first):
2021-01-17 12:37:53,019	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=8795, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:53,027	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7018)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7018)[0m   agg_primitives: ['count']
[2m[36m(pid=7018)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7018)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8795)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=8795)[0m 
[2m[36m(pid=8795)[0m Stack (most recent call first):
[2m[36m(pid=7018)[0m LSTM is selected.
[2m[36m(pid=7018)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7018)[0m Instructions for updating:
[2m[36m(pid=7018)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 36 ({'TERMINATED': 14, 'ERROR': 12, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 6 not shown
 - train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAKE(datetime)=0.98913,bayes_feature_IS_BUSY_HOURS(datetime)=0.34742,bayes_feature_IS_WEEKEND(datetime)=0.8595,bayes_feature_MONTH(datetime)=0.48424,bayes_feature_WEEKDAY(datetime)=0.31937,dropout_1=0.36935,dropout_2=0.22907,epochs=5,lr=0.0097569,lstm_1_units_float=127.94,lstm_2_units_float=127.44,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_24_batch_size_log=6.0005,bayes_feature_DAY(datetime)=0.37182,bayes_feature_HOUR(datetime)=0.71423,bayes_feature_IS_AWAK_2021-01-17_12-37-23ykywtvcx/error_2021-01-17_12-37-39.txt
 - train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_25_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-29781sms92/error_2021-01-17_12-37-47.txt
 - train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAKE(datetime)=0.69567,bayes_feature_IS_BUSY_HOURS(datetime)=0.97691,bayes_feature_IS_WEEKEND(datetime)=0.67976,bayes_feature_MONTH(datetime)=0.32582,bayes_feature_WEEKDAY(datetime)=0.58246,dropout_1=0.41655,dropout_2=0.41658,epochs=5,lr=0.0094211,lstm_1_units_float=126.24,lstm_2_units_float=127.19,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAK_2021-01-17_12-37-41a21kanv4/error_2021-01-17_12-37-52.txt
RUNNING trials:
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7018)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7018)[0m Instructions for updating:
[2m[36m(pid=7018)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7022)[0m 2021-01-17 12:37:54,733	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7022)[0m Traceback (most recent call last):
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7022)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7022)[0m     param_dset[:] = val
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7022)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7022)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7022)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7022)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:54 2021
[2m[36m(pid=7022)[0m , filename = '/tmp/thalvari/4571140/automl_save_67q1979h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f440687ab5c, total write size = 1072884, bytes this sub-write = 1072884, bytes actually written = 18446744073709551615, offset = 2850816)
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m Traceback (most recent call last):
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7022)[0m     self._entrypoint()
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7022)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7022)[0m     output = train_func(config, reporter)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7022)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7022)[0m     config=config)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7022)[0m     model.save(model_path, config_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7022)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7022)[0m     self.model.save(model_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7022)[0m     signatures)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7022)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7022)[0m     f.close()
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7022)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7022)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:54 2021
[2m[36m(pid=7022)[0m , filename = '/tmp/thalvari/4571140/automl_save_67q1979h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4406734a00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7022)[0m Exception in thread Thread-1:
[2m[36m(pid=7022)[0m Traceback (most recent call last):
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7022)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7022)[0m     param_dset[:] = val
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7022)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7022)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7022)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7022)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:54 2021
[2m[36m(pid=7022)[0m , filename = '/tmp/thalvari/4571140/automl_save_67q1979h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f440687ab5c, total write size = 1072884, bytes this sub-write = 1072884, bytes actually written = 18446744073709551615, offset = 2850816)
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m Traceback (most recent call last):
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7022)[0m     self._entrypoint()
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7022)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7022)[0m     output = train_func(config, reporter)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7022)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7022)[0m     config=config)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7022)[0m     model.save(model_path, config_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7022)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7022)[0m     self.model.save(model_path)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7022)[0m     signatures)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7022)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7022)[0m     f.close()
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7022)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7022)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7022)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:54 2021
[2m[36m(pid=7022)[0m , filename = '/tmp/thalvari/4571140/automl_save_67q1979h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4406734a00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m Traceback (most recent call last):
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7022)[0m     self.run()
[2m[36m(pid=7022)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7022)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7022)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7029)[0m 2021-01-17 12:37:55,252	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7029)[0m Traceback (most recent call last):
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7029)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7029)[0m     param_dset[:] = val
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7029)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7029)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7029)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7029)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:55 2021
[2m[36m(pid=7029)[0m , filename = '/tmp/thalvari/4571140/automl_save_le6zvyp2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f501a8bf51c, total write size = 1081076, bytes this sub-write = 1081076, bytes actually written = 18446744073709551615, offset = 2842624)
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m Traceback (most recent call last):
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7029)[0m     self._entrypoint()
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7029)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7029)[0m     output = train_func(config, reporter)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7029)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7029)[0m     config=config)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7029)[0m     model.save(model_path, config_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7029)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7029)[0m     self.model.save(model_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7029)[0m     signatures)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7029)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7029)[0m     f.close()
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7029)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7029)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:55 2021
[2m[36m(pid=7029)[0m , filename = '/tmp/thalvari/4571140/automl_save_le6zvyp2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f50195cd2c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7029)[0m Exception in thread Thread-1:
[2m[36m(pid=7029)[0m Traceback (most recent call last):
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7029)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7029)[0m     param_dset[:] = val
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7029)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7029)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7029)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7029)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:55 2021
[2m[36m(pid=7029)[0m , filename = '/tmp/thalvari/4571140/automl_save_le6zvyp2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f501a8bf51c, total write size = 1081076, bytes this sub-write = 1081076, bytes actually written = 18446744073709551615, offset = 2842624)
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m Traceback (most recent call last):
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7029)[0m     self._entrypoint()
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7029)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7029)[0m     output = train_func(config, reporter)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7029)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7029)[0m     config=config)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7029)[0m     model.save(model_path, config_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7029)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7029)[0m     self.model.save(model_path)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7029)[0m     signatures)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7029)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7029)[0m     f.close()
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7029)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7029)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7029)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:55 2021
[2m[36m(pid=7029)[0m , filename = '/tmp/thalvari/4571140/automl_save_le6zvyp2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f50195cd2c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m Traceback (most recent call last):
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7029)[0m     self.run()
[2m[36m(pid=7029)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7029)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7029)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7018)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7018)[0m 2021-01-17 12:37:55.433935: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7018)[0m 2021-01-17 12:37:55.443984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7018)[0m 2021-01-17 12:37:55.446431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f45c10cf620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7018)[0m 2021-01-17 12:37:55.446470: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:37:55,878	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7022, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:55,883	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7022)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7022)[0m 
[2m[36m(pid=7022)[0m Stack (most recent call first):
[2m[36m(pid=7038)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7038)[0m   agg_primitives: ['count']
[2m[36m(pid=7038)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7038)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7015)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7015)[0m   agg_primitives: ['count']
[2m[36m(pid=7015)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7015)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7019)[0m 2021-01-17 12:37:56,680	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7019)[0m Traceback (most recent call last):
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7019)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7019)[0m     param_dset[:] = val
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7019)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7019)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7019)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7019)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:56 2021
[2m[36m(pid=7019)[0m , filename = '/tmp/thalvari/4571140/automl_save_r70383op/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc0c22081d0, total write size = 1001260, bytes this sub-write = 1001260, bytes actually written = 18446744073709551615, offset = 2830336)
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m Traceback (most recent call last):
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7019)[0m     self._entrypoint()
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7019)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7019)[0m     output = train_func(config, reporter)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7019)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7019)[0m     config=config)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7019)[0m     model.save(model_path, config_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7019)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7019)[0m     self.model.save(model_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7019)[0m     signatures)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7019)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7019)[0m     f.close()
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7019)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7019)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:56 2021
[2m[36m(pid=7019)[0m , filename = '/tmp/thalvari/4571140/automl_save_r70383op/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc0c21e9dc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7019)[0m Exception in thread Thread-1:
[2m[36m(pid=7019)[0m Traceback (most recent call last):
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7019)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7019)[0m     param_dset[:] = val
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7019)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7019)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7019)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7019)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:56 2021
[2m[36m(pid=7019)[0m , filename = '/tmp/thalvari/4571140/automl_save_r70383op/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc0c22081d0, total write size = 1001260, bytes this sub-write = 1001260, bytes actually written = 18446744073709551615, offset = 2830336)
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m Traceback (most recent call last):
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7019)[0m     self._entrypoint()
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7019)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7019)[0m     output = train_func(config, reporter)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7019)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7019)[0m     config=config)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7019)[0m     model.save(model_path, config_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7019)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7019)[0m     self.model.save(model_path)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7019)[0m     signatures)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7019)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7019)[0m     f.close()
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7019)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7019)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7019)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:56 2021
[2m[36m(pid=7019)[0m , filename = '/tmp/thalvari/4571140/automl_save_r70383op/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc0c21e9dc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m Traceback (most recent call last):
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7019)[0m     self.run()
[2m[36m(pid=7019)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7019)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7019)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7019)[0m 
2021-01-17 12:37:57,011	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7029, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:57,014	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_26_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7038)[0m LSTM is selected.
[2m[36m(pid=7015)[0m LSTM is selected.
[2m[36m(pid=7038)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7038)[0m Instructions for updating:
[2m[36m(pid=7038)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7015)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7015)[0m Instructions for updating:
[2m[36m(pid=7015)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7029)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7029)[0m 
[2m[36m(pid=7029)[0m Stack (most recent call first):
[2m[36m(pid=7038)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7038)[0m Instructions for updating:
[2m[36m(pid=7038)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7015)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7015)[0m Instructions for updating:
[2m[36m(pid=7015)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:37:58,222	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7019, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:58,226	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAKE(datetime)=0.9359,bayes_feature_IS_BUSY_HOURS(datetime)=0.81544,bayes_feature_IS_WEEKEND(datetime)=0.74263,bayes_feature_MONTH(datetime)=0.88698,bayes_feature_WEEKDAY(datetime)=0.96113,dropout_1=0.32115,dropout_2=0.3297,epochs=5,lr=0.0070948,lstm_1_units_float=127.81,lstm_2_units_float=125.13,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7040)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7040)[0m   agg_primitives: ['count']
[2m[36m(pid=7040)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7040)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7019)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7019)[0m 
[2m[36m(pid=7019)[0m Stack (most recent call first):
[2m[36m(pid=7038)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7038)[0m 2021-01-17 12:37:58.655471: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7038)[0m 2021-01-17 12:37:58.665089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7038)[0m 2021-01-17 12:37:58.667804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98d90cf400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7038)[0m 2021-01-17 12:37:58.667839: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7015)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7015)[0m 2021-01-17 12:37:58.738013: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7015)[0m 2021-01-17 12:37:58.748454: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7040)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7040)[0m Instructions for updating:
[2m[36m(pid=7040)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7040)[0m LSTM is selected.
[2m[36m(pid=7015)[0m 2021-01-17 12:37:58.751517: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0d10cea90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7015)[0m 2021-01-17 12:37:58.751547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7007)[0m 2021-01-17 12:37:58,889	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7007)[0m Traceback (most recent call last):
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7007)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7007)[0m     param_dset[:] = val
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7007)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7007)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7007)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7007)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:58 2021
[2m[36m(pid=7007)[0m , filename = '/tmp/thalvari/4571140/automl_save_0qu_0l18/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63b2a16b0c, total write size = 1097460, bytes this sub-write = 1097460, bytes actually written = 18446744073709551615, offset = 2826240)
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m Traceback (most recent call last):
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7007)[0m     self._entrypoint()
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7007)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7007)[0m     output = train_func(config, reporter)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7007)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7007)[0m     config=config)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7007)[0m     model.save(model_path, config_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7007)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7007)[0m     self.model.save(model_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7007)[0m     signatures)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7007)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7007)[0m     f.close()
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7007)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7007)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:58 2021
[2m[36m(pid=7007)[0m , filename = '/tmp/thalvari/4571140/automl_save_0qu_0l18/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63b1475580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7007)[0m Exception in thread Thread-1:
[2m[36m(pid=7007)[0m Traceback (most recent call last):
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7007)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7007)[0m     param_dset[:] = val
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7007)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7007)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7007)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7007)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:37:58 2021
[2m[36m(pid=7007)[0m , filename = '/tmp/thalvari/4571140/automl_save_0qu_0l18/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63b2a16b0c, total write size = 1097460, bytes this sub-write = 1097460, bytes actually written = 18446744073709551615, offset = 2826240)
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m Traceback (most recent call last):
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7007)[0m     self._entrypoint()
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7007)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7007)[0m     output = train_func(config, reporter)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7007)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7007)[0m     config=config)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7007)[0m     model.save(model_path, config_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7007)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7007)[0m     self.model.save(model_path)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7007)[0m     signatures)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7007)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7007)[0m     f.close()
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7007)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7007)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7007)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:37:58 2021
[2m[36m(pid=7007)[0m , filename = '/tmp/thalvari/4571140/automl_save_0qu_0l18/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63b1475580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m Traceback (most recent call last):
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7007)[0m     self.run()
[2m[36m(pid=7007)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7007)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7007)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7040)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7040)[0m Instructions for updating:
[2m[36m(pid=7040)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 39 ({'TERMINATED': 14, 'ERROR': 15, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 9 not shown
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_27_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-39avvcxrn8/error_2021-01-17_12-37-55.txt
 - train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAKE(datetime)=0.69567,bayes_feature_IS_BUSY_HOURS(datetime)=0.97691,bayes_feature_IS_WEEKEND(datetime)=0.67976,bayes_feature_MONTH(datetime)=0.32582,bayes_feature_WEEKDAY(datetime)=0.58246,dropout_1=0.41655,dropout_2=0.41658,epochs=5,lr=0.0094211,lstm_1_units_float=126.24,lstm_2_units_float=127.19,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_28_batch_size_log=8.5698,bayes_feature_DAY(datetime)=0.79096,bayes_feature_HOUR(datetime)=0.74021,bayes_feature_IS_AWAK_2021-01-17_12-37-41a21kanv4/error_2021-01-17_12-37-52.txt
 - train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAKE(datetime)=0.9359,bayes_feature_IS_BUSY_HOURS(datetime)=0.81544,bayes_feature_IS_WEEKEND(datetime)=0.74263,bayes_feature_MONTH(datetime)=0.88698,bayes_feature_WEEKDAY(datetime)=0.96113,dropout_1=0.32115,dropout_2=0.3297,epochs=5,lr=0.0070948,lstm_1_units_float=127.81,lstm_2_units_float=125.13,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAK_2021-01-17_12-37-447fo7vwj4/error_2021-01-17_12-37-58.txt
RUNNING trials:
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:37:59,959	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7007, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:37:59,963	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_29_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7007)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7007)[0m 
[2m[36m(pid=7007)[0m Stack (most recent call first):
[2m[36m(pid=7040)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7040)[0m 2021-01-17 12:38:00.399596: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7040)[0m 2021-01-17 12:38:00.411308: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7040)[0m 2021-01-17 12:38:00.415802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f49990e8a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7040)[0m 2021-01-17 12:38:00.415847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7000)[0m 2021-01-17 12:38:00,931	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7000)[0m Traceback (most recent call last):
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7000)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7000)[0m     param_dset[:] = val
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7000)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7000)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7000)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7000)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:00 2021
[2m[36m(pid=7000)[0m , filename = '/tmp/thalvari/4571140/automl_save_vh27dd84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f959e837e0c, total write size = 1097460, bytes this sub-write = 1097460, bytes actually written = 18446744073709551615, offset = 2818048)
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m Traceback (most recent call last):
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7000)[0m     self._entrypoint()
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7000)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7000)[0m     output = train_func(config, reporter)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7000)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7000)[0m     config=config)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7000)[0m     model.save(model_path, config_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7000)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7000)[0m     self.model.save(model_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7000)[0m     signatures)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7000)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7000)[0m     f.close()
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7000)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7000)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:00 2021
[2m[36m(pid=7000)[0m , filename = '/tmp/thalvari/4571140/automl_save_vh27dd84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f959e1a6610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7000)[0m Exception in thread Thread-1:
[2m[36m(pid=7000)[0m Traceback (most recent call last):
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7000)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7000)[0m     param_dset[:] = val
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7000)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7000)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7000)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7000)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:00 2021
[2m[36m(pid=7000)[0m , filename = '/tmp/thalvari/4571140/automl_save_vh27dd84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f959e837e0c, total write size = 1097460, bytes this sub-write = 1097460, bytes actually written = 18446744073709551615, offset = 2818048)
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m Traceback (most recent call last):
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7000)[0m     self._entrypoint()
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7000)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7000)[0m     output = train_func(config, reporter)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7000)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7000)[0m     config=config)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7000)[0m     model.save(model_path, config_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7000)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7000)[0m     self.model.save(model_path)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7000)[0m     signatures)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7000)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7000)[0m     f.close()
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7000)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7000)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7000)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:00 2021
[2m[36m(pid=7000)[0m , filename = '/tmp/thalvari/4571140/automl_save_vh27dd84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f959e1a6610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m Traceback (most recent call last):
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7000)[0m     self.run()
[2m[36m(pid=7000)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7000)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7000)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7028)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7028)[0m   agg_primitives: ['count']
[2m[36m(pid=7028)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7028)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7026)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7026)[0m   agg_primitives: ['count']
[2m[36m(pid=7026)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7026)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7028)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7028)[0m Instructions for updating:
[2m[36m(pid=7028)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7028)[0m LSTM is selected.
[2m[36m(pid=7026)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7026)[0m Instructions for updating:
[2m[36m(pid=7026)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7026)[0m LSTM is selected.
2021-01-17 12:38:02,106	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7000, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:02,111	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7000)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7000)[0m 
[2m[36m(pid=7000)[0m Stack (most recent call first):
[2m[36m(pid=7026)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7026)[0m Instructions for updating:
[2m[36m(pid=7026)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7028)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7028)[0m Instructions for updating:
[2m[36m(pid=7028)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8786)[0m 2021-01-17 12:38:02,893	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=8786)[0m Traceback (most recent call last):
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8786)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8786)[0m     param_dset[:] = val
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8786)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8786)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8786)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8786)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:02 2021
[2m[36m(pid=8786)[0m , filename = '/tmp/thalvari/4571140/automl_save_t7il_r57/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eec1686405c, total write size = 1113844, bytes this sub-write = 1113844, bytes actually written = 18446744073709551615, offset = 2805760)
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m Traceback (most recent call last):
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8786)[0m     self._entrypoint()
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8786)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8786)[0m     output = train_func(config, reporter)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8786)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8786)[0m     config=config)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8786)[0m     model.save(model_path, config_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8786)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8786)[0m     self.model.save(model_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8786)[0m     signatures)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8786)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8786)[0m     f.close()
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8786)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8786)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:02 2021
[2m[36m(pid=8786)[0m , filename = '/tmp/thalvari/4571140/automl_save_t7il_r57/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eec164b3020, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8786)[0m Exception in thread Thread-1:
[2m[36m(pid=8786)[0m Traceback (most recent call last):
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8786)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8786)[0m     param_dset[:] = val
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8786)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8786)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8786)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8786)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:02 2021
[2m[36m(pid=8786)[0m , filename = '/tmp/thalvari/4571140/automl_save_t7il_r57/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eec1686405c, total write size = 1113844, bytes this sub-write = 1113844, bytes actually written = 18446744073709551615, offset = 2805760)
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m Traceback (most recent call last):
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8786)[0m     self._entrypoint()
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8786)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8786)[0m     output = train_func(config, reporter)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8786)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8786)[0m     config=config)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8786)[0m     model.save(model_path, config_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8786)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8786)[0m     self.model.save(model_path)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8786)[0m     signatures)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8786)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8786)[0m     f.close()
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8786)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8786)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8786)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:02 2021
[2m[36m(pid=8786)[0m , filename = '/tmp/thalvari/4571140/automl_save_t7il_r57/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eec164b3020, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m Traceback (most recent call last):
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=8786)[0m     self.run()
[2m[36m(pid=8786)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=8786)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=8786)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=8786)[0m 
[2m[36m(pid=7001)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7001)[0m   agg_primitives: ['count']
[2m[36m(pid=7001)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7001)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7028)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7028)[0m 2021-01-17 12:38:03.492323: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7026)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7026)[0m 2021-01-17 12:38:03.508435: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7026)[0m 2021-01-17 12:38:03.518766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7026)[0m 2021-01-17 12:38:03.521717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4cd0ce6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7026)[0m 2021-01-17 12:38:03.521746: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7028)[0m 2021-01-17 12:38:03.500172: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7028)[0m 2021-01-17 12:38:03.502705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2d890b5300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7028)[0m 2021-01-17 12:38:03.502731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7001)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7001)[0m Instructions for updating:
[2m[36m(pid=7001)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7001)[0m LSTM is selected.
2021-01-17 12:38:04,099	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=8786, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:04,103	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=8786)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=8786)[0m 
[2m[36m(pid=8786)[0m Stack (most recent call first):
[2m[36m(pid=7001)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7001)[0m Instructions for updating:
[2m[36m(pid=7001)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7002)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7002)[0m   agg_primitives: ['count']
[2m[36m(pid=7002)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7002)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 42 ({'TERMINATED': 14, 'ERROR': 18, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 12 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_30_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-43axblbl7h/error_2021-01-17_12-38-02.txt
 - train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAKE(datetime)=0.9359,bayes_feature_IS_BUSY_HOURS(datetime)=0.81544,bayes_feature_IS_WEEKEND(datetime)=0.74263,bayes_feature_MONTH(datetime)=0.88698,bayes_feature_WEEKDAY(datetime)=0.96113,dropout_1=0.32115,dropout_2=0.3297,epochs=5,lr=0.0070948,lstm_1_units_float=127.81,lstm_2_units_float=125.13,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_31_batch_size_log=6.6098,bayes_feature_DAY(datetime)=0.51873,bayes_feature_HOUR(datetime)=0.55124,bayes_feature_IS_AWAK_2021-01-17_12-37-447fo7vwj4/error_2021-01-17_12-37-58.txt
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-45oc8ts9si/error_2021-01-17_12-38-04.txt
RUNNING trials:
 - train_func_33_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE(datetime)=0.3105,bayes_feature_IS_BUSY_HOURS(datetime)=0.82051,bayes_feature_IS_WEEKEND(datetime)=0.96686,bayes_feature_MONTH(datetime)=0.88972,bayes_feature_WEEKDAY(datetime)=0.74926,dropout_1=0.45814,dropout_2=0.23274,epochs=5,lr=0.0035308,lstm_1_units_float=127.41,lstm_2_units_float=126.14,past_seq_len=2:	RUNNING
 - train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7002)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7002)[0m Instructions for updating:
[2m[36m(pid=7002)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7002)[0m LSTM is selected.
[2m[36m(pid=7001)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7001)[0m 2021-01-17 12:38:05.533376: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7001)[0m 2021-01-17 12:38:05.545312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7001)[0m 2021-01-17 12:38:05.549612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3050b4c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7001)[0m 2021-01-17 12:38:05.549663: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7002)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7002)[0m Instructions for updating:
[2m[36m(pid=7002)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7018)[0m 2021-01-17 12:38:06,914	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7018)[0m Traceback (most recent call last):
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7018)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7018)[0m     param_dset[:] = val
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7018)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7018)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7018)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7018)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:06 2021
[2m[36m(pid=7018)[0m , filename = '/tmp/thalvari/4571140/automl_save_1usvyae4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f45c2a5355c, total write size = 1122036, bytes this sub-write = 1122036, bytes actually written = 18446744073709551615, offset = 2797568)
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m Traceback (most recent call last):
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7018)[0m     self._entrypoint()
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7018)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7018)[0m     output = train_func(config, reporter)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7018)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7018)[0m     config=config)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7018)[0m     model.save(model_path, config_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7018)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7018)[0m     self.model.save(model_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7018)[0m     signatures)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7018)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7018)[0m     f.close()
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7018)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7018)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:06 2021
[2m[36m(pid=7018)[0m , filename = '/tmp/thalvari/4571140/automl_save_1usvyae4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f45c27f0e30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7018)[0m Exception in thread Thread-1:
[2m[36m(pid=7018)[0m Traceback (most recent call last):
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7018)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7018)[0m     param_dset[:] = val
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7018)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7018)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7018)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7018)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:06 2021
[2m[36m(pid=7018)[0m , filename = '/tmp/thalvari/4571140/automl_save_1usvyae4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f45c2a5355c, total write size = 1122036, bytes this sub-write = 1122036, bytes actually written = 18446744073709551615, offset = 2797568)
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m Traceback (most recent call last):
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7018)[0m     self._entrypoint()
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7018)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7018)[0m     output = train_func(config, reporter)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7018)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7018)[0m     config=config)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7018)[0m     model.save(model_path, config_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7018)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7018)[0m     self.model.save(model_path)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7018)[0m     signatures)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7018)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7018)[0m     f.close()
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7018)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7018)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7018)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:06 2021
[2m[36m(pid=7018)[0m , filename = '/tmp/thalvari/4571140/automl_save_1usvyae4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f45c27f0e30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m Traceback (most recent call last):
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7018)[0m     self.run()
[2m[36m(pid=7018)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7018)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7018)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7002)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7002)[0m 2021-01-17 12:38:07.126937: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7002)[0m 2021-01-17 12:38:07.139849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7002)[0m 2021-01-17 12:38:07.142655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22f90b4620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7002)[0m 2021-01-17 12:38:07.142696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7010)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7010)[0m   agg_primitives: ['count']
[2m[36m(pid=7010)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7010)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:38:07,969	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7018, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:07,973	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_33_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7018)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7018)[0m 
[2m[36m(pid=7018)[0m Stack (most recent call first):
[2m[36m(pid=7010)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7010)[0m Instructions for updating:
[2m[36m(pid=7010)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7010)[0m LSTM is selected.
[2m[36m(pid=7010)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7010)[0m Instructions for updating:
[2m[36m(pid=7010)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7003)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7003)[0m   agg_primitives: ['count']
[2m[36m(pid=7003)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7003)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7010)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7010)[0m 2021-01-17 12:38:10.105541: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7010)[0m 2021-01-17 12:38:10.121056: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7010)[0m 2021-01-17 12:38:10.125898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcad103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7010)[0m 2021-01-17 12:38:10.125949: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7003)[0m LSTM is selected.
[2m[36m(pid=7003)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7003)[0m Instructions for updating:
[2m[36m(pid=7003)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7015)[0m 2021-01-17 12:38:10,832	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7015)[0m Traceback (most recent call last):
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7015)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7015)[0m     param_dset[:] = val
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7015)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7015)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7015)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7015)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:10 2021
[2m[36m(pid=7015)[0m , filename = '/tmp/thalvari/4571140/automl_save_zk7jsd8m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb0d29e5100, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 2781428)
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m Traceback (most recent call last):
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7015)[0m     self._entrypoint()
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7015)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7015)[0m     output = train_func(config, reporter)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7015)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7015)[0m     config=config)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7015)[0m     model.save(model_path, config_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7015)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7015)[0m     self.model.save(model_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7015)[0m     signatures)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7015)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7015)[0m     f.close()
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7015)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7015)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:10 2021
[2m[36m(pid=7015)[0m , filename = '/tmp/thalvari/4571140/automl_save_zk7jsd8m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb0d15e8b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7015)[0m Exception in thread Thread-1:
[2m[36m(pid=7015)[0m Traceback (most recent call last):
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7015)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7015)[0m     param_dset[:] = val
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7015)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7015)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7015)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7015)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:10 2021
[2m[36m(pid=7015)[0m , filename = '/tmp/thalvari/4571140/automl_save_zk7jsd8m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb0d29e5100, total write size = 1138176, bytes this sub-write = 1138176, bytes actually written = 18446744073709551615, offset = 2781428)
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m Traceback (most recent call last):
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7015)[0m     self._entrypoint()
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7015)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7015)[0m     output = train_func(config, reporter)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7015)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7015)[0m     config=config)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7015)[0m     model.save(model_path, config_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7015)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7015)[0m     self.model.save(model_path)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7015)[0m     signatures)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7015)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7015)[0m     f.close()
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7015)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7015)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7015)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:10 2021
[2m[36m(pid=7015)[0m , filename = '/tmp/thalvari/4571140/automl_save_zk7jsd8m/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb0d15e8b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m Traceback (most recent call last):
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7015)[0m     self.run()
[2m[36m(pid=7015)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7015)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7015)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7003)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7003)[0m Instructions for updating:
[2m[36m(pid=7003)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7038)[0m 2021-01-17 12:38:11,129	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7038)[0m Traceback (most recent call last):
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7038)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7038)[0m     param_dset[:] = val
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7038)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7038)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7038)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7038)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7038)[0m , filename = '/tmp/thalvari/4571140/automl_save_e313gjmc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98da79946c, total write size = 4340, bytes this sub-write = 4340, bytes actually written = 18446744073709551615, offset = 2772992)
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m Traceback (most recent call last):
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7038)[0m     self._entrypoint()
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7038)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7038)[0m     output = train_func(config, reporter)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7038)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7038)[0m     config=config)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7038)[0m     model.save(model_path, config_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7038)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7038)[0m     self.model.save(model_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7038)[0m     signatures)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7038)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7038)[0m     f.close()
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7038)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7038)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7038)[0m , filename = '/tmp/thalvari/4571140/automl_save_e313gjmc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98da521f90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7038)[0m Exception in thread Thread-1:
[2m[36m(pid=7038)[0m Traceback (most recent call last):
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7038)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7038)[0m     param_dset[:] = val
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7038)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7038)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7038)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7038)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7038)[0m , filename = '/tmp/thalvari/4571140/automl_save_e313gjmc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98da79946c, total write size = 4340, bytes this sub-write = 4340, bytes actually written = 18446744073709551615, offset = 2772992)
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m Traceback (most recent call last):
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7038)[0m     self._entrypoint()
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7038)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7038)[0m     output = train_func(config, reporter)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7038)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7038)[0m     config=config)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7038)[0m     model.save(model_path, config_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7038)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7038)[0m     self.model.save(model_path)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7038)[0m     signatures)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7038)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7038)[0m     f.close()
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7038)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7038)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7038)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7038)[0m , filename = '/tmp/thalvari/4571140/automl_save_e313gjmc/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98da521f90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m Traceback (most recent call last):
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7038)[0m     self.run()
[2m[36m(pid=7038)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7038)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7038)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7040)[0m 2021-01-17 12:38:11,397	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7040)[0m Traceback (most recent call last):
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7040)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7040)[0m     param_dset[:] = val
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7040)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7040)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7040)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7040)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7040)[0m , filename = '/tmp/thalvari/4571140/automl_save_92x2ev79/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f499a8f37fc, total write size = 4340, bytes this sub-write = 4340, bytes actually written = 18446744073709551615, offset = 2777088)
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m Traceback (most recent call last):
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7040)[0m     self._entrypoint()
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7040)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7040)[0m     output = train_func(config, reporter)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7040)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7040)[0m     config=config)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7040)[0m     model.save(model_path, config_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7040)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7040)[0m     self.model.save(model_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7040)[0m     signatures)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7040)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7040)[0m     f.close()
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7040)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7040)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7040)[0m , filename = '/tmp/thalvari/4571140/automl_save_92x2ev79/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f499a2d96a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7040)[0m Exception in thread Thread-1:
[2m[36m(pid=7040)[0m Traceback (most recent call last):
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7040)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7040)[0m     param_dset[:] = val
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7040)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7040)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7040)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7040)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7040)[0m , filename = '/tmp/thalvari/4571140/automl_save_92x2ev79/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f499a8f37fc, total write size = 4340, bytes this sub-write = 4340, bytes actually written = 18446744073709551615, offset = 2777088)
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m Traceback (most recent call last):
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7040)[0m     self._entrypoint()
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7040)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7040)[0m     output = train_func(config, reporter)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7040)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7040)[0m     config=config)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7040)[0m     model.save(model_path, config_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7040)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7040)[0m     self.model.save(model_path)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7040)[0m     signatures)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7040)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7040)[0m     f.close()
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7040)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7040)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7040)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:11 2021
[2m[36m(pid=7040)[0m , filename = '/tmp/thalvari/4571140/automl_save_92x2ev79/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f499a2d96a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m Traceback (most recent call last):
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7040)[0m     self.run()
[2m[36m(pid=7040)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7040)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7040)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7040)[0m 
2021-01-17 12:38:11,942	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7015, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:11,946	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 43 ({'TERMINATED': 14, 'ERROR': 20, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 14 not shown
 - train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_32_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-45oc8ts9si/error_2021-01-17_12-38-04.txt
 - train_func_33_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_33_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-48np6l6deb/error_2021-01-17_12-38-07.txt
 - train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-52_3ecxx63/error_2021-01-17_12-38-11.txt
RUNNING trials:
 - train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE(datetime)=0.3105,bayes_feature_IS_BUSY_HOURS(datetime)=0.82051,bayes_feature_IS_WEEKEND(datetime)=0.96686,bayes_feature_MONTH(datetime)=0.88972,bayes_feature_WEEKDAY(datetime)=0.74926,dropout_1=0.45814,dropout_2=0.23274,epochs=5,lr=0.0035308,lstm_1_units_float=127.41,lstm_2_units_float=126.14,past_seq_len=2:	RUNNING
 - train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_43_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7003)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7003)[0m 2021-01-17 12:38:11.954010: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7003)[0m 2021-01-17 12:38:11.963556: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7003)[0m 2021-01-17 12:38:11.967323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae6111d400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7003)[0m 2021-01-17 12:38:11.967444: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7015)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7015)[0m 
[2m[36m(pid=7015)[0m Stack (most recent call first):
2021-01-17 12:38:13,379	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7038, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:13,383	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_34_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7038)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7038)[0m 
[2m[36m(pid=7038)[0m Stack (most recent call first):
[2m[36m(pid=8783)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=8783)[0m   agg_primitives: ['count']
[2m[36m(pid=8783)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=8783)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=8783)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=8783)[0m Instructions for updating:
[2m[36m(pid=8783)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=8783)[0m LSTM is selected.
2021-01-17 12:38:14,668	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7040, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:14,674	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7040)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7040)[0m 
[2m[36m(pid=7040)[0m Stack (most recent call first):
[2m[36m(pid=8783)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=8783)[0m Instructions for updating:
[2m[36m(pid=8783)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7028)[0m 2021-01-17 12:38:15,577	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7028)[0m Traceback (most recent call last):
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7028)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7028)[0m     param_dset[:] = val
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7028)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7028)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7028)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7028)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7028)[0m , filename = '/tmp/thalvari/4571140/automl_save__xbayr6v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2d89f9a28c, total write size = 35060, bytes this sub-write = 35060, bytes actually written = 18446744073709551615, offset = 2473984)
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m Traceback (most recent call last):
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7028)[0m     self._entrypoint()
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7028)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7028)[0m     output = train_func(config, reporter)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7028)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7028)[0m     config=config)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7028)[0m     model.save(model_path, config_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7028)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7028)[0m     self.model.save(model_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7028)[0m     signatures)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7028)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7028)[0m     f.close()
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7028)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7028)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7028)[0m , filename = '/tmp/thalvari/4571140/automl_save__xbayr6v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2d8a1676f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7028)[0m Exception in thread Thread-1:
[2m[36m(pid=7028)[0m Traceback (most recent call last):
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7028)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7028)[0m     param_dset[:] = val
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7028)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7028)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7028)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7028)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7028)[0m , filename = '/tmp/thalvari/4571140/automl_save__xbayr6v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2d89f9a28c, total write size = 35060, bytes this sub-write = 35060, bytes actually written = 18446744073709551615, offset = 2473984)
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m Traceback (most recent call last):
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7028)[0m     self._entrypoint()
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7028)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7028)[0m     output = train_func(config, reporter)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7028)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7028)[0m     config=config)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7028)[0m     model.save(model_path, config_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7028)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7028)[0m     self.model.save(model_path)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7028)[0m     signatures)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7028)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7028)[0m     f.close()
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7028)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7028)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7028)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7028)[0m , filename = '/tmp/thalvari/4571140/automl_save__xbayr6v/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2d8a1676f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m Traceback (most recent call last):
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7028)[0m     self.run()
[2m[36m(pid=7028)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7028)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7028)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7026)[0m 2021-01-17 12:38:15,680	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7026)[0m Traceback (most recent call last):
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7026)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7026)[0m     param_dset[:] = val
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7026)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7026)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7026)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7026)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7026)[0m , filename = '/tmp/thalvari/4571140/automl_save_mus8ld96/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ce23563c, total write size = 43252, bytes this sub-write = 43252, bytes actually written = 18446744073709551615, offset = 2469888)
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m Traceback (most recent call last):
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7026)[0m     self._entrypoint()
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7026)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7026)[0m     output = train_func(config, reporter)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7026)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7026)[0m     config=config)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7026)[0m     model.save(model_path, config_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7026)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7026)[0m     self.model.save(model_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7026)[0m     signatures)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7026)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7026)[0m     f.close()
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7026)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7026)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7026)[0m , filename = '/tmp/thalvari/4571140/automl_save_mus8ld96/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ce12c650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7026)[0m Exception in thread Thread-1:
[2m[36m(pid=7026)[0m Traceback (most recent call last):
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7026)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7026)[0m     param_dset[:] = val
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7026)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7026)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7026)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7026)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7026)[0m , filename = '/tmp/thalvari/4571140/automl_save_mus8ld96/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ce23563c, total write size = 43252, bytes this sub-write = 43252, bytes actually written = 18446744073709551615, offset = 2469888)
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m Traceback (most recent call last):
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7026)[0m     self._entrypoint()
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7026)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7026)[0m     output = train_func(config, reporter)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7026)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7026)[0m     config=config)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7026)[0m     model.save(model_path, config_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7026)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7026)[0m     self.model.save(model_path)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7026)[0m     signatures)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7026)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7026)[0m     f.close()
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7026)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7026)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7026)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7026)[0m , filename = '/tmp/thalvari/4571140/automl_save_mus8ld96/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ce12c650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m Traceback (most recent call last):
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7026)[0m     self.run()
[2m[36m(pid=7026)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7026)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7026)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7010)[0m 2021-01-17 12:38:15,811	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7010)[0m Traceback (most recent call last):
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7010)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7010)[0m     param_dset[:] = val
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7010)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7010)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7010)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7010)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7010)[0m , filename = '/tmp/thalvari/4571140/automl_save_ktohn8ek/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdcaeb29994, total write size = 1100836, bytes this sub-write = 1100836, bytes actually written = 18446744073709551615, offset = 2752512)
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m Traceback (most recent call last):
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7010)[0m     self._entrypoint()
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7010)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7010)[0m     output = train_func(config, reporter)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7010)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7010)[0m     config=config)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7010)[0m     model.save(model_path, config_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7010)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7010)[0m     self.model.save(model_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7010)[0m     signatures)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7010)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7010)[0m     f.close()
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7010)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7010)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7010)[0m , filename = '/tmp/thalvari/4571140/automl_save_ktohn8ek/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdcae8bc420, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7010)[0m Exception in thread Thread-1:
[2m[36m(pid=7010)[0m Traceback (most recent call last):
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7010)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7010)[0m     param_dset[:] = val
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7010)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7010)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7010)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7010)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7010)[0m , filename = '/tmp/thalvari/4571140/automl_save_ktohn8ek/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdcaeb29994, total write size = 1100836, bytes this sub-write = 1100836, bytes actually written = 18446744073709551615, offset = 2752512)
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m Traceback (most recent call last):
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7010)[0m     self._entrypoint()
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7010)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7010)[0m     output = train_func(config, reporter)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7010)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7010)[0m     config=config)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7010)[0m     model.save(model_path, config_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7010)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7010)[0m     self.model.save(model_path)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7010)[0m     signatures)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7010)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7010)[0m     f.close()
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7010)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7010)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7010)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:15 2021
[2m[36m(pid=7010)[0m , filename = '/tmp/thalvari/4571140/automl_save_ktohn8ek/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdcae8bc420, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m Traceback (most recent call last):
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7010)[0m     self.run()
[2m[36m(pid=7010)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7010)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7010)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7010)[0m 
[2m[36m(pid=8783)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=8783)[0m 2021-01-17 12:38:16.191703: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=8783)[0m 2021-01-17 12:38:16.200841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=8783)[0m 2021-01-17 12:38:16.204638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f72a90b5300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=8783)[0m 2021-01-17 12:38:16.204690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:38:16,713	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7026, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:16,717	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7026)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7026)[0m 
[2m[36m(pid=7026)[0m Stack (most recent call first):
[2m[36m(pid=7001)[0m 2021-01-17 12:38:16,951	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7001)[0m Traceback (most recent call last):
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7001)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7001)[0m     param_dset[:] = val
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7001)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7001)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7001)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7001)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:16 2021
[2m[36m(pid=7001)[0m , filename = '/tmp/thalvari/4571140/automl_save_p6zo4yuh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3053c5ddc, total write size = 28916, bytes this sub-write = 28916, bytes actually written = 18446744073709551615, offset = 2744320)
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m Traceback (most recent call last):
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7001)[0m     self._entrypoint()
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7001)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7001)[0m     output = train_func(config, reporter)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7001)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7001)[0m     config=config)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7001)[0m     model.save(model_path, config_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7001)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7001)[0m     self.model.save(model_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7001)[0m     signatures)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7001)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7001)[0m     f.close()
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7001)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7001)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:16 2021
[2m[36m(pid=7001)[0m , filename = '/tmp/thalvari/4571140/automl_save_p6zo4yuh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe30551f9d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7001)[0m Exception in thread Thread-1:
[2m[36m(pid=7001)[0m Traceback (most recent call last):
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7001)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7001)[0m     param_dset[:] = val
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7001)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7001)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7001)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7001)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:16 2021
[2m[36m(pid=7001)[0m , filename = '/tmp/thalvari/4571140/automl_save_p6zo4yuh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3053c5ddc, total write size = 28916, bytes this sub-write = 28916, bytes actually written = 18446744073709551615, offset = 2744320)
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m Traceback (most recent call last):
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7001)[0m     self._entrypoint()
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7001)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7001)[0m     output = train_func(config, reporter)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7001)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7001)[0m     config=config)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7001)[0m     model.save(model_path, config_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7001)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7001)[0m     self.model.save(model_path)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7001)[0m     signatures)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7001)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7001)[0m     f.close()
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7001)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7001)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7001)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:16 2021
[2m[36m(pid=7001)[0m , filename = '/tmp/thalvari/4571140/automl_save_p6zo4yuh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe30551f9d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m Traceback (most recent call last):
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7001)[0m     self.run()
[2m[36m(pid=7001)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7001)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7001)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7014)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7014)[0m   agg_primitives: ['count']
[2m[36m(pid=7014)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7014)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7025)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7025)[0m   agg_primitives: ['count']
[2m[36m(pid=7025)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7025)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7002)[0m 2021-01-17 12:38:17,772	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7002)[0m Traceback (most recent call last):
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7002)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7002)[0m     param_dset[:] = val
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7002)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7002)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7002)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7002)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:17 2021
[2m[36m(pid=7002)[0m , filename = '/tmp/thalvari/4571140/automl_save_ga5oi7ej/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22faa0d80c, total write size = 37108, bytes this sub-write = 37108, bytes actually written = 18446744073709551615, offset = 2736128)
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m Traceback (most recent call last):
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7002)[0m     self._entrypoint()
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7002)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7002)[0m     output = train_func(config, reporter)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7002)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7002)[0m     config=config)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7002)[0m     model.save(model_path, config_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7002)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7002)[0m     self.model.save(model_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7002)[0m     signatures)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7002)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7002)[0m     f.close()
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7002)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7002)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:17 2021
[2m[36m(pid=7002)[0m , filename = '/tmp/thalvari/4571140/automl_save_ga5oi7ej/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22fa6610a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7002)[0m Exception in thread Thread-1:
[2m[36m(pid=7002)[0m Traceback (most recent call last):
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7002)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7002)[0m     param_dset[:] = val
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7002)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7002)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7002)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7002)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:17 2021
[2m[36m(pid=7002)[0m , filename = '/tmp/thalvari/4571140/automl_save_ga5oi7ej/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22faa0d80c, total write size = 37108, bytes this sub-write = 37108, bytes actually written = 18446744073709551615, offset = 2736128)
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m Traceback (most recent call last):
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7002)[0m     self._entrypoint()
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7002)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7002)[0m     output = train_func(config, reporter)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7002)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7002)[0m     config=config)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7002)[0m     model.save(model_path, config_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7002)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7002)[0m     self.model.save(model_path)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7002)[0m     signatures)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7002)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7002)[0m     f.close()
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7002)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7002)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7002)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:17 2021
[2m[36m(pid=7002)[0m , filename = '/tmp/thalvari/4571140/automl_save_ga5oi7ej/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22fa6610a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m Traceback (most recent call last):
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7002)[0m     self.run()
[2m[36m(pid=7002)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7002)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7002)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7002)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 47 ({'TERMINATED': 14, 'ERROR': 23, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 17 not shown
 - train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_35_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-52_3ecxx63/error_2021-01-17_12-38-11.txt
 - train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_36_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-54g62i42_h/error_2021-01-17_12-38-14.txt
 - train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_37_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-56h1ye3ns2/error_2021-01-17_12-38-16.txt
RUNNING trials:
 - train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=5.6411,bayes_feature_DAY(datetime)=0.80329,bayes_feature_HOUR(datetime)=0.81973,bayes_feature_IS_AWAKE(datetime)=0.74653,bayes_feature_IS_BUSY_HOURS(datetime)=0.43799,bayes_feature_IS_WEEKEND(datetime)=0.58093,bayes_feature_MONTH(datetime)=0.56959,bayes_feature_WEEKDAY(datetime)=0.33524,dropout_1=0.3049,dropout_2=0.25796,epochs=5,lr=0.0043745,lstm_1_units_float=127.84,lstm_2_units_float=127.34,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:38:17,837	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7010, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:17,841	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE(datetime)=0.3105,bayes_feature_IS_BUSY_HOURS(datetime)=0.82051,bayes_feature_IS_WEEKEND(datetime)=0.96686,bayes_feature_MONTH(datetime)=0.88972,bayes_feature_WEEKDAY(datetime)=0.74926,dropout_1=0.45814,dropout_2=0.23274,epochs=5,lr=0.0035308,lstm_1_units_float=127.41,lstm_2_units_float=126.14,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7010)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7010)[0m 
[2m[36m(pid=7010)[0m Stack (most recent call first):
[2m[36m(pid=7014)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7014)[0m Instructions for updating:
[2m[36m(pid=7014)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7014)[0m LSTM is selected.
[2m[36m(pid=7025)[0m LSTM is selected.
[2m[36m(pid=7025)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7025)[0m Instructions for updating:
[2m[36m(pid=7025)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7014)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7014)[0m Instructions for updating:
[2m[36m(pid=7014)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7025)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7025)[0m Instructions for updating:
[2m[36m(pid=7025)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:38:18,868	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7001, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:18,873	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_39_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7032)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7032)[0m   agg_primitives: ['count']
[2m[36m(pid=7032)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7032)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7001)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7001)[0m 
[2m[36m(pid=7001)[0m Stack (most recent call first):
[2m[36m(pid=7032)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7032)[0m Instructions for updating:
[2m[36m(pid=7032)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7032)[0m LSTM is selected.
[2m[36m(pid=7014)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7014)[0m 2021-01-17 12:38:19.634238: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7014)[0m 2021-01-17 12:38:19.642492: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7014)[0m 2021-01-17 12:38:19.644843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1ff9137530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7014)[0m 2021-01-17 12:38:19.644874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7025)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7025)[0m 2021-01-17 12:38:19.717787: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7025)[0m 2021-01-17 12:38:19.726332: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7025)[0m 2021-01-17 12:38:19.728759: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f55c1103900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7025)[0m 2021-01-17 12:38:19.728782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7032)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7032)[0m Instructions for updating:
[2m[36m(pid=7032)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:38:20,220	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7028, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:20,223	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_38_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7028)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7028)[0m 
[2m[36m(pid=7028)[0m Stack (most recent call first):
[2m[36m(pid=7032)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7032)[0m 2021-01-17 12:38:21.080974: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7032)[0m 2021-01-17 12:38:21.091159: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7032)[0m 2021-01-17 12:38:21.095256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f14b5103c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7032)[0m 2021-01-17 12:38:21.095290: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7027)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7027)[0m   agg_primitives: ['count']
[2m[36m(pid=7027)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7027)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:38:21,549	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7002, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:21,553	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7002)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7002)[0m 
[2m[36m(pid=7002)[0m Stack (most recent call first):
[2m[36m(pid=7031)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7031)[0m   agg_primitives: ['count']
[2m[36m(pid=7031)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7031)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7027)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7027)[0m Instructions for updating:
[2m[36m(pid=7027)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7027)[0m LSTM is selected.
[2m[36m(pid=7031)[0m LSTM is selected.
[2m[36m(pid=7031)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7031)[0m Instructions for updating:
[2m[36m(pid=7031)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7027)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7027)[0m Instructions for updating:
[2m[36m(pid=7027)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7003)[0m 2021-01-17 12:38:22,809	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7003)[0m Traceback (most recent call last):
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7003)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7003)[0m     param_dset[:] = val
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7003)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7003)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7003)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7003)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:22 2021
[2m[36m(pid=7003)[0m , filename = '/tmp/thalvari/4571140/automl_save_03_9ymgb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae627f992c, total write size = 61684, bytes this sub-write = 61684, bytes actually written = 18446744073709551615, offset = 2727936)
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m Traceback (most recent call last):
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7003)[0m     self._entrypoint()
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7003)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7003)[0m     output = train_func(config, reporter)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7003)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7003)[0m     config=config)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7003)[0m     model.save(model_path, config_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7003)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7003)[0m     self.model.save(model_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7003)[0m     signatures)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7003)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7003)[0m     f.close()
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7003)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7003)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:22 2021
[2m[36m(pid=7003)[0m , filename = '/tmp/thalvari/4571140/automl_save_03_9ymgb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae62477160, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7003)[0m Exception in thread Thread-1:
[2m[36m(pid=7003)[0m Traceback (most recent call last):
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7003)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7003)[0m     param_dset[:] = val
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7003)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7003)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7003)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7003)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:22 2021
[2m[36m(pid=7003)[0m , filename = '/tmp/thalvari/4571140/automl_save_03_9ymgb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae627f992c, total write size = 61684, bytes this sub-write = 61684, bytes actually written = 18446744073709551615, offset = 2727936)
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m Traceback (most recent call last):
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7003)[0m     self._entrypoint()
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7003)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7003)[0m     output = train_func(config, reporter)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7003)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7003)[0m     config=config)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7003)[0m     model.save(model_path, config_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7003)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7003)[0m     self.model.save(model_path)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7003)[0m     signatures)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7003)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7003)[0m     f.close()
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7003)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7003)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7003)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:22 2021
[2m[36m(pid=7003)[0m , filename = '/tmp/thalvari/4571140/automl_save_03_9ymgb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fae62477160, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m Traceback (most recent call last):
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7003)[0m     self.run()
[2m[36m(pid=7003)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7003)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7003)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7031)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7031)[0m Instructions for updating:
[2m[36m(pid=7031)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7027)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7027)[0m 2021-01-17 12:38:23.636926: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7027)[0m 2021-01-17 12:38:23.646803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7027)[0m 2021-01-17 12:38:23.652097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe731103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7027)[0m 2021-01-17 12:38:23.652138: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=17552)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=17552)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-17 12:38:23,987	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7003, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:23,992	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 51 ({'TERMINATED': 14, 'ERROR': 28, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 22 not shown
 - train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_40_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-01k3sq2ddy/error_2021-01-17_12-38-21.txt
 - train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE(datetime)=0.3105,bayes_feature_IS_BUSY_HOURS(datetime)=0.82051,bayes_feature_IS_WEEKEND(datetime)=0.96686,bayes_feature_MONTH(datetime)=0.88972,bayes_feature_WEEKDAY(datetime)=0.74926,dropout_1=0.45814,dropout_2=0.23274,epochs=5,lr=0.0035308,lstm_1_units_float=127.41,lstm_2_units_float=126.14,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE_2021-01-17_12-38-030dj0t2bo/error_2021-01-17_12-38-17.txt
 - train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-05jlrqcqom/error_2021-01-17_12-38-23.txt
RUNNING trials:
 - train_func_43_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_44_batch_size_log=5.7502,bayes_feature_DAY(datetime)=0.97401,bayes_feature_HOUR(datetime)=0.69259,bayes_feature_IS_AWAKE(datetime)=0.87816,bayes_feature_IS_BUSY_HOURS(datetime)=0.79049,bayes_feature_IS_WEEKEND(datetime)=0.53937,bayes_feature_MONTH(datetime)=0.53047,bayes_feature_WEEKDAY(datetime)=0.50751,dropout_1=0.39484,dropout_2=0.42743,epochs=5,lr=0.0073878,lstm_1_units_float=127.31,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_49_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.0010996,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=7003)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7003)[0m 
[2m[36m(pid=7003)[0m Stack (most recent call first):
[2m[36m(pid=7031)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7031)[0m 2021-01-17 12:38:24.126157: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7031)[0m 2021-01-17 12:38:24.139520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7031)[0m 2021-01-17 12:38:24.145690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe39d0cf300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7031)[0m 2021-01-17 12:38:24.145735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7037)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7037)[0m   agg_primitives: ['count']
[2m[36m(pid=7037)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7037)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7037)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7037)[0m Instructions for updating:
[2m[36m(pid=7037)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7037)[0m LSTM is selected.
[2m[36m(pid=17718)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=17718)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7037)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7037)[0m Instructions for updating:
[2m[36m(pid=7037)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7036)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=7036)[0m   agg_primitives: ['count']
[2m[36m(pid=7036)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=7036)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=17891)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=17894)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=17894)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=17891)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7036)[0m LSTM is selected.
[2m[36m(pid=7036)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=7036)[0m Instructions for updating:
[2m[36m(pid=7036)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=7037)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7037)[0m 2021-01-17 12:38:26.720338: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7037)[0m 2021-01-17 12:38:26.734354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7037)[0m 2021-01-17 12:38:26.738110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2ef11026c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7037)[0m 2021-01-17 12:38:26.738151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7036)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=7036)[0m Instructions for updating:
[2m[36m(pid=7036)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=8783)[0m 2021-01-17 12:38:27,289	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=8783)[0m Traceback (most recent call last):
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8783)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8783)[0m     param_dset[:] = val
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8783)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8783)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8783)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8783)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:27 2021
[2m[36m(pid=8783)[0m , filename = '/tmp/thalvari/4571140/automl_save_zttvbm08/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f72aa787d0c, total write size = 86260, bytes this sub-write = 86260, bytes actually written = 18446744073709551615, offset = 2686976)
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m Traceback (most recent call last):
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8783)[0m     self._entrypoint()
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8783)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8783)[0m     output = train_func(config, reporter)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8783)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8783)[0m     config=config)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8783)[0m     model.save(model_path, config_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8783)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8783)[0m     self.model.save(model_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8783)[0m     signatures)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8783)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8783)[0m     f.close()
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8783)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8783)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:27 2021
[2m[36m(pid=8783)[0m , filename = '/tmp/thalvari/4571140/automl_save_zttvbm08/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f72aa0b8c20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8783)[0m Exception in thread Thread-1:
[2m[36m(pid=8783)[0m Traceback (most recent call last):
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=8783)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=8783)[0m     param_dset[:] = val
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=8783)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=8783)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=8783)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=8783)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:27 2021
[2m[36m(pid=8783)[0m , filename = '/tmp/thalvari/4571140/automl_save_zttvbm08/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f72aa787d0c, total write size = 86260, bytes this sub-write = 86260, bytes actually written = 18446744073709551615, offset = 2686976)
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m Traceback (most recent call last):
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=8783)[0m     self._entrypoint()
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=8783)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=8783)[0m     output = train_func(config, reporter)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=8783)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=8783)[0m     config=config)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=8783)[0m     model.save(model_path, config_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=8783)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=8783)[0m     self.model.save(model_path)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=8783)[0m     signatures)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=8783)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=8783)[0m     f.close()
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=8783)[0m     h5i.dec_ref(id_)
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=8783)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=8783)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:27 2021
[2m[36m(pid=8783)[0m , filename = '/tmp/thalvari/4571140/automl_save_zttvbm08/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f72aa0b8c20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m Traceback (most recent call last):
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=8783)[0m     self.run()
[2m[36m(pid=8783)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=8783)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=8783)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=8783)[0m 
[2m[36m(pid=7036)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=7036)[0m 2021-01-17 12:38:28.185518: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=7036)[0m 2021-01-17 12:38:28.195686: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=7036)[0m 2021-01-17 12:38:28.198277: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4e5103530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=7036)[0m 2021-01-17 12:38:28.198315: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=7014)[0m 2021-01-17 12:38:28,232	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7014)[0m Traceback (most recent call last):
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7014)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7014)[0m     param_dset[:] = val
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7014)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7014)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7014)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7014)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:28 2021
[2m[36m(pid=7014)[0m , filename = '/tmp/thalvari/4571140/automl_save_edbp03he/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1ff9d43518, total write size = 83352, bytes this sub-write = 83352, bytes actually written = 18446744073709551615, offset = 2674688)
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m Traceback (most recent call last):
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7014)[0m     self._entrypoint()
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7014)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7014)[0m     output = train_func(config, reporter)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7014)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7014)[0m     config=config)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7014)[0m     model.save(model_path, config_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7014)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7014)[0m     self.model.save(model_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7014)[0m     signatures)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7014)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7014)[0m     f.close()
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7014)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7014)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:28 2021
[2m[36m(pid=7014)[0m , filename = '/tmp/thalvari/4571140/automl_save_edbp03he/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1ffa4fe7a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7014)[0m Exception in thread Thread-1:
[2m[36m(pid=7014)[0m Traceback (most recent call last):
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7014)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7014)[0m     param_dset[:] = val
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7014)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7014)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7014)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7014)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:28 2021
[2m[36m(pid=7014)[0m , filename = '/tmp/thalvari/4571140/automl_save_edbp03he/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1ff9d43518, total write size = 83352, bytes this sub-write = 83352, bytes actually written = 18446744073709551615, offset = 2674688)
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m Traceback (most recent call last):
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7014)[0m     self._entrypoint()
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7014)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7014)[0m     output = train_func(config, reporter)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7014)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7014)[0m     config=config)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7014)[0m     model.save(model_path, config_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7014)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7014)[0m     self.model.save(model_path)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7014)[0m     signatures)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7014)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7014)[0m     f.close()
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7014)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7014)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7014)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:28 2021
[2m[36m(pid=7014)[0m , filename = '/tmp/thalvari/4571140/automl_save_edbp03he/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1ffa4fe7a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m Traceback (most recent call last):
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7014)[0m     self.run()
[2m[36m(pid=7014)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7014)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7014)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7014)[0m 
2021-01-17 12:38:28,390	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=8783, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:28,396	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_43_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=8783)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=8783)[0m 
[2m[36m(pid=8783)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 53 ({'TERMINATED': 14, 'ERROR': 29, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 23 not shown
 - train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE(datetime)=0.3105,bayes_feature_IS_BUSY_HOURS(datetime)=0.82051,bayes_feature_IS_WEEKEND(datetime)=0.96686,bayes_feature_MONTH(datetime)=0.88972,bayes_feature_WEEKDAY(datetime)=0.74926,dropout_1=0.45814,dropout_2=0.23274,epochs=5,lr=0.0035308,lstm_1_units_float=127.41,lstm_2_units_float=126.14,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_41_batch_size_log=7.0104,bayes_feature_DAY(datetime)=0.86461,bayes_feature_HOUR(datetime)=0.4629,bayes_feature_IS_AWAKE_2021-01-17_12-38-030dj0t2bo/error_2021-01-17_12-38-17.txt
 - train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_42_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-05jlrqcqom/error_2021-01-17_12-38-23.txt
 - train_func_43_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_43_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-09p4woixkm/error_2021-01-17_12-38-28.txt
RUNNING trials:
 - train_func_44_batch_size_log=5.7502,bayes_feature_DAY(datetime)=0.97401,bayes_feature_HOUR(datetime)=0.69259,bayes_feature_IS_AWAKE(datetime)=0.87816,bayes_feature_IS_BUSY_HOURS(datetime)=0.79049,bayes_feature_IS_WEEKEND(datetime)=0.53937,bayes_feature_MONTH(datetime)=0.53047,bayes_feature_WEEKDAY(datetime)=0.50751,dropout_1=0.39484,dropout_2=0.42743,epochs=5,lr=0.0073878,lstm_1_units_float=127.31,lstm_2_units_float=127.71,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:38:29,863	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7014, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:29,867	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_44_batch_size_log=5.7502,bayes_feature_DAY(datetime)=0.97401,bayes_feature_HOUR(datetime)=0.69259,bayes_feature_IS_AWAKE(datetime)=0.87816,bayes_feature_IS_BUSY_HOURS(datetime)=0.79049,bayes_feature_IS_WEEKEND(datetime)=0.53937,bayes_feature_MONTH(datetime)=0.53047,bayes_feature_WEEKDAY(datetime)=0.50751,dropout_1=0.39484,dropout_2=0.42743,epochs=5,lr=0.0073878,lstm_1_units_float=127.31,lstm_2_units_float=127.71,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7014)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7014)[0m 
[2m[36m(pid=7014)[0m Stack (most recent call first):
[2m[36m(pid=17552)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=17552)[0m   agg_primitives: ['count']
[2m[36m(pid=17552)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=17552)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=17718)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=17718)[0m   agg_primitives: ['count']
[2m[36m(pid=17718)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=17718)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=7025)[0m 2021-01-17 12:38:31,186	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7025)[0m Traceback (most recent call last):
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7025)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7025)[0m     param_dset[:] = val
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7025)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7025)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7025)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7025)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:31 2021
[2m[36m(pid=7025)[0m , filename = '/tmp/thalvari/4571140/automl_save_v8jo13d_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55c22a73bc, total write size = 119028, bytes this sub-write = 119028, bytes actually written = 18446744073709551615, offset = 2666496)
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m Traceback (most recent call last):
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7025)[0m     self._entrypoint()
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7025)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7025)[0m     output = train_func(config, reporter)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7025)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7025)[0m     config=config)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7025)[0m     model.save(model_path, config_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7025)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7025)[0m     self.model.save(model_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7025)[0m     signatures)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7025)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7025)[0m     f.close()
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7025)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7025)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:31 2021
[2m[36m(pid=7025)[0m , filename = '/tmp/thalvari/4571140/automl_save_v8jo13d_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55c1dcb400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7025)[0m Exception in thread Thread-1:
[2m[36m(pid=7025)[0m Traceback (most recent call last):
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7025)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7025)[0m     param_dset[:] = val
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7025)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7025)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7025)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7025)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:31 2021
[2m[36m(pid=7025)[0m , filename = '/tmp/thalvari/4571140/automl_save_v8jo13d_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55c22a73bc, total write size = 119028, bytes this sub-write = 119028, bytes actually written = 18446744073709551615, offset = 2666496)
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m Traceback (most recent call last):
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7025)[0m     self._entrypoint()
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7025)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7025)[0m     output = train_func(config, reporter)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7025)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7025)[0m     config=config)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7025)[0m     model.save(model_path, config_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7025)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7025)[0m     self.model.save(model_path)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7025)[0m     signatures)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7025)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7025)[0m     f.close()
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7025)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7025)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7025)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:31 2021
[2m[36m(pid=7025)[0m , filename = '/tmp/thalvari/4571140/automl_save_v8jo13d_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55c1dcb400, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m Traceback (most recent call last):
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7025)[0m     self.run()
[2m[36m(pid=7025)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7025)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7025)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7025)[0m 
[2m[36m(pid=17552)[0m LSTM is selected.
[2m[36m(pid=17718)[0m LSTM is selected.
[2m[36m(pid=17552)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=17552)[0m Instructions for updating:
[2m[36m(pid=17552)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=17718)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=17718)[0m Instructions for updating:
[2m[36m(pid=17718)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=17552)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=17552)[0m Instructions for updating:
[2m[36m(pid=17552)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=17718)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=17718)[0m Instructions for updating:
[2m[36m(pid=17718)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:38:32,251	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7025, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:32,254	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7025)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7025)[0m 
[2m[36m(pid=7025)[0m Stack (most recent call first):
[2m[36m(pid=7027)[0m 2021-01-17 12:38:32,499	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7027)[0m Traceback (most recent call last):
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7027)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7027)[0m     param_dset[:] = val
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7027)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7027)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7027)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7027)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7027)[0m , filename = '/tmp/thalvari/4571140/automl_save_x77ee239/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe73260fca8, total write size = 99800, bytes this sub-write = 99800, bytes actually written = 18446744073709551615, offset = 2650112)
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m Traceback (most recent call last):
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7027)[0m     self._entrypoint()
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7027)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7027)[0m     output = train_func(config, reporter)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7027)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7027)[0m     config=config)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7027)[0m     model.save(model_path, config_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7027)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7027)[0m     self.model.save(model_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7027)[0m     signatures)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7027)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7027)[0m     f.close()
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7027)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7027)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7027)[0m , filename = '/tmp/thalvari/4571140/automl_save_x77ee239/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe73279fdd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7027)[0m Exception in thread Thread-1:
[2m[36m(pid=7027)[0m Traceback (most recent call last):
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7027)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7027)[0m     param_dset[:] = val
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7027)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7027)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7027)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7027)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7027)[0m , filename = '/tmp/thalvari/4571140/automl_save_x77ee239/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe73260fca8, total write size = 99800, bytes this sub-write = 99800, bytes actually written = 18446744073709551615, offset = 2650112)
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m Traceback (most recent call last):
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7027)[0m     self._entrypoint()
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7027)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7027)[0m     output = train_func(config, reporter)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7027)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7027)[0m     config=config)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7027)[0m     model.save(model_path, config_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7027)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7027)[0m     self.model.save(model_path)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7027)[0m     signatures)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7027)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7027)[0m     f.close()
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7027)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7027)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7027)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7027)[0m , filename = '/tmp/thalvari/4571140/automl_save_x77ee239/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe73279fdd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m Traceback (most recent call last):
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7027)[0m     self.run()
[2m[36m(pid=7027)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7027)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7027)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7032)[0m 2021-01-17 12:38:32,768	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7032)[0m Traceback (most recent call last):
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7032)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7032)[0m     param_dset[:] = val
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7032)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7032)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7032)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7032)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7032)[0m , filename = '/tmp/thalvari/4571140/automl_save_aw_crawh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f14b67c89bc, total write size = 135412, bytes this sub-write = 135412, bytes actually written = 18446744073709551615, offset = 2650112)
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m Traceback (most recent call last):
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7032)[0m     self._entrypoint()
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7032)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7032)[0m     output = train_func(config, reporter)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7032)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7032)[0m     config=config)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7032)[0m     model.save(model_path, config_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7032)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7032)[0m     self.model.save(model_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7032)[0m     signatures)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7032)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7032)[0m     f.close()
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7032)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7032)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7032)[0m , filename = '/tmp/thalvari/4571140/automl_save_aw_crawh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f14b6751e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7032)[0m Exception in thread Thread-1:
[2m[36m(pid=7032)[0m Traceback (most recent call last):
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7032)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7032)[0m     param_dset[:] = val
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7032)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7032)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7032)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7032)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7032)[0m , filename = '/tmp/thalvari/4571140/automl_save_aw_crawh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f14b67c89bc, total write size = 135412, bytes this sub-write = 135412, bytes actually written = 18446744073709551615, offset = 2650112)
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m Traceback (most recent call last):
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7032)[0m     self._entrypoint()
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7032)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7032)[0m     output = train_func(config, reporter)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7032)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7032)[0m     config=config)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7032)[0m     model.save(model_path, config_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7032)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7032)[0m     self.model.save(model_path)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7032)[0m     signatures)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7032)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7032)[0m     f.close()
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7032)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7032)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7032)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:32 2021
[2m[36m(pid=7032)[0m , filename = '/tmp/thalvari/4571140/automl_save_aw_crawh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f14b6751e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m Traceback (most recent call last):
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7032)[0m     self.run()
[2m[36m(pid=7032)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7032)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7032)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7032)[0m 
[2m[36m(pid=17718)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=17718)[0m 2021-01-17 12:38:33.213572: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=17718)[0m 2021-01-17 12:38:33.222025: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=17718)[0m 2021-01-17 12:38:33.224724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf710e86c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=17718)[0m 2021-01-17 12:38:33.224752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=17552)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=17552)[0m 2021-01-17 12:38:33.297000: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=17552)[0m 2021-01-17 12:38:33.305620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=17552)[0m 2021-01-17 12:38:33.308317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fad8d0ce6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=17552)[0m 2021-01-17 12:38:33.308367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:38:33,699	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7027, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:33,702	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_47_batch_size_log=5.6411,bayes_feature_DAY(datetime)=0.80329,bayes_feature_HOUR(datetime)=0.81973,bayes_feature_IS_AWAKE(datetime)=0.74653,bayes_feature_IS_BUSY_HOURS(datetime)=0.43799,bayes_feature_IS_WEEKEND(datetime)=0.58093,bayes_feature_MONTH(datetime)=0.56959,bayes_feature_WEEKDAY(datetime)=0.33524,dropout_1=0.3049,dropout_2=0.25796,epochs=5,lr=0.0043745,lstm_1_units_float=127.84,lstm_2_units_float=127.34,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7027)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7027)[0m 
[2m[36m(pid=7027)[0m Stack (most recent call first):
[2m[36m(pid=17891)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=17891)[0m   agg_primitives: ['count']
[2m[36m(pid=17891)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=17891)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=17894)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=17894)[0m   agg_primitives: ['count']
[2m[36m(pid=17894)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=17894)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=17894)[0m LSTM is selected.
[2m[36m(pid=17891)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=17891)[0m Instructions for updating:
[2m[36m(pid=17891)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=17891)[0m LSTM is selected.
[2m[36m(pid=17894)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=17894)[0m Instructions for updating:
[2m[36m(pid=17894)[0m If using Keras pass *_constraint arguments to layers.
2021-01-17 12:38:34,816	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7032, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:34,821	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18676)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18682)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18681)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18879)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18680)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18678)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18676)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18682)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18681)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18879)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18680)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18678)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=7032)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7032)[0m 
[2m[36m(pid=7032)[0m Stack (most recent call first):
[2m[36m(pid=17894)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=17894)[0m Instructions for updating:
[2m[36m(pid=17894)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=17891)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=17891)[0m Instructions for updating:
[2m[36m(pid=17891)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=7031)[0m 2021-01-17 12:38:36,053	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7031)[0m Traceback (most recent call last):
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7031)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7031)[0m     param_dset[:] = val
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7031)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7031)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7031)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7031)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:36 2021
[2m[36m(pid=7031)[0m , filename = '/tmp/thalvari/4571140/automl_save_jqd0lq1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe39e9640bc, total write size = 258292, bytes this sub-write = 258292, bytes actually written = 18446744073709551615, offset = 2519040)
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m Traceback (most recent call last):
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7031)[0m     self._entrypoint()
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7031)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7031)[0m     output = train_func(config, reporter)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7031)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7031)[0m     config=config)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7031)[0m     model.save(model_path, config_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7031)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7031)[0m     self.model.save(model_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7031)[0m     signatures)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7031)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7031)[0m     f.close()
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7031)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7031)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:36 2021
[2m[36m(pid=7031)[0m , filename = '/tmp/thalvari/4571140/automl_save_jqd0lq1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe39e621930, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7031)[0m Exception in thread Thread-1:
[2m[36m(pid=7031)[0m Traceback (most recent call last):
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7031)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7031)[0m     param_dset[:] = val
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7031)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7031)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7031)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7031)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:36 2021
[2m[36m(pid=7031)[0m , filename = '/tmp/thalvari/4571140/automl_save_jqd0lq1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe39e9640bc, total write size = 258292, bytes this sub-write = 258292, bytes actually written = 18446744073709551615, offset = 2519040)
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m Traceback (most recent call last):
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7031)[0m     self._entrypoint()
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7031)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7031)[0m     output = train_func(config, reporter)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7031)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7031)[0m     config=config)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7031)[0m     model.save(model_path, config_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7031)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7031)[0m     self.model.save(model_path)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7031)[0m     signatures)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7031)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7031)[0m     f.close()
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7031)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7031)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7031)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:36 2021
[2m[36m(pid=7031)[0m , filename = '/tmp/thalvari/4571140/automl_save_jqd0lq1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe39e621930, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m Traceback (most recent call last):
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7031)[0m     self.run()
[2m[36m(pid=7031)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7031)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7031)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7031)[0m 
[2m[36m(pid=18951)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18951)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18953)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18953)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18952)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18952)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18932)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18932)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18934)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18934)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18931)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18931)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18948)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18944)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18944)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18949)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18949)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18933)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18933)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18941)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=18941)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18948)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=17894)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=17894)[0m 2021-01-17 12:38:36.352063: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=17894)[0m 2021-01-17 12:38:36.363821: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=17894)[0m 2021-01-17 12:38:36.368382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2b450ce900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=17894)[0m 2021-01-17 12:38:36.368424: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=17891)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=17891)[0m 2021-01-17 12:38:36.528222: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=17891)[0m 2021-01-17 12:38:36.591445: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=17891)[0m 2021-01-17 12:38:36.600883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eee610ceee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=17891)[0m 2021-01-17 12:38:36.600930: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 57 ({'TERMINATED': 14, 'ERROR': 33, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 27 not shown
 - train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_45_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-145t_9_903/error_2021-01-17_12-38-32.txt
 - train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_46_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-15y4gshoax/error_2021-01-17_12-38-34.txt
 - train_func_47_batch_size_log=5.6411,bayes_feature_DAY(datetime)=0.80329,bayes_feature_HOUR(datetime)=0.81973,bayes_feature_IS_AWAKE(datetime)=0.74653,bayes_feature_IS_BUSY_HOURS(datetime)=0.43799,bayes_feature_IS_WEEKEND(datetime)=0.58093,bayes_feature_MONTH(datetime)=0.56959,bayes_feature_WEEKDAY(datetime)=0.33524,dropout_1=0.3049,dropout_2=0.25796,epochs=5,lr=0.0043745,lstm_1_units_float=127.84,lstm_2_units_float=127.34,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_47_batch_size_log=5.6411,bayes_feature_DAY(datetime)=0.80329,bayes_feature_HOUR(datetime)=0.81973,bayes_feature_IS_AWAK_2021-01-17_12-38-17d679jqt9/error_2021-01-17_12-38-33.txt
RUNNING trials:
 - train_func_48_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_49_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.0010996,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_56_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:38:37,213	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7031, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:37,216	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_48_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7031)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7031)[0m 
[2m[36m(pid=7031)[0m Stack (most recent call first):
2021-01-17 12:38:38,805	WARNING util.py:64 -- The `start_trial` operation took 0.13601279258728027 seconds to complete, which may be a performance bottleneck.
[2m[36m(pid=7037)[0m 2021-01-17 12:38:39,047	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7037)[0m Traceback (most recent call last):
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7037)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7037)[0m     param_dset[:] = val
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7037)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7037)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7037)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7037)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:39 2021
[2m[36m(pid=7037)[0m , filename = '/tmp/thalvari/4571140/automl_save_loeb06jf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2ef21ff3ac, total write size = 35060, bytes this sub-write = 35060, bytes actually written = 18446744073709551615, offset = 2486272)
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m Traceback (most recent call last):
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7037)[0m     self._entrypoint()
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7037)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7037)[0m     output = train_func(config, reporter)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7037)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7037)[0m     config=config)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7037)[0m     model.save(model_path, config_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7037)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7037)[0m     self.model.save(model_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7037)[0m     signatures)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7037)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7037)[0m     f.close()
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7037)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7037)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:39 2021
[2m[36m(pid=7037)[0m , filename = '/tmp/thalvari/4571140/automl_save_loeb06jf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2ef28e0330, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7037)[0m Exception in thread Thread-1:
[2m[36m(pid=7037)[0m Traceback (most recent call last):
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7037)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7037)[0m     param_dset[:] = val
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7037)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7037)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7037)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7037)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:39 2021
[2m[36m(pid=7037)[0m , filename = '/tmp/thalvari/4571140/automl_save_loeb06jf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2ef21ff3ac, total write size = 35060, bytes this sub-write = 35060, bytes actually written = 18446744073709551615, offset = 2486272)
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m Traceback (most recent call last):
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7037)[0m     self._entrypoint()
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7037)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7037)[0m     output = train_func(config, reporter)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7037)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7037)[0m     config=config)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7037)[0m     model.save(model_path, config_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7037)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7037)[0m     self.model.save(model_path)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7037)[0m     signatures)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7037)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7037)[0m     f.close()
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7037)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7037)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7037)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:39 2021
[2m[36m(pid=7037)[0m , filename = '/tmp/thalvari/4571140/automl_save_loeb06jf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2ef28e0330, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m Traceback (most recent call last):
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7037)[0m     self.run()
[2m[36m(pid=7037)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7037)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7037)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7037)[0m 
2021-01-17 12:38:40,122	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7037, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:40,126	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_49_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=7037)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7037)[0m 
[2m[36m(pid=7037)[0m Stack (most recent call first):
[2m[36m(pid=7036)[0m 2021-01-17 12:38:40,416	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=7036)[0m Traceback (most recent call last):
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7036)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7036)[0m     param_dset[:] = val
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7036)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7036)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7036)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7036)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:40 2021
[2m[36m(pid=7036)[0m , filename = '/tmp/thalvari/4571140/automl_save_o5581ex6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4e67d99bc, total write size = 43252, bytes this sub-write = 43252, bytes actually written = 18446744073709551615, offset = 2478080)
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m Traceback (most recent call last):
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7036)[0m     self._entrypoint()
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7036)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7036)[0m     output = train_func(config, reporter)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7036)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7036)[0m     config=config)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7036)[0m     model.save(model_path, config_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7036)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7036)[0m     self.model.save(model_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7036)[0m     signatures)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7036)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7036)[0m     f.close()
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7036)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7036)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:40 2021
[2m[36m(pid=7036)[0m , filename = '/tmp/thalvari/4571140/automl_save_o5581ex6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4e6807a60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7036)[0m Exception in thread Thread-1:
[2m[36m(pid=7036)[0m Traceback (most recent call last):
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=7036)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=7036)[0m     param_dset[:] = val
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=7036)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=7036)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=7036)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=7036)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:40 2021
[2m[36m(pid=7036)[0m , filename = '/tmp/thalvari/4571140/automl_save_o5581ex6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4e67d99bc, total write size = 43252, bytes this sub-write = 43252, bytes actually written = 18446744073709551615, offset = 2478080)
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m Traceback (most recent call last):
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=7036)[0m     self._entrypoint()
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=7036)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=7036)[0m     output = train_func(config, reporter)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=7036)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=7036)[0m     config=config)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=7036)[0m     model.save(model_path, config_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=7036)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=7036)[0m     self.model.save(model_path)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=7036)[0m     signatures)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=7036)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=7036)[0m     f.close()
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=7036)[0m     h5i.dec_ref(id_)
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=7036)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=7036)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:40 2021
[2m[36m(pid=7036)[0m , filename = '/tmp/thalvari/4571140/automl_save_o5581ex6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4e6807a60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m Traceback (most recent call last):
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=7036)[0m     self.run()
[2m[36m(pid=7036)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=7036)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=7036)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=7036)[0m 
[2m[36m(pid=18879)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18879)[0m   agg_primitives: ['count']
[2m[36m(pid=18879)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18879)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18678)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18678)[0m   agg_primitives: ['count']
[2m[36m(pid=18678)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18678)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18941)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18941)[0m   agg_primitives: ['count']
[2m[36m(pid=18941)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18941)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:38:41,554	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=7036, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:41,558	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.0010996,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18879)[0m LSTM is selected.
[2m[36m(pid=18678)[0m LSTM is selected.
[2m[36m(pid=7036)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=7036)[0m 
[2m[36m(pid=7036)[0m Stack (most recent call first):
[2m[36m(pid=18879)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18879)[0m Instructions for updating:
[2m[36m(pid=18879)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18678)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18678)[0m Instructions for updating:
[2m[36m(pid=18678)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18941)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18941)[0m Instructions for updating:
[2m[36m(pid=18941)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18941)[0m LSTM is selected.
[2m[36m(pid=18879)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18879)[0m Instructions for updating:
[2m[36m(pid=18879)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18678)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18678)[0m Instructions for updating:
[2m[36m(pid=18678)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18941)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18941)[0m Instructions for updating:
[2m[36m(pid=18941)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 60 ({'TERMINATED': 14, 'ERROR': 36, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 30 not shown
 - train_func_48_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_48_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-186_htduvt/error_2021-01-17_12-38-37.txt
 - train_func_49_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_49_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-20fgw7heli/error_2021-01-17_12-38-40.txt
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.0010996,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-21xq2sppxd/error_2021-01-17_12-38-41.txt
RUNNING trials:
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=18948)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18948)[0m   agg_primitives: ['count']
[2m[36m(pid=18948)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18948)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18948)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18948)[0m Instructions for updating:
[2m[36m(pid=18948)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18948)[0m LSTM is selected.
[2m[36m(pid=18879)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18879)[0m 2021-01-17 12:38:43.283981: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18879)[0m 2021-01-17 12:38:43.293404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18879)[0m 2021-01-17 12:38:43.297293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f20250ce860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18879)[0m 2021-01-17 12:38:43.297334: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18678)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18678)[0m 2021-01-17 12:38:43.299614: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18678)[0m 2021-01-17 12:38:43.308905: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18678)[0m 2021-01-17 12:38:43.313925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3f90cf530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18678)[0m 2021-01-17 12:38:43.313972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18941)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18941)[0m 2021-01-17 12:38:43.478559: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18941)[0m 2021-01-17 12:38:43.487994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18941)[0m 2021-01-17 12:38:43.491186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f12350cf230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18941)[0m 2021-01-17 12:38:43.491220: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18948)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18948)[0m Instructions for updating:
[2m[36m(pid=18948)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=17552)[0m 2021-01-17 12:38:44,637	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=17552)[0m Traceback (most recent call last):
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=17552)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=17552)[0m     param_dset[:] = val
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17552)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17552)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17552)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17552)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17552)[0m , filename = '/tmp/thalvari/4571140/automl_save_vbe6u_yi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad8eb175e8, total write size = 99928, bytes this sub-write = 99928, bytes actually written = 18446744073709551615, offset = 1855488)
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m Traceback (most recent call last):
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17552)[0m     self._entrypoint()
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17552)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17552)[0m     output = train_func(config, reporter)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17552)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17552)[0m     config=config)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17552)[0m     model.save(model_path, config_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17552)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17552)[0m     self.model.save(model_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17552)[0m     signatures)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17552)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17552)[0m     f.close()
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17552)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17552)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17552)[0m , filename = '/tmp/thalvari/4571140/automl_save_vbe6u_yi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad8d70f070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17552)[0m Exception in thread Thread-1:
[2m[36m(pid=17552)[0m Traceback (most recent call last):
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=17552)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=17552)[0m     param_dset[:] = val
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17552)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17552)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17552)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17552)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17552)[0m , filename = '/tmp/thalvari/4571140/automl_save_vbe6u_yi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad8eb175e8, total write size = 99928, bytes this sub-write = 99928, bytes actually written = 18446744073709551615, offset = 1855488)
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m Traceback (most recent call last):
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17552)[0m     self._entrypoint()
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17552)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17552)[0m     output = train_func(config, reporter)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17552)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17552)[0m     config=config)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17552)[0m     model.save(model_path, config_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17552)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17552)[0m     self.model.save(model_path)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17552)[0m     signatures)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17552)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17552)[0m     f.close()
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17552)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17552)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17552)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17552)[0m , filename = '/tmp/thalvari/4571140/automl_save_vbe6u_yi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad8d70f070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17718)[0m 2021-01-17 12:38:44,637	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=17718)[0m Traceback (most recent call last):
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=17718)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=17718)[0m     param_dset[:] = val
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17718)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17718)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17718)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17718)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17718)[0m , filename = '/tmp/thalvari/4571140/automl_save_y9rf889c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbf72240778, total write size = 200792, bytes this sub-write = 200792, bytes actually written = 18446744073709551615, offset = 614400)
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m Traceback (most recent call last):
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17718)[0m     self._entrypoint()
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17718)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17718)[0m     output = train_func(config, reporter)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17718)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17718)[0m     config=config)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17718)[0m     model.save(model_path, config_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17718)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17718)[0m     self.model.save(model_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17718)[0m     signatures)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17718)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17718)[0m     f.close()
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17718)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17718)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17718)[0m , filename = '/tmp/thalvari/4571140/automl_save_y9rf889c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbf72895650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17718)[0m Exception in thread Thread-1:
[2m[36m(pid=17718)[0m Traceback (most recent call last):
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=17718)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=17718)[0m     param_dset[:] = val
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17718)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17718)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17718)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17718)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17718)[0m , filename = '/tmp/thalvari/4571140/automl_save_y9rf889c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbf72240778, total write size = 200792, bytes this sub-write = 200792, bytes actually written = 18446744073709551615, offset = 614400)
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m Traceback (most recent call last):
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17718)[0m     self._entrypoint()
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17718)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17718)[0m     output = train_func(config, reporter)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17718)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17718)[0m     config=config)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17718)[0m     model.save(model_path, config_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17718)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17718)[0m     self.model.save(model_path)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17718)[0m     signatures)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17718)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17718)[0m     f.close()
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17718)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17718)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17718)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:44 2021
[2m[36m(pid=17718)[0m , filename = '/tmp/thalvari/4571140/automl_save_y9rf889c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbf72895650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m Traceback (most recent call last):
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=17552)[0m     self.run()
[2m[36m(pid=17552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=17552)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=17552)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m Traceback (most recent call last):
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=17718)[0m     self.run()
[2m[36m(pid=17718)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=17718)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=17718)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=17718)[0m 
[2m[36m(pid=18948)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18948)[0m 2021-01-17 12:38:44.703170: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18948)[0m 2021-01-17 12:38:44.711390: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18948)[0m 2021-01-17 12:38:44.714306: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f61810cf300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18948)[0m 2021-01-17 12:38:44.714338: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18944)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18944)[0m   agg_primitives: ['count']
[2m[36m(pid=18944)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18944)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:38:45,711	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=17718, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:45,716	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18944)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18944)[0m Instructions for updating:
[2m[36m(pid=18944)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18944)[0m LSTM is selected.
[2m[36m(pid=17718)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=17718)[0m 
[2m[36m(pid=17718)[0m Stack (most recent call first):
[2m[36m(pid=18949)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18949)[0m   agg_primitives: ['count']
[2m[36m(pid=18949)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18949)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18944)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18944)[0m Instructions for updating:
[2m[36m(pid=18944)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18949)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18949)[0m Instructions for updating:
[2m[36m(pid=18949)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18949)[0m LSTM is selected.
[2m[36m(pid=18949)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18949)[0m Instructions for updating:
[2m[36m(pid=18949)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:38:47,289	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=17552, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:47,292	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18944)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18944)[0m 2021-01-17 12:38:47.368196: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18944)[0m 2021-01-17 12:38:47.379617: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18944)[0m 2021-01-17 12:38:47.384132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f56f50e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18944)[0m 2021-01-17 12:38:47.384176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=17552)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=17552)[0m 
[2m[36m(pid=17552)[0m Stack (most recent call first):
[2m[36m(pid=17891)[0m 2021-01-17 12:38:47,607	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=17891)[0m Traceback (most recent call last):
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=17891)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=17891)[0m     param_dset[:] = val
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17891)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17891)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17891)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17891)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:47 2021
[2m[36m(pid=17891)[0m , filename = '/tmp/thalvari/4571140/automl_save_64ttt0gj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee62a1fc2c, total write size = 63732, bytes this sub-write = 63732, bytes actually written = 18446744073709551615, offset = 2449408)
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m Traceback (most recent call last):
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17891)[0m     self._entrypoint()
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17891)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17891)[0m     output = train_func(config, reporter)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17891)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17891)[0m     config=config)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17891)[0m     model.save(model_path, config_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17891)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17891)[0m     self.model.save(model_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17891)[0m     signatures)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17891)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17891)[0m     f.close()
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17891)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17891)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:47 2021
[2m[36m(pid=17891)[0m , filename = '/tmp/thalvari/4571140/automl_save_64ttt0gj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee62842f40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17891)[0m Exception in thread Thread-1:
[2m[36m(pid=17891)[0m Traceback (most recent call last):
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=17891)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=17891)[0m     param_dset[:] = val
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17891)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17891)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17891)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17891)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:47 2021
[2m[36m(pid=17891)[0m , filename = '/tmp/thalvari/4571140/automl_save_64ttt0gj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee62a1fc2c, total write size = 63732, bytes this sub-write = 63732, bytes actually written = 18446744073709551615, offset = 2449408)
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m Traceback (most recent call last):
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17891)[0m     self._entrypoint()
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17891)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17891)[0m     output = train_func(config, reporter)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17891)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17891)[0m     config=config)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17891)[0m     model.save(model_path, config_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17891)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17891)[0m     self.model.save(model_path)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17891)[0m     signatures)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17891)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17891)[0m     f.close()
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17891)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17891)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17891)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:47 2021
[2m[36m(pid=17891)[0m , filename = '/tmp/thalvari/4571140/automl_save_64ttt0gj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee62842f40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m Traceback (most recent call last):
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=17891)[0m     self.run()
[2m[36m(pid=17891)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=17891)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=17891)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=17891)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 62 ({'TERMINATED': 14, 'ERROR': 38, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 32 not shown
 - train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.0010996,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_50_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-21xq2sppxd/error_2021-01-17_12-38-41.txt
 - train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_51_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-220rqa505m/error_2021-01-17_12-38-47.txt
 - train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_52_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-24tml1f5go/error_2021-01-17_12-38-45.txt
RUNNING trials:
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_54_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_61_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=18949)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18949)[0m 2021-01-17 12:38:48.196198: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18949)[0m 2021-01-17 12:38:48.205389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18949)[0m 2021-01-17 12:38:48.208066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3590cf620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18949)[0m 2021-01-17 12:38:48.208109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=17894)[0m 2021-01-17 12:38:48,439	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=17894)[0m Traceback (most recent call last):
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=17894)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=17894)[0m     param_dset[:] = val
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17894)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17894)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17894)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17894)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:48 2021
[2m[36m(pid=17894)[0m , filename = '/tmp/thalvari/4571140/automl_save_dkx493qe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2b4611097c, total write size = 71924, bytes this sub-write = 71924, bytes actually written = 18446744073709551615, offset = 2441216)
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m Traceback (most recent call last):
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17894)[0m     self._entrypoint()
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17894)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17894)[0m     output = train_func(config, reporter)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17894)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17894)[0m     config=config)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17894)[0m     model.save(model_path, config_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17894)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17894)[0m     self.model.save(model_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17894)[0m     signatures)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17894)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17894)[0m     f.close()
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17894)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17894)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:48 2021
[2m[36m(pid=17894)[0m , filename = '/tmp/thalvari/4571140/automl_save_dkx493qe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2b467fefd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17894)[0m Exception in thread Thread-1:
[2m[36m(pid=17894)[0m Traceback (most recent call last):
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=17894)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=17894)[0m     param_dset[:] = val
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=17894)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=17894)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=17894)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=17894)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:48 2021
[2m[36m(pid=17894)[0m , filename = '/tmp/thalvari/4571140/automl_save_dkx493qe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2b4611097c, total write size = 71924, bytes this sub-write = 71924, bytes actually written = 18446744073709551615, offset = 2441216)
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m Traceback (most recent call last):
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=17894)[0m     self._entrypoint()
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=17894)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=17894)[0m     output = train_func(config, reporter)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=17894)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=17894)[0m     config=config)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=17894)[0m     model.save(model_path, config_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=17894)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=17894)[0m     self.model.save(model_path)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=17894)[0m     signatures)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=17894)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=17894)[0m     f.close()
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=17894)[0m     h5i.dec_ref(id_)
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=17894)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=17894)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:48 2021
[2m[36m(pid=17894)[0m , filename = '/tmp/thalvari/4571140/automl_save_dkx493qe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2b467fefd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m Traceback (most recent call last):
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=17894)[0m     self.run()
[2m[36m(pid=17894)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=17894)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=17894)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=17894)[0m 
2021-01-17 12:38:48,770	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=17891, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:48,774	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_54_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=17891)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=17891)[0m 
[2m[36m(pid=17891)[0m Stack (most recent call first):
2021-01-17 12:38:50,166	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=17894, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:50,170	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=17894)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=17894)[0m 
[2m[36m(pid=17894)[0m Stack (most recent call first):
[2m[36m(pid=18933)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18933)[0m   agg_primitives: ['count']
[2m[36m(pid=18933)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18933)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18931)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18931)[0m   agg_primitives: ['count']
[2m[36m(pid=18931)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18931)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18933)[0m LSTM is selected.
[2m[36m(pid=18931)[0m LSTM is selected.
[2m[36m(pid=18933)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18933)[0m Instructions for updating:
[2m[36m(pid=18933)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18931)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18931)[0m Instructions for updating:
[2m[36m(pid=18931)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18933)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18933)[0m Instructions for updating:
[2m[36m(pid=18933)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18931)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18931)[0m Instructions for updating:
[2m[36m(pid=18931)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18931)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18931)[0m 2021-01-17 12:38:54.038724: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18931)[0m 2021-01-17 12:38:54.051075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18931)[0m 2021-01-17 12:38:54.056338: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f840d0ce900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18931)[0m 2021-01-17 12:38:54.056381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18933)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18933)[0m 2021-01-17 12:38:54.094516: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18933)[0m 2021-01-17 12:38:54.107718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18933)[0m 2021-01-17 12:38:54.112977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8f90cf900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18933)[0m 2021-01-17 12:38:54.113022: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18678)[0m 2021-01-17 12:38:54,705	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18678)[0m Traceback (most recent call last):
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18678)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18678)[0m     param_dset[:] = val
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18678)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18678)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18678)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18678)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:54 2021
[2m[36m(pid=18678)[0m , filename = '/tmp/thalvari/4571140/automl_save_8z16ikst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa3fa2666fc, total write size = 80116, bytes this sub-write = 80116, bytes actually written = 18446744073709551615, offset = 2433024)
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m Traceback (most recent call last):
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18678)[0m     self._entrypoint()
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18678)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18678)[0m     output = train_func(config, reporter)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18678)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18678)[0m     config=config)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18678)[0m     model.save(model_path, config_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18678)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18678)[0m     self.model.save(model_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18678)[0m     signatures)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18678)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18678)[0m     f.close()
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18678)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18678)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:54 2021
[2m[36m(pid=18678)[0m , filename = '/tmp/thalvari/4571140/automl_save_8z16ikst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa3fa11c7e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18678)[0m Exception in thread Thread-1:
[2m[36m(pid=18678)[0m Traceback (most recent call last):
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18678)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18678)[0m     param_dset[:] = val
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18678)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18678)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18678)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18678)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:54 2021
[2m[36m(pid=18678)[0m , filename = '/tmp/thalvari/4571140/automl_save_8z16ikst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa3fa2666fc, total write size = 80116, bytes this sub-write = 80116, bytes actually written = 18446744073709551615, offset = 2433024)
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m Traceback (most recent call last):
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18678)[0m     self._entrypoint()
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18678)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18678)[0m     output = train_func(config, reporter)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18678)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18678)[0m     config=config)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18678)[0m     model.save(model_path, config_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18678)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18678)[0m     self.model.save(model_path)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18678)[0m     signatures)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18678)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18678)[0m     f.close()
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18678)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18678)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18678)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:54 2021
[2m[36m(pid=18678)[0m , filename = '/tmp/thalvari/4571140/automl_save_8z16ikst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa3fa11c7e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m Traceback (most recent call last):
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18678)[0m     self.run()
[2m[36m(pid=18678)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18678)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18678)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18951)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18951)[0m   agg_primitives: ['count']
[2m[36m(pid=18951)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18951)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18953)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18953)[0m   agg_primitives: ['count']
[2m[36m(pid=18953)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18953)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18941)[0m 2021-01-17 12:38:55,106	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18941)[0m Traceback (most recent call last):
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18941)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18941)[0m     param_dset[:] = val
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18941)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18941)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18941)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18941)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18941)[0m , filename = '/tmp/thalvari/4571140/automl_save_xc7p0e8p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f123620c25c, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2416640)
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m Traceback (most recent call last):
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18941)[0m     self._entrypoint()
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18941)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18941)[0m     output = train_func(config, reporter)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18941)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18941)[0m     config=config)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18941)[0m     model.save(model_path, config_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18941)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18941)[0m     self.model.save(model_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18941)[0m     signatures)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18941)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18941)[0m     f.close()
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18941)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18941)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18941)[0m , filename = '/tmp/thalvari/4571140/automl_save_xc7p0e8p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1236452610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18941)[0m Exception in thread Thread-1:
[2m[36m(pid=18941)[0m Traceback (most recent call last):
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18941)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18941)[0m     param_dset[:] = val
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18941)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18941)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18941)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18941)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18941)[0m , filename = '/tmp/thalvari/4571140/automl_save_xc7p0e8p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f123620c25c, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2416640)
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m Traceback (most recent call last):
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18941)[0m     self._entrypoint()
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18941)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18941)[0m     output = train_func(config, reporter)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18941)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18941)[0m     config=config)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18941)[0m     model.save(model_path, config_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18941)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18941)[0m     self.model.save(model_path)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18941)[0m     signatures)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18941)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18941)[0m     f.close()
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18941)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18941)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18941)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18941)[0m , filename = '/tmp/thalvari/4571140/automl_save_xc7p0e8p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1236452610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m Traceback (most recent call last):
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18941)[0m     self.run()
[2m[36m(pid=18941)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18941)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18941)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18879)[0m 2021-01-17 12:38:55,340	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18879)[0m Traceback (most recent call last):
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18879)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18879)[0m     param_dset[:] = val
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18879)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18879)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18879)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18879)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18879)[0m , filename = '/tmp/thalvari/4571140/automl_save_72xs4d9c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20254657cc, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2416640)
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m Traceback (most recent call last):
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18879)[0m     self._entrypoint()
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18879)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18879)[0m     output = train_func(config, reporter)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18879)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18879)[0m     config=config)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18879)[0m     model.save(model_path, config_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18879)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18879)[0m     self.model.save(model_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18879)[0m     signatures)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18879)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18879)[0m     f.close()
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18879)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18879)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18879)[0m , filename = '/tmp/thalvari/4571140/automl_save_72xs4d9c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f202540d960, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18879)[0m Exception in thread Thread-1:
[2m[36m(pid=18879)[0m Traceback (most recent call last):
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18879)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18879)[0m     param_dset[:] = val
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18879)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18879)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18879)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18879)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18879)[0m , filename = '/tmp/thalvari/4571140/automl_save_72xs4d9c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f20254657cc, total write size = 96500, bytes this sub-write = 96500, bytes actually written = 18446744073709551615, offset = 2416640)
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m Traceback (most recent call last):
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18879)[0m     self._entrypoint()
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18879)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18879)[0m     output = train_func(config, reporter)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18879)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18879)[0m     config=config)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18879)[0m     model.save(model_path, config_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18879)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18879)[0m     self.model.save(model_path)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18879)[0m     signatures)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18879)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18879)[0m     f.close()
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18879)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18879)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18879)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:55 2021
[2m[36m(pid=18879)[0m , filename = '/tmp/thalvari/4571140/automl_save_72xs4d9c/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f202540d960, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m Traceback (most recent call last):
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18879)[0m     self.run()
[2m[36m(pid=18879)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18879)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18879)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18951)[0m LSTM is selected.
[2m[36m(pid=18953)[0m LSTM is selected.
[2m[36m(pid=18951)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18951)[0m Instructions for updating:
[2m[36m(pid=18951)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18953)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18953)[0m Instructions for updating:
[2m[36m(pid=18953)[0m If using Keras pass *_constraint arguments to layers.
2021-01-17 12:38:55,785	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18678, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:55,789	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 64 ({'TERMINATED': 14, 'ERROR': 41, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 35 not shown
 - train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_53_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-29p53c9hz1/error_2021-01-17_12-38-50.txt
 - train_func_54_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_54_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-311j1ribgu/error_2021-01-17_12-38-48.txt
 - train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_55_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-3360a8xjvd/error_2021-01-17_12-38-55.txt
RUNNING trials:
 - train_func_56_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=18678)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18678)[0m 
[2m[36m(pid=18678)[0m Stack (most recent call first):
[2m[36m(pid=18953)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18953)[0m Instructions for updating:
[2m[36m(pid=18953)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18951)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18951)[0m Instructions for updating:
[2m[36m(pid=18951)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18948)[0m 2021-01-17 12:38:56,166	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18948)[0m Traceback (most recent call last):
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18948)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18948)[0m     param_dset[:] = val
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18948)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18948)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18948)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18948)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:56 2021
[2m[36m(pid=18948)[0m , filename = '/tmp/thalvari/4571140/automl_save_kj4mvqab/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6181d70e0c, total write size = 104692, bytes this sub-write = 104692, bytes actually written = 18446744073709551615, offset = 2408448)
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m Traceback (most recent call last):
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18948)[0m     self._entrypoint()
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18948)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18948)[0m     output = train_func(config, reporter)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18948)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18948)[0m     config=config)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18948)[0m     model.save(model_path, config_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18948)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18948)[0m     self.model.save(model_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18948)[0m     signatures)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18948)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18948)[0m     f.close()
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18948)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18948)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:56 2021
[2m[36m(pid=18948)[0m , filename = '/tmp/thalvari/4571140/automl_save_kj4mvqab/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618170fda0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18948)[0m Exception in thread Thread-1:
[2m[36m(pid=18948)[0m Traceback (most recent call last):
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18948)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18948)[0m     param_dset[:] = val
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18948)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18948)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18948)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18948)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:56 2021
[2m[36m(pid=18948)[0m , filename = '/tmp/thalvari/4571140/automl_save_kj4mvqab/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6181d70e0c, total write size = 104692, bytes this sub-write = 104692, bytes actually written = 18446744073709551615, offset = 2408448)
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m Traceback (most recent call last):
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18948)[0m     self._entrypoint()
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18948)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18948)[0m     output = train_func(config, reporter)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18948)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18948)[0m     config=config)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18948)[0m     model.save(model_path, config_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18948)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18948)[0m     self.model.save(model_path)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18948)[0m     signatures)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18948)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18948)[0m     f.close()
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18948)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18948)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18948)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:56 2021
[2m[36m(pid=18948)[0m , filename = '/tmp/thalvari/4571140/automl_save_kj4mvqab/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618170fda0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m Traceback (most recent call last):
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18948)[0m     self.run()
[2m[36m(pid=18948)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18948)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18948)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18951)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18951)[0m 2021-01-17 12:38:57.095530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18951)[0m 2021-01-17 12:38:57.104462: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18951)[0m 2021-01-17 12:38:57.106900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3e50e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18951)[0m 2021-01-17 12:38:57.106932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18953)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18953)[0m 2021-01-17 12:38:57.069275: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18953)[0m 2021-01-17 12:38:57.079732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18953)[0m 2021-01-17 12:38:57.082613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef749102ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18953)[0m 2021-01-17 12:38:57.082647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:38:57,480	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18879, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:57,483	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_56_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18879)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18879)[0m 
[2m[36m(pid=18879)[0m Stack (most recent call first):
[2m[36m(pid=18944)[0m 2021-01-17 12:38:58,649	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18944)[0m Traceback (most recent call last):
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18944)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18944)[0m     param_dset[:] = val
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18944)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18944)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18944)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18944)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:58 2021
[2m[36m(pid=18944)[0m , filename = '/tmp/thalvari/4571140/automl_save_86n_s80d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56f69aa67c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m Traceback (most recent call last):
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18944)[0m     self._entrypoint()
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18944)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18944)[0m     output = train_func(config, reporter)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18944)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18944)[0m     config=config)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18944)[0m     model.save(model_path, config_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18944)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18944)[0m     self.model.save(model_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18944)[0m     signatures)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18944)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18944)[0m     f.close()
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18944)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18944)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:58 2021
[2m[36m(pid=18944)[0m , filename = '/tmp/thalvari/4571140/automl_save_86n_s80d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56f62c93e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18944)[0m Exception in thread Thread-1:
[2m[36m(pid=18944)[0m Traceback (most recent call last):
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18944)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18944)[0m     param_dset[:] = val
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18944)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18944)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18944)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18944)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:58 2021
[2m[36m(pid=18944)[0m , filename = '/tmp/thalvari/4571140/automl_save_86n_s80d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56f69aa67c, total write size = 112884, bytes this sub-write = 112884, bytes actually written = 18446744073709551615, offset = 2404352)
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m Traceback (most recent call last):
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18944)[0m     self._entrypoint()
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18944)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18944)[0m     output = train_func(config, reporter)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18944)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18944)[0m     config=config)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18944)[0m     model.save(model_path, config_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18944)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18944)[0m     self.model.save(model_path)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18944)[0m     signatures)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18944)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18944)[0m     f.close()
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18944)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18944)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18944)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:58 2021
[2m[36m(pid=18944)[0m , filename = '/tmp/thalvari/4571140/automl_save_86n_s80d/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56f62c93e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m Traceback (most recent call last):
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18944)[0m     self.run()
[2m[36m(pid=18944)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18944)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18944)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18944)[0m 
2021-01-17 12:38:58,993	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18948, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:38:58,997	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18948)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18948)[0m 
[2m[36m(pid=18948)[0m Stack (most recent call first):
[2m[36m(pid=18949)[0m 2021-01-17 12:38:59,520	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18949)[0m Traceback (most recent call last):
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18949)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18949)[0m     param_dset[:] = val
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18949)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18949)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18949)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18949)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:59 2021
[2m[36m(pid=18949)[0m , filename = '/tmp/thalvari/4571140/automl_save_fqadserl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa359fe98dc, total write size = 121076, bytes this sub-write = 121076, bytes actually written = 18446744073709551615, offset = 2392064)
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m Traceback (most recent call last):
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18949)[0m     self._entrypoint()
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18949)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18949)[0m     output = train_func(config, reporter)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18949)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18949)[0m     config=config)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18949)[0m     model.save(model_path, config_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18949)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18949)[0m     self.model.save(model_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18949)[0m     signatures)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18949)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18949)[0m     f.close()
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18949)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18949)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:59 2021
[2m[36m(pid=18949)[0m , filename = '/tmp/thalvari/4571140/automl_save_fqadserl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa359544b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18949)[0m Exception in thread Thread-1:
[2m[36m(pid=18949)[0m Traceback (most recent call last):
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18949)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18949)[0m     param_dset[:] = val
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18949)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18949)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18949)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18949)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:38:59 2021
[2m[36m(pid=18949)[0m , filename = '/tmp/thalvari/4571140/automl_save_fqadserl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa359fe98dc, total write size = 121076, bytes this sub-write = 121076, bytes actually written = 18446744073709551615, offset = 2392064)
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m Traceback (most recent call last):
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18949)[0m     self._entrypoint()
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18949)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18949)[0m     output = train_func(config, reporter)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18949)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18949)[0m     config=config)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18949)[0m     model.save(model_path, config_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18949)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18949)[0m     self.model.save(model_path)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18949)[0m     signatures)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18949)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18949)[0m     f.close()
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18949)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18949)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18949)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:38:59 2021
[2m[36m(pid=18949)[0m , filename = '/tmp/thalvari/4571140/automl_save_fqadserl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa359544b30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m Traceback (most recent call last):
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18949)[0m     self.run()
[2m[36m(pid=18949)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18949)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18949)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18949)[0m 
2021-01-17 12:39:00,080	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18941, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:00,084	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18941)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18941)[0m 
[2m[36m(pid=18941)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 68 ({'TERMINATED': 14, 'ERROR': 44, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 38 not shown
 - train_func_56_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_56_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-34yo1wziks/error_2021-01-17_12-38-57.txt
 - train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_57_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-36rdn4t4ze/error_2021-01-17_12-39-00.txt
 - train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_58_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-38xxxs515e/error_2021-01-17_12-38-58.txt
RUNNING trials:
 - train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_61_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAKE(datetime)=0.42515,bayes_feature_IS_BUSY_HOURS(datetime)=0.82409,bayes_feature_IS_WEEKEND(datetime)=0.63197,bayes_feature_MONTH(datetime)=0.49685,bayes_feature_WEEKDAY(datetime)=0.65397,dropout_1=0.27652,dropout_2=0.28965,epochs=5,lr=0.0026301,lstm_1_units_float=127.98,lstm_2_units_float=127.65,past_seq_len=2:	RUNNING
 - train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_68_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:39:01,642	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18944, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:01,646	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18952)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18952)[0m   agg_primitives: ['count']
[2m[36m(pid=18952)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18952)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18944)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18944)[0m 
[2m[36m(pid=18944)[0m Stack (most recent call first):
[2m[36m(pid=18952)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18952)[0m Instructions for updating:
[2m[36m(pid=18952)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18952)[0m LSTM is selected.
[2m[36m(pid=18932)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18932)[0m   agg_primitives: ['count']
[2m[36m(pid=18932)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18932)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18952)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18952)[0m Instructions for updating:
[2m[36m(pid=18952)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:03,063	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18949, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:03,068	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18932)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18932)[0m Instructions for updating:
[2m[36m(pid=18932)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18932)[0m LSTM is selected.
[2m[36m(pid=18949)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18949)[0m 
[2m[36m(pid=18949)[0m Stack (most recent call first):
[2m[36m(pid=18932)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18932)[0m Instructions for updating:
[2m[36m(pid=18932)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18952)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18952)[0m 2021-01-17 12:39:04.010873: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18952)[0m 2021-01-17 12:39:04.020257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18952)[0m 2021-01-17 12:39:04.024794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f973511d6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18952)[0m 2021-01-17 12:39:04.024837: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18934)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18934)[0m   agg_primitives: ['count']
[2m[36m(pid=18934)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18934)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18934)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18934)[0m Instructions for updating:
[2m[36m(pid=18934)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18934)[0m LSTM is selected.
[2m[36m(pid=18932)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18932)[0m 2021-01-17 12:39:04.832754: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18932)[0m 2021-01-17 12:39:04.840934: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18932)[0m 2021-01-17 12:39:04.843209: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9890cf900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18932)[0m 2021-01-17 12:39:04.843243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18933)[0m 2021-01-17 12:39:04,973	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18933)[0m Traceback (most recent call last):
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18933)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18933)[0m     param_dset[:] = val
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18933)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18933)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18933)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18933)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:04 2021
[2m[36m(pid=18933)[0m , filename = '/tmp/thalvari/4571140/automl_save__ekhr_0o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe8fa7943bc, total write size = 147700, bytes this sub-write = 147700, bytes actually written = 18446744073709551615, offset = 2097152)
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m Traceback (most recent call last):
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18933)[0m     self._entrypoint()
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18933)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18933)[0m     output = train_func(config, reporter)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18933)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18933)[0m     config=config)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18933)[0m     model.save(model_path, config_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18933)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18933)[0m     self.model.save(model_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18933)[0m     signatures)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18933)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18933)[0m     f.close()
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18933)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18933)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:04 2021
[2m[36m(pid=18933)[0m , filename = '/tmp/thalvari/4571140/automl_save__ekhr_0o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe8f93f2ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18933)[0m Exception in thread Thread-1:
[2m[36m(pid=18933)[0m Traceback (most recent call last):
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18933)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18933)[0m     param_dset[:] = val
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18933)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18933)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18933)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18933)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:04 2021
[2m[36m(pid=18933)[0m , filename = '/tmp/thalvari/4571140/automl_save__ekhr_0o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe8fa7943bc, total write size = 147700, bytes this sub-write = 147700, bytes actually written = 18446744073709551615, offset = 2097152)
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m Traceback (most recent call last):
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18933)[0m     self._entrypoint()
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18933)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18933)[0m     output = train_func(config, reporter)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18933)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18933)[0m     config=config)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18933)[0m     model.save(model_path, config_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18933)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18933)[0m     self.model.save(model_path)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18933)[0m     signatures)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18933)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18933)[0m     f.close()
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18933)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18933)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18933)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:04 2021
[2m[36m(pid=18933)[0m , filename = '/tmp/thalvari/4571140/automl_save__ekhr_0o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe8f93f2ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m Traceback (most recent call last):
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18933)[0m     self.run()
[2m[36m(pid=18933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18933)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18933)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18931)[0m 2021-01-17 12:39:05,064	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18931)[0m Traceback (most recent call last):
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18931)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18931)[0m     param_dset[:] = val
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18931)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18931)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18931)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18931)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:05 2021
[2m[36m(pid=18931)[0m , filename = '/tmp/thalvari/4571140/automl_save_o_tsg68_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f840e7b2b6c, total write size = 137460, bytes this sub-write = 137460, bytes actually written = 18446744073709551615, offset = 2375680)
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m Traceback (most recent call last):
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18931)[0m     self._entrypoint()
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18931)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18931)[0m     output = train_func(config, reporter)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18931)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18931)[0m     config=config)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18931)[0m     model.save(model_path, config_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18931)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18931)[0m     self.model.save(model_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18931)[0m     signatures)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18931)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18931)[0m     f.close()
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18931)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18931)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:05 2021
[2m[36m(pid=18931)[0m , filename = '/tmp/thalvari/4571140/automl_save_o_tsg68_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f840e761c00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18931)[0m Exception in thread Thread-1:
[2m[36m(pid=18931)[0m Traceback (most recent call last):
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18931)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18931)[0m     param_dset[:] = val
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18931)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18931)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18931)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18931)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:05 2021
[2m[36m(pid=18931)[0m , filename = '/tmp/thalvari/4571140/automl_save_o_tsg68_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f840e7b2b6c, total write size = 137460, bytes this sub-write = 137460, bytes actually written = 18446744073709551615, offset = 2375680)
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m Traceback (most recent call last):
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18931)[0m     self._entrypoint()
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18931)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18931)[0m     output = train_func(config, reporter)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18931)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18931)[0m     config=config)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18931)[0m     model.save(model_path, config_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18931)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18931)[0m     self.model.save(model_path)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18931)[0m     signatures)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18931)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18931)[0m     f.close()
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18931)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18931)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18931)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:05 2021
[2m[36m(pid=18931)[0m , filename = '/tmp/thalvari/4571140/automl_save_o_tsg68_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f840e761c00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m Traceback (most recent call last):
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18931)[0m     self.run()
[2m[36m(pid=18931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18931)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18931)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18934)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18934)[0m Instructions for updating:
[2m[36m(pid=18934)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18930)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18930)[0m   agg_primitives: ['count']
[2m[36m(pid=18930)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18930)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:39:06,079	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18933, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:06,085	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_61_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18930)[0m LSTM is selected.
[2m[36m(pid=18930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18930)[0m Instructions for updating:
[2m[36m(pid=18930)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18933)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18933)[0m 
[2m[36m(pid=18933)[0m Stack (most recent call first):
[2m[36m(pid=18934)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18934)[0m 2021-01-17 12:39:06.372136: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18934)[0m 2021-01-17 12:39:06.384284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18934)[0m 2021-01-17 12:39:06.389419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92710e9230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18934)[0m 2021-01-17 12:39:06.389460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18676)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18676)[0m   agg_primitives: ['count']
[2m[36m(pid=18676)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18676)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18930)[0m Instructions for updating:
[2m[36m(pid=18930)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18676)[0m LSTM is selected.
[2m[36m(pid=18676)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18676)[0m Instructions for updating:
[2m[36m(pid=18676)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18951)[0m 2021-01-17 12:39:07,339	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18951)[0m Traceback (most recent call last):
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18951)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18951)[0m     param_dset[:] = val
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18951)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18951)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18951)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18951)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18951)[0m , filename = '/tmp/thalvari/4571140/automl_save_2gmq0n69/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3e681a8fc, total write size = 153844, bytes this sub-write = 153844, bytes actually written = 18446744073709551615, offset = 2363392)
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m Traceback (most recent call last):
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18951)[0m     self._entrypoint()
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18951)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18951)[0m     output = train_func(config, reporter)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18951)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18951)[0m     config=config)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18951)[0m     model.save(model_path, config_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18951)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18951)[0m     self.model.save(model_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18951)[0m     signatures)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18951)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18951)[0m     f.close()
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18951)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18951)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18951)[0m , filename = '/tmp/thalvari/4571140/automl_save_2gmq0n69/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3e67e8310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18951)[0m Exception in thread Thread-1:
[2m[36m(pid=18951)[0m Traceback (most recent call last):
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18951)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18951)[0m     param_dset[:] = val
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18951)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18951)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18951)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18951)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18951)[0m , filename = '/tmp/thalvari/4571140/automl_save_2gmq0n69/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3e681a8fc, total write size = 153844, bytes this sub-write = 153844, bytes actually written = 18446744073709551615, offset = 2363392)
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m Traceback (most recent call last):
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18951)[0m     self._entrypoint()
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18951)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18951)[0m     output = train_func(config, reporter)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18951)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18951)[0m     config=config)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18951)[0m     model.save(model_path, config_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18951)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18951)[0m     self.model.save(model_path)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18951)[0m     signatures)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18951)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18951)[0m     f.close()
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18951)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18951)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18951)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18951)[0m , filename = '/tmp/thalvari/4571140/automl_save_2gmq0n69/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe3e67e8310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m Traceback (most recent call last):
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18951)[0m     self.run()
[2m[36m(pid=18951)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18951)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18951)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18676)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18676)[0m Instructions for updating:
[2m[36m(pid=18676)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18953)[0m 2021-01-17 12:39:07,623	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18953)[0m Traceback (most recent call last):
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18953)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18953)[0m     param_dset[:] = val
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18953)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18953)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18953)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18953)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18953)[0m , filename = '/tmp/thalvari/4571140/automl_save_wo7ljmwo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef749d9a7cc, total write size = 162036, bytes this sub-write = 162036, bytes actually written = 18446744073709551615, offset = 2359296)
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m Traceback (most recent call last):
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18953)[0m     self._entrypoint()
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18953)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18953)[0m     output = train_func(config, reporter)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18953)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18953)[0m     config=config)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18953)[0m     model.save(model_path, config_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18953)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18953)[0m     self.model.save(model_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18953)[0m     signatures)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18953)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18953)[0m     f.close()
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18953)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18953)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18953)[0m , filename = '/tmp/thalvari/4571140/automl_save_wo7ljmwo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef749dc28d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18953)[0m Exception in thread Thread-1:
[2m[36m(pid=18953)[0m Traceback (most recent call last):
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18953)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18953)[0m     param_dset[:] = val
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18953)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18953)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18953)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18953)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18953)[0m , filename = '/tmp/thalvari/4571140/automl_save_wo7ljmwo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef749d9a7cc, total write size = 162036, bytes this sub-write = 162036, bytes actually written = 18446744073709551615, offset = 2359296)
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m Traceback (most recent call last):
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18953)[0m     self._entrypoint()
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18953)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18953)[0m     output = train_func(config, reporter)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18953)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18953)[0m     config=config)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18953)[0m     model.save(model_path, config_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18953)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18953)[0m     self.model.save(model_path)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18953)[0m     signatures)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18953)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18953)[0m     f.close()
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18953)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18953)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18953)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:07 2021
[2m[36m(pid=18953)[0m , filename = '/tmp/thalvari/4571140/automl_save_wo7ljmwo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef749dc28d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m Traceback (most recent call last):
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18953)[0m     self.run()
[2m[36m(pid=18953)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18953)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18953)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18953)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 71 ({'TERMINATED': 14, 'ERROR': 47, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 41 not shown
 - train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_59_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-41qtieuh8p/error_2021-01-17_12-39-01.txt
 - train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_60_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-42_iuf1okn/error_2021-01-17_12-39-03.txt
 - train_func_61_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_61_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-476s3l6cg0/error_2021-01-17_12-39-06.txt
RUNNING trials:
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_64_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAKE(datetime)=0.48788,bayes_feature_IS_BUSY_HOURS(datetime)=0.56194,bayes_feature_IS_WEEKEND(datetime)=0.93627,bayes_feature_MONTH(datetime)=0.7839,bayes_feature_WEEKDAY(datetime)=0.80738,dropout_1=0.47007,dropout_2=0.20587,epochs=5,lr=0.0091957,lstm_1_units_float=125.8,lstm_2_units_float=127.42,past_seq_len=2:	RUNNING
 - train_func_70_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:39:07,663	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18931, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:07,666	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_62_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18930)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18930)[0m 2021-01-17 12:39:07.739139: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18930)[0m 2021-01-17 12:39:07.760764: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18930)[0m 2021-01-17 12:39:07.763252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1da50b4a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18930)[0m 2021-01-17 12:39:07.763278: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18931)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18931)[0m 
[2m[36m(pid=18931)[0m Stack (most recent call first):
[2m[36m(pid=18681)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18681)[0m   agg_primitives: ['count']
[2m[36m(pid=18681)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18681)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18952)[0m 2021-01-17 12:39:08,457	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18952)[0m Traceback (most recent call last):
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18952)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18952)[0m     param_dset[:] = val
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18952)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18952)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18952)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18952)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:08 2021
[2m[36m(pid=18952)[0m , filename = '/tmp/thalvari/4571140/automl_save_vijsbt_z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97362c0824, total write size = 125756, bytes this sub-write = 125756, bytes actually written = 18446744073709551615, offset = 2351104)
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m Traceback (most recent call last):
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18952)[0m     self._entrypoint()
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18952)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18952)[0m     output = train_func(config, reporter)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18952)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18952)[0m     config=config)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18952)[0m     model.save(model_path, config_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18952)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18952)[0m     self.model.save(model_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18952)[0m     signatures)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18952)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18952)[0m     f.close()
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18952)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18952)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:08 2021
[2m[36m(pid=18952)[0m , filename = '/tmp/thalvari/4571140/automl_save_vijsbt_z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f973629d870, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18952)[0m Exception in thread Thread-1:
[2m[36m(pid=18952)[0m Traceback (most recent call last):
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18952)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18952)[0m     param_dset[:] = val
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18952)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18952)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18952)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18952)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:08 2021
[2m[36m(pid=18952)[0m , filename = '/tmp/thalvari/4571140/automl_save_vijsbt_z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97362c0824, total write size = 125756, bytes this sub-write = 125756, bytes actually written = 18446744073709551615, offset = 2351104)
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m Traceback (most recent call last):
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18952)[0m     self._entrypoint()
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18952)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18952)[0m     output = train_func(config, reporter)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18952)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18952)[0m     config=config)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18952)[0m     model.save(model_path, config_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18952)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18952)[0m     self.model.save(model_path)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18952)[0m     signatures)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18952)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18952)[0m     f.close()
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18952)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18952)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18952)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:08 2021
[2m[36m(pid=18952)[0m , filename = '/tmp/thalvari/4571140/automl_save_vijsbt_z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f973629d870, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m Traceback (most recent call last):
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18952)[0m     self.run()
[2m[36m(pid=18952)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18952)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18952)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18676)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18676)[0m 2021-01-17 12:39:08.615941: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18676)[0m 2021-01-17 12:39:08.623964: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18676)[0m 2021-01-17 12:39:08.626363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7741103620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18676)[0m 2021-01-17 12:39:08.626386: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18681)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18681)[0m Instructions for updating:
[2m[36m(pid=18681)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18681)[0m LSTM is selected.
2021-01-17 12:39:08,963	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18951, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:08,966	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18951)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18951)[0m 
[2m[36m(pid=18951)[0m Stack (most recent call first):
[2m[36m(pid=18681)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18681)[0m Instructions for updating:
[2m[36m(pid=18681)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18681)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18681)[0m 2021-01-17 12:39:10.220710: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18681)[0m 2021-01-17 12:39:10.228922: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18681)[0m 2021-01-17 12:39:10.233769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb34d103860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18681)[0m 2021-01-17 12:39:10.233811: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:39:10,443	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18952, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:10,447	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_65_batch_size_log=7.5956,bayes_feature_DAY(datetime)=0.51522,bayes_feature_HOUR(datetime)=0.75413,bayes_feature_IS_AWAKE(datetime)=0.9194,bayes_feature_IS_BUSY_HOURS(datetime)=0.91233,bayes_feature_IS_WEEKEND(datetime)=0.76697,bayes_feature_MONTH(datetime)=0.93289,bayes_feature_WEEKDAY(datetime)=0.4753,dropout_1=0.20525,dropout_2=0.38211,epochs=5,lr=0.0045225,lstm_1_units_float=127.11,lstm_2_units_float=126.9,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18932)[0m 2021-01-17 12:39:10,515	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18932)[0m Traceback (most recent call last):
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18932)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18932)[0m     param_dset[:] = val
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18932)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18932)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18932)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18932)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:10 2021
[2m[36m(pid=18932)[0m , filename = '/tmp/thalvari/4571140/automl_save_qj0vbmfe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc98a234358, total write size = 138760, bytes this sub-write = 138760, bytes actually written = 18446744073709551615, offset = 2342912)
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m Traceback (most recent call last):
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18932)[0m     self._entrypoint()
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18932)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18932)[0m     output = train_func(config, reporter)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18932)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18932)[0m     config=config)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18932)[0m     model.save(model_path, config_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18932)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18932)[0m     self.model.save(model_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18932)[0m     signatures)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18932)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18932)[0m     f.close()
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18932)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18932)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:10 2021
[2m[36m(pid=18932)[0m , filename = '/tmp/thalvari/4571140/automl_save_qj0vbmfe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc98a469bf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18932)[0m Exception in thread Thread-1:
[2m[36m(pid=18932)[0m Traceback (most recent call last):
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18932)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18932)[0m     param_dset[:] = val
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18932)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18932)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18932)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18932)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:10 2021
[2m[36m(pid=18932)[0m , filename = '/tmp/thalvari/4571140/automl_save_qj0vbmfe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc98a234358, total write size = 138760, bytes this sub-write = 138760, bytes actually written = 18446744073709551615, offset = 2342912)
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m Traceback (most recent call last):
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18932)[0m     self._entrypoint()
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18932)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18932)[0m     output = train_func(config, reporter)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18932)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18932)[0m     config=config)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18932)[0m     model.save(model_path, config_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18932)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18932)[0m     self.model.save(model_path)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18932)[0m     signatures)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18932)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18932)[0m     f.close()
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18932)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18932)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18932)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:10 2021
[2m[36m(pid=18932)[0m , filename = '/tmp/thalvari/4571140/automl_save_qj0vbmfe/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc98a469bf0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m Traceback (most recent call last):
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18932)[0m     self.run()
[2m[36m(pid=18932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18932)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18932)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18952)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18952)[0m 
[2m[36m(pid=18952)[0m Stack (most recent call first):
[2m[36m(pid=18682)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18682)[0m   agg_primitives: ['count']
[2m[36m(pid=18682)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18682)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=22572)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22571)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22572)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=22571)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=22573)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22573)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-17 12:39:11,821	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18932, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:11,825	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAKE(datetime)=0.42515,bayes_feature_IS_BUSY_HOURS(datetime)=0.82409,bayes_feature_IS_WEEKEND(datetime)=0.63197,bayes_feature_MONTH(datetime)=0.49685,bayes_feature_WEEKDAY(datetime)=0.65397,dropout_1=0.27652,dropout_2=0.28965,epochs=5,lr=0.0026301,lstm_1_units_float=127.98,lstm_2_units_float=127.65,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18932)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18932)[0m 
[2m[36m(pid=18932)[0m Stack (most recent call first):
[2m[36m(pid=18682)[0m LSTM is selected.
[2m[36m(pid=18682)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18682)[0m Instructions for updating:
[2m[36m(pid=18682)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=22695)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22695)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=22737)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22737)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=22741)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=22741)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=18682)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18682)[0m Instructions for updating:
[2m[36m(pid=18682)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=18680)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=18680)[0m   agg_primitives: ['count']
[2m[36m(pid=18680)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=18680)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18676)[0m 2021-01-17 12:39:12,904	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18676)[0m Traceback (most recent call last):
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18676)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18676)[0m     param_dset[:] = val
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18676)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18676)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18676)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18676)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:12 2021
[2m[36m(pid=18676)[0m , filename = '/tmp/thalvari/4571140/automl_save_9xxob4ok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f77425af408, total write size = 179592, bytes this sub-write = 179592, bytes actually written = 18446744073709551615, offset = 2285568)
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m Traceback (most recent call last):
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18676)[0m     self._entrypoint()
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18676)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18676)[0m     output = train_func(config, reporter)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18676)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18676)[0m     config=config)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18676)[0m     model.save(model_path, config_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18676)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18676)[0m     self.model.save(model_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18676)[0m     signatures)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18676)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18676)[0m     f.close()
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18676)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18676)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:12 2021
[2m[36m(pid=18676)[0m , filename = '/tmp/thalvari/4571140/automl_save_9xxob4ok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f77415ebd00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18676)[0m Exception in thread Thread-1:
[2m[36m(pid=18676)[0m Traceback (most recent call last):
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18676)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18676)[0m     param_dset[:] = val
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18676)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18676)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18676)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18676)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:12 2021
[2m[36m(pid=18676)[0m , filename = '/tmp/thalvari/4571140/automl_save_9xxob4ok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f77425af408, total write size = 179592, bytes this sub-write = 179592, bytes actually written = 18446744073709551615, offset = 2285568)
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m Traceback (most recent call last):
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18676)[0m     self._entrypoint()
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18676)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18676)[0m     output = train_func(config, reporter)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18676)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18676)[0m     config=config)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18676)[0m     model.save(model_path, config_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18676)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18676)[0m     self.model.save(model_path)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18676)[0m     signatures)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18676)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18676)[0m     f.close()
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18676)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18676)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18676)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:12 2021
[2m[36m(pid=18676)[0m , filename = '/tmp/thalvari/4571140/automl_save_9xxob4ok/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f77415ebd00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m Traceback (most recent call last):
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18676)[0m     self.run()
[2m[36m(pid=18676)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18676)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18676)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18676)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 75 ({'TERMINATED': 14, 'ERROR': 51, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 45 not shown
 - train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_63_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-38-50gtw4vu1b/error_2021-01-17_12-39-08.txt
 - train_func_65_batch_size_log=7.5956,bayes_feature_DAY(datetime)=0.51522,bayes_feature_HOUR(datetime)=0.75413,bayes_feature_IS_AWAKE(datetime)=0.9194,bayes_feature_IS_BUSY_HOURS(datetime)=0.91233,bayes_feature_IS_WEEKEND(datetime)=0.76697,bayes_feature_MONTH(datetime)=0.93289,bayes_feature_WEEKDAY(datetime)=0.4753,dropout_1=0.20525,dropout_2=0.38211,epochs=5,lr=0.0045225,lstm_1_units_float=127.11,lstm_2_units_float=126.9,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_65_batch_size_log=7.5956,bayes_feature_DAY(datetime)=0.51522,bayes_feature_HOUR(datetime)=0.75413,bayes_feature_IS_AWAK_2021-01-17_12-38-57imfsel1u/error_2021-01-17_12-39-10.txt
 - train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAKE(datetime)=0.42515,bayes_feature_IS_BUSY_HOURS(datetime)=0.82409,bayes_feature_IS_WEEKEND(datetime)=0.63197,bayes_feature_MONTH(datetime)=0.49685,bayes_feature_WEEKDAY(datetime)=0.65397,dropout_1=0.27652,dropout_2=0.28965,epochs=5,lr=0.0026301,lstm_1_units_float=127.98,lstm_2_units_float=127.65,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAK_2021-01-17_12-38-58um49c_96/error_2021-01-17_12-39-11.txt
RUNNING trials:
 - train_func_64_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_68_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_73_batch_size_log=6.439,bayes_feature_DAY(datetime)=0.66422,bayes_feature_HOUR(datetime)=0.33057,bayes_feature_IS_AWAKE(datetime)=0.84672,bayes_feature_IS_BUSY_HOURS(datetime)=0.4812,bayes_feature_IS_WEEKEND(datetime)=0.45968,bayes_feature_MONTH(datetime)=0.32279,bayes_feature_WEEKDAY(datetime)=0.80895,dropout_1=0.29312,dropout_2=0.4939,epochs=5,lr=0.0051361,lstm_1_units_float=127.01,lstm_2_units_float=127.13,past_seq_len=2:	RUNNING
 - train_func_74_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:39:13,267	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18953, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:13,271	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_64_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18680)[0m LSTM is selected.
[2m[36m(pid=18680)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=18680)[0m Instructions for updating:
[2m[36m(pid=18680)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18953)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18953)[0m 
[2m[36m(pid=18953)[0m Stack (most recent call first):
[2m[36m(pid=18682)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18682)[0m 2021-01-17 12:39:13.708782: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18682)[0m 2021-01-17 12:39:13.717927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18682)[0m 2021-01-17 12:39:13.721297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7c750cec40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18682)[0m 2021-01-17 12:39:13.721333: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18680)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=18680)[0m Instructions for updating:
[2m[36m(pid=18680)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:14,672	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18676, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:14,674	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAKE(datetime)=0.48788,bayes_feature_IS_BUSY_HOURS(datetime)=0.56194,bayes_feature_IS_WEEKEND(datetime)=0.93627,bayes_feature_MONTH(datetime)=0.7839,bayes_feature_WEEKDAY(datetime)=0.80738,dropout_1=0.47007,dropout_2=0.20587,epochs=5,lr=0.0091957,lstm_1_units_float=125.8,lstm_2_units_float=127.42,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18676)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18676)[0m 
[2m[36m(pid=18676)[0m Stack (most recent call first):
[2m[36m(pid=18680)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=18680)[0m 2021-01-17 12:39:14.971379: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=18680)[0m 2021-01-17 12:39:14.981396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=18680)[0m 2021-01-17 12:39:14.983879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f16690cefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=18680)[0m 2021-01-17 12:39:14.983919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=22572)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22572)[0m   agg_primitives: ['count']
[2m[36m(pid=22572)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22572)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=22571)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22571)[0m   agg_primitives: ['count']
[2m[36m(pid=22571)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22571)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=22741)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22741)[0m   agg_primitives: ['count']
[2m[36m(pid=22741)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22741)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=18934)[0m 2021-01-17 12:39:17,540	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18934)[0m Traceback (most recent call last):
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18934)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18934)[0m     param_dset[:] = val
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18934)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18934)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18934)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18934)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:17 2021
[2m[36m(pid=18934)[0m , filename = '/tmp/thalvari/4571140/automl_save_dzdwkfzj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9271f989bc, total write size = 235764, bytes this sub-write = 235764, bytes actually written = 18446744073709551615, offset = 2281472)
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m Traceback (most recent call last):
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18934)[0m     self._entrypoint()
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18934)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18934)[0m     output = train_func(config, reporter)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18934)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18934)[0m     config=config)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18934)[0m     model.save(model_path, config_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18934)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18934)[0m     self.model.save(model_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18934)[0m     signatures)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18934)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18934)[0m     f.close()
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18934)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18934)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:17 2021
[2m[36m(pid=18934)[0m , filename = '/tmp/thalvari/4571140/automl_save_dzdwkfzj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9272a00ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18934)[0m Exception in thread Thread-1:
[2m[36m(pid=18934)[0m Traceback (most recent call last):
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18934)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18934)[0m     param_dset[:] = val
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18934)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18934)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18934)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18934)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:17 2021
[2m[36m(pid=18934)[0m , filename = '/tmp/thalvari/4571140/automl_save_dzdwkfzj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9271f989bc, total write size = 235764, bytes this sub-write = 235764, bytes actually written = 18446744073709551615, offset = 2281472)
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m Traceback (most recent call last):
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18934)[0m     self._entrypoint()
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18934)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18934)[0m     output = train_func(config, reporter)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18934)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18934)[0m     config=config)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18934)[0m     model.save(model_path, config_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18934)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18934)[0m     self.model.save(model_path)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18934)[0m     signatures)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18934)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18934)[0m     f.close()
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18934)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18934)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18934)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:17 2021
[2m[36m(pid=18934)[0m , filename = '/tmp/thalvari/4571140/automl_save_dzdwkfzj/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9272a00ef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m Traceback (most recent call last):
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18934)[0m     self.run()
[2m[36m(pid=18934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18934)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18934)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18934)[0m 
[2m[36m(pid=22572)[0m LSTM is selected.
[2m[36m(pid=22571)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22571)[0m Instructions for updating:
[2m[36m(pid=22571)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=22571)[0m LSTM is selected.
[2m[36m(pid=22741)[0m LSTM is selected.
[2m[36m(pid=22572)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22572)[0m Instructions for updating:
[2m[36m(pid=22572)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=22741)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22741)[0m Instructions for updating:
[2m[36m(pid=22741)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=22737)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22737)[0m   agg_primitives: ['count']
[2m[36m(pid=22737)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22737)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=22572)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22572)[0m Instructions for updating:
[2m[36m(pid=22572)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22571)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22571)[0m Instructions for updating:
[2m[36m(pid=22571)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22741)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22741)[0m Instructions for updating:
[2m[36m(pid=22741)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:18,631	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18934, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:18,636	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 77 ({'TERMINATED': 14, 'ERROR': 54, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 48 not shown
 - train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAKE(datetime)=0.42515,bayes_feature_IS_BUSY_HOURS(datetime)=0.82409,bayes_feature_IS_WEEKEND(datetime)=0.63197,bayes_feature_MONTH(datetime)=0.49685,bayes_feature_WEEKDAY(datetime)=0.65397,dropout_1=0.27652,dropout_2=0.28965,epochs=5,lr=0.0026301,lstm_1_units_float=127.98,lstm_2_units_float=127.65,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_66_batch_size_log=6.3892,bayes_feature_DAY(datetime)=0.39325,bayes_feature_HOUR(datetime)=0.30248,bayes_feature_IS_AWAK_2021-01-17_12-38-58um49c_96/error_2021-01-17_12-39-11.txt
 - train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_67_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-009xig7r4p/error_2021-01-17_12-39-18.txt
 - train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAKE(datetime)=0.48788,bayes_feature_IS_BUSY_HOURS(datetime)=0.56194,bayes_feature_IS_WEEKEND(datetime)=0.93627,bayes_feature_MONTH(datetime)=0.7839,bayes_feature_WEEKDAY(datetime)=0.80738,dropout_1=0.47007,dropout_2=0.20587,epochs=5,lr=0.0091957,lstm_1_units_float=125.8,lstm_2_units_float=127.42,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAK_2021-01-17_12-39-03hm85ikag/error_2021-01-17_12-39-14.txt
RUNNING trials:
 - train_func_68_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_70_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2:	RUNNING
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=22737)[0m LSTM is selected.
[2m[36m(pid=22737)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22737)[0m Instructions for updating:
[2m[36m(pid=22737)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18934)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18934)[0m 
[2m[36m(pid=18934)[0m Stack (most recent call first):
[2m[36m(pid=18930)[0m 2021-01-17 12:39:18,964	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18930)[0m Traceback (most recent call last):
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18930)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18930)[0m     param_dset[:] = val
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18930)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:18 2021
[2m[36m(pid=18930)[0m , filename = '/tmp/thalvari/4571140/automl_save_6h09hxy3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1da69cb52c, total write size = 235764, bytes this sub-write = 235764, bytes actually written = 18446744073709551615, offset = 2273280)
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m Traceback (most recent call last):
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18930)[0m     self._entrypoint()
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18930)[0m     output = train_func(config, reporter)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18930)[0m     config=config)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18930)[0m     model.save(model_path, config_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18930)[0m     self.model.save(model_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18930)[0m     signatures)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18930)[0m     f.close()
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18930)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:18 2021
[2m[36m(pid=18930)[0m , filename = '/tmp/thalvari/4571140/automl_save_6h09hxy3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1da559bec0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18930)[0m Exception in thread Thread-1:
[2m[36m(pid=18930)[0m Traceback (most recent call last):
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18930)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18930)[0m     param_dset[:] = val
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18930)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:18 2021
[2m[36m(pid=18930)[0m , filename = '/tmp/thalvari/4571140/automl_save_6h09hxy3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1da69cb52c, total write size = 235764, bytes this sub-write = 235764, bytes actually written = 18446744073709551615, offset = 2273280)
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m Traceback (most recent call last):
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18930)[0m     self._entrypoint()
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18930)[0m     output = train_func(config, reporter)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18930)[0m     config=config)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18930)[0m     model.save(model_path, config_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18930)[0m     self.model.save(model_path)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18930)[0m     signatures)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18930)[0m     f.close()
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18930)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:18 2021
[2m[36m(pid=18930)[0m , filename = '/tmp/thalvari/4571140/automl_save_6h09hxy3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1da559bec0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m Traceback (most recent call last):
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18930)[0m     self.run()
[2m[36m(pid=18930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18930)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18930)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18930)[0m 
[2m[36m(pid=22737)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22737)[0m Instructions for updating:
[2m[36m(pid=22737)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22572)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22572)[0m 2021-01-17 12:39:19.435399: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22572)[0m 2021-01-17 12:39:19.443409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22572)[0m 2021-01-17 12:39:19.445658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f58090e8a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22572)[0m 2021-01-17 12:39:19.445684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=22741)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22741)[0m 2021-01-17 12:39:19.538034: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22741)[0m 2021-01-17 12:39:19.546043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22741)[0m 2021-01-17 12:39:19.549141: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4fed0e9620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22741)[0m 2021-01-17 12:39:19.549169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=22571)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22571)[0m 2021-01-17 12:39:19.561068: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22571)[0m 2021-01-17 12:39:19.570079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22571)[0m 2021-01-17 12:39:19.573925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f28a90ce900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22571)[0m 2021-01-17 12:39:19.573965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=22695)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22695)[0m   agg_primitives: ['count']
[2m[36m(pid=22695)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22695)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=22695)[0m LSTM is selected.
2021-01-17 12:39:20,315	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18930, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:20,319	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_68_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=22695)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22695)[0m Instructions for updating:
[2m[36m(pid=22695)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=22737)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22737)[0m 2021-01-17 12:39:20.379038: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22737)[0m 2021-01-17 12:39:20.387512: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22737)[0m 2021-01-17 12:39:20.391355: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9b10cea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22737)[0m 2021-01-17 12:39:20.391398: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18930)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18930)[0m 
[2m[36m(pid=18930)[0m Stack (most recent call first):
[2m[36m(pid=18681)[0m 2021-01-17 12:39:20,777	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18681)[0m Traceback (most recent call last):
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18681)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18681)[0m     param_dset[:] = val
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18681)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18681)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18681)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18681)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:20 2021
[2m[36m(pid=18681)[0m , filename = '/tmp/thalvari/4571140/automl_save_wis_c5x4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb34e7ac23c, total write size = 260340, bytes this sub-write = 260340, bytes actually written = 18446744073709551615, offset = 2260992)
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m Traceback (most recent call last):
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18681)[0m     self._entrypoint()
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18681)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18681)[0m     output = train_func(config, reporter)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18681)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18681)[0m     config=config)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18681)[0m     model.save(model_path, config_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18681)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18681)[0m     self.model.save(model_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18681)[0m     signatures)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18681)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18681)[0m     f.close()
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18681)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18681)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:20 2021
[2m[36m(pid=18681)[0m , filename = '/tmp/thalvari/4571140/automl_save_wis_c5x4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb34d44d900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18681)[0m Exception in thread Thread-1:
[2m[36m(pid=18681)[0m Traceback (most recent call last):
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18681)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18681)[0m     param_dset[:] = val
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18681)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18681)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18681)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18681)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:20 2021
[2m[36m(pid=18681)[0m , filename = '/tmp/thalvari/4571140/automl_save_wis_c5x4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb34e7ac23c, total write size = 260340, bytes this sub-write = 260340, bytes actually written = 18446744073709551615, offset = 2260992)
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m Traceback (most recent call last):
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18681)[0m     self._entrypoint()
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18681)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18681)[0m     output = train_func(config, reporter)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18681)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18681)[0m     config=config)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18681)[0m     model.save(model_path, config_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18681)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18681)[0m     self.model.save(model_path)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18681)[0m     signatures)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18681)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18681)[0m     f.close()
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18681)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18681)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18681)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:20 2021
[2m[36m(pid=18681)[0m , filename = '/tmp/thalvari/4571140/automl_save_wis_c5x4/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb34d44d900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m Traceback (most recent call last):
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18681)[0m     self.run()
[2m[36m(pid=18681)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18681)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18681)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18681)[0m 
[2m[36m(pid=22695)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22695)[0m Instructions for updating:
[2m[36m(pid=22695)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:21,937	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18681, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:21,942	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_70_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=22695)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22695)[0m 2021-01-17 12:39:22.037733: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22695)[0m 2021-01-17 12:39:22.054306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22695)[0m 2021-01-17 12:39:22.112058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f446d0cf400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22695)[0m 2021-01-17 12:39:22.112104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=18681)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18681)[0m 
[2m[36m(pid=18681)[0m Stack (most recent call first):
[2m[36m(pid=23911)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=23911)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=23910)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=23910)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=23869)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=23869)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=23909)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=23909)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=22741)[0m 2021-01-17 12:39:23,225	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22741)[0m Traceback (most recent call last):
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22741)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22741)[0m     param_dset[:] = val
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22741)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22741)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22741)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22741)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=22741)[0m , filename = '/tmp/thalvari/4571140/automl_save_zkagvp60/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4fee1c5f18, total write size = 5592, bytes this sub-write = 5592, bytes actually written = 18446744073709551615, offset = 2215936)
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m Traceback (most recent call last):
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22741)[0m     self._entrypoint()
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22741)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22741)[0m     output = train_func(config, reporter)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22741)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22741)[0m     config=config)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22741)[0m     model.save(model_path, config_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22741)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22741)[0m     self.model.save(model_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22741)[0m     signatures)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22741)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22741)[0m     f.close()
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22741)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22741)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=22741)[0m , filename = '/tmp/thalvari/4571140/automl_save_zkagvp60/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4fee3990e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22741)[0m Exception in thread Thread-1:
[2m[36m(pid=22741)[0m Traceback (most recent call last):
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22741)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22741)[0m     param_dset[:] = val
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22741)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22741)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22741)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22741)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=22741)[0m , filename = '/tmp/thalvari/4571140/automl_save_zkagvp60/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4fee1c5f18, total write size = 5592, bytes this sub-write = 5592, bytes actually written = 18446744073709551615, offset = 2215936)
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m Traceback (most recent call last):
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22741)[0m     self._entrypoint()
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22741)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22741)[0m     output = train_func(config, reporter)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22741)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22741)[0m     config=config)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22741)[0m     model.save(model_path, config_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22741)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22741)[0m     self.model.save(model_path)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22741)[0m     signatures)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22741)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22741)[0m     f.close()
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22741)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22741)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22741)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=22741)[0m , filename = '/tmp/thalvari/4571140/automl_save_zkagvp60/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f4fee3990e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m Traceback (most recent call last):
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22741)[0m     self.run()
[2m[36m(pid=22741)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22741)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22741)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22741)[0m 
[2m[36m(pid=18682)[0m 2021-01-17 12:39:23,508	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18682)[0m Traceback (most recent call last):
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18682)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18682)[0m     param_dset[:] = val
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18682)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18682)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18682)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18682)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=18682)[0m , filename = '/tmp/thalvari/4571140/automl_save_6nz33lev/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c75ffb8fc, total write size = 33012, bytes this sub-write = 33012, bytes actually written = 18446744073709551615, offset = 2211840)
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m Traceback (most recent call last):
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18682)[0m     self._entrypoint()
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18682)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18682)[0m     output = train_func(config, reporter)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18682)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18682)[0m     config=config)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18682)[0m     model.save(model_path, config_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18682)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18682)[0m     self.model.save(model_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18682)[0m     signatures)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18682)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18682)[0m     f.close()
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18682)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18682)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=18682)[0m , filename = '/tmp/thalvari/4571140/automl_save_6nz33lev/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c76123690, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18682)[0m Exception in thread Thread-1:
[2m[36m(pid=18682)[0m Traceback (most recent call last):
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=18682)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=18682)[0m     param_dset[:] = val
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18682)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18682)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18682)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18682)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=18682)[0m , filename = '/tmp/thalvari/4571140/automl_save_6nz33lev/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c75ffb8fc, total write size = 33012, bytes this sub-write = 33012, bytes actually written = 18446744073709551615, offset = 2211840)
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m Traceback (most recent call last):
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18682)[0m     self._entrypoint()
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18682)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18682)[0m     output = train_func(config, reporter)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18682)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18682)[0m     config=config)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18682)[0m     model.save(model_path, config_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18682)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18682)[0m     self.model.save(model_path)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18682)[0m     signatures)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18682)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18682)[0m     f.close()
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18682)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18682)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18682)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:23 2021
[2m[36m(pid=18682)[0m , filename = '/tmp/thalvari/4571140/automl_save_6nz33lev/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7c76123690, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m Traceback (most recent call last):
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18682)[0m     self.run()
[2m[36m(pid=18682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18682)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18682)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18682)[0m 
[2m[36m(pid=24166)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=24159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=24164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=24166)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=24159)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=24164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2021-01-17 12:39:24,391	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22741, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:24,396	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 80 ({'TERMINATED': 14, 'ERROR': 57, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 51 not shown
 - train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAKE(datetime)=0.48788,bayes_feature_IS_BUSY_HOURS(datetime)=0.56194,bayes_feature_IS_WEEKEND(datetime)=0.93627,bayes_feature_MONTH(datetime)=0.7839,bayes_feature_WEEKDAY(datetime)=0.80738,dropout_1=0.47007,dropout_2=0.20587,epochs=5,lr=0.0091957,lstm_1_units_float=125.8,lstm_2_units_float=127.42,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_69_batch_size_log=8.0794,bayes_feature_DAY(datetime)=0.96625,bayes_feature_HOUR(datetime)=0.41047,bayes_feature_IS_AWAK_2021-01-17_12-39-03hm85ikag/error_2021-01-17_12-39-14.txt
 - train_func_70_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_70_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-04tvr6lcux/error_2021-01-17_12-39-21.txt
 - train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAK_2021-01-17_12-39-13vhyawg43/error_2021-01-17_12-39-24.txt
RUNNING trials:
 - train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_72_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_73_batch_size_log=6.439,bayes_feature_DAY(datetime)=0.66422,bayes_feature_HOUR(datetime)=0.33057,bayes_feature_IS_AWAKE(datetime)=0.84672,bayes_feature_IS_BUSY_HOURS(datetime)=0.4812,bayes_feature_IS_WEEKEND(datetime)=0.45968,bayes_feature_MONTH(datetime)=0.32279,bayes_feature_WEEKDAY(datetime)=0.80895,dropout_1=0.29312,dropout_2=0.4939,epochs=5,lr=0.0051361,lstm_1_units_float=127.01,lstm_2_units_float=127.13,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=22741)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22741)[0m 
[2m[36m(pid=22741)[0m Stack (most recent call first):
[2m[36m(pid=22573)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=22573)[0m   agg_primitives: ['count']
[2m[36m(pid=22573)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=22573)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:39:25,686	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18682, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:25,690	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_71_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18682)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18682)[0m 
[2m[36m(pid=18682)[0m Stack (most recent call first):
[2m[36m(pid=22573)[0m LSTM is selected.
[2m[36m(pid=18680)[0m 2021-01-17 12:39:26,040	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=18680)[0m Traceback (most recent call last):
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=18680)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=18680)[0m     param_dset[:] = val
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18680)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18680)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18680)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18680)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=18680)[0m , filename = '/tmp/thalvari/4571140/automl_save_irccmq2o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f166ab40518, total write size = 58968, bytes this sub-write = 58968, bytes actually written = 18446744073709551615, offset = 1896448)
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m Traceback (most recent call last):
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18680)[0m     self._entrypoint()
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18680)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18680)[0m     output = train_func(config, reporter)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18680)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18680)[0m     config=config)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18680)[0m     model.save(model_path, config_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18680)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18680)[0m     self.model.save(model_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18680)[0m     signatures)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18680)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18680)[0m     f.close()
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18680)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18680)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=18680)[0m , filename = '/tmp/thalvari/4571140/automl_save_irccmq2o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f166946c760, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=18680)[0m Exception in thread Thread-1:
[2m[36m(pid=18680)[0m Traceback (most recent call last):
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=18680)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=18680)[0m     param_dset[:] = val
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=18680)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=18680)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=18680)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=18680)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=18680)[0m , filename = '/tmp/thalvari/4571140/automl_save_irccmq2o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f166ab40518, total write size = 58968, bytes this sub-write = 58968, bytes actually written = 18446744073709551615, offset = 1896448)
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m Traceback (most recent call last):
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=18680)[0m     self._entrypoint()
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=18680)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=18680)[0m     output = train_func(config, reporter)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=18680)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=18680)[0m     config=config)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=18680)[0m     model.save(model_path, config_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=18680)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=18680)[0m     self.model.save(model_path)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=18680)[0m     signatures)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=18680)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=18680)[0m     f.close()
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=18680)[0m     h5i.dec_ref(id_)
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=18680)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=18680)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=18680)[0m , filename = '/tmp/thalvari/4571140/automl_save_irccmq2o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f166946c760, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22573)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=22573)[0m Instructions for updating:
[2m[36m(pid=22573)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m Traceback (most recent call last):
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=18680)[0m     self.run()
[2m[36m(pid=18680)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=18680)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=18680)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=18680)[0m 
[2m[36m(pid=22571)[0m 2021-01-17 12:39:26,170	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22571)[0m Traceback (most recent call last):
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22571)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22571)[0m     param_dset[:] = val
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22571)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22571)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22571)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22571)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=22571)[0m , filename = '/tmp/thalvari/4571140/automl_save_ty73goz9/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f28aa3cd0a8, total write size = 46584, bytes this sub-write = 46584, bytes actually written = 18446744073709551615, offset = 2170880)
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m Traceback (most recent call last):
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22571)[0m     self._entrypoint()
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22571)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22571)[0m     output = train_func(config, reporter)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22571)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22571)[0m     config=config)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22571)[0m     model.save(model_path, config_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22571)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22571)[0m     self.model.save(model_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22571)[0m     signatures)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22571)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22571)[0m     f.close()
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22571)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22571)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=22571)[0m , filename = '/tmp/thalvari/4571140/automl_save_ty73goz9/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f28aa7883f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22571)[0m Exception in thread Thread-1:
[2m[36m(pid=22571)[0m Traceback (most recent call last):
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22571)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22571)[0m     param_dset[:] = val
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22571)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22571)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22571)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22571)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=22571)[0m , filename = '/tmp/thalvari/4571140/automl_save_ty73goz9/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f28aa3cd0a8, total write size = 46584, bytes this sub-write = 46584, bytes actually written = 18446744073709551615, offset = 2170880)
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m Traceback (most recent call last):
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22571)[0m     self._entrypoint()
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22571)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22571)[0m     output = train_func(config, reporter)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22571)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22571)[0m     config=config)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22571)[0m     model.save(model_path, config_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22571)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22571)[0m     self.model.save(model_path)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22571)[0m     signatures)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22571)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22571)[0m     f.close()
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22571)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22571)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22571)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:26 2021
[2m[36m(pid=22571)[0m , filename = '/tmp/thalvari/4571140/automl_save_ty73goz9/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f28aa7883f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m Traceback (most recent call last):
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22571)[0m     self.run()
[2m[36m(pid=22571)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22571)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22571)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22573)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=22573)[0m Instructions for updating:
[2m[36m(pid=22573)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:27,122	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=18680, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:27,126	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_72_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=18680)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=18680)[0m 
[2m[36m(pid=18680)[0m Stack (most recent call first):
[2m[36m(pid=22573)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=22573)[0m 2021-01-17 12:39:27.590596: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=22573)[0m 2021-01-17 12:39:27.599162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=22573)[0m 2021-01-17 12:39:27.601621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9725103300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=22573)[0m 2021-01-17 12:39:27.601662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:39:28,365	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22571, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:28,369	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_73_batch_size_log=6.439,bayes_feature_DAY(datetime)=0.66422,bayes_feature_HOUR(datetime)=0.33057,bayes_feature_IS_AWAKE(datetime)=0.84672,bayes_feature_IS_BUSY_HOURS(datetime)=0.4812,bayes_feature_IS_WEEKEND(datetime)=0.45968,bayes_feature_MONTH(datetime)=0.32279,bayes_feature_WEEKDAY(datetime)=0.80895,dropout_1=0.29312,dropout_2=0.4939,epochs=5,lr=0.0051361,lstm_1_units_float=127.01,lstm_2_units_float=127.13,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=22571)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22571)[0m 
[2m[36m(pid=22571)[0m Stack (most recent call first):
[2m[36m(pid=23911)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=23911)[0m   agg_primitives: ['count']
[2m[36m(pid=23911)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=23911)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23909)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=23909)[0m   agg_primitives: ['count']
[2m[36m(pid=23909)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=23909)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=24166)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=24166)[0m   agg_primitives: ['count']
[2m[36m(pid=24166)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=24166)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23911)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=23911)[0m Instructions for updating:
[2m[36m(pid=23911)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=23911)[0m LSTM is selected.
[2m[36m(pid=23909)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=23909)[0m Instructions for updating:
[2m[36m(pid=23909)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=23909)[0m LSTM is selected.
[2m[36m(pid=24166)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=24166)[0m Instructions for updating:
[2m[36m(pid=24166)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=24166)[0m LSTM is selected.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 84 ({'TERMINATED': 14, 'ERROR': 60, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 54 not shown
 - train_func_72_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_72_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-081c72x5jk/error_2021-01-17_12-39-27.txt
 - train_func_73_batch_size_log=6.439,bayes_feature_DAY(datetime)=0.66422,bayes_feature_HOUR(datetime)=0.33057,bayes_feature_IS_AWAKE(datetime)=0.84672,bayes_feature_IS_BUSY_HOURS(datetime)=0.4812,bayes_feature_IS_WEEKEND(datetime)=0.45968,bayes_feature_MONTH(datetime)=0.32279,bayes_feature_WEEKDAY(datetime)=0.80895,dropout_1=0.29312,dropout_2=0.4939,epochs=5,lr=0.0051361,lstm_1_units_float=127.01,lstm_2_units_float=127.13,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_73_batch_size_log=6.439,bayes_feature_DAY(datetime)=0.66422,bayes_feature_HOUR(datetime)=0.33057,bayes_feature_IS_AWAKE_2021-01-17_12-39-10lcem_1cb/error_2021-01-17_12-39-28.txt
 - train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAK_2021-01-17_12-39-13vhyawg43/error_2021-01-17_12-39-24.txt
RUNNING trials:
 - train_func_74_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=23911)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=23911)[0m Instructions for updating:
[2m[36m(pid=23911)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=23909)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=23909)[0m Instructions for updating:
[2m[36m(pid=23909)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=24166)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=24166)[0m Instructions for updating:
[2m[36m(pid=24166)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22572)[0m 2021-01-17 12:39:30,535	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22572)[0m Traceback (most recent call last):
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22572)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22572)[0m     param_dset[:] = val
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22572)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22572)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22572)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22572)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:30 2021
[2m[36m(pid=22572)[0m , filename = '/tmp/thalvari/4571140/automl_save_z2ds6o1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f580a9e0a1c, total write size = 82164, bytes this sub-write = 82164, bytes actually written = 18446744073709551615, offset = 2166784)
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m Traceback (most recent call last):
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22572)[0m     self._entrypoint()
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22572)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22572)[0m     output = train_func(config, reporter)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22572)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22572)[0m     config=config)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22572)[0m     model.save(model_path, config_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22572)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22572)[0m     self.model.save(model_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22572)[0m     signatures)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22572)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22572)[0m     f.close()
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22572)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22572)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:30 2021
[2m[36m(pid=22572)[0m , filename = '/tmp/thalvari/4571140/automl_save_z2ds6o1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f580a57f6c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22572)[0m Exception in thread Thread-1:
[2m[36m(pid=22572)[0m Traceback (most recent call last):
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22572)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22572)[0m     param_dset[:] = val
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22572)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22572)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22572)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22572)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:30 2021
[2m[36m(pid=22572)[0m , filename = '/tmp/thalvari/4571140/automl_save_z2ds6o1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f580a9e0a1c, total write size = 82164, bytes this sub-write = 82164, bytes actually written = 18446744073709551615, offset = 2166784)
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m Traceback (most recent call last):
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22572)[0m     self._entrypoint()
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22572)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22572)[0m     output = train_func(config, reporter)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22572)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22572)[0m     config=config)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22572)[0m     model.save(model_path, config_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22572)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22572)[0m     self.model.save(model_path)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22572)[0m     signatures)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22572)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22572)[0m     f.close()
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22572)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22572)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22572)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:30 2021
[2m[36m(pid=22572)[0m , filename = '/tmp/thalvari/4571140/automl_save_z2ds6o1o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f580a57f6c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m Traceback (most recent call last):
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22572)[0m     self.run()
[2m[36m(pid=22572)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22572)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22572)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22572)[0m 
[2m[36m(pid=24164)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=24164)[0m   agg_primitives: ['count']
[2m[36m(pid=24164)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=24164)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23911)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=23911)[0m 2021-01-17 12:39:30.716789: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=23911)[0m 2021-01-17 12:39:30.725048: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=23911)[0m 2021-01-17 12:39:30.727440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f55250e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=23911)[0m 2021-01-17 12:39:30.727462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=23909)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=23909)[0m 2021-01-17 12:39:30.733946: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=24166)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=24166)[0m 2021-01-17 12:39:30.713248: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=24166)[0m 2021-01-17 12:39:30.722768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=24166)[0m 2021-01-17 12:39:30.725082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe1b10ce6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=24166)[0m 2021-01-17 12:39:30.725106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=23909)[0m 2021-01-17 12:39:30.743782: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=23909)[0m 2021-01-17 12:39:30.746866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f33210cfa70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=23909)[0m 2021-01-17 12:39:30.746896: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=24164)[0m LSTM is selected.
[2m[36m(pid=24164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=24164)[0m Instructions for updating:
[2m[36m(pid=24164)[0m If using Keras pass *_constraint arguments to layers.
2021-01-17 12:39:31,561	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22572, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:31,566	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_74_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=22737)[0m 2021-01-17 12:39:31,594	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22737)[0m Traceback (most recent call last):
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22737)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22737)[0m     param_dset[:] = val
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22737)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22737)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22737)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22737)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:31 2021
[2m[36m(pid=22737)[0m , filename = '/tmp/thalvari/4571140/automl_save_wc4g5bli/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9b2a153ac, total write size = 90356, bytes this sub-write = 90356, bytes actually written = 18446744073709551615, offset = 2154496)
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m Traceback (most recent call last):
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22737)[0m     self._entrypoint()
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22737)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22737)[0m     output = train_func(config, reporter)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22737)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22737)[0m     config=config)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22737)[0m     model.save(model_path, config_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22737)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22737)[0m     self.model.save(model_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22737)[0m     signatures)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22737)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22737)[0m     f.close()
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22737)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22737)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:31 2021
[2m[36m(pid=22737)[0m , filename = '/tmp/thalvari/4571140/automl_save_wc4g5bli/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9b22bb7c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22737)[0m Exception in thread Thread-1:
[2m[36m(pid=22737)[0m Traceback (most recent call last):
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22737)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22737)[0m     param_dset[:] = val
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22737)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22737)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22737)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22737)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:31 2021
[2m[36m(pid=22737)[0m , filename = '/tmp/thalvari/4571140/automl_save_wc4g5bli/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9b2a153ac, total write size = 90356, bytes this sub-write = 90356, bytes actually written = 18446744073709551615, offset = 2154496)
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m Traceback (most recent call last):
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22737)[0m     self._entrypoint()
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22737)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22737)[0m     output = train_func(config, reporter)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22737)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22737)[0m     config=config)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22737)[0m     model.save(model_path, config_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22737)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22737)[0m     self.model.save(model_path)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22737)[0m     signatures)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22737)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22737)[0m     f.close()
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22737)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22737)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22737)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:31 2021
[2m[36m(pid=22737)[0m , filename = '/tmp/thalvari/4571140/automl_save_wc4g5bli/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd9b22bb7c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m Traceback (most recent call last):
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22737)[0m     self.run()
[2m[36m(pid=22737)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22737)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22737)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22572)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22572)[0m 
[2m[36m(pid=22572)[0m Stack (most recent call first):
[2m[36m(pid=24164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=24164)[0m Instructions for updating:
[2m[36m(pid=24164)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22695)[0m 2021-01-17 12:39:32,149	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22695)[0m Traceback (most recent call last):
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22695)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22695)[0m     param_dset[:] = val
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22695)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22695)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22695)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22695)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:32 2021
[2m[36m(pid=22695)[0m , filename = '/tmp/thalvari/4571140/automl_save_rjzny29l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f446dfa311c, total write size = 98548, bytes this sub-write = 98548, bytes actually written = 18446744073709551615, offset = 2146304)
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m Traceback (most recent call last):
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22695)[0m     self._entrypoint()
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22695)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22695)[0m     output = train_func(config, reporter)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22695)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22695)[0m     config=config)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22695)[0m     model.save(model_path, config_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22695)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22695)[0m     self.model.save(model_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22695)[0m     signatures)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22695)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22695)[0m     f.close()
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22695)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22695)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:32 2021
[2m[36m(pid=22695)[0m , filename = '/tmp/thalvari/4571140/automl_save_rjzny29l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f446e6f6380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22695)[0m Exception in thread Thread-1:
[2m[36m(pid=22695)[0m Traceback (most recent call last):
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22695)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22695)[0m     param_dset[:] = val
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22695)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22695)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22695)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22695)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:32 2021
[2m[36m(pid=22695)[0m , filename = '/tmp/thalvari/4571140/automl_save_rjzny29l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f446dfa311c, total write size = 98548, bytes this sub-write = 98548, bytes actually written = 18446744073709551615, offset = 2146304)
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m Traceback (most recent call last):
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22695)[0m     self._entrypoint()
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22695)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22695)[0m     output = train_func(config, reporter)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22695)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22695)[0m     config=config)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22695)[0m     model.save(model_path, config_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22695)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22695)[0m     self.model.save(model_path)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22695)[0m     signatures)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22695)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22695)[0m     f.close()
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22695)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22695)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22695)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:32 2021
[2m[36m(pid=22695)[0m , filename = '/tmp/thalvari/4571140/automl_save_rjzny29l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f446e6f6380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m Traceback (most recent call last):
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22695)[0m     self.run()
[2m[36m(pid=22695)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22695)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22695)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22695)[0m 
[2m[36m(pid=24159)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=24159)[0m   agg_primitives: ['count']
[2m[36m(pid=24159)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=24159)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23869)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=23869)[0m   agg_primitives: ['count']
[2m[36m(pid=23869)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=23869)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:39:32,732	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22737, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:32,736	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=24159)[0m LSTM is selected.
[2m[36m(pid=24159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=24159)[0m Instructions for updating:
[2m[36m(pid=24159)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=24164)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=24164)[0m 2021-01-17 12:39:32.836963: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=24164)[0m 2021-01-17 12:39:32.849439: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=24164)[0m 2021-01-17 12:39:32.853244: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef74d0e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=24164)[0m 2021-01-17 12:39:32.853270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=22737)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22737)[0m 
[2m[36m(pid=22737)[0m Stack (most recent call first):
[2m[36m(pid=23869)[0m LSTM is selected.
[2m[36m(pid=23869)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=23869)[0m Instructions for updating:
[2m[36m(pid=23869)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=24159)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=24159)[0m Instructions for updating:
[2m[36m(pid=24159)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=23869)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=23869)[0m Instructions for updating:
[2m[36m(pid=23869)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:34,034	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22695, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:34,037	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=22695)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22695)[0m 
[2m[36m(pid=22695)[0m Stack (most recent call first):
[2m[36m(pid=24159)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=24159)[0m 2021-01-17 12:39:34.523558: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=24159)[0m 2021-01-17 12:39:34.537110: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=24159)[0m 2021-01-17 12:39:34.541778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f235511d400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=24159)[0m 2021-01-17 12:39:34.541809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=23869)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=23869)[0m 2021-01-17 12:39:34.901929: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=23869)[0m 2021-01-17 12:39:34.913575: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=23869)[0m 2021-01-17 12:39:34.918388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7bd50e95a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=23869)[0m 2021-01-17 12:39:34.918438: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 87 ({'TERMINATED': 14, 'ERROR': 63, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 57 not shown
 - train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAKE(datetime)=0.34281,bayes_feature_IS_BUSY_HOURS(datetime)=0.38033,bayes_feature_IS_WEEKEND(datetime)=0.69345,bayes_feature_MONTH(datetime)=0.48642,bayes_feature_WEEKDAY(datetime)=0.68236,dropout_1=0.32449,dropout_2=0.43948,epochs=5,lr=0.0046274,lstm_1_units_float=127.51,lstm_2_units_float=127.58,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_75_batch_size_log=9.0246,bayes_feature_DAY(datetime)=0.68069,bayes_feature_HOUR(datetime)=0.72085,bayes_feature_IS_AWAK_2021-01-17_12-39-13vhyawg43/error_2021-01-17_12-39-24.txt
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-14yiul7u6u/error_2021-01-17_12-39-32.txt
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-15x2uxco5_/error_2021-01-17_12-39-34.txt
RUNNING trials:
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=25252)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25252)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25253)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25253)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25254)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25254)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=25631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=23910)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=23910)[0m   agg_primitives: ['count']
[2m[36m(pid=23910)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=23910)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23910)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=23910)[0m Instructions for updating:
[2m[36m(pid=23910)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=23910)[0m LSTM is selected.
[2m[36m(pid=23910)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=23910)[0m Instructions for updating:
[2m[36m(pid=23910)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=22573)[0m 2021-01-17 12:39:39,340	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=22573)[0m Traceback (most recent call last):
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22573)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22573)[0m     param_dset[:] = val
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22573)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22573)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22573)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22573)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:39 2021
[2m[36m(pid=22573)[0m , filename = '/tmp/thalvari/4571140/automl_save_ajjbj_w8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97268684bc, total write size = 164084, bytes this sub-write = 164084, bytes actually written = 18446744073709551615, offset = 2088960)
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m Traceback (most recent call last):
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22573)[0m     self._entrypoint()
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22573)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22573)[0m     output = train_func(config, reporter)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22573)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22573)[0m     config=config)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22573)[0m     model.save(model_path, config_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22573)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22573)[0m     self.model.save(model_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22573)[0m     signatures)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22573)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22573)[0m     f.close()
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22573)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22573)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:39 2021
[2m[36m(pid=22573)[0m , filename = '/tmp/thalvari/4571140/automl_save_ajjbj_w8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97264e9d70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22573)[0m Exception in thread Thread-1:
[2m[36m(pid=22573)[0m Traceback (most recent call last):
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=22573)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=22573)[0m     param_dset[:] = val
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=22573)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=22573)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=22573)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=22573)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:39 2021
[2m[36m(pid=22573)[0m , filename = '/tmp/thalvari/4571140/automl_save_ajjbj_w8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97268684bc, total write size = 164084, bytes this sub-write = 164084, bytes actually written = 18446744073709551615, offset = 2088960)
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m Traceback (most recent call last):
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=22573)[0m     self._entrypoint()
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=22573)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=22573)[0m     output = train_func(config, reporter)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=22573)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=22573)[0m     config=config)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=22573)[0m     model.save(model_path, config_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=22573)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=22573)[0m     self.model.save(model_path)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=22573)[0m     signatures)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=22573)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=22573)[0m     f.close()
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=22573)[0m     h5i.dec_ref(id_)
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=22573)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=22573)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:39 2021
[2m[36m(pid=22573)[0m , filename = '/tmp/thalvari/4571140/automl_save_ajjbj_w8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f97264e9d70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m Traceback (most recent call last):
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=22573)[0m     self.run()
[2m[36m(pid=22573)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=22573)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=22573)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=22573)[0m 
[2m[36m(pid=23910)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=23910)[0m 2021-01-17 12:39:40.042577: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=23910)[0m 2021-01-17 12:39:40.056519: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=23910)[0m 2021-01-17 12:39:40.061391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7250b4a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=23910)[0m 2021-01-17 12:39:40.061442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:39:40,524	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=22573, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:40,530	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 87 ({'TERMINATED': 14, 'ERROR': 64, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 58 not shown
 - train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_76_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-14yiul7u6u/error_2021-01-17_12-39-32.txt
 - train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_77_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-15x2uxco5_/error_2021-01-17_12-39-34.txt
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-205tb4ws0k/error_2021-01-17_12-39-40.txt
RUNNING trials:
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=22573)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=22573)[0m 
[2m[36m(pid=22573)[0m Stack (most recent call first):
[2m[36m(pid=25254)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25254)[0m   agg_primitives: ['count']
[2m[36m(pid=25254)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25254)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=25252)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25252)[0m   agg_primitives: ['count']
[2m[36m(pid=25252)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25252)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=23911)[0m 2021-01-17 12:39:42,032	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=23911)[0m Traceback (most recent call last):
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23911)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23911)[0m     param_dset[:] = val
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23911)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23911)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23911)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23911)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23911)[0m , filename = '/tmp/thalvari/4571140/automl_save_w2wqg8vg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55267b95ec, total write size = 164084, bytes this sub-write = 164084, bytes actually written = 18446744073709551615, offset = 2084864)
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m Traceback (most recent call last):
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23911)[0m     self._entrypoint()
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23911)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23911)[0m     output = train_func(config, reporter)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23911)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23911)[0m     config=config)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23911)[0m     model.save(model_path, config_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23911)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23911)[0m     self.model.save(model_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23911)[0m     signatures)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23911)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23911)[0m     f.close()
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23911)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23911)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23911)[0m , filename = '/tmp/thalvari/4571140/automl_save_w2wqg8vg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f552589d380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23911)[0m Exception in thread Thread-1:
[2m[36m(pid=23911)[0m Traceback (most recent call last):
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23911)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23911)[0m     param_dset[:] = val
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23911)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23911)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23911)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23911)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23911)[0m , filename = '/tmp/thalvari/4571140/automl_save_w2wqg8vg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f55267b95ec, total write size = 164084, bytes this sub-write = 164084, bytes actually written = 18446744073709551615, offset = 2084864)
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m Traceback (most recent call last):
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23911)[0m     self._entrypoint()
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23911)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23911)[0m     output = train_func(config, reporter)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23911)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23911)[0m     config=config)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23911)[0m     model.save(model_path, config_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23911)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23911)[0m     self.model.save(model_path)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23911)[0m     signatures)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23911)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23911)[0m     f.close()
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23911)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23911)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23911)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23911)[0m , filename = '/tmp/thalvari/4571140/automl_save_w2wqg8vg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f552589d380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m Traceback (most recent call last):
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=23911)[0m     self.run()
[2m[36m(pid=23911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=23911)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=23911)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=23911)[0m 
[2m[36m(pid=25252)[0m LSTM is selected.
[2m[36m(pid=25254)[0m LSTM is selected.
[2m[36m(pid=25252)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25252)[0m Instructions for updating:
[2m[36m(pid=25252)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=25254)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25254)[0m Instructions for updating:
[2m[36m(pid=25254)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=23909)[0m 2021-01-17 12:39:42,893	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=23909)[0m Traceback (most recent call last):
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=23909)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=23909)[0m     param_dset[:] = val
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23909)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23909)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23909)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23909)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23909)[0m , filename = '/tmp/thalvari/4571140/automl_save_fijl3nw2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3322983718, total write size = 169560, bytes this sub-write = 169560, bytes actually written = 18446744073709551615, offset = 1785856)
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m Traceback (most recent call last):
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23909)[0m     self._entrypoint()
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23909)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23909)[0m     output = train_func(config, reporter)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23909)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23909)[0m     config=config)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23909)[0m     model.save(model_path, config_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23909)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23909)[0m     self.model.save(model_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23909)[0m     signatures)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23909)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23909)[0m     f.close()
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23909)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23909)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23909)[0m , filename = '/tmp/thalvari/4571140/automl_save_fijl3nw2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f33219c6950, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23909)[0m Exception in thread Thread-1:
[2m[36m(pid=23909)[0m Traceback (most recent call last):
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=23909)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=23909)[0m     param_dset[:] = val
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23909)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23909)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23909)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23909)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23909)[0m , filename = '/tmp/thalvari/4571140/automl_save_fijl3nw2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3322983718, total write size = 169560, bytes this sub-write = 169560, bytes actually written = 18446744073709551615, offset = 1785856)
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m Traceback (most recent call last):
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23909)[0m     self._entrypoint()
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23909)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23909)[0m     output = train_func(config, reporter)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23909)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23909)[0m     config=config)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23909)[0m     model.save(model_path, config_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23909)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23909)[0m     self.model.save(model_path)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23909)[0m     signatures)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23909)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23909)[0m     f.close()
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23909)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23909)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23909)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=23909)[0m , filename = '/tmp/thalvari/4571140/automl_save_fijl3nw2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f33219c6950, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m Traceback (most recent call last):
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=23909)[0m     self.run()
[2m[36m(pid=23909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=23909)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=23909)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=23909)[0m 
[2m[36m(pid=24166)[0m 2021-01-17 12:39:42,996	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=24166)[0m Traceback (most recent call last):
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24166)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24166)[0m     param_dset[:] = val
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24166)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24166)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24166)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24166)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=24166)[0m , filename = '/tmp/thalvari/4571140/automl_save_u_vg8x94/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe1b276e0fc, total write size = 180468, bytes this sub-write = 180468, bytes actually written = 18446744073709551615, offset = 2064384)
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m Traceback (most recent call last):
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24166)[0m     self._entrypoint()
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24166)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24166)[0m     output = train_func(config, reporter)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24166)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24166)[0m     config=config)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24166)[0m     model.save(model_path, config_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24166)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24166)[0m     self.model.save(model_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24166)[0m     signatures)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24166)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24166)[0m     f.close()
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24166)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24166)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=24166)[0m , filename = '/tmp/thalvari/4571140/automl_save_u_vg8x94/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe1b27b7ae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=24166)[0m Exception in thread Thread-1:
[2m[36m(pid=24166)[0m Traceback (most recent call last):
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24166)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24166)[0m     param_dset[:] = val
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24166)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24166)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24166)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24166)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=24166)[0m , filename = '/tmp/thalvari/4571140/automl_save_u_vg8x94/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe1b276e0fc, total write size = 180468, bytes this sub-write = 180468, bytes actually written = 18446744073709551615, offset = 2064384)
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m Traceback (most recent call last):
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24166)[0m     self._entrypoint()
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24166)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24166)[0m     output = train_func(config, reporter)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24166)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24166)[0m     config=config)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24166)[0m     model.save(model_path, config_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24166)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24166)[0m     self.model.save(model_path)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24166)[0m     signatures)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24166)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24166)[0m     f.close()
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24166)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24166)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24166)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:42 2021
[2m[36m(pid=24166)[0m , filename = '/tmp/thalvari/4571140/automl_save_u_vg8x94/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fe1b27b7ae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=25254)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25254)[0m Instructions for updating:
[2m[36m(pid=25254)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m Traceback (most recent call last):
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=24166)[0m     self.run()
[2m[36m(pid=24166)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=24166)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=24166)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=24166)[0m 
[2m[36m(pid=25252)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25252)[0m Instructions for updating:
[2m[36m(pid=25252)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:43,054	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=23911, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:43,058	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=23911)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=23911)[0m 
[2m[36m(pid=23911)[0m Stack (most recent call first):
[2m[36m(pid=25252)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25252)[0m 2021-01-17 12:39:44.054202: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25254)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25254)[0m 2021-01-17 12:39:44.030579: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25254)[0m 2021-01-17 12:39:44.039453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25254)[0m 2021-01-17 12:39:44.043902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc70d0e8530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25254)[0m 2021-01-17 12:39:44.043940: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=25252)[0m 2021-01-17 12:39:44.062926: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25252)[0m 2021-01-17 12:39:44.066566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efa1d0e8620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25252)[0m 2021-01-17 12:39:44.066602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:39:44,271	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=23909, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:44,276	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=23909)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=23909)[0m 
[2m[36m(pid=23909)[0m Stack (most recent call first):
[2m[36m(pid=24164)[0m 2021-01-17 12:39:44,580	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=24164)[0m Traceback (most recent call last):
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24164)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24164)[0m     param_dset[:] = val
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24164)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:44 2021
[2m[36m(pid=24164)[0m , filename = '/tmp/thalvari/4571140/automl_save_1bba6kq9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef74e94368c, total write size = 188660, bytes this sub-write = 188660, bytes actually written = 18446744073709551615, offset = 2060288)
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m Traceback (most recent call last):
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24164)[0m     self._entrypoint()
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24164)[0m     output = train_func(config, reporter)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24164)[0m     config=config)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24164)[0m     model.save(model_path, config_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24164)[0m     self.model.save(model_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24164)[0m     signatures)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24164)[0m     f.close()
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24164)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:44 2021
[2m[36m(pid=24164)[0m , filename = '/tmp/thalvari/4571140/automl_save_1bba6kq9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef74d92b3a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=24164)[0m Exception in thread Thread-1:
[2m[36m(pid=24164)[0m Traceback (most recent call last):
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24164)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24164)[0m     param_dset[:] = val
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24164)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:44 2021
[2m[36m(pid=24164)[0m , filename = '/tmp/thalvari/4571140/automl_save_1bba6kq9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef74e94368c, total write size = 188660, bytes this sub-write = 188660, bytes actually written = 18446744073709551615, offset = 2060288)
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m Traceback (most recent call last):
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24164)[0m     self._entrypoint()
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24164)[0m     output = train_func(config, reporter)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24164)[0m     config=config)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24164)[0m     model.save(model_path, config_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24164)[0m     self.model.save(model_path)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24164)[0m     signatures)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24164)[0m     f.close()
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24164)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:44 2021
[2m[36m(pid=24164)[0m , filename = '/tmp/thalvari/4571140/automl_save_1bba6kq9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef74d92b3a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m Traceback (most recent call last):
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=24164)[0m     self.run()
[2m[36m(pid=24164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=24164)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=24164)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=24164)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 90 ({'TERMINATED': 14, 'ERROR': 66, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 60 not shown
 - train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_78_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-205tb4ws0k/error_2021-01-17_12-39-40.txt
 - train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_79_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-21f7ms62j6/error_2021-01-17_12-39-44.txt
 - train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_80_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-239iuoag_7/error_2021-01-17_12-39-43.txt
RUNNING trials:
 - train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:39:45,721	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=24164, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:45,727	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=24164)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=24164)[0m 
[2m[36m(pid=24164)[0m Stack (most recent call first):
[2m[36m(pid=25627)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25627)[0m   agg_primitives: ['count']
[2m[36m(pid=25627)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25627)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=24159)[0m 2021-01-17 12:39:46,103	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=24159)[0m Traceback (most recent call last):
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24159)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24159)[0m     param_dset[:] = val
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24159)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=24159)[0m , filename = '/tmp/thalvari/4571140/automl_save__hxg_0gt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f235540354c, total write size = 205044, bytes this sub-write = 205044, bytes actually written = 18446744073709551615, offset = 2052096)
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m Traceback (most recent call last):
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24159)[0m     self._entrypoint()
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24159)[0m     output = train_func(config, reporter)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24159)[0m     config=config)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24159)[0m     model.save(model_path, config_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24159)[0m     self.model.save(model_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24159)[0m     signatures)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24159)[0m     f.close()
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24159)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=24159)[0m , filename = '/tmp/thalvari/4571140/automl_save__hxg_0gt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f23556df710, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=24159)[0m Exception in thread Thread-1:
[2m[36m(pid=24159)[0m Traceback (most recent call last):
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=24159)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=24159)[0m     param_dset[:] = val
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=24159)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=24159)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=24159)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=24159)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=24159)[0m , filename = '/tmp/thalvari/4571140/automl_save__hxg_0gt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f235540354c, total write size = 205044, bytes this sub-write = 205044, bytes actually written = 18446744073709551615, offset = 2052096)
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m Traceback (most recent call last):
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=24159)[0m     self._entrypoint()
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=24159)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=24159)[0m     output = train_func(config, reporter)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=24159)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=24159)[0m     config=config)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=24159)[0m     model.save(model_path, config_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=24159)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=24159)[0m     self.model.save(model_path)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=24159)[0m     signatures)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=24159)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=24159)[0m     f.close()
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=24159)[0m     h5i.dec_ref(id_)
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=24159)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=24159)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=24159)[0m , filename = '/tmp/thalvari/4571140/automl_save__hxg_0gt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f23556df710, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m Traceback (most recent call last):
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=24159)[0m     self.run()
[2m[36m(pid=24159)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=24159)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=24159)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=24159)[0m 
[2m[36m(pid=25627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25627)[0m Instructions for updating:
[2m[36m(pid=25627)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=25627)[0m LSTM is selected.
[2m[36m(pid=23869)[0m 2021-01-17 12:39:46,676	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=23869)[0m Traceback (most recent call last):
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23869)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23869)[0m     param_dset[:] = val
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23869)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23869)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23869)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23869)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=23869)[0m , filename = '/tmp/thalvari/4571140/automl_save_v9wzqqst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7bd5fa445c, total write size = 205044, bytes this sub-write = 205044, bytes actually written = 18446744073709551615, offset = 2043904)
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m Traceback (most recent call last):
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23869)[0m     self._entrypoint()
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23869)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23869)[0m     output = train_func(config, reporter)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23869)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23869)[0m     config=config)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23869)[0m     model.save(model_path, config_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23869)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23869)[0m     self.model.save(model_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23869)[0m     signatures)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23869)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23869)[0m     f.close()
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23869)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23869)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=23869)[0m , filename = '/tmp/thalvari/4571140/automl_save_v9wzqqst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7bd5fff3d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23869)[0m Exception in thread Thread-1:
[2m[36m(pid=23869)[0m Traceback (most recent call last):
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23869)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23869)[0m     param_dset[:] = val
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23869)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23869)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23869)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23869)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=23869)[0m , filename = '/tmp/thalvari/4571140/automl_save_v9wzqqst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7bd5fa445c, total write size = 205044, bytes this sub-write = 205044, bytes actually written = 18446744073709551615, offset = 2043904)
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m Traceback (most recent call last):
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23869)[0m     self._entrypoint()
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23869)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23869)[0m     output = train_func(config, reporter)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23869)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23869)[0m     config=config)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23869)[0m     model.save(model_path, config_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23869)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23869)[0m     self.model.save(model_path)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23869)[0m     signatures)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23869)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23869)[0m     f.close()
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23869)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23869)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23869)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:46 2021
[2m[36m(pid=23869)[0m , filename = '/tmp/thalvari/4571140/automl_save_v9wzqqst/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7bd5fff3d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m Traceback (most recent call last):
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=23869)[0m     self.run()
[2m[36m(pid=23869)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=23869)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=23869)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=23869)[0m 
[2m[36m(pid=25627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25627)[0m Instructions for updating:
[2m[36m(pid=25627)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:47,124	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=24166, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:47,129	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_81_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=24166)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=24166)[0m 
[2m[36m(pid=24166)[0m Stack (most recent call first):
[2m[36m(pid=25627)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25627)[0m 2021-01-17 12:39:48.029830: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25627)[0m 2021-01-17 12:39:48.039456: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25627)[0m 2021-01-17 12:39:48.042052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2a6911d530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25627)[0m 2021-01-17 12:39:48.042076: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=25632)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25632)[0m   agg_primitives: ['count']
[2m[36m(pid=25632)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25632)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2021-01-17 12:39:48,287	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=23869, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:48,291	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=23869)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=23869)[0m 
[2m[36m(pid=23869)[0m Stack (most recent call first):
[2m[36m(pid=25632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25632)[0m Instructions for updating:
[2m[36m(pid=25632)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=25632)[0m LSTM is selected.
[2m[36m(pid=25631)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25631)[0m   agg_primitives: ['count']
[2m[36m(pid=25631)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25631)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=25632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25632)[0m Instructions for updating:
[2m[36m(pid=25632)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=26555)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26555)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=26553)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26553)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=26554)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26554)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25631)[0m LSTM is selected.
2021-01-17 12:39:49,866	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=24159, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:49,870	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=25631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25631)[0m Instructions for updating:
[2m[36m(pid=25631)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26679)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26679)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=24159)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=24159)[0m 
[2m[36m(pid=24159)[0m Stack (most recent call first):
[2m[36m(pid=25631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25631)[0m Instructions for updating:
[2m[36m(pid=25631)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=26723)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26723)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=25632)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25632)[0m 2021-01-17 12:39:50.539406: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25632)[0m 2021-01-17 12:39:50.550435: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25632)[0m 2021-01-17 12:39:50.553838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7d50e9400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25632)[0m 2021-01-17 12:39:50.553882: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=26727)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=26727)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 94 ({'TERMINATED': 14, 'ERROR': 70, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 64 not shown
 - train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_82_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-26nv4nl2qd/error_2021-01-17_12-39-45.txt
 - train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_83_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-282ctt32go/error_2021-01-17_12-39-49.txt
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-293a28olgz/error_2021-01-17_12-39-48.txt
RUNNING trials:
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=23910)[0m 2021-01-17 12:39:51,394	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=23910)[0m Traceback (most recent call last):
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23910)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23910)[0m     param_dset[:] = val
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23910)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23910)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23910)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23910)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:51 2021
[2m[36m(pid=23910)[0m , filename = '/tmp/thalvari/4571140/automl_save_jj3_v78e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe725f6a76c, total write size = 254196, bytes this sub-write = 254196, bytes actually written = 18446744073709551615, offset = 1986560)
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m Traceback (most recent call last):
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23910)[0m     self._entrypoint()
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23910)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23910)[0m     output = train_func(config, reporter)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23910)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23910)[0m     config=config)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23910)[0m     model.save(model_path, config_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23910)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23910)[0m     self.model.save(model_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23910)[0m     signatures)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23910)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23910)[0m     f.close()
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23910)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23910)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:51 2021
[2m[36m(pid=23910)[0m , filename = '/tmp/thalvari/4571140/automl_save_jj3_v78e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7258e4be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23910)[0m Exception in thread Thread-1:
[2m[36m(pid=23910)[0m Traceback (most recent call last):
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=23910)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=23910)[0m     param_dset[:] = val
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=23910)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=23910)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=23910)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=23910)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:51 2021
[2m[36m(pid=23910)[0m , filename = '/tmp/thalvari/4571140/automl_save_jj3_v78e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe725f6a76c, total write size = 254196, bytes this sub-write = 254196, bytes actually written = 18446744073709551615, offset = 1986560)
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m Traceback (most recent call last):
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=23910)[0m     self._entrypoint()
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=23910)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=23910)[0m     output = train_func(config, reporter)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=23910)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=23910)[0m     config=config)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=23910)[0m     model.save(model_path, config_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=23910)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=23910)[0m     self.model.save(model_path)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=23910)[0m     signatures)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=23910)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=23910)[0m     f.close()
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=23910)[0m     h5i.dec_ref(id_)
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=23910)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=23910)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:51 2021
[2m[36m(pid=23910)[0m , filename = '/tmp/thalvari/4571140/automl_save_jj3_v78e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe7258e4be0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m Traceback (most recent call last):
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=23910)[0m     self.run()
[2m[36m(pid=23910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=23910)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=23910)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=23910)[0m 
[2m[36m(pid=25631)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25631)[0m 2021-01-17 12:39:51.510129: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25253)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=25253)[0m   agg_primitives: ['count']
[2m[36m(pid=25253)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=25253)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=25631)[0m 2021-01-17 12:39:51.520572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25631)[0m 2021-01-17 12:39:51.534085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f86f10e8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25631)[0m 2021-01-17 12:39:51.534118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=25253)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=25253)[0m Instructions for updating:
[2m[36m(pid=25253)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=25253)[0m LSTM is selected.
2021-01-17 12:39:52,577	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=23910, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:52,581	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=25253)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=25253)[0m Instructions for updating:
[2m[36m(pid=25253)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=23910)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=23910)[0m 
[2m[36m(pid=23910)[0m Stack (most recent call first):
[2m[36m(pid=25253)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=25253)[0m 2021-01-17 12:39:53.695566: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=25253)[0m 2021-01-17 12:39:53.705886: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=25253)[0m 2021-01-17 12:39:53.709354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f699511d400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=25253)[0m 2021-01-17 12:39:53.709393: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25252)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1d600784, total write size = 6388, bytes this sub-write = 6388, bytes actually written = 18446744073709551615, offset = 1978368)
[2m[36m(pid=25252)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25252)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1d600784, total write size = 6388, bytes this sub-write = 6388, bytes actually written = 18446744073709551615, offset = 1978368)
[2m[36m(pid=25252)[0m 2021-01-17 12:39:54,350	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=25252)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=25252)[0m     param_dset[:] = val
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=25252)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=25252)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=25252)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=25252)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1e2578b0, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 1986804)
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25252)[0m     self._entrypoint()
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25252)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25252)[0m     output = train_func(config, reporter)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25252)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25252)[0m     config=config)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=25252)[0m     model.save(model_path, config_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=25252)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=25252)[0m     self.model.save(model_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=25252)[0m     signatures)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=25252)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=25252)[0m     f.close()
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=25252)[0m     h5i.dec_ref(id_)
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=25252)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1d666280, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=25252)[0m Exception in thread Thread-1:
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=25252)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=25252)[0m     param_dset[:] = val
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=25252)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=25252)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=25252)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=25252)[0m OSError: Can't write data (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1e2578b0, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 1986804)
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25252)[0m     self._entrypoint()
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25252)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25252)[0m     output = train_func(config, reporter)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25252)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25252)[0m     config=config)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=25252)[0m     model.save(model_path, config_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=25252)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=25252)[0m     self.model.save(model_path)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=25252)[0m     signatures)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=25252)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=25252)[0m     f.close()
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=25252)[0m     h5i.dec_ref(id_)
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=25252)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=25252)[0m RuntimeError: Problems closing file (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25252)[0m , filename = '/tmp/thalvari/4571140/automl_save_ijzrxj60/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efa1d666280, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m Traceback (most recent call last):
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=25252)[0m     self.run()
[2m[36m(pid=25252)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=25252)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=25252)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25254)[0m Traceback (most recent call last):
[2m[36m(pid=25254)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25254)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25254)[0m , filename = '/tmp/thalvari/4571140/automl_save_mcszujrn/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fc70d444b40, total write size = 4372, bytes this sub-write = 4372, bytes actually written = 18446744073709551615, offset = 1961984)
[2m[36m(pid=25254)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=25254)[0m Traceback (most recent call last):
[2m[36m(pid=25254)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25254)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:54 2021
[2m[36m(pid=25254)[0m , filename = '/tmp/thalvari/4571140/automl_save_mcszujrn/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fc70d444b40, total write size = 4372, bytes this sub-write = 4372, bytes actually written = 18446744073709551615, offset = 1961984)
[2m[36m(pid=25254)[0m Traceback (most recent call last):
[2m[36m(pid=25254)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25254)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:55 2021
[2m[36m(pid=25254)[0m , filename = '/tmp/thalvari/4571140/automl_save_mcszujrn/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fc70d901598, total write size = 8, bytes this sub-write = 8, bytes actually written = 18446744073709551615, offset = 1970132)
[2m[36m(pid=25254)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=25254)[0m Traceback (most recent call last):
[2m[36m(pid=25254)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=25254)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Sun Jan 17 12:39:55 2021
[2m[36m(pid=25254)[0m , filename = '/tmp/thalvari/4571140/automl_save_mcszujrn/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fc70d901598, total write size = 8, bytes this sub-write = 8, bytes actually written = 18446744073709551615, off
2021-01-17 12:39:55,103	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-01-17 12:39:55,106	ERROR worker.py:1672 -- A worker died or was killed while executing task d58736c09dafd325b7a3d2234e8d8d31.
2021-01-17 12:39:55,108	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=26553)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26553)[0m   agg_primitives: ['count']
[2m[36m(pid=26553)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26553)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26679)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26679)[0m   agg_primitives: ['count']
[2m[36m(pid=26679)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26679)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26727)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26727)[0m   agg_primitives: ['count']
[2m[36m(pid=26727)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26727)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26553)[0m LSTM is selected.
[2m[36m(pid=26679)[0m LSTM is selected.
[2m[36m(pid=26727)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26727)[0m Instructions for updating:
[2m[36m(pid=26727)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26727)[0m LSTM is selected.
[2m[36m(pid=26553)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26553)[0m Instructions for updating:
[2m[36m(pid=26553)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26679)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26679)[0m Instructions for updating:
[2m[36m(pid=26679)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26553)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26553)[0m Instructions for updating:
[2m[36m(pid=26553)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=26679)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26679)[0m Instructions for updating:
[2m[36m(pid=26679)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=26727)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26727)[0m Instructions for updating:
[2m[36m(pid=26727)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 96 ({'TERMINATED': 14, 'ERROR': 72, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 66 not shown
 - train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_84_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-293a28olgz/error_2021-01-17_12-39-48.txt
 - train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_85_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-32rqe0blkx/error_2021-01-17_12-39-52.txt
 - train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_86_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-33905hk414/error_2021-01-17_12-39-55.txt
RUNNING trials:
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:39:56,669	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=25252, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:56,672	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=25252)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=25252)[0m 
[2m[36m(pid=25252)[0m Stack (most recent call first):
[2m[36m(pid=26553)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26553)[0m 2021-01-17 12:39:57.295511: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26553)[0m 2021-01-17 12:39:57.305185: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26553)[0m 2021-01-17 12:39:57.308943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f01910ce5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26553)[0m 2021-01-17 12:39:57.308985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=26679)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26679)[0m 2021-01-17 12:39:57.296117: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26679)[0m 2021-01-17 12:39:57.305984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26679)[0m 2021-01-17 12:39:57.309509: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f24450cea90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26679)[0m 2021-01-17 12:39:57.309539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=26727)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26727)[0m 2021-01-17 12:39:57.382690: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26727)[0m 2021-01-17 12:39:57.393898: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26727)[0m 2021-01-17 12:39:57.397293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4a690b4fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26727)[0m 2021-01-17 12:39:57.397333: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=26555)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26555)[0m   agg_primitives: ['count']
[2m[36m(pid=26555)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26555)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26555)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26555)[0m Instructions for updating:
[2m[36m(pid=26555)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26555)[0m LSTM is selected.
[2m[36m(pid=25627)[0m 2021-01-17 12:39:58,738	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=25627)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25627)[0m 
[2m[36m(pid=25627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25627)[0m 
[2m[36m(pid=25627)[0m Traceback (most recent call last):
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25627)[0m     self._entrypoint()
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25627)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25627)[0m     output = train_func(config, reporter)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25627)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25627)[0m     config=config)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=25627)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=25627)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=25627)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=25627)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25627)[0m Exception in thread Thread-1:
[2m[36m(pid=25627)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25627)[0m 
[2m[36m(pid=25627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25627)[0m 
[2m[36m(pid=25627)[0m Traceback (most recent call last):
[2m[36m(pid=25627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=26555)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26555)[0m Instructions for updating:
[2m[36m(pid=26555)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:39:59,752	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=25627, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:39:59,757	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=26555)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26555)[0m 2021-01-17 12:40:00.328405: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26555)[0m 2021-01-17 12:40:00.341607: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26555)[0m 2021-01-17 12:40:00.347446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efe210e8a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26555)[0m 2021-01-17 12:40:00.347496: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=25632)[0m 2021-01-17 12:40:01,158	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=25632)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25632)[0m 
[2m[36m(pid=25632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25632)[0m 
[2m[36m(pid=25632)[0m Traceback (most recent call last):
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25632)[0m     self._entrypoint()
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25632)[0m     output = train_func(config, reporter)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25632)[0m     config=config)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=25632)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=25632)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=25632)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=25632)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25632)[0m Exception in thread Thread-1:
[2m[36m(pid=25632)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25632)[0m 
[2m[36m(pid=25632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25632)[0m 
[2m[36m(pid=25632)[0m Traceback (most recent call last):
[2m[36m(pid=25632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=26554)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26554)[0m   agg_primitives: ['count']
[2m[36m(pid=26554)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26554)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26723)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=26723)[0m   agg_primitives: ['count']
[2m[36m(pid=26723)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=26723)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=26554)[0m LSTM is selected.
[2m[36m(pid=26723)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26723)[0m Instructions for updating:
[2m[36m(pid=26723)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=26723)[0m LSTM is selected.
[2m[36m(pid=26554)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=26554)[0m Instructions for updating:
[2m[36m(pid=26554)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=25631)[0m 2021-01-17 12:40:02,016	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=25631)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25631)[0m 
[2m[36m(pid=25631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25631)[0m 
[2m[36m(pid=25631)[0m Traceback (most recent call last):
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25631)[0m     self._entrypoint()
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25631)[0m     output = train_func(config, reporter)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25631)[0m     config=config)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=25631)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=25631)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=25631)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=25631)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25631)[0m Exception in thread Thread-1:
[2m[36m(pid=25631)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25631)[0m 
[2m[36m(pid=25631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25631)[0m 
[2m[36m(pid=25631)[0m Traceback (most recent call last):
[2m[36m(pid=25631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=26554)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26554)[0m Instructions for updating:
[2m[36m(pid=26554)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=26723)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=26723)[0m Instructions for updating:
[2m[36m(pid=26723)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2021-01-17 12:40:02,364	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=25632, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:02,368	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 98 ({'TERMINATED': 14, 'ERROR': 75, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 69 not shown
 - train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0064912,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_87_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-35793uj893/error_2021-01-17_12-39-56.txt
 - train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_88_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-41_njpjyn5/error_2021-01-17_12-39-59.txt
 - train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-44qva8qmu3/error_2021-01-17_12-40-02.txt
RUNNING trials:
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_97_batch_size_log=5.0843,bayes_feature_DAY(datetime)=0.48984,bayes_feature_HOUR(datetime)=0.46581,bayes_feature_IS_AWAKE(datetime)=0.98543,bayes_feature_IS_BUSY_HOURS(datetime)=0.53667,bayes_feature_IS_WEEKEND(datetime)=0.6837,bayes_feature_MONTH(datetime)=0.33296,bayes_feature_WEEKDAY(datetime)=0.91214,dropout_1=0.42773,dropout_2=0.38935,epochs=5,lr=0.0038261,lstm_1_units_float=127.87,lstm_2_units_float=127.17,past_seq_len=2:	RUNNING
 - train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=26723)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26723)[0m 2021-01-17 12:40:03.465464: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26723)[0m 2021-01-17 12:40:03.476564: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26723)[0m 2021-01-17 12:40:03.481833: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb02d0e9220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26723)[0m 2021-01-17 12:40:03.481885: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=26554)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=26554)[0m 2021-01-17 12:40:03.542716: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=26554)[0m 2021-01-17 12:40:03.553168: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=26554)[0m 2021-01-17 12:40:03.557468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2fc90e8620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=26554)[0m 2021-01-17 12:40:03.557524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-17 12:40:03,948	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=25631, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:03,951	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=25253)[0m 2021-01-17 12:40:05,279	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=25253)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25253)[0m 
[2m[36m(pid=25253)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25253)[0m 
[2m[36m(pid=25253)[0m Traceback (most recent call last):
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=25253)[0m     self._entrypoint()
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=25253)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=25253)[0m     output = train_func(config, reporter)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=25253)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=25253)[0m     config=config)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=25253)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=25253)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=25253)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=25253)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25253)[0m Exception in thread Thread-1:
[2m[36m(pid=25253)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=25253)[0m 
[2m[36m(pid=25253)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=25253)[0m 
[2m[36m(pid=25253)[0m Traceback (most recent call last):
[2m[36m(pid=25253)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-17 12:40:06,400	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=25253, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:06,406	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 101 ({'TERMINATED': 14, 'ERROR': 77, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 71 not shown
 - train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_89_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-44qva8qmu3/error_2021-01-17_12-40-02.txt
 - train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_90_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-45xmy3ahi7/error_2021-01-17_12-40-03.txt
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-474wxq5qr0/error_2021-01-17_12-40-06.txt
RUNNING trials:
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

[2m[36m(pid=26679)[0m 2021-01-17 12:40:09,057	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=26679)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26679)[0m 
[2m[36m(pid=26679)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26679)[0m 
[2m[36m(pid=26679)[0m Traceback (most recent call last):
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=26679)[0m     self._entrypoint()
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=26679)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=26679)[0m     output = train_func(config, reporter)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=26679)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=26679)[0m     config=config)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=26679)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=26679)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=26679)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=26679)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26679)[0m Exception in thread Thread-1:
[2m[36m(pid=26679)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26679)[0m 
[2m[36m(pid=26679)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26679)[0m 
[2m[36m(pid=26679)[0m Traceback (most recent call last):
[2m[36m(pid=26679)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=26553)[0m 2021-01-17 12:40:09,552	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=26553)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26553)[0m 
[2m[36m(pid=26553)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26553)[0m 
[2m[36m(pid=26553)[0m Traceback (most recent call last):
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=26553)[0m     self._entrypoint()
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=26553)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=26553)[0m     output = train_func(config, reporter)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=26553)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=26553)[0m     config=config)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=26553)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=26553)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=26553)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=26553)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26553)[0m Exception in thread Thread-1:
[2m[36m(pid=26553)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26553)[0m 
[2m[36m(pid=26553)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26553)[0m 
[2m[36m(pid=26553)[0m Traceback (most recent call last):
[2m[36m(pid=26553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
[2m[36m(pid=26727)[0m 2021-01-17 12:40:09,534	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=26727)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26727)[0m 
[2m[36m(pid=26727)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26727)[0m 
[2m[36m(pid=26727)[0m Traceback (most recent call last):
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=26727)[0m     self._entrypoint()
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=26727)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=26727)[0m     output = train_func(config, reporter)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=26727)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=26727)[0m     config=config)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=26727)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=26727)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=26727)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=26727)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26727)[0m Exception in thread Thread-1:
[2m[36m(pid=26727)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=26727)[0m 
[2m[36m(pid=26727)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=26727)[0m 
[2m[36m(pid=26727)[0m Traceback (most recent call last):
[2m[36m(pid=26727)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fun
2021-01-17 12:40:10,110	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=26679, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:10,115	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2021-01-17 12:40:11,973	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=26727, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:11,976	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 103 ({'TERMINATED': 14, 'ERROR': 79, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 73 not shown
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_91_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-474wxq5qr0/error_2021-01-17_12-40-06.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-49nrcayblz/error_2021-01-17_12-40-10.txt
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-51f9mcdjdm/error_2021-01-17_12-40-11.txt
RUNNING trials:
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_101_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

2021-01-17 12:40:13,106	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=26553, host=r18c06.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2021-01-17 12:40:13,110	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 13.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 104 ({'TERMINATED': 14, 'ERROR': 80, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 74 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-48qqz0tg2s/error_2021-01-17_12-40-13.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-49nrcayblz/error_2021-01-17_12-40-10.txt
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-51f9mcdjdm/error_2021-01-17_12-40-11.txt
RUNNING trials:
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26555], 24 s, 2 iter
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26723], 13 s, 1 iter
 - train_func_97_batch_size_log=5.0843,bayes_feature_DAY(datetime)=0.48984,bayes_feature_HOUR(datetime)=0.46581,bayes_feature_IS_AWAKE(datetime)=0.98543,bayes_feature_IS_BUSY_HOURS(datetime)=0.53667,bayes_feature_IS_WEEKEND(datetime)=0.6837,bayes_feature_MONTH(datetime)=0.33296,bayes_feature_WEEKDAY(datetime)=0.91214,dropout_1=0.42773,dropout_2=0.38935,epochs=5,lr=0.0038261,lstm_1_units_float=127.87,lstm_2_units_float=127.17,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26554], 14 s, 1 iter
  ... 4 not shown
 - train_func_102_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 8 not shown
 - train_func_14_batch_size_log=7.4655,bayes_feature_DAY(datetime)=0.8154,bayes_feature_HOUR(datetime)=0.37975,bayes_feature_IS_AWAKE(datetime)=0.77873,bayes_feature_IS_BUSY_HOURS(datetime)=0.7045,bayes_feature_IS_WEEKEND(datetime)=0.64252,bayes_feature_MONTH(datetime)=0.85346,bayes_feature_WEEKDAY(datetime)=0.87071,dropout_1=0.47748,dropout_2=0.46091,epochs=5,lr=0.0078617,lstm_1_units_float=18.65,lstm_2_units_float=43.774,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8797], 16 s, 5 iter
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 105 ({'TERMINATED': 15, 'ERROR': 80, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 74 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-48qqz0tg2s/error_2021-01-17_12-40-13.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-49nrcayblz/error_2021-01-17_12-40-10.txt
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-51f9mcdjdm/error_2021-01-17_12-40-11.txt
RUNNING trials:
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26555], 31 s, 3 iter
 - train_func_97_batch_size_log=5.0843,bayes_feature_DAY(datetime)=0.48984,bayes_feature_HOUR(datetime)=0.46581,bayes_feature_IS_AWAKE(datetime)=0.98543,bayes_feature_IS_BUSY_HOURS(datetime)=0.53667,bayes_feature_IS_WEEKEND(datetime)=0.6837,bayes_feature_MONTH(datetime)=0.33296,bayes_feature_WEEKDAY(datetime)=0.91214,dropout_1=0.42773,dropout_2=0.38935,epochs=5,lr=0.0038261,lstm_1_units_float=127.87,lstm_2_units_float=127.17,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26554], 22 s, 2 iter
 - train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=71.608,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 9 not shown
 - train_func_15_batch_size_log=8.3907,bayes_feature_DAY(datetime)=0.401,bayes_feature_HOUR(datetime)=0.33002,bayes_feature_IS_AWAKE(datetime)=0.76197,bayes_feature_IS_BUSY_HOURS(datetime)=0.38887,bayes_feature_IS_WEEKEND(datetime)=0.59416,bayes_feature_MONTH(datetime)=0.92469,bayes_feature_WEEKDAY(datetime)=0.80565,dropout_1=0.23479,dropout_2=0.37419,epochs=5,lr=0.0068073,lstm_1_units_float=8.5801,lstm_2_units_float=127.34,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=8798], 13 s, 5 iter
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26723], 22 s, 2 iter

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 105 ({'TERMINATED': 16, 'ERROR': 80, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 74 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-48qqz0tg2s/error_2021-01-17_12-40-13.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-49nrcayblz/error_2021-01-17_12-40-10.txt
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-51f9mcdjdm/error_2021-01-17_12-40-11.txt
RUNNING trials:
 - train_func_97_batch_size_log=5.0843,bayes_feature_DAY(datetime)=0.48984,bayes_feature_HOUR(datetime)=0.46581,bayes_feature_IS_AWAKE(datetime)=0.98543,bayes_feature_IS_BUSY_HOURS(datetime)=0.53667,bayes_feature_IS_WEEKEND(datetime)=0.6837,bayes_feature_MONTH(datetime)=0.33296,bayes_feature_WEEKDAY(datetime)=0.91214,dropout_1=0.42773,dropout_2=0.38935,epochs=5,lr=0.0038261,lstm_1_units_float=127.87,lstm_2_units_float=127.17,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=26554], 31 s, 3 iter
 - train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_103_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=71.608,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 10 not shown
 - train_func_17_batch_size_log=9.7272,bayes_feature_DAY(datetime)=0.47429,bayes_feature_HOUR(datetime)=0.88093,bayes_feature_IS_AWAKE(datetime)=0.73418,bayes_feature_IS_BUSY_HOURS(datetime)=0.46668,bayes_feature_IS_WEEKEND(datetime)=0.30313,bayes_feature_MONTH(datetime)=0.83785,bayes_feature_WEEKDAY(datetime)=0.48759,dropout_1=0.37141,dropout_2=0.46446,epochs=5,lr=0.0038511,lstm_1_units_float=11.418,lstm_2_units_float=87.378,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7039], 12 s, 5 iter
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26555], 39 s, 4 iter
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26723], 22 s, 2 iter

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 12.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_tskax4i3/automl
Number of trials: 106 ({'TERMINATED': 17, 'ERROR': 80, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE(datetime)=0.59211,bayes_feature_IS_BUSY_HOURS(datetime)=0.69108,bayes_feature_IS_WEEKEND(datetime)=0.39827,bayes_feature_MONTH(datetime)=0.43867,bayes_feature_WEEKDAY(datetime)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(datetime)=0.31917,bayes_feature_HOUR(datetime)=0.76933,bayes_feature_IS_AWAKE_2021-01-17_12-36-41bjqv5tu5/error_2021-01-17_12-36-56.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE(datetime)=0.5857,bayes_feature_IS_BUSY_HOURS(datetime)=0.46592,bayes_feature_IS_WEEKEND(datetime)=0.93237,bayes_feature_MONTH(datetime)=0.70158,bayes_feature_WEEKDAY(datetime)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(datetime)=0.61494,bayes_feature_HOUR(datetime)=0.70487,bayes_feature_IS_AWAKE_2021-01-17_12-36-41avbdtykf/error_2021-01-17_12-36-56.txt
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-37-02uqbquuwo/error_2021-01-17_12-37-53.txt, [4 CPUs, 0 GPUs], [pid=8795], 31 s, 3 iter
  ... 74 not shown
 - train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_92_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-48qqz0tg2s/error_2021-01-17_12-40-13.txt
 - train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_93_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-49nrcayblz/error_2021-01-17_12-40-10.txt
 - train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_tskax4i3/automl/train_func_94_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)_2021-01-17_12-39-51f9mcdjdm/error_2021-01-17_12-40-11.txt
RUNNING trials:
 - train_func_98_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_99_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_100_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_104_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_105_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=71.608,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_106_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=1.0,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.0030077,lstm_1_units_float=71.741,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(datetime)=0.80423,bayes_feature_HOUR(datetime)=0.30008,bayes_feature_IS_AWAKE(datetime)=0.51163,bayes_feature_IS_BUSY_HOURS(datetime)=0.40273,bayes_feature_IS_WEEKEND(datetime)=0.36464,bayes_feature_MONTH(datetime)=0.43038,bayes_feature_WEEKDAY(datetime)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7030], 18 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(datetime)=0.32734,bayes_feature_HOUR(datetime)=0.41888,bayes_feature_IS_AWAKE(datetime)=0.9147,bayes_feature_IS_BUSY_HOURS(datetime)=0.36884,bayes_feature_IS_WEEKEND(datetime)=0.59478,bayes_feature_MONTH(datetime)=0.97052,bayes_feature_WEEKDAY(datetime)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7020], 38 s, 5 iter
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(datetime)=0.9922,bayes_feature_HOUR(datetime)=0.82372,bayes_feature_IS_AWAKE(datetime)=0.49631,bayes_feature_IS_BUSY_HOURS(datetime)=0.8525,bayes_feature_IS_WEEKEND(datetime)=0.37226,bayes_feature_MONTH(datetime)=0.61353,bayes_feature_WEEKDAY(datetime)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=7013], 11 s, 5 iter
  ... 11 not shown
 - train_func_95_batch_size_log=5.0,bayes_feature_DAY(datetime)=1.0,bayes_feature_HOUR(datetime)=0.3,bayes_feature_IS_AWAKE(datetime)=0.3,bayes_feature_IS_BUSY_HOURS(datetime)=1.0,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26555], 39 s, 4 iter
 - train_func_96_batch_size_log=5.0,bayes_feature_DAY(datetime)=0.3,bayes_feature_HOUR(datetime)=1.0,bayes_feature_IS_AWAKE(datetime)=1.0,bayes_feature_IS_BUSY_HOURS(datetime)=0.3,bayes_feature_IS_WEEKEND(datetime)=0.3,bayes_feature_MONTH(datetime)=1.0,bayes_feature_WEEKDAY(datetime)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26723], 22 s, 2 iter
 - train_func_97_batch_size_log=5.0843,bayes_feature_DAY(datetime)=0.48984,bayes_feature_HOUR(datetime)=0.46581,bayes_feature_IS_AWAKE(datetime)=0.98543,bayes_feature_IS_BUSY_HOURS(datetime)=0.53667,bayes_feature_IS_WEEKEND(datetime)=0.6837,bayes_feature_MONTH(datetime)=0.33296,bayes_feature_WEEKDAY(datetime)=0.91214,dropout_1=0.42773,dropout_2=0.38935,epochs=5,lr=0.0038261,lstm_1_units_float=127.87,lstm_2_units_float=127.17,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=26554], 46 s, 5 iter

2021-01-17 14:00:01,825	ERROR worker.py:1672 -- The reporter on node r18c06.bullx failed with the following error:
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/36178/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 176, in run
    self.perform_iteration()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 165, in perform_iteration
    stats = self.get_all_stats()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 156, in get_all_stats
    "workers": self.get_workers(),
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in get_workers
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in <listcomp>
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/__init__.py", line 634, in name
    name = self._proc.name()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1610, in name
    name = self._parse_stat_file()['name']
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=36178)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 218, in <module>
    reporter.run()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 178, in run
    traceback.print_exc()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 105, in print_exception
    print(line, file=file, end="")
OSError: [Errno 28] No space left on device

