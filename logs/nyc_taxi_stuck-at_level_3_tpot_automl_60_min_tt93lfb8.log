30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   9%|▉         | 9/100 [00:38<06:31,  4.31s/pipeline]Optimization Progress:  89%|████████▉ | 89/100 [00:45<00:33,  3.04s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:45<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:46<00:00,  3.04s/pipeline]Optimization Progress: 100%|██████████| 100/100 [00:46<00:00,  2.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:47<00:00,  2.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 100/100 [00:47<00:00,  2.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:48<00:00,  2.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:48<00:00,  2.17s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [00:51<03:15,  2.01s/pipeline]Optimization Progress:  52%|█████▏    | 104/200 [01:14<13:08,  8.21s/pipeline]Optimization Progress:  92%|█████████▏| 184/200 [01:17<01:32,  5.76s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-1003709729.60485	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-891130810.6719137	GradientBoostingRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.25), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:17<00:00,  5.76s/pipeline]Optimization Progress: 100%|██████████| 200/200 [01:17<00:00,  4.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 200/200 [01:18<00:00,  4.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:19<00:00,  4.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [01:20<00:00,  4.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 200/200 [01:24<00:00,  4.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:25<00:00,  4.04s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 201/300 [01:25<06:40,  4.04s/pipeline]Optimization Progress:  67%|██████▋   | 202/300 [01:25<06:34,  4.03s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [01:25<06:34,  4.03s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 203/300 [01:25<06:30,  4.03s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 204/300 [01:25<06:26,  4.03s/pipeline]Optimization Progress:  69%|██████▊   | 206/300 [02:16<10:26,  6.66s/pipeline]Optimization Progress:  95%|█████████▌| 286/300 [02:21<01:05,  4.68s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1003709729.60485	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-891130810.6719137	GradientBoostingRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.25), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [02:23<00:00,  4.68s/pipeline]Optimization Progress: 100%|██████████| 300/300 [02:23<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [02:24<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:26<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [02:27<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [02:27<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [02:28<00:00,  3.32s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [02:29<06:43,  4.07s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  75%|███████▌  | 301/400 [02:29<06:43,  4.07s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [03:20<17:06, 10.58s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [03:23<02:06,  7.42s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1002574691.7975286	ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=2, ExtraTreesRegressor__n_estimators=100)
-2	-891130810.6719137	GradientBoostingRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.25), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:23<00:00,  7.42s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:23<00:00,  7.42s/pipeline]Optimization Progress: 100%|██████████| 400/400 [03:23<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:25<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:28<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [03:29<00:00,  5.21s/pipeline]Optimization Progress:  81%|████████  | 403/500 [03:30<06:58,  4.32s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 403/500 [03:30<06:58,  4.32s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 404/500 [03:30<06:54,  4.32s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 405/500 [03:30<06:50,  4.32s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  81%|████████  | 406/500 [03:30<06:46,  4.32s/pipeline]Optimization Progress:  82%|████████▏ | 408/500 [04:24<09:36,  6.27s/pipeline]Optimization Progress:  98%|█████████▊| 488/500 [05:00<00:54,  4.52s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1001081588.9577694	ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-2	-891130810.6719137	GradientBoostingRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.25), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 500/500 [05:01<00:00,  4.52s/pipeline]Optimization Progress: 100%|██████████| 500/500 [05:01<00:00,  3.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [05:04<00:00,  3.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 500/500 [05:04<00:00,  3.18s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [05:07<04:17,  2.69s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 504/600 [05:07<04:17,  2.69s/pipeline]Optimization Progress:  84%|████████▍ | 506/600 [06:07<17:03, 10.89s/pipeline]Optimization Progress:  98%|█████████▊| 586/600 [06:10<01:46,  7.64s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1001081588.9577694	ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-2	-891130810.6719137	GradientBoostingRegressor(RBFSampler(input_matrix, RBFSampler__gamma=0.25), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [06:11<00:00,  7.64s/pipeline]Optimization Progress: 100%|██████████| 600/600 [06:11<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [06:11<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [06:11<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [06:12<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 600/600 [06:13<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [06:13<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [06:51:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f9a8c531dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f9a8c642669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f9a8c64ff8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f9a8c636cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f9a8c523f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f909a2de9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f909a2de067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f909a2f627e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f909a2f6cb4]

.
Optimization Progress: 100%|██████████| 600/600 [06:14<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [06:15<00:00,  5.37s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [06:15<00:00,  5.37s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [06:18<08:56,  5.37s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 601/700 [06:18<08:51,  5.37s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [06:18<07:50,  4.80s/pipeline]Optimization Progress:  86%|████████▌ | 603/700 [07:13<32:31, 20.11s/pipeline]Optimization Progress:  98%|█████████▊| 683/700 [07:16<03:59, 14.09s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-999217505.5796554	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-747253805.8236958	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [07:18<00:00, 14.09s/pipeline]Optimization Progress: 100%|██████████| 700/700 [07:18<00:00,  9.90s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 700/700 [07:22<00:00,  9.90s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [07:23<00:00,  9.90s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [07:24<00:00,  9.90s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [07:24<12:42,  7.78s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [07:33<13:31,  8.37s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  98%|█████████▊| 783/800 [12:48<01:59,  7.04s/pipeline]                                                                              Skipped pipeline #797 due to time out. Continuing to the next pipeline.
Optimization Progress: 100%|█████████▉| 797/800 [12:48<00:21,  7.04s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-995399245.2206459	ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=18, ExtraTreesRegressor__min_samples_split=2, ExtraTreesRegressor__n_estimators=100)
-2	-747253805.8236958	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=1, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [12:50,  7.04s/pipeline]Optimization Progress: 801pipeline [12:50,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 801pipeline [12:51,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 801pipeline [12:51,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [12:53,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 801pipeline [12:55,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [12:56,  4.95s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [12:57,  4.95s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [12:58<09:38,  5.90s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [13:52<32:50, 20.31s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [13:55<04:01, 14.23s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-836338669.1862586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [14:01, 14.23s/pipeline]Optimization Progress: 901pipeline [14:01, 10.07s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [14:06, 10.07s/pipeline]Optimization Progress:  90%|█████████ | 904/1000 [14:06<12:04,  7.54s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 904/1000 [14:06<12:04,  7.54s/pipeline]Optimization Progress:  91%|█████████ | 906/1000 [15:04<21:53, 13.98s/pipeline]Optimization Progress:  99%|█████████▊| 986/1000 [15:15<02:17,  9.83s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-836338669.1862586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 1001pipeline [15:18,  9.83s/pipeline]Optimization Progress: 1001pipeline [15:18,  6.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 1001pipeline [15:24,  6.93s/pipeline]Optimization Progress:  91%|█████████ | 1003/1100 [15:27<09:56,  6.15s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [16:20<32:39, 20.41s/pipeline]Optimization Progress:  99%|█████████▊| 1084/1100 [16:26<03:48, 14.31s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-836338669.1862586	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [16:27, 14.31s/pipeline]Optimization Progress: 1101pipeline [16:27, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [16:29, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 1101pipeline [16:29, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [16:31, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1101pipeline [16:32, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [16:35, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [16:37, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [07:02:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f9a8c531dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f9a8c642669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f9a8c64ff8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f9a8c636cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f9a8c523f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f909a2de9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f909a2de067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f909a2f627e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f909a2f6cb4]

.
Optimization Progress: 1101pipeline [16:37, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [16:38, 10.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1101pipeline [16:38, 10.03s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [16:38<13:03,  8.16s/pipeline]Optimization Progress:  92%|█████████▏| 1105/1200 [16:43<11:22,  7.19s/pipeline]Optimization Progress:  99%|█████████▉| 1185/1200 [17:14<01:17,  5.14s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-834664063.6130949	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [17:15,  5.14s/pipeline]Optimization Progress: 1201pipeline [17:15,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 1201pipeline [17:16,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 1201pipeline [17:17,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [17:22,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1201pipeline [17:23,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [17:24,  3.62s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1201pipeline [17:24,  3.62s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [17:24<08:53,  5.44s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [22:24<2:31:38, 93.80s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  99%|█████████▊| 1283/1300 [22:28<18:36, 65.68s/pipeline]  
Generation 12 - Current Pareto front scores:
-1	-834664063.6130949	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [22:29, 65.68s/pipeline]Optimization Progress: 1301pipeline [22:29, 45.99s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [22:30, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 1301pipeline [22:30, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 1301pipeline [22:30, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1301pipeline [22:32, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1301pipeline [22:32, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [22:33, 45.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1301pipeline [22:34, 45.99s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [22:38<52:53, 33.06s/pipeline]Optimization Progress:  93%|█████████▎| 1305/1400 [22:50<42:39, 26.95s/pipeline]Optimization Progress:  99%|█████████▉| 1385/1400 [22:52<04:43, 18.87s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-834350217.3280107	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [22:52, 18.87s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [22:57, 18.87s/pipeline]Optimization Progress: 1401pipeline [22:57, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1401pipeline [22:57, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [22:58, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 1401pipeline [22:58, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 1401pipeline [22:59, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [23:00, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1401pipeline [23:00, 13.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [23:01, 13.29s/pipeline]Optimization Progress:  94%|█████████▎| 1404/1500 [23:02<15:48,  9.88s/pipeline]Optimization Progress:  94%|█████████▎| 1405/1500 [23:35<26:36, 16.80s/pipeline]Optimization Progress:  99%|█████████▉| 1485/1500 [23:47<02:57, 11.81s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-834350217.3280107	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1501pipeline [23:50, 11.81s/pipeline]Optimization Progress: 1501pipeline [23:50,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [23:50,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [23:50,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1501pipeline [23:51,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 1501pipeline [23:54,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [23:55,  8.33s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [23:56<12:15,  7.51s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [24:48<33:38, 20.81s/pipeline]Optimization Progress:  99%|█████████▉| 1583/1600 [24:53<04:07, 14.58s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-834350217.3280107	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1601pipeline [24:53, 14.58s/pipeline]Optimization Progress: 1601pipeline [24:53, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 1601pipeline [24:54, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 1601pipeline [24:54, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:55, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:57, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:57, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:57, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:57, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:57, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [24:58, 10.22s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 1601pipeline [24:59, 10.22s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [25:00<13:14,  8.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1603/1700 [25:00<13:14,  8.19s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1604/1700 [25:00<13:06,  8.19s/pipeline]Optimization Progress:  94%|█████████▍| 1606/1700 [25:13<10:58,  7.00s/pipeline]Optimization Progress:  99%|█████████▉| 1686/1700 [25:18<01:08,  4.92s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-834275347.1561959	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.5)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [25:19,  4.92s/pipeline]Optimization Progress: 1701pipeline [25:19,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [25:20,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [25:20,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [25:22,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [25:23,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [25:25,  3.47s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1701pipeline [25:25,  3.47s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [25:27<05:44,  3.55s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▍| 1703/1800 [25:27<05:44,  3.55s/pipeline]Optimization Progress:  95%|█████████▍| 1705/1800 [25:33<05:32,  3.50s/pipeline]Optimization Progress:  99%|█████████▉| 1785/1800 [25:36<00:36,  2.46s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-833798829.4454138	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1801pipeline [25:37,  2.46s/pipeline]Optimization Progress: 1801pipeline [25:37,  1.74s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1801pipeline [25:37,  1.74s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 1801pipeline [25:40,  1.74s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1801pipeline [25:42,  1.74s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1801pipeline [25:44,  1.74s/pipeline]Optimization Progress:  95%|█████████▍| 1804/1900 [25:45<03:16,  2.05s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [26:04<10:59,  6.94s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [26:09<01:13,  4.88s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-833798829.4454138	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:11,  4.88s/pipeline]Optimization Progress: 1901pipeline [26:11,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:11,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:13,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:14,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [26:15,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:15,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:15,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [26:17,  3.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1901pipeline [26:18,  3.45s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [26:18<07:27,  4.57s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1902/2000 [26:18<07:27,  4.57s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▌| 1903/2000 [26:18<07:23,  4.57s/pipeline]Optimization Progress:  95%|█████████▌| 1905/2000 [26:53<10:33,  6.67s/pipeline]Optimization Progress:  99%|█████████▉| 1985/2000 [26:56<01:10,  4.68s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-833423342.6943899	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [26:58,  4.68s/pipeline]Optimization Progress: 2001pipeline [26:58,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2001pipeline [26:59,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [27:00,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [27:01,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 2001pipeline [27:01,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2001pipeline [27:03,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2001pipeline [27:03,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2001pipeline [27:04,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2001pipeline [27:04,  3.33s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [27:06<07:41,  4.71s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [27:43<22:56, 14.19s/pipeline]Optimization Progress:  99%|█████████▉| 2083/2100 [27:54<02:49,  9.98s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-832723529.076579	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [27:56,  9.98s/pipeline]Optimization Progress: 2101pipeline [27:56,  7.02s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [27:59,  7.02s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 2101pipeline [28:00,  7.02s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2101pipeline [28:01,  7.02s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [28:03<09:44,  6.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2103/2200 [28:03<09:44,  6.02s/pipeline]Optimization Progress:  96%|█████████▌| 2105/2200 [29:14<23:28, 14.83s/pipeline]Optimization Progress:  99%|█████████▉| 2185/2200 [29:18<02:35, 10.40s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-832723529.076579	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [29:19, 10.40s/pipeline]Optimization Progress: 2201pipeline [29:19,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [29:19,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [29:19,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [29:20,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [29:22,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 2201pipeline [29:23,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [29:25,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 2201pipeline [29:28,  7.29s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2201pipeline [29:28,  7.29s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [29:30<12:01,  7.29s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [29:30<11:53,  7.29s/pipeline]Optimization Progress:  96%|█████████▌| 2203/2300 [30:18<22:36, 13.98s/pipeline]Optimization Progress:  99%|█████████▉| 2283/2300 [31:31<02:51, 10.06s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-832723529.076579	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2301pipeline [31:34, 10.06s/pipeline]Optimization Progress: 2301pipeline [31:34,  7.10s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 2301pipeline [31:35,  7.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [31:38,  7.10s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [31:40,  7.10s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [31:42<09:07,  5.71s/pipeline]Optimization Progress:  96%|█████████▌| 2305/2400 [32:02<15:49,  9.99s/pipeline]Optimization Progress:  99%|█████████▉| 2385/2400 [32:07<01:45,  7.01s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-832723529.076579	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [32:09,  7.01s/pipeline]Optimization Progress: 2401pipeline [32:09,  4.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 2401pipeline [32:09,  4.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [32:09,  4.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [32:12,  4.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2401pipeline [32:16,  4.95s/pipeline]Optimization Progress:  96%|█████████▌| 2402/2500 [32:46<23:42, 14.51s/pipeline]Optimization Progress:  99%|█████████▉| 2482/2500 [32:52<03:03, 10.18s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 2501pipeline [32:55, 10.18s/pipeline]Optimization Progress: 2501pipeline [32:55,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [32:55,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [32:56,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 2501pipeline [32:57,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [32:58,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [32:58,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [32:58,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [32:59,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 2501pipeline [33:00,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [33:02,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2501pipeline [33:04,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 2501pipeline [33:04,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [33:05,  7.17s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2501pipeline [33:05,  7.17s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [33:05<13:21,  8.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2502/2600 [33:05<13:21,  8.18s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [34:36<30:50, 19.27s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [34:39<03:36, 13.50s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [34:41, 13.50s/pipeline]Optimization Progress: 2601pipeline [34:41,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [34:42,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [34:44,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [34:49,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [34:50,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2601pipeline [34:52,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 2601pipeline [34:52,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=3 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=4 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=5 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2601pipeline [34:54,  9.50s/pipeline]Optimization Progress:  96%|█████████▋| 2605/2700 [34:54<12:03,  7.61s/pipeline]Optimization Progress:  97%|█████████▋| 2606/2700 [35:43<31:06, 19.86s/pipeline]Optimization Progress:  99%|█████████▉| 2686/2700 [35:47<03:14, 13.92s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 2701pipeline [35:51, 13.92s/pipeline]Optimization Progress: 2701pipeline [35:51,  9.81s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [35:55,  9.81s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [35:55,  9.81s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [36:00,  9.81s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [36:02<13:53,  8.59s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [37:13<43:15, 27.04s/pipeline]Optimization Progress:  99%|█████████▉| 2784/2800 [37:49<05:04, 19.06s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [37:49, 19.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [37:49, 19.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 2801pipeline [37:52, 19.06s/pipeline]Optimization Progress: 2801pipeline [37:52, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [37:53, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 2801pipeline [37:54, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [37:55, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2801pipeline [37:59, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2801pipeline [37:59, 13.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [38:00, 13.40s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [38:04<21:18, 13.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [38:04<21:18, 13.05s/pipeline]Optimization Progress:  97%|█████████▋| 2804/2900 [38:24<19:30, 12.20s/pipeline]Optimization Progress:  99%|█████████▉| 2884/2900 [38:32<02:17,  8.57s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [38:39,  8.57s/pipeline]Optimization Progress: 2901pipeline [38:39,  6.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2901pipeline [38:40,  6.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 2901pipeline [38:40,  6.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 2901pipeline [38:42,  6.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [38:48,  6.12s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [38:49<11:56,  7.32s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [40:23<53:34, 33.14s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [40:28<06:34, 23.22s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [40:28, 23.22s/pipeline]Optimization Progress: 3001pipeline [40:28, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 3001pipeline [40:31, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3001pipeline [40:32, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [40:35, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3001pipeline [40:35, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 3001pipeline [40:37, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 3001pipeline [40:37, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [40:38, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [40:39, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3001pipeline [40:40, 16.26s/pipeline]Optimization Progress: 3001pipeline [40:40, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 3001pipeline [40:40, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [40:41, 16.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3001pipeline [40:41, 16.26s/pipeline]Optimization Progress:  97%|█████████▋| 3005/3100 [40:42<19:36, 12.39s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3005/3100 [40:42<19:36, 12.39s/pipeline]Optimization Progress:  97%|█████████▋| 3007/3100 [41:33<25:27, 16.42s/pipeline]Optimization Progress: 100%|█████████▉| 3087/3100 [41:43<02:29, 11.53s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [41:46, 11.53s/pipeline]Optimization Progress: 3101pipeline [41:46,  8.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 3101pipeline [41:48,  8.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3101pipeline [41:49,  8.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 3101pipeline [41:49,  8.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3101pipeline [41:52,  8.13s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3101pipeline [41:53,  8.13s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 3101pipeline [41:54,  8.13s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [41:59<12:27,  7.71s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [41:59<12:27,  7.71s/pipeline]Optimization Progress:  97%|█████████▋| 3105/3200 [42:51<20:54, 13.20s/pipeline]Optimization Progress: 100%|█████████▉| 3185/3200 [43:18<02:20,  9.34s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [43:18,  9.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [43:20,  9.34s/pipeline]Optimization Progress: 3201pipeline [43:20,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 3201pipeline [43:21,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [43:24,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 3201pipeline [43:24,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..
Optimization Progress: 3201pipeline [43:24,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [43:26,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 3201pipeline [43:28,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [43:31,  6.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 3201pipeline [43:33,  6.57s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [44:47<50:12, 30.74s/pipeline]Optimization Progress:  99%|█████████▉| 3282/3300 [46:12<06:33, 21.84s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [46:12, 21.84s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3301pipeline [46:19, 21.84s/pipeline]Optimization Progress: 3301pipeline [46:19, 15.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [46:21, 15.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 3301pipeline [46:23, 15.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 3301pipeline [46:25, 15.40s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [46:26<19:06, 11.82s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [46:55<27:03, 16.91s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [47:03<03:09, 11.87s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [47:05, 11.87s/pipeline]Optimization Progress: 3401pipeline [47:05,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3401pipeline [47:10,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3401pipeline [47:11,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3401pipeline [47:13,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [47:13,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [47:15,  8.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3401pipeline [47:16,  8.33s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [47:19<12:53,  7.97s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3403/3500 [47:19<12:53,  7.97s/pipeline]Optimization Progress:  97%|█████████▋| 3405/3500 [48:57<32:05, 20.27s/pipeline]Optimization Progress: 100%|█████████▉| 3485/3500 [49:55<03:36, 14.41s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [49:57, 14.41s/pipeline]Optimization Progress: 3501pipeline [49:57, 10.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [49:57, 10.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 3501pipeline [49:58, 10.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [07:35:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f9a8c531dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f9a8c642669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f9a8c64ff8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f9a8c636cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f9a8c523f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f909a2de9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f909a2de067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f909a2f627e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f909a2f6cb4]

.
Optimization Progress: 3501pipeline [50:08, 10.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [50:08, 10.12s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3501pipeline [50:09, 10.12s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [50:09<14:25,  8.92s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [50:09<14:25,  8.92s/pipeline]Optimization Progress:  97%|█████████▋| 3505/3600 [51:31<29:16, 18.49s/pipeline]Optimization Progress: 100%|█████████▉| 3585/3600 [52:23<03:17, 13.14s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 3601pipeline [52:26, 13.14s/pipeline]Optimization Progress: 3601pipeline [52:26,  9.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [52:27,  9.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 3601pipeline [52:28,  9.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [52:30,  9.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [52:30,  9.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [52:30,  9.26s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [52:35<12:41,  7.85s/pipeline]Optimization Progress:  97%|█████████▋| 3604/3700 [53:27<33:24, 20.88s/pipeline]Optimization Progress: 100%|█████████▉| 3684/3700 [53:55<03:55, 14.72s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [53:57, 14.72s/pipeline]Optimization Progress: 3701pipeline [53:57, 10.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 3701pipeline [54:00, 10.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [54:02, 10.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 3701pipeline [54:02, 10.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 3701pipeline [54:09, 10.35s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [54:10<14:40,  9.08s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [55:24<45:53, 28.68s/pipeline]Optimization Progress: 100%|█████████▉| 3784/3800 [55:53<05:22, 20.18s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [55:54, 20.18s/pipeline]Optimization Progress: 3801pipeline [55:54, 14.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 3801pipeline [55:59, 14.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 3801pipeline [56:01, 14.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3801pipeline [56:02, 14.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [56:03, 14.14s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 3801pipeline [56:05, 14.14s/pipeline]Optimization Progress:  97%|█████████▋| 3801/3900 [56:10<23:19, 14.14s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [56:58<47:29, 29.08s/pipeline]Optimization Progress: 100%|█████████▉| 3882/3900 [57:15<06:07, 20.42s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [57:16, 20.42s/pipeline]Optimization Progress: 3901pipeline [57:16, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [57:19, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [57:20, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [57:22, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [57:22, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [57:25, 14.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 3901pipeline [57:25, 14.30s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [57:26<18:39, 11.54s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [58:28<42:34, 26.61s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [59:07<05:00, 18.77s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [59:10, 18.77s/pipeline]Optimization Progress: 4001pipeline [59:10, 13.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [59:10, 13.21s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [59:15, 13.21s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [59:18<16:50, 10.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4003/4100 [59:18<16:50, 10.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4004/4100 [59:18<16:39, 10.41s/pipeline]Optimization Progress:  98%|█████████▊| 4006/4100 [59:51<16:33, 10.56s/pipeline]Optimization Progress: 100%|█████████▉| 4086/4100 [1:00:42<01:46,  7.59s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-832641121.0169313	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-717798040.0969216	XGBRegressor(Nystroem(input_matrix, Nystroem__gamma=0.15000000000000002, Nystroem__kernel=additive_chi2, Nystroem__n_components=7), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=10, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.4)
-4	-623218452.9945548	AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.6000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)
-5	-614174067.5500934	AdaBoostRegressor(AdaBoostRegressor(VarianceThreshold(RBFSampler(StandardScaler(input_matrix), RBFSampler__gamma=0.7000000000000001), VarianceThreshold__threshold=0.01), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), AdaBoostRegressor__learning_rate=0.01, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)                                                                                  _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4101pipeline [1:00:44,  7.59s/pipeline]Optimization Progress: 4101pipeline [1:00:44,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [1:00:46,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [1:00:49,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 4101pipeline [1:00:49,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [1:00:49,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [1:00:50,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [1:00:50,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [1:00:51,  5.36s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [1:00:51,  5.36s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [1:00:52<07:54,  4.89s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [1:00:52<07:54,  4.89s/pipeline]                                                                                  Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4104/4200 [1:00:52<07:49,  4.89s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4105/4200 [1:00:52<07:44,  4.89s/pipeline]                                                                                  Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4106/4200 [1:00:52<07:39,  4.89s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4107/4200 [1:00:52<07:34,  4.89s/pipeline]                                                                                  60.97 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 4107/4200 [1:00:52<07:34,  4.89s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4107/4200 [1:00:52<07:34,  4.89s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 4107/4200 [1:00:52<07:34,  4.89s/pipeline]                                                                                  Best pipeline:
0. StandardScaler()
1. RBFSampler(gamma=0.7000000000000001)
2. VarianceThreshold(threshold=0.01)
3. StackingEstimator(estimator=AdaBoostRegressor(loss='exponential',
                                              n_estimators=100))
4. AdaBoostRegressor(learning_rate=0.01, loss='exponential', n_estimators=100)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
