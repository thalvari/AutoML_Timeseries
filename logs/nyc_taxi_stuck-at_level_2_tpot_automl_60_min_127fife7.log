30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  10%|█         | 10/100 [00:08<01:18,  1.15pipeline/s]Optimization Progress:  90%|█████████ | 90/100 [00:12<00:06,  1.61pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  1.61pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  2.24pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.24pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.24pipeline/s]Optimization Progress:  52%|█████▏    | 103/200 [00:17<01:17,  1.25pipeline/s]Optimization Progress:  52%|█████▏    | 104/200 [00:22<03:08,  1.96s/pipeline]Optimization Progress:  92%|█████████▏| 184/200 [00:27<00:22,  1.39s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-1340584058.4778028	RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=5, RandomForestRegressor__min_samples_split=2, RandomForestRegressor__n_estimators=100)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  1.39s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  1.39s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:27<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 100%|██████████| 200/200 [00:28<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 200/200 [00:28<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.02pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 200/200 [00:30<00:00,  1.02pipeline/s]Optimization Progress:  68%|██████▊   | 203/300 [00:38<02:55,  1.81s/pipeline]Optimization Progress:  94%|█████████▍| 282/300 [01:18<00:25,  1.42s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1080838877.9111516	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=1, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:20<00:00,  1.42s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:20<00:00,  1.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:23<00:00,  1.04s/pipeline]Optimization Progress:  77%|███████▋  | 308/400 [01:25<01:21,  1.13pipeline/s]Optimization Progress:  77%|███████▋  | 309/400 [01:36<06:12,  4.09s/pipeline]Optimization Progress:  97%|█████████▋| 389/400 [01:42<00:31,  2.89s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1075587721.191065	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:44<00:00,  2.89s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:44<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:45<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 400/400 [01:45<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 400/400 [01:45<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:46<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:47<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 400/400 [01:47<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:48<00:00,  2.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:48<00:00,  2.07s/pipeline]Optimization Progress:  80%|████████  | 401/500 [01:48<04:22,  2.65s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 401/500 [01:48<04:22,  2.65s/pipeline]Optimization Progress:  81%|████████  | 403/500 [03:34<28:40, 17.73s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [03:38<03:31, 12.43s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1073915394.0774884	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:40<00:00, 12.43s/pipeline]Optimization Progress: 100%|██████████| 500/500 [03:40<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [03:41<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:42<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [03:43<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:43<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:43<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [03:43<00:00,  8.73s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:43<00:00,  8.73s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [03:45<12:20,  7.48s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [03:52<12:07,  7.42s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [03:58<01:33,  5.22s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-1064791979.3434627	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 600/600 [03:59<00:00,  5.22s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:59<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [04:00<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [04:00<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [17:22:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f93c4eb3dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f93c4fc4669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f93c4fd1f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f93c4fb8cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f93c4ea5f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f89d2c609dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f89d2c60067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f89d2c7827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f89d2c78cb4]

.
Optimization Progress: 100%|██████████| 600/600 [04:01<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [17:22:15] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f93c4eb3dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f93c4fc4669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f93c4fd1f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f93c4fb8cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f93c4ea5f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f89d2c609dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f89d2c60067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f89d2c7827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f89d2c78cb4]

.
Optimization Progress: 100%|██████████| 600/600 [04:01<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [04:04<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [17:22:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f93c4eb3dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f93c4fc4669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f93c4fd1f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f93c4fb8cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f93c4ea5f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f89d2c609dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f89d2c60067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f89d2c7827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f89d2c78cb4]

.
Optimization Progress: 100%|██████████| 600/600 [04:04<00:00,  3.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [04:04<00:00,  3.67s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [04:05<06:06,  3.67s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [04:05<07:11,  4.36s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [05:38<50:17, 30.79s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [05:42<06:28, 21.57s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-1064791979.3434627	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [05:42<00:00, 21.57s/pipeline]Optimization Progress: 100%|██████████| 700/700 [05:42<00:00, 15.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [05:45<00:00, 15.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [05:48<00:00, 15.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 700/700 [05:49<00:00, 15.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [05:50<00:00, 15.10s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [05:51<24:55, 15.10s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [06:00<24:39, 15.10s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [06:40<26:29, 16.39s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [06:44<03:15, 11.48s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-1064791979.3434627	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 800/800 [06:48<00:00, 11.48s/pipeline]Optimization Progress: 100%|██████████| 800/800 [06:48<00:00,  8.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [06:49<00:00,  8.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 800/800 [06:49<00:00,  8.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [06:50<00:00,  8.11s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [17:25:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f93c4eb3dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f93c4fc4669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f93c4fd1f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f93c4fb8cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f93c4ea5f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f89d2c609dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f89d2c60067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f89d2c7827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f89d2c78cb4]

.
Optimization Progress: 100%|██████████| 800/800 [06:51<00:00,  8.11s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 800/900 [06:53<13:31,  8.11s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [06:53<11:48,  7.16s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 801/900 [06:53<11:48,  7.16s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [09:12<41:42, 25.80s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [09:16<05:07, 18.08s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-1064704691.4973549	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.35000000000000003)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:18<00:00, 18.08s/pipeline]Optimization Progress: 100%|██████████| 900/900 [09:18<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [09:18<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [09:20<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:21<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:21<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:23<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [09:24<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [09:24<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [09:24<00:00, 12.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 900/900 [09:26<00:00, 12.68s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 900/1000 [09:26<21:07, 12.68s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [09:26<18:50, 11.42s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [09:32<16:04,  9.84s/pipeline]Optimization Progress:  98%|█████████▊| 982/1000 [09:38<02:04,  6.91s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-1064069761.3778	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [09:44<00:00,  6.91s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [09:44<00:00,  4.95s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [09:47<07:10,  4.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [09:47<07:10,  4.35s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [09:47<07:06,  4.35s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [10:18<09:42,  6.07s/pipeline]Optimization Progress:  99%|█████████▊| 1084/1100 [10:20<01:08,  4.26s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-1063567240.6904776	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [10:21<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [10:21<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [10:22<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [10:24<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 1100/1100 [10:26<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [10:28<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [10:28<00:00,  2.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1100/1200 [10:32<04:58,  2.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1101/1200 [10:33<04:55,  2.99s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [10:33<06:16,  3.84s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [11:00<17:38, 10.92s/pipeline]Optimization Progress:  99%|█████████▊| 1183/1200 [11:04<02:10,  7.66s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-1063567240.6904776	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [11:04<00:00,  7.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [11:04<00:00,  7.66s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [11:04<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [11:07<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [11:08<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 1200/1200 [11:08<00:00,  5.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1200/1300 [11:16<08:56,  5.37s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [11:20<08:51,  5.37s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [11:26<11:31,  7.06s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [11:32<01:29,  4.96s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-1063559464.152426	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1300/1300 [11:35<00:00,  4.96s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [11:35<00:00,  3.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1300/1300 [11:41<00:00,  3.53s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [11:54<13:08,  7.96s/pipeline]Optimization Progress:  99%|█████████▊| 1381/1400 [11:59<01:46,  5.60s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-1063469669.6448896	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 1400/1400 [12:00<00:00,  5.60s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [12:00<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1400/1400 [12:02<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [12:03<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 1400/1400 [12:06<00:00,  3.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [12:09<00:00,  3.93s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [12:21<14:43,  8.93s/pipeline]Optimization Progress:  99%|█████████▊| 1481/1500 [12:25<01:59,  6.26s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-1063469669.6448896	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:29<00:00,  6.26s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [12:29<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [12:30<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [12:30<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [12:31<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:31<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [12:33<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 1500/1500 [12:34<00:00,  4.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [12:34<00:00,  4.46s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [13:29<34:29, 20.90s/pipeline]Optimization Progress:  99%|█████████▉| 1581/1600 [13:37<04:38, 14.66s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-1063469669.6448896	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [13:38<00:00, 14.66s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [13:38<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [13:38<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1600/1600 [13:38<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [13:40<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [13:42<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [13:43<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [13:44<00:00, 10.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [13:45<00:00, 10.28s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [13:48<12:17,  7.76s/pipeline]Optimization Progress:  94%|█████████▍| 1606/1700 [14:20<23:51, 15.23s/pipeline]Optimization Progress:  99%|█████████▉| 1686/1700 [14:26<02:29, 10.68s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-1063469669.6448896	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [14:26<00:00, 10.68s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [14:26<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1700/1700 [14:26<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1700/1700 [14:27<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1700/1700 [14:28<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1700/1700 [14:30<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [14:32<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1700/1700 [14:36<00:00,  7.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [14:37<00:00,  7.49s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [14:40<12:21,  7.49s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [16:19<36:12, 22.17s/pipeline]Optimization Progress:  99%|█████████▉| 1782/1800 [16:26<04:39, 15.55s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-1063469669.6448896	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [16:27<00:00, 15.55s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [16:27<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1800/1800 [16:28<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [16:30<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 1800/1800 [16:31<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1800/1800 [16:32<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 1800/1800 [16:33<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1800/1800 [16:34<00:00, 10.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [16:35<00:00, 10.89s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [16:37<14:03,  8.70s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▍| 1803/1900 [16:37<14:03,  8.70s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [17:09<17:08, 10.83s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [17:12<01:53,  7.59s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-1063461053.0915794	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [17:15<00:00,  7.59s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [17:15<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [17:17<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [17:17<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:20<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [17:20<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:21<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [17:21<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1900/1900 [17:22<00:00,  5.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 1900/1900 [17:23<00:00,  5.37s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [17:23<10:20,  6.27s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [17:31<10:45,  6.59s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [17:35<01:23,  4.63s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-1063410843.4245799	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:36<00:00,  4.63s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [17:36<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:36<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:37<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2000/2000 [17:39<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:39<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:41<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2000/2000 [17:44<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2000/2000 [17:44<00:00,  3.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [17:44<00:00,  3.25s/pipeline]Optimization Progress:  95%|█████████▌| 2002/2100 [17:48<06:48,  4.17s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [17:57<08:59,  5.56s/pipeline]Optimization Progress:  99%|█████████▉| 2083/2100 [18:05<01:06,  3.92s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-1063375138.8416752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [18:05<00:00,  3.92s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [18:05<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [18:05<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2100/2100 [18:07<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:10<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2100/2100 [18:10<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [18:11<00:00,  2.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [18:12<00:00,  2.75s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [18:20<04:32,  2.75s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [18:43<12:25,  7.61s/pipeline]Optimization Progress:  99%|█████████▉| 2182/2200 [18:51<01:36,  5.35s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-1063375138.8416752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [18:51<00:00,  5.35s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [18:51<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:54<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:57<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:58<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2200/2200 [18:59<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 2200/2200 [18:59<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2200/2200 [18:59<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [19:01<00:00,  3.75s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2200/2200 [19:02<00:00,  3.75s/pipeline]Optimization Progress:  96%|█████████▌| 2204/2300 [19:02<05:33,  3.47s/pipeline]Optimization Progress:  96%|█████████▌| 2205/2300 [19:09<07:05,  4.48s/pipeline]Optimization Progress:  99%|█████████▉| 2285/2300 [19:14<00:47,  3.15s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-1063375138.8416752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2300/2300 [19:14<00:00,  3.15s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [19:14<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2300/2300 [19:15<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:16<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:18<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:23<00:00,  2.22s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [19:25<03:50,  2.40s/pipeline]Optimization Progress:  96%|█████████▌| 2305/2400 [19:43<11:07,  7.03s/pipeline]Optimization Progress:  99%|█████████▉| 2385/2400 [19:47<01:13,  4.93s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-1063375138.8416752	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.3, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:50<00:00,  4.93s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [19:50<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:57<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:57<00:00,  3.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:57<00:00,  3.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2400/2500 [19:59<05:50,  3.51s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [19:59<08:36,  5.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2401/2500 [19:59<08:36,  5.22s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [19:59<08:31,  5.22s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [20:38<12:06,  7.57s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [20:41<01:24,  5.31s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [20:45<00:00,  5.31s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [20:45<00:00,  3.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [20:48<00:00,  3.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [20:50<00:00,  3.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [20:52<00:00,  3.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [20:52<00:00,  3.80s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [20:54<08:47,  5.32s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [21:03<10:18,  6.31s/pipeline]Optimization Progress:  99%|█████████▉| 2582/2600 [21:06<01:19,  4.43s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [21:06<00:00,  4.43s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [21:06<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [21:07<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2600/2600 [21:07<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2600/2600 [21:09<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2600/2600 [21:13<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [21:15<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2600/2600 [21:16<00:00,  3.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 2600/2600 [21:18<00:00,  3.11s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [21:19<06:31,  4.00s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [21:19<06:31,  4.00s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [22:16<18:22, 11.48s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [22:21<02:08,  8.05s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 2700/2700 [22:21<00:00,  8.05s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [22:21<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [22:23<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2700/2700 [22:23<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [22:24<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [22:24<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2700/2700 [22:24<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2700/2700 [22:26<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [22:29<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [22:30<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [22:31<00:00,  5.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [22:32<00:00,  5.64s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2703/2800 [22:35<09:07,  5.64s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [22:40<09:01,  5.64s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [23:05<10:30,  6.63s/pipeline]Optimization Progress:  99%|█████████▉| 2785/2800 [23:24<01:10,  4.71s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [23:34<00:00,  4.71s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [23:34<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [23:34<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2800/2800 [23:38<00:00,  3.49s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [23:39<05:23,  3.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2802/2900 [23:39<05:23,  3.30s/pipeline]Optimization Progress:  97%|█████████▋| 2804/2900 [23:58<08:17,  5.18s/pipeline]Optimization Progress:  99%|█████████▉| 2884/2900 [24:20<00:59,  3.71s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [24:21<00:00,  3.71s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [24:21<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [24:23<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2900/2900 [24:26<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [24:29<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [24:30<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [24:32<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [24:34<00:00,  2.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2900/2900 [24:35<00:00,  2.63s/pipeline]Optimization Progress:  97%|█████████▋| 2901/3000 [24:35<09:47,  5.93s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [25:39<38:02, 23.29s/pipeline]Optimization Progress:  99%|█████████▉| 2982/3000 [25:43<04:53, 16.32s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3000/3000 [25:44<00:00, 16.32s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [25:44<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3000/3000 [25:46<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3000/3000 [25:49<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [25:49<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [25:50<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3000/3000 [25:50<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3000/3000 [25:51<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3000/3000 [25:52<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 3000/3000 [25:53<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [25:55<00:00, 11.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [25:57<00:00, 11.45s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [25:57<19:44, 11.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3001/3100 [25:58<19:44, 11.96s/pipeline]Optimization Progress:  97%|█████████▋| 3003/3100 [26:17<18:18, 11.33s/pipeline]Optimization Progress:  99%|█████████▉| 3083/3100 [26:23<02:15,  7.95s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [26:28<00:00,  7.95s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [26:28<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3100/3100 [26:28<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [26:31<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [26:32<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [26:34<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3100/3100 [26:36<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [26:36<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [26:36<00:00,  5.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [26:38<00:00,  5.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3100/3200 [26:40<09:25,  5.65s/pipeline]Optimization Progress:  97%|█████████▋| 3101/3200 [26:40<12:24,  7.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [26:40<12:24,  7.52s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [26:49<10:41,  6.62s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [26:54<01:19,  4.65s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-869831568.1235807	ExtraTreesRegressor(Normalizer(ElasticNetCV(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [26:55<00:00,  4.65s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [26:55<00:00,  3.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3200/3200 [26:56<00:00,  3.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [26:57<00:00,  3.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 3200/3200 [27:01<00:00,  3.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3200/3200 [27:04<00:00,  3.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [27:07<00:00,  3.27s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [27:19<15:39,  9.49s/pipeline]Optimization Progress:  99%|█████████▉| 3281/3300 [27:22<02:06,  6.66s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-1063185900.2576149	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-6	-869831568.1235807	ExtraTreesRegressor(Normalizer(ElasticNetCV(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=1e-05), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [27:26<00:00,  6.66s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [27:26<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [27:26<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3300/3300 [27:28<00:00,  4.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [27:37<00:00,  4.72s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [27:39<08:41,  5.32s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [27:50<11:03,  6.84s/pipeline]Optimization Progress: 100%|█████████▉| 3383/3400 [27:55<01:21,  4.81s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-1063183773.5544338	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-871586050.5447187	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3400/3400 [27:59<00:00,  4.81s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [27:59<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [27:59<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [28:05<00:00,  3.43s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [28:09<00:00,  3.43s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [28:11<10:03,  6.09s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [28:30<16:20, 10.01s/pipeline]Optimization Progress:  99%|█████████▉| 3482/3500 [28:35<02:06,  7.02s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-1063183773.5544338	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [28:40<00:00,  7.02s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [28:40<00:00,  5.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [28:40<00:00,  5.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [28:48<00:00,  5.00s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [28:50<10:42,  6.49s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [28:56<10:20,  6.33s/pipeline]Optimization Progress: 100%|█████████▉| 3582/3600 [28:59<01:19,  4.44s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-1063183773.5544338	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3600/3600 [29:08<00:00,  4.44s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [29:08<00:00,  3.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 3600/3600 [29:09<00:00,  3.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [29:09<00:00,  3.26s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [29:14<06:43,  4.07s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [29:35<15:16,  9.35s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [29:38<01:57,  6.55s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-1063157162.5517753	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [29:39<00:00,  6.55s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [29:39<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3700/3700 [29:39<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [29:41<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [29:41<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [29:44<00:00,  4.61s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [29:50<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 3700/3700 [29:51<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 3700/3700 [29:55<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [29:56<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [29:56<00:00,  4.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [29:56<00:00,  4.61s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [30:05<18:17, 11.08s/pipeline]Optimization Progress: 100%|█████████▉| 3781/3800 [30:24<02:28,  7.83s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3800/3800 [30:27<00:00,  7.83s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [30:27<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [30:30<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [30:36<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [30:37<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [30:37<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [30:38<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3800/3800 [30:40<00:00,  5.54s/pipeline]Optimization Progress:  97%|█████████▋| 3801/3900 [30:41<12:52,  7.80s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [31:17<26:57, 16.51s/pipeline]Optimization Progress: 100%|█████████▉| 3882/3900 [31:24<03:28, 11.58s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [31:26<00:00, 11.58s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [31:26<00:00,  8.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 3900/3900 [31:40<00:00,  8.14s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [31:41<11:35,  7.17s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [31:49<11:44,  7.34s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [31:53<01:22,  5.15s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [31:56<00:00,  5.15s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [31:56<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 4000/4000 [31:57<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4000/4000 [31:57<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [32:01<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [32:04<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 4000/4000 [32:06<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4000/4000 [32:08<00:00,  3.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [32:08<00:00,  3.67s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [32:11<11:30,  6.98s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [32:37<20:39, 12.65s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [32:42<02:39,  8.88s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [32:42<00:00,  8.88s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [32:42<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [32:42<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [32:42<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=3 X contains negative values..
Optimization Progress: 100%|██████████| 4100/4100 [32:42<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 4100/4100 [32:43<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [32:46<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [32:49<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [32:49<00:00,  6.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [32:59<00:00,  6.22s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [33:00<00:00,  6.22s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [33:01<11:43,  7.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4102/4200 [33:01<11:43,  7.18s/pipeline]Optimization Progress:  98%|█████████▊| 4104/4200 [33:11<10:20,  6.47s/pipeline]Optimization Progress: 100%|█████████▉| 4184/4200 [33:26<01:13,  4.58s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [33:28<00:00,  4.58s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [33:28<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [33:31<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 4200/4200 [33:34<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [33:36<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [33:37<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4200/4200 [33:40<00:00,  3.24s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4200/4200 [33:44<00:00,  3.24s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [33:46<06:31,  4.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [33:46<06:31,  4.04s/pipeline]Optimization Progress:  98%|█████████▊| 4205/4300 [34:35<16:08, 10.20s/pipeline]Optimization Progress: 100%|█████████▉| 4285/4300 [35:28<01:50,  7.34s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-850088973.9386501	ExtraTreesRegressor(StandardScaler(PolynomialFeatures(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)
-8	-849090427.4939059	RidgeCV(SGDRegressor(RBFSampler(Normalizer(StandardScaler(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.2, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=14, ExtraTreesRegressor__min_samples_split=14, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1)), Normalizer__norm=l1), RBFSampler__gamma=0.4), SGDRegressor__alpha=0.01, SGDRegressor__eta0=1.0, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.5, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [35:29<00:00,  7.34s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [35:29<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [35:36<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [35:39<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [35:40<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [35:40<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 4300/4300 [35:42<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 4300/4300 [35:49<00:00,  5.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 4300/4300 [35:50<00:00,  5.14s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4300/4400 [35:50<08:33,  5.14s/pipeline]Optimization Progress:  98%|█████████▊| 4301/4400 [35:50<16:26,  9.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4301/4400 [35:50<16:26,  9.96s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4302/4400 [35:50<16:16,  9.96s/pipeline]Optimization Progress:  98%|█████████▊| 4304/4400 [36:42<19:35, 12.24s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 4384/4400 [41:43<02:35,  9.70s/pipeline]                                                                                Skipped pipeline #4389 due to time out. Continuing to the next pipeline.
Optimization Progress: 100%|█████████▉| 4389/4400 [41:43<01:46,  9.70s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-1063140568.2258368	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-847759468.7153562	ExtraTreesRegressor(StandardScaler(LinearSVR(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [41:45,  9.70s/pipeline]Optimization Progress: 4401pipeline [41:45,  6.82s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4401pipeline [41:50,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [41:53,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [41:57,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [41:57,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [41:58,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4401pipeline [42:01,  6.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4401pipeline [42:01,  6.82s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [42:03<16:42, 10.23s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [42:15<17:35, 10.88s/pipeline]Optimization Progress: 100%|█████████▉| 4483/4500 [42:21<02:09,  7.64s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-847759468.7153562	ExtraTreesRegressor(StandardScaler(LinearSVR(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [42:22,  7.64s/pipeline]Optimization Progress: 4501pipeline [42:22,  5.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4501pipeline [42:28,  5.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [42:30,  5.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [42:31,  5.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [42:40,  5.37s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [42:41<09:02,  5.65s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [42:53<11:46,  7.43s/pipeline]Optimization Progress: 100%|█████████▉| 4585/4600 [42:58<01:18,  5.22s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-5	-860514601.2921988	ExtraTreesRegressor(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-6	-855814437.429205	ExtraTreesRegressor(Normalizer(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.4, ElasticNetCV__tol=0.01), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), Normalizer__norm=l1), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=12, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-7	-828617056.6799817	ExtraTreesRegressor(StandardScaler(LinearSVR(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 4601pipeline [42:59,  5.22s/pipeline]Optimization Progress: 4601pipeline [42:59,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [43:04,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 4601pipeline [43:07,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [43:07,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4601pipeline [43:08,  3.67s/pipeline]Optimization Progress: 4601pipeline [43:10,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [43:13,  3.67s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4601pipeline [43:13,  3.67s/pipeline]Optimization Progress:  98%|█████████▊| 4603/4700 [43:16<08:22,  5.18s/pipeline]Optimization Progress:  98%|█████████▊| 4604/4700 [44:30<41:22, 25.86s/pipeline]Optimization Progress: 100%|█████████▉| 4684/4700 [44:35<04:49, 18.12s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-869940138.3598158	RandomForestRegressor(Nystroem(input_matrix, Nystroem__gamma=0.9500000000000001, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=2, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100)
-3	-864459029.3843439	LinearSVR(LinearSVR(MaxAbsScaler(input_matrix), LinearSVR__C=25.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05)
-4	-847286741.4249878	KNeighborsRegressor(Normalizer(ExtraTreesRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), KNeighborsRegressor__n_neighbors=31, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=distance)
-7	-828617056.6799817	ExtraTreesRegressor(StandardScaler(LinearSVR(Normalizer(ExtraTreesRegressor(ElasticNetCV(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.75, ElasticNetCV__tol=1e-05), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8500000000000001, ExtraTreesRegressor__min_samples_leaf=1, ExtraTreesRegressor__min_samples_split=11, ExtraTreesRegressor__n_estimators=100), Normalizer__norm=l1), LinearSVR__C=0.001, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.01)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.8, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=20, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4701pipeline [44:38, 18.12s/pipeline]Optimization Progress: 4701pipeline [44:38, 12.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [44:38, 12.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4701pipeline [44:40, 12.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [44:41, 12.75s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [44:46, 12.75s/pipeline]Optimization Progress:  98%|█████████▊| 4704/4800 [44:55<16:55, 10.58s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [44:55<16:55, 10.58s/pipeline]Optimization Progress:  98%|█████████▊| 4706/4800 [46:03<27:30, 17.56s/pipeline]Optimization Progress: 100%|█████████▉| 4786/4800 [46:11<02:52, 12.33s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [46:16, 12.33s/pipeline]Optimization Progress: 4801pipeline [46:16,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [46:17,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [46:23,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 4801pipeline [46:24,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [46:24,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [46:26,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 4801pipeline [46:26,  8.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 4801pipeline [46:26,  8.73s/pipeline]Optimization Progress:  98%|█████████▊| 4804/4900 [46:33<12:26,  7.78s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4804/4900 [46:33<12:26,  7.78s/pipeline]Optimization Progress:  98%|█████████▊| 4806/4900 [47:40<24:23, 15.57s/pipeline]Optimization Progress: 100%|█████████▉| 4886/4900 [47:47<02:32, 10.92s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [47:47, 10.92s/pipeline]Optimization Progress: 4901pipeline [47:47,  7.65s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [47:47,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 4901pipeline [47:51,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4901pipeline [47:55,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [47:56,  7.65s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [47:58,  7.65s/pipeline]Optimization Progress: 4901pipeline [48:00,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [48:05,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [48:05,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [48:05,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [48:07,  7.65s/pipeline]Optimization Progress:  98%|█████████▊| 4902/5000 [48:09<19:32, 11.96s/pipeline]Optimization Progress:  98%|█████████▊| 4903/5000 [48:33<25:07, 15.55s/pipeline]Optimization Progress: 100%|█████████▉| 4983/5000 [48:38<03:05, 10.90s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [48:39, 10.90s/pipeline]Optimization Progress: 5001pipeline [48:39,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [48:42,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [48:43,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 5001pipeline [48:44,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [48:44,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [48:45,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [48:50,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5001pipeline [48:52,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5001pipeline [48:55,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [48:55,  7.65s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [48:57<17:40, 10.82s/pipeline]Optimization Progress:  98%|█████████▊| 5003/5100 [49:09<17:49, 11.03s/pipeline]Optimization Progress: 100%|█████████▉| 5083/5100 [49:14<02:11,  7.74s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [49:16,  7.74s/pipeline]Optimization Progress: 5101pipeline [49:16,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5101pipeline [49:22,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 5101pipeline [49:25,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 5101pipeline [49:25,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 5101pipeline [49:26,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5101pipeline [49:34,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 5101pipeline [49:36,  5.45s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [49:39,  5.45s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [49:39<17:39, 10.81s/pipeline]Optimization Progress:  98%|█████████▊| 5103/5200 [54:41<2:38:47, 98.22s/pipeline]                                                                                  Skipped pipeline #5152 due to time out. Continuing to the next pipeline.
Optimization Progress:  99%|█████████▉| 5152/5200 [54:41<1:18:34, 98.22s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 5184/5200 [54:50<18:20, 68.79s/pipeline]  
Generation 51 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 5202pipeline [54:53, 68.79s/pipeline]Optimization Progress: 5202pipeline [54:53, 48.19s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 5202pipeline [54:53, 48.19s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 5202pipeline [54:53, 48.19s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=3 X contains negative values..
Optimization Progress: 5202pipeline [54:53, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [54:56, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [55:01, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [55:04, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [55:06, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5202pipeline [55:11, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5202pipeline [55:13, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 5202pipeline [55:14, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [55:14, 48.19s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5202pipeline [55:14, 48.19s/pipeline]Optimization Progress:  98%|█████████▊| 5205/5300 [55:15<56:57, 35.98s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5205/5300 [55:15<56:57, 35.98s/pipeline]Optimization Progress:  98%|█████████▊| 5207/5300 [55:46<46:09, 29.78s/pipeline]Optimization Progress: 100%|█████████▉| 5287/5300 [55:52<04:31, 20.87s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5302pipeline [55:57, 20.87s/pipeline]Optimization Progress: 5302pipeline [55:57, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5302pipeline [56:08, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5302pipeline [56:09, 14.69s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 5302pipeline [56:11, 14.69s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 5302pipeline [56:11, 14.69s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 5302pipeline [56:11, 14.69s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=3 X contains negative values..
Optimization Progress: 5302pipeline [56:11, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5302pipeline [56:12, 14.69s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5302pipeline [56:14, 14.69s/pipeline]Optimization Progress:  98%|█████████▊| 5303/5400 [56:15<25:30, 15.77s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5303/5400 [56:15<25:30, 15.77s/pipeline]Optimization Progress:  98%|█████████▊| 5305/5400 [56:32<21:29, 13.58s/pipeline]Optimization Progress: 100%|█████████▉| 5385/5400 [56:44<02:23,  9.55s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))
-4	-679003496.7866825	RidgeCV(AdaBoostRegressor(Nystroem(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5402pipeline [56:49,  9.55s/pipeline]Optimization Progress: 5402pipeline [56:49,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5402pipeline [56:51,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5402pipeline [56:58,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5402pipeline [56:59,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5402pipeline [57:00,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5402pipeline [57:01,  6.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5402pipeline [57:02,  6.78s/pipeline]Optimization Progress:  98%|█████████▊| 5403/5500 [57:28<26:27, 16.36s/pipeline]Optimization Progress: 100%|█████████▉| 5483/5500 [57:32<03:14, 11.47s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))
-4	-679003496.7866825	RidgeCV(AdaBoostRegressor(Nystroem(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5502pipeline [57:33, 11.47s/pipeline]Optimization Progress: 5502pipeline [57:33,  8.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5502pipeline [57:38,  8.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5502pipeline [57:43,  8.04s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 5502pipeline [57:50,  8.04s/pipeline]Optimization Progress: 5502pipeline [57:50,  8.04s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 5502pipeline [57:53,  8.04s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 X contains negative values..
Optimization Progress: 5502pipeline [57:53,  8.04s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=2 X contains negative values..
Optimization Progress: 5502pipeline [57:53,  8.04s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=3 X contains negative values..
Optimization Progress: 5502pipeline [57:53,  8.04s/pipeline]Optimization Progress:  98%|█████████▊| 5503/5600 [57:53<18:53, 11.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5503/5600 [57:53<18:53, 11.68s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 5504/5600 [57:53<18:41, 11.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5505/5600 [57:53<18:30, 11.68s/pipeline]Optimization Progress:  98%|█████████▊| 5507/5600 [58:01<13:37,  8.80s/pipeline]Optimization Progress: 100%|█████████▉| 5587/5600 [58:09<01:20,  6.18s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))
-4	-679003496.7866825	RidgeCV(AdaBoostRegressor(Nystroem(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5602pipeline [58:10,  6.18s/pipeline]Optimization Progress: 5602pipeline [58:10,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5602pipeline [58:10,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5602pipeline [58:15,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 5602pipeline [58:21,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 5602pipeline [58:25,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5602pipeline [58:25,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5602pipeline [58:31,  4.35s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5602pipeline [58:31,  4.35s/pipeline]Optimization Progress:  98%|█████████▊| 5605/5700 [58:34<08:36,  5.44s/pipeline]Optimization Progress:  98%|█████████▊| 5606/5700 [59:13<24:10, 15.44s/pipeline]Optimization Progress: 100%|█████████▉| 5686/5700 [59:19<02:31, 10.83s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-1063104911.7287	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-776636694.9196308	LinearSVR(LinearSVR(input_matrix, LinearSVR__C=1.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=1e-05), LinearSVR__C=0.5, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=epsilon_insensitive, LinearSVR__tol=0.001)
-3	-775696120.8492887	RidgeCV(AdaBoostRegressor(Nystroem(input_matrix, Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))
-4	-679003496.7866825	RidgeCV(AdaBoostRegressor(Nystroem(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), Nystroem__gamma=0.4, Nystroem__kernel=additive_chi2, Nystroem__n_components=6), AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100))                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5702pipeline [59:23, 10.83s/pipeline]Optimization Progress: 5702pipeline [59:23,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5702pipeline [59:27,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 5702pipeline [59:35,  7.65s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5702pipeline [59:38,  7.65s/pipeline]Optimization Progress:  98%|█████████▊| 5703/5800 [59:40<16:59, 10.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5703/5800 [59:40<16:59, 10.51s/pipeline]Optimization Progress:  98%|█████████▊| 5705/5800 [1:00:53<28:55, 18.27s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 5784/5800 [1:00:53<04:52, 18.27s/pipeline]                                                                                  60.96 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 5784/5800 [1:00:53<04:52, 18.27s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 5784/5800 [1:00:53<04:52, 18.27s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 5784/5800 [1:00:53<04:52, 18.27s/pipeline]                                                                                  Best pipeline:
0. PolynomialFeatures(include_bias=False)
1. Nystroem(gamma=0.4, kernel='additive_chi2', n_components=6)
2. StackingEstimator(estimator=AdaBoostRegressor(loss='square', n_estimators=100))
3. RidgeCV(alphas=array([ 0.1,  1. , 10. ]))
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
