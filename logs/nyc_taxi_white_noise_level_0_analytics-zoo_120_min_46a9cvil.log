Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
Adding /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.1-jar-with-dependencies.jar to BIGDL_JARS
Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
Current pyspark location is : /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/__init__.py
Start to getOrCreate SparkContext
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.11-2.4.3.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2020-11-20 13:43:19 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

User settings:

   KMP_AFFINITY=granularity=fine,compact,1,0
   KMP_BLOCKTIME=0
   KMP_DUPLICATE_LIB_OK=True
   KMP_INIT_AT_FORK=FALSE
   KMP_SETTINGS=1
   OMP_NUM_THREADS=40

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=160
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_HAND_THREAD=false
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=40
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='40'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_TOOL=enabled
   OMP_TOOL_LIBRARIES: value is not defined
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'

cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
Successfully got a SparkContext
2020-11-20 13:43:23,529	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2020-11-20 13:43:23,529	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-11-20_13-43-23_529429_163216/logs.
2020-11-20 13:43:23,643	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:57463 to respond...
2020-11-20 13:43:23,758	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:48984 to respond...
2020-11-20 13:43:23,758	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2020-11-20 13:43:23,781	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-11-20_13-43-23_529429_163216/logs.
2020-11-20 13:43:23,781	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2020-11-20 13:43:23,781	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2020-11-20 13:43:24,219	WARNING bayesopt.py:69 -- `reward_attr` is deprecated and will be removed in a future version of Tune. Setting `metric=reward_metric` and `mode=max`.
2020-11-20 13:43:24,299	INFO tune.py:65 -- Did not find checkpoint file in /scratch/project_2003107/ray_results_2xem8yv7/automl.
2020-11-20 13:43:24,299	INFO tune.py:233 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/0 GPUs
Memory usage on this node: 11.6/200.9 GB

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/40 CPUs, 0/0 GPUs
Memory usage on this node: 11.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	PENDING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	PENDING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	PENDING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	PENDING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	PENDING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	PENDING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	PENDING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	PENDING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	PENDING
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING

[2m[36m(pid=163555)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163566)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163534)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163553)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163545)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163563)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163531)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163546)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163551)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163533)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163555)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163536)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163550)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163550)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163566)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163569)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163569)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163534)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163554)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163554)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163568)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163568)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163549)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163549)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163565)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163565)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163540)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163540)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163544)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163544)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163543)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163543)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163567)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163567)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163560)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163560)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163552)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163552)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163537)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163537)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163539)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163539)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163559)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163559)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163561)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163561)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163548)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163548)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163558)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163558)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163547)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163547)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163551)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163556)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163556)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163570)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163570)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163557)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163557)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163564)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163564)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163542)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163542)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163533)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163530)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163530)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163553)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163545)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163563)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163531)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163546)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163532)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163532)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163538)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163538)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163541)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=163541)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163536)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165333)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165321)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165321)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165315)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165315)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165325)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165313)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165327)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165343)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165313)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165333)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165327)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165330)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165330)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165336)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165336)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165318)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165318)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165325)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165343)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=165339)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=165339)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163555)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163555)[0m   agg_primitives: ['count']
[2m[36m(pid=163555)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163555)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163536)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163536)[0m   agg_primitives: ['count']
[2m[36m(pid=163536)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163536)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163550)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163550)[0m   agg_primitives: ['count']
[2m[36m(pid=163550)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163550)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163566)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163566)[0m   agg_primitives: ['count']
[2m[36m(pid=163566)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163566)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163569)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163569)[0m   agg_primitives: ['count']
[2m[36m(pid=163569)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163569)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163534)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163534)[0m   agg_primitives: ['count']
[2m[36m(pid=163534)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163534)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163532)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163532)[0m   agg_primitives: ['count']
[2m[36m(pid=163532)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163532)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163562)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163562)[0m   agg_primitives: ['count']
[2m[36m(pid=163562)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163562)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163538)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163538)[0m   agg_primitives: ['count']
[2m[36m(pid=163538)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163538)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163541)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163541)[0m   agg_primitives: ['count']
[2m[36m(pid=163541)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163541)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163566)[0m LSTM is selected.
[2m[36m(pid=163555)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163555)[0m Instructions for updating:
[2m[36m(pid=163555)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163555)[0m LSTM is selected.
[2m[36m(pid=163536)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163536)[0m Instructions for updating:
[2m[36m(pid=163536)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163536)[0m LSTM is selected.
[2m[36m(pid=163550)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163550)[0m Instructions for updating:
[2m[36m(pid=163550)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163550)[0m LSTM is selected.
[2m[36m(pid=163566)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163566)[0m Instructions for updating:
[2m[36m(pid=163566)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163569)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163569)[0m Instructions for updating:
[2m[36m(pid=163569)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163569)[0m LSTM is selected.
[2m[36m(pid=163534)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163534)[0m Instructions for updating:
[2m[36m(pid=163534)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163534)[0m LSTM is selected.
[2m[36m(pid=163532)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163532)[0m Instructions for updating:
[2m[36m(pid=163532)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163532)[0m LSTM is selected.
[2m[36m(pid=163562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163562)[0m Instructions for updating:
[2m[36m(pid=163562)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163562)[0m LSTM is selected.
[2m[36m(pid=163538)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163538)[0m Instructions for updating:
[2m[36m(pid=163538)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163538)[0m LSTM is selected.
[2m[36m(pid=163541)[0m LSTM is selected.
[2m[36m(pid=163541)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163541)[0m Instructions for updating:
[2m[36m(pid=163541)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163555)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163555)[0m Instructions for updating:
[2m[36m(pid=163555)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163536)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163536)[0m Instructions for updating:
[2m[36m(pid=163536)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163550)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163550)[0m Instructions for updating:
[2m[36m(pid=163550)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163566)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163566)[0m Instructions for updating:
[2m[36m(pid=163566)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163569)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163569)[0m Instructions for updating:
[2m[36m(pid=163569)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163534)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163534)[0m Instructions for updating:
[2m[36m(pid=163534)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163532)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163532)[0m Instructions for updating:
[2m[36m(pid=163532)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163562)[0m Instructions for updating:
[2m[36m(pid=163562)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163538)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163538)[0m Instructions for updating:
[2m[36m(pid=163538)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163541)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163541)[0m Instructions for updating:
[2m[36m(pid=163541)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163555)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163555)[0m 2020-11-20 13:43:34.233536: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163550)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163550)[0m 2020-11-20 13:43:34.220145: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163550)[0m 2020-11-20 13:43:34.227991: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163550)[0m 2020-11-20 13:43:34.230135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef3150e9fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163550)[0m 2020-11-20 13:43:34.230157: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163566)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163566)[0m 2020-11-20 13:43:34.195052: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163566)[0m 2020-11-20 13:43:34.202546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163566)[0m 2020-11-20 13:43:34.204523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdec50d3f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163566)[0m 2020-11-20 13:43:34.204542: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163569)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163569)[0m 2020-11-20 13:43:34.231231: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163534)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163534)[0m 2020-11-20 13:43:34.212028: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163534)[0m 2020-11-20 13:43:34.219371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163534)[0m 2020-11-20 13:43:34.221609: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eff150be5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163534)[0m 2020-11-20 13:43:34.221630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163532)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163532)[0m 2020-11-20 13:43:34.225567: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163532)[0m 2020-11-20 13:43:34.233031: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163562)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163562)[0m 2020-11-20 13:43:34.206705: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163562)[0m 2020-11-20 13:43:34.214222: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163562)[0m 2020-11-20 13:43:34.216040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f34390d6ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163562)[0m 2020-11-20 13:43:34.216059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163538)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163538)[0m 2020-11-20 13:43:34.218837: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163538)[0m 2020-11-20 13:43:34.226494: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163538)[0m 2020-11-20 13:43:34.228645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f21950ef620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163538)[0m 2020-11-20 13:43:34.228667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163536)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163532)[0m 2020-11-20 13:43:34.235299: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f19550a3860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163532)[0m 2020-11-20 13:43:34.235322: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163536)[0m 2020-11-20 13:43:34.235751: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163555)[0m 2020-11-20 13:43:34.241200: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163555)[0m 2020-11-20 13:43:34.243328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8010ef860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163555)[0m 2020-11-20 13:43:34.243350: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163536)[0m 2020-11-20 13:43:34.243379: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163536)[0m 2020-11-20 13:43:34.245621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0de10d4900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163536)[0m 2020-11-20 13:43:34.245646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163569)[0m 2020-11-20 13:43:34.239229: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163569)[0m 2020-11-20 13:43:34.241422: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6e890d6fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163569)[0m 2020-11-20 13:43:34.241445: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163541)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163541)[0m 2020-11-20 13:43:34.427442: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163541)[0m 2020-11-20 13:43:34.435241: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163541)[0m 2020-11-20 13:43:34.437447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d11107620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163541)[0m 2020-11-20 13:43:34.437470: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:119: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 21.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 10 ({'RUNNING': 10})
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	RUNNING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	RUNNING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	RUNNING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163532], 5 s, 1 iter

[2m[36m(pid=163541)[0m Traceback (most recent call last):
[2m[36m(pid=163541)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163541)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163541)[0m , filename = '/tmp/thalvari/4065562/automl_save_31ytch00/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d11bc0aa0, total write size = 21528, bytes this sub-write = 21528, bytes actually written = 18446744073709551615, offset = 139264)
[2m[36m(pid=163541)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=163541)[0m Traceback (most recent call last):
[2m[36m(pid=163541)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163541)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163541)[0m , filename = '/tmp/thalvari/4065562/automl_save_31ytch00/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d11bc0aa0, total write size = 21528, bytes this sub-write = 21528, bytes actually written = 18446744073709551615, offset = 139264)
[2m[36m(pid=163541)[0m Traceback (most recent call last):
[2m[36m(pid=163541)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163541)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163541)[0m , filename = '/tmp/thalvari/4065562/automl_save_31ytch00/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d117d2898, total write size = 7056, bytes this sub-write = 7056, bytes actually written = 18446744073709551615, offset = 162840)
[2m[36m(pid=163541)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=163541)[0m Traceback (most recent call last):
[2m[36m(pid=163541)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163541)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163541)[0m , filename = '/tmp/thalvari/4065562/automl_save_31ytch00/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d117d2898, total write size = 7056, bytes this sub-write = 7056, bytes actually written = 18446744073
[2m[36m(pid=163550)[0m 2020-11-20 13:43:37,483	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163550)[0m Traceback (most recent call last):
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163550)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163550)[0m     param_dset[:] = val
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163550)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163550)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163550)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163550)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163550)[0m , filename = '/tmp/thalvari/4065562/automl_save_bf3feng2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef3169fd588, total write size = 722344, bytes this sub-write = 722344, bytes actually written = 18446744073709551615, offset = 1085440)
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m Traceback (most recent call last):
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163550)[0m     self._entrypoint()
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163550)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163550)[0m     output = train_func(config, reporter)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163550)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163550)[0m     config=config)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163550)[0m     model.save(model_path, config_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163550)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163550)[0m     self.model.save(model_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163550)[0m     signatures)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163550)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163550)[0m     f.close()
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163550)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163550)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163550)[0m , filename = '/tmp/thalvari/4065562/automl_save_bf3feng2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef3163ff9c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163550)[0m Exception in thread Thread-1:
[2m[36m(pid=163550)[0m Traceback (most recent call last):
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163550)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163550)[0m     param_dset[:] = val
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163550)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163550)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163550)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163550)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163550)[0m , filename = '/tmp/thalvari/4065562/automl_save_bf3feng2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef3169fd588, total write size = 722344, bytes this sub-write = 722344, bytes actually written = 18446744073709551615, offset = 1085440)
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m Traceback (most recent call last):
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163550)[0m     self._entrypoint()
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163550)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163550)[0m     output = train_func(config, reporter)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163550)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163550)[0m     config=config)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163550)[0m     model.save(model_path, config_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163550)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163550)[0m     self.model.save(model_path)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163550)[0m     signatures)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163550)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163550)[0m     f.close()
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163550)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163550)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163550)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163550)[0m , filename = '/tmp/thalvari/4065562/automl_save_bf3feng2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef3163ff9c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163562)[0m 2020-11-20 13:43:37,472	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163562)[0m Traceback (most recent call last):
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163562)[0m     param_dset[:] = val
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163562)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163562)[0m , filename = '/tmp/thalvari/4065562/automl_save_vb4__0tt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f343a42f970, total write size = 153664, bytes this sub-write = 153664, bytes actually written = 18446744073709551615, offset = 177976)
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m Traceback (most recent call last):
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163562)[0m     self._entrypoint()
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163562)[0m     output = train_func(config, reporter)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163562)[0m     config=config)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163562)[0m     model.save(model_path, config_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163562)[0m     self.model.save(model_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163562)[0m     signatures)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163562)[0m     f.close()
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163562)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163562)[0m , filename = '/tmp/thalvari/4065562/automl_save_vb4__0tt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f343a5a6160, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163562)[0m Exception in thread Thread-1:
[2m[36m(pid=163562)[0m Traceback (most recent call last):
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163562)[0m     param_dset[:] = val
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163562)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163562)[0m , filename = '/tmp/thalvari/4065562/automl_save_vb4__0tt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f343a42f970, total write size = 153664, bytes this sub-write = 153664, bytes actually written = 18446744073709551615, offset = 177976)
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m Traceback (most recent call last):
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163562)[0m     self._entrypoint()
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163562)[0m     output = train_func(config, reporter)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163562)[0m     config=config)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163562)[0m     model.save(model_path, config_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163562)[0m     self.model.save(model_path)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163562)[0m     signatures)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163562)[0m     f.close()
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163562)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163562)[0m , filename = '/tmp/thalvari/4065562/automl_save_vb4__0tt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f343a5a6160, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m Traceback (most recent call last):
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163550)[0m     self.run()
[2m[36m(pid=163550)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163550)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163550)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m Traceback (most recent call last):
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163562)[0m     self.run()
[2m[36m(pid=163562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163562)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163562)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163541)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163541)[0m 
[2m[36m(pid=163541)[0m Stack (most recent call first):
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120 in save
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135 in save_zip
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340 in train_func
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262 in _trainable_func
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143 in entrypoint
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92 in run
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916 in _bootstrap_inner
[2m[36m(pid=163541)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 884 in _bootstrap
2020-11-20 13:43:37,605	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2020-11-20 13:43:37,610	ERROR worker.py:1672 -- A worker died or was killed while executing task 52d290968ccf124b5e6a6dd712ce4ff5.
2020-11-20 13:43:37,615	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163569)[0m 2020-11-20 13:43:37,621	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163569)[0m Traceback (most recent call last):
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163569)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163569)[0m     param_dset[:] = val
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163569)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163569)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163569)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163569)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163569)[0m , filename = '/tmp/thalvari/4065562/automl_save_00gnwe0n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6e8a8368f8, total write size = 286008, bytes this sub-write = 286008, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m Traceback (most recent call last):
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163569)[0m     self._entrypoint()
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163569)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163569)[0m     output = train_func(config, reporter)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163569)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163569)[0m     config=config)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163569)[0m     model.save(model_path, config_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163569)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163569)[0m     self.model.save(model_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163569)[0m     signatures)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163569)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163569)[0m     f.close()
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163569)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163569)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163569)[0m , filename = '/tmp/thalvari/4065562/automl_save_00gnwe0n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6e8a556d80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163569)[0m Exception in thread Thread-1:
[2m[36m(pid=163569)[0m Traceback (most recent call last):
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163569)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163569)[0m     param_dset[:] = val
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163569)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163569)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163569)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163569)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163569)[0m , filename = '/tmp/thalvari/4065562/automl_save_00gnwe0n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6e8a8368f8, total write size = 286008, bytes this sub-write = 286008, bytes actually written = 18446744073709551615, offset = 1318912)
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m Traceback (most recent call last):
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163569)[0m     self._entrypoint()
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163569)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163569)[0m     output = train_func(config, reporter)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163569)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163569)[0m     config=config)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163569)[0m     model.save(model_path, config_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163569)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163569)[0m     self.model.save(model_path)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163569)[0m     signatures)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163569)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163569)[0m     f.close()
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163569)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163569)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163569)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:37 2020
[2m[36m(pid=163569)[0m , filename = '/tmp/thalvari/4065562/automl_save_00gnwe0n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6e8a556d80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m Traceback (most recent call last):
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163569)[0m     self.run()
[2m[36m(pid=163569)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163569)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163569)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163555)[0m 2020-11-20 13:43:38,415	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163555)[0m Traceback (most recent call last):
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163555)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163555)[0m     param_dset[:] = val
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163555)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163555)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163555)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163555)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163555)[0m , filename = '/tmp/thalvari/4065562/automl_save_n2m2g8xi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd802aa0928, total write size = 291160, bytes this sub-write = 291160, bytes actually written = 18446744073709551615, offset = 1306624)
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m Traceback (most recent call last):
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163555)[0m     self._entrypoint()
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163555)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163555)[0m     output = train_func(config, reporter)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163555)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163555)[0m     config=config)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163555)[0m     model.save(model_path, config_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163555)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163555)[0m     self.model.save(model_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163555)[0m     signatures)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163555)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163555)[0m     f.close()
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163555)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163555)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163555)[0m , filename = '/tmp/thalvari/4065562/automl_save_n2m2g8xi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd80269bb10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163555)[0m Exception in thread Thread-1:
[2m[36m(pid=163555)[0m Traceback (most recent call last):
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163555)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163555)[0m     param_dset[:] = val
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163555)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163555)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163555)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163555)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163555)[0m , filename = '/tmp/thalvari/4065562/automl_save_n2m2g8xi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd802aa0928, total write size = 291160, bytes this sub-write = 291160, bytes actually written = 18446744073709551615, offset = 1306624)
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m Traceback (most recent call last):
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163555)[0m     self._entrypoint()
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163555)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163555)[0m     output = train_func(config, reporter)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163555)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163555)[0m     config=config)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163555)[0m     model.save(model_path, config_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163555)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163555)[0m     self.model.save(model_path)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163555)[0m     signatures)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163555)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163555)[0m     f.close()
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163555)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163555)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163555)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163555)[0m , filename = '/tmp/thalvari/4065562/automl_save_n2m2g8xi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd80269bb10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m Traceback (most recent call last):
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163555)[0m     self.run()
[2m[36m(pid=163555)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163555)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163555)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163555)[0m 
2020-11-20 13:43:38,571	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163550, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:38,575	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 13:43:38,614	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163562, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:38,616	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163538)[0m 2020-11-20 13:43:38,591	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163538)[0m Traceback (most recent call last):
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163538)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163538)[0m     param_dset[:] = val
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163538)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163538)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163538)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163538)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163538)[0m , filename = '/tmp/thalvari/4065562/automl_save_ujy3zcvm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2196013eb8, total write size = 28600, bytes this sub-write = 28600, bytes actually written = 18446744073709551615, offset = 1089536)
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m Traceback (most recent call last):
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163538)[0m     self._entrypoint()
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163538)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163538)[0m     output = train_func(config, reporter)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163538)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163538)[0m     config=config)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163538)[0m     model.save(model_path, config_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163538)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163538)[0m     self.model.save(model_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163538)[0m     signatures)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163538)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163538)[0m     f.close()
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163538)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163538)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163538)[0m , filename = '/tmp/thalvari/4065562/automl_save_ujy3zcvm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21957209a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163538)[0m Exception in thread Thread-1:
[2m[36m(pid=163538)[0m Traceback (most recent call last):
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163538)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163538)[0m     param_dset[:] = val
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163538)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163538)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163538)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163538)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163538)[0m , filename = '/tmp/thalvari/4065562/automl_save_ujy3zcvm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2196013eb8, total write size = 28600, bytes this sub-write = 28600, bytes actually written = 18446744073709551615, offset = 1089536)
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m Traceback (most recent call last):
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163538)[0m     self._entrypoint()
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163538)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163538)[0m     output = train_func(config, reporter)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163538)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163538)[0m     config=config)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163538)[0m     model.save(model_path, config_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163538)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163538)[0m     self.model.save(model_path)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163538)[0m     signatures)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163538)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163538)[0m     f.close()
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163538)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163538)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163538)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:38 2020
[2m[36m(pid=163538)[0m , filename = '/tmp/thalvari/4065562/automl_save_ujy3zcvm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21957209a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m Traceback (most recent call last):
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163538)[0m     self.run()
[2m[36m(pid=163538)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163538)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163538)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163550)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163550)[0m 
[2m[36m(pid=163550)[0m Stack (most recent call first):
[2m[36m(pid=163562)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163562)[0m 
[2m[36m(pid=163562)[0m Stack (most recent call first):
2020-11-20 13:43:38,796	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163569, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:38,799	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163569)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163569)[0m 
[2m[36m(pid=163569)[0m Stack (most recent call first):
2020-11-20 13:43:39,581	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163555, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:39,584	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 13:43:39,732	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163538, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:39,737	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163555)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163555)[0m 
[2m[36m(pid=163555)[0m Stack (most recent call first):
[2m[36m(pid=163538)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163538)[0m 
[2m[36m(pid=163538)[0m Stack (most recent call first):
[2m[36m(pid=165330)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165330)[0m   agg_primitives: ['count']
[2m[36m(pid=165330)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165330)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165318)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165318)[0m   agg_primitives: ['count']
[2m[36m(pid=165318)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165318)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165339)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165339)[0m   agg_primitives: ['count']
[2m[36m(pid=165339)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165339)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165325)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165325)[0m   agg_primitives: ['count']
[2m[36m(pid=165325)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165325)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165318)[0m LSTM is selected.
[2m[36m(pid=165339)[0m LSTM is selected.
[2m[36m(pid=165330)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165330)[0m Instructions for updating:
[2m[36m(pid=165330)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165330)[0m LSTM is selected.
[2m[36m(pid=165318)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165318)[0m Instructions for updating:
[2m[36m(pid=165318)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165339)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165339)[0m Instructions for updating:
[2m[36m(pid=165339)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165325)[0m LSTM is selected.
[2m[36m(pid=165325)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165325)[0m Instructions for updating:
[2m[36m(pid=165325)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165330)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165330)[0m Instructions for updating:
[2m[36m(pid=165330)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165318)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165318)[0m Instructions for updating:
[2m[36m(pid=165318)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165339)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165339)[0m Instructions for updating:
[2m[36m(pid=165339)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165325)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165325)[0m Instructions for updating:
[2m[36m(pid=165325)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165333)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165333)[0m   agg_primitives: ['count']
[2m[36m(pid=165333)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165333)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165313)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165313)[0m   agg_primitives: ['count']
[2m[36m(pid=165313)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165313)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 17 ({'RUNNING': 10, 'ERROR': 6, 'TERMINATED': 1})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAK_2020-11-20_13-43-24rramu4xg/error_2020-11-20_13-43-37.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_13-43-24ebb6fcf_/error_2020-11-20_13-43-39.txt, [4 CPUs, 0 GPUs], [pid=163538], 5 s, 1 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_13-43-249vpfgxxl/error_2020-11-20_13-43-38.txt
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163534], 11 s, 3 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163566], 10 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163536], 8 s, 1 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter

[2m[36m(pid=165333)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165333)[0m Instructions for updating:
[2m[36m(pid=165333)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165333)[0m LSTM is selected.
[2m[36m(pid=165313)[0m LSTM is selected.
[2m[36m(pid=165313)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165313)[0m Instructions for updating:
[2m[36m(pid=165313)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165339)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165339)[0m 2020-11-20 13:43:43.147062: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165318)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165318)[0m 2020-11-20 13:43:43.149113: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165330)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165330)[0m 2020-11-20 13:43:43.172109: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165330)[0m 2020-11-20 13:43:43.179961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165330)[0m 2020-11-20 13:43:43.182227: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8f390a3860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165330)[0m 2020-11-20 13:43:43.182253: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165318)[0m 2020-11-20 13:43:43.157612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165318)[0m 2020-11-20 13:43:43.160879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1a35107230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165318)[0m 2020-11-20 13:43:43.160904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165339)[0m 2020-11-20 13:43:43.155220: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165339)[0m 2020-11-20 13:43:43.157478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6dc50e9860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165339)[0m 2020-11-20 13:43:43.157498: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165321)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165321)[0m   agg_primitives: ['count']
[2m[36m(pid=165321)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165321)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165325)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165325)[0m 2020-11-20 13:43:43.467966: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165325)[0m 2020-11-20 13:43:43.476205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165325)[0m 2020-11-20 13:43:43.479114: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4b5511fa90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165325)[0m 2020-11-20 13:43:43.479167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165333)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165333)[0m Instructions for updating:
[2m[36m(pid=165333)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165313)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165313)[0m Instructions for updating:
[2m[36m(pid=165313)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165321)[0m LSTM is selected.
[2m[36m(pid=165321)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165321)[0m Instructions for updating:
[2m[36m(pid=165321)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165321)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165321)[0m Instructions for updating:
[2m[36m(pid=165321)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165333)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165333)[0m 2020-11-20 13:43:44.558738: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165333)[0m 2020-11-20 13:43:44.571100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165333)[0m 2020-11-20 13:43:44.577172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f154d0ef400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165333)[0m 2020-11-20 13:43:44.577215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165313)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165313)[0m 2020-11-20 13:43:44.575402: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165313)[0m 2020-11-20 13:43:44.583813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165313)[0m 2020-11-20 13:43:44.588130: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7fcd0d6860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165313)[0m 2020-11-20 13:43:44.588167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165321)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165321)[0m 2020-11-20 13:43:45.281232: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165321)[0m 2020-11-20 13:43:45.291316: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165321)[0m 2020-11-20 13:43:45.295658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efe090cafb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165321)[0m 2020-11-20 13:43:45.295709: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=165333)[0m 2020-11-20 13:43:47,785	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165333)[0m Traceback (most recent call last):
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165333)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165333)[0m     param_dset[:] = val
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165333)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165333)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165333)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165333)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:47 2020
[2m[36m(pid=165333)[0m , filename = '/tmp/thalvari/4065562/automl_save_sqb_0z0_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f154e79cf48, total write size = 539928, bytes this sub-write = 539928, bytes actually written = 18446744073709551615, offset = 1294336)
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m Traceback (most recent call last):
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165333)[0m     self._entrypoint()
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165333)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165333)[0m     output = train_func(config, reporter)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165333)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165333)[0m     config=config)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165333)[0m     model.save(model_path, config_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165333)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165333)[0m     self.model.save(model_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165333)[0m     signatures)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165333)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165333)[0m     f.close()
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165333)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165333)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:47 2020
[2m[36m(pid=165333)[0m , filename = '/tmp/thalvari/4065562/automl_save_sqb_0z0_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f154e3ab440, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165333)[0m Exception in thread Thread-1:
[2m[36m(pid=165333)[0m Traceback (most recent call last):
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165333)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165333)[0m     param_dset[:] = val
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165333)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165333)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165333)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165333)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:47 2020
[2m[36m(pid=165333)[0m , filename = '/tmp/thalvari/4065562/automl_save_sqb_0z0_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f154e79cf48, total write size = 539928, bytes this sub-write = 539928, bytes actually written = 18446744073709551615, offset = 1294336)
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m Traceback (most recent call last):
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165333)[0m     self._entrypoint()
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165333)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165333)[0m     output = train_func(config, reporter)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165333)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165333)[0m     config=config)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165333)[0m     model.save(model_path, config_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165333)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165333)[0m     self.model.save(model_path)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165333)[0m     signatures)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165333)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165333)[0m     f.close()
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165333)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165333)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165333)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:47 2020
[2m[36m(pid=165333)[0m , filename = '/tmp/thalvari/4065562/automl_save_sqb_0z0_/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f154e3ab440, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m Traceback (most recent call last):
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165333)[0m     self.run()
[2m[36m(pid=165333)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165333)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165333)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165333)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 19.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 18 ({'TERMINATED': 2, 'ERROR': 6, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAK_2020-11-20_13-43-24rramu4xg/error_2020-11-20_13-43-37.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_13-43-24ebb6fcf_/error_2020-11-20_13-43-39.txt, [4 CPUs, 0 GPUs], [pid=163538], 5 s, 1 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_13-43-249vpfgxxl/error_2020-11-20_13-43-38.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163566], 10 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163536], 15 s, 3 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165339], 6 s, 2 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165325], 5 s, 1 iter
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_18_batch_size_log=6.2657,bayes_feature_DAY(timestamp)=0.525,bayes_feature_HOUR(timestamp)=0.39319,bayes_feature_IS_AWAKE(timestamp)=0.72607,bayes_feature_IS_BUSY_HOURS(timestamp)=0.44228,bayes_feature_IS_WEEKEND(timestamp)=0.60691,bayes_feature_MONTH(timestamp)=0.90781,bayes_feature_WEEKDAY(timestamp)=0.81902,dropout_1=0.32945,dropout_2=0.47667,epochs=5,lr=0.0011228,lstm_1_units_float=87.648,lstm_2_units_float=30.891,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter

[2m[36m(pid=165313)[0m 2020-11-20 13:43:48,390	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165313)[0m Traceback (most recent call last):
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165313)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165313)[0m     param_dset[:] = val
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165313)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165313)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165313)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165313)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:48 2020
[2m[36m(pid=165313)[0m , filename = '/tmp/thalvari/4065562/automl_save_ycruiia_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fce6228f8, total write size = 263064, bytes this sub-write = 263064, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m Traceback (most recent call last):
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165313)[0m     self._entrypoint()
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165313)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165313)[0m     output = train_func(config, reporter)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165313)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165313)[0m     config=config)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165313)[0m     model.save(model_path, config_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165313)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165313)[0m     self.model.save(model_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165313)[0m     signatures)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165313)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165313)[0m     f.close()
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165313)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165313)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:48 2020
[2m[36m(pid=165313)[0m , filename = '/tmp/thalvari/4065562/automl_save_ycruiia_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fcdf5b390, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165313)[0m Exception in thread Thread-1:
[2m[36m(pid=165313)[0m Traceback (most recent call last):
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165313)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165313)[0m     param_dset[:] = val
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165313)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165313)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165313)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165313)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:48 2020
[2m[36m(pid=165313)[0m , filename = '/tmp/thalvari/4065562/automl_save_ycruiia_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fce6228f8, total write size = 263064, bytes this sub-write = 263064, bytes actually written = 18446744073709551615, offset = 1286144)
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m Traceback (most recent call last):
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165313)[0m     self._entrypoint()
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165313)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165313)[0m     output = train_func(config, reporter)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165313)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165313)[0m     config=config)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165313)[0m     model.save(model_path, config_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165313)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165313)[0m     self.model.save(model_path)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165313)[0m     signatures)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165313)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165313)[0m     f.close()
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165313)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165313)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165313)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:48 2020
[2m[36m(pid=165313)[0m , filename = '/tmp/thalvari/4065562/automl_save_ycruiia_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7fcdf5b390, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m Traceback (most recent call last):
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165313)[0m     self.run()
[2m[36m(pid=165313)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165313)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165313)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165313)[0m 
2020-11-20 13:43:48,818	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165333, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:48,822	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165333)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165333)[0m 
[2m[36m(pid=165333)[0m Stack (most recent call first):
2020-11-20 13:43:49,431	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165313, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:49,436	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165313)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165313)[0m 
[2m[36m(pid=165313)[0m Stack (most recent call first):
[2m[36m(pid=165318)[0m 2020-11-20 13:43:49,686	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165318)[0m Traceback (most recent call last):
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165318)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165318)[0m     param_dset[:] = val
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165318)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165318)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165318)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165318)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:49 2020
[2m[36m(pid=165318)[0m , filename = '/tmp/thalvari/4065562/automl_save_z8hdik43/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1a353e8a48, total write size = 622264, bytes this sub-write = 622264, bytes actually written = 18446744073709551615, offset = 1277952)
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m Traceback (most recent call last):
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165318)[0m     self._entrypoint()
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165318)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165318)[0m     output = train_func(config, reporter)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165318)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165318)[0m     config=config)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165318)[0m     model.save(model_path, config_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165318)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165318)[0m     self.model.save(model_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165318)[0m     signatures)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165318)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165318)[0m     f.close()
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165318)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165318)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:49 2020
[2m[36m(pid=165318)[0m , filename = '/tmp/thalvari/4065562/automl_save_z8hdik43/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1a355a2b40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165318)[0m Exception in thread Thread-1:
[2m[36m(pid=165318)[0m Traceback (most recent call last):
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165318)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165318)[0m     param_dset[:] = val
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165318)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165318)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165318)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165318)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:49 2020
[2m[36m(pid=165318)[0m , filename = '/tmp/thalvari/4065562/automl_save_z8hdik43/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1a353e8a48, total write size = 622264, bytes this sub-write = 622264, bytes actually written = 18446744073709551615, offset = 1277952)
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m Traceback (most recent call last):
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165318)[0m     self._entrypoint()
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165318)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165318)[0m     output = train_func(config, reporter)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165318)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165318)[0m     config=config)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165318)[0m     model.save(model_path, config_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165318)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165318)[0m     self.model.save(model_path)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165318)[0m     signatures)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165318)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165318)[0m     f.close()
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165318)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165318)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165318)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:49 2020
[2m[36m(pid=165318)[0m , filename = '/tmp/thalvari/4065562/automl_save_z8hdik43/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1a355a2b40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m Traceback (most recent call last):
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165318)[0m     self.run()
[2m[36m(pid=165318)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165318)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165318)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165318)[0m 
2020-11-20 13:43:50,859	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165318, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:50,863	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165321)[0m 2020-11-20 13:43:50,902	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165321)[0m Traceback (most recent call last):
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165321)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165321)[0m     param_dset[:] = val
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165321)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165321)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165321)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165321)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165321)[0m , filename = '/tmp/thalvari/4065562/automl_save_3gi1sgt6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe09d1d858, total write size = 43096, bytes this sub-write = 43096, bytes actually written = 18446744073709551615, offset = 200704)
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m Traceback (most recent call last):
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165321)[0m     self._entrypoint()
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165321)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165321)[0m     output = train_func(config, reporter)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165321)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165321)[0m     config=config)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165321)[0m     model.save(model_path, config_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165321)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165321)[0m     self.model.save(model_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165321)[0m     signatures)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165321)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165321)[0m     f.close()
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165321)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165321)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165321)[0m , filename = '/tmp/thalvari/4065562/automl_save_3gi1sgt6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe0a5e7420, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165321)[0m Exception in thread Thread-1:
[2m[36m(pid=165321)[0m Traceback (most recent call last):
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165321)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165321)[0m     param_dset[:] = val
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165321)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165321)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165321)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165321)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165321)[0m , filename = '/tmp/thalvari/4065562/automl_save_3gi1sgt6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe09d1d858, total write size = 43096, bytes this sub-write = 43096, bytes actually written = 18446744073709551615, offset = 200704)
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m Traceback (most recent call last):
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165321)[0m     self._entrypoint()
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165321)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165321)[0m     output = train_func(config, reporter)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165321)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165321)[0m     config=config)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165321)[0m     model.save(model_path, config_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165321)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165321)[0m     self.model.save(model_path)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165321)[0m     signatures)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165321)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165321)[0m     f.close()
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165321)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165321)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165321)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165321)[0m , filename = '/tmp/thalvari/4065562/automl_save_3gi1sgt6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7efe0a5e7420, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165330)[0m 2020-11-20 13:43:50,904	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165330)[0m Traceback (most recent call last):
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165330)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165330)[0m     param_dset[:] = val
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165330)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165330)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165330)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165330)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165330)[0m , filename = '/tmp/thalvari/4065562/automl_save_s2cscyfr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8f3a709dc8, total write size = 44392, bytes this sub-write = 44392, bytes actually written = 18446744073709551615, offset = 1269760)
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m Traceback (most recent call last):
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165330)[0m     self._entrypoint()
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165330)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165330)[0m     output = train_func(config, reporter)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165330)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165330)[0m     config=config)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165330)[0m     model.save(model_path, config_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165330)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165330)[0m     self.model.save(model_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165330)[0m     signatures)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165330)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165330)[0m     f.close()
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165330)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165330)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165330)[0m , filename = '/tmp/thalvari/4065562/automl_save_s2cscyfr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8f39589470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165330)[0m Exception in thread Thread-1:
[2m[36m(pid=165330)[0m Traceback (most recent call last):
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=165330)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=165330)[0m     param_dset[:] = val
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165330)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165330)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165330)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165330)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165330)[0m , filename = '/tmp/thalvari/4065562/automl_save_s2cscyfr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8f3a709dc8, total write size = 44392, bytes this sub-write = 44392, bytes actually written = 18446744073709551615, offset = 1269760)
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m Traceback (most recent call last):
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165330)[0m     self._entrypoint()
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165330)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165330)[0m     output = train_func(config, reporter)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165330)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165330)[0m     config=config)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165330)[0m     model.save(model_path, config_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165330)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165330)[0m     self.model.save(model_path)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165330)[0m     signatures)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165330)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165330)[0m     f.close()
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165330)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165330)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165330)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:43:50 2020
[2m[36m(pid=165330)[0m , filename = '/tmp/thalvari/4065562/automl_save_s2cscyfr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8f39589470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m Traceback (most recent call last):
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165321)[0m     self.run()
[2m[36m(pid=165321)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165321)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165321)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m Traceback (most recent call last):
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165330)[0m     self.run()
[2m[36m(pid=165330)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165330)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165330)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165318)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165318)[0m 
[2m[36m(pid=165318)[0m Stack (most recent call first):
[2m[36m(pid=163549)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163549)[0m   agg_primitives: ['count']
[2m[36m(pid=163549)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163549)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165327)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165327)[0m   agg_primitives: ['count']
[2m[36m(pid=165327)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165327)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 13:43:52,651	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165330, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:52,654	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163549)[0m LSTM is selected.
[2m[36m(pid=165327)[0m LSTM is selected.
[2m[36m(pid=163549)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163549)[0m Instructions for updating:
[2m[36m(pid=163549)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165327)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165327)[0m Instructions for updating:
[2m[36m(pid=165327)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165330)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165330)[0m 
[2m[36m(pid=165330)[0m Stack (most recent call first):
[2m[36m(pid=163540)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163540)[0m   agg_primitives: ['count']
[2m[36m(pid=163540)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163540)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165327)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165327)[0m Instructions for updating:
[2m[36m(pid=165327)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163549)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163549)[0m Instructions for updating:
[2m[36m(pid=163549)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163540)[0m LSTM is selected.
[2m[36m(pid=163540)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163540)[0m Instructions for updating:
[2m[36m(pid=163540)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163540)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163540)[0m Instructions for updating:
[2m[36m(pid=163540)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 23 ({'TERMINATED': 3, 'ERROR': 10, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAK_2020-11-20_13-43-24rramu4xg/error_2020-11-20_13-43-37.txt
  ... 2 not shown
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AW_2020-11-20_13-43-38cc3st3ht/error_2020-11-20_13-43-52.txt
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AW_2020-11-20_13-43-38rksi7eh0/error_2020-11-20_13-43-50.txt
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AW_2020-11-20_13-43-39938w3q6k/error_2020-11-20_13-43-49.txt
 - train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AW_2020-11-20_13-43-391uhzi0v1/error_2020-11-20_13-43-48.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163566], 16 s, 2 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163536], 19 s, 4 iter
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165325], 9 s, 3 iter
 - train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165321], 6 s, 1 iter
  ... 2 not shown
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165339], 10 s, 5 iter

2020-11-20 13:43:53,959	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165321, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:43:53,963	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163543)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163543)[0m   agg_primitives: ['count']
[2m[36m(pid=163543)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163543)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165321)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165321)[0m 
[2m[36m(pid=165321)[0m Stack (most recent call first):
[2m[36m(pid=165327)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165327)[0m 2020-11-20 13:43:54.159551: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165327)[0m 2020-11-20 13:43:54.167266: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165327)[0m 2020-11-20 13:43:54.169362: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f45010efcb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165327)[0m 2020-11-20 13:43:54.169385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163549)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163549)[0m 2020-11-20 13:43:54.268802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163549)[0m 2020-11-20 13:43:54.277505: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163549)[0m 2020-11-20 13:43:54.280140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa68111f6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163549)[0m 2020-11-20 13:43:54.280176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163543)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163543)[0m Instructions for updating:
[2m[36m(pid=163543)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163543)[0m LSTM is selected.
[2m[36m(pid=163540)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163540)[0m 2020-11-20 13:43:54.828059: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163540)[0m 2020-11-20 13:43:54.835739: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163540)[0m 2020-11-20 13:43:54.837864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4c890ef620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163540)[0m 2020-11-20 13:43:54.837892: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163543)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163543)[0m Instructions for updating:
[2m[36m(pid=163543)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163533)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163533)[0m   agg_primitives: ['count']
[2m[36m(pid=163533)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163533)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163543)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163543)[0m 2020-11-20 13:43:55.998209: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163543)[0m 2020-11-20 13:43:56.007621: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163543)[0m 2020-11-20 13:43:56.009879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1ff10ef9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163543)[0m 2020-11-20 13:43:56.009904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163533)[0m LSTM is selected.
[2m[36m(pid=163533)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163533)[0m Instructions for updating:
[2m[36m(pid=163533)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163533)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163533)[0m Instructions for updating:
[2m[36m(pid=163533)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163554)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163554)[0m   agg_primitives: ['count']
[2m[36m(pid=163554)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163554)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163533)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163533)[0m 2020-11-20 13:43:57.768634: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163533)[0m 2020-11-20 13:43:57.779330: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163533)[0m 2020-11-20 13:43:57.781866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5381104900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163533)[0m 2020-11-20 13:43:57.781900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163554)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163554)[0m Instructions for updating:
[2m[36m(pid=163554)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163554)[0m LSTM is selected.
[2m[36m(pid=163554)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163554)[0m Instructions for updating:
[2m[36m(pid=163554)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163565)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163565)[0m   agg_primitives: ['count']
[2m[36m(pid=163565)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163565)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163530)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163530)[0m   agg_primitives: ['count']
[2m[36m(pid=163530)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163530)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163556)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163556)[0m   agg_primitives: ['count']
[2m[36m(pid=163556)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163556)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 26 ({'TERMINATED': 5, 'ERROR': 11, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAK_2020-11-20_13-43-24rramu4xg/error_2020-11-20_13-43-37.txt
  ... 3 not shown
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AW_2020-11-20_13-43-38rksi7eh0/error_2020-11-20_13-43-50.txt
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AW_2020-11-20_13-43-39938w3q6k/error_2020-11-20_13-43-49.txt
 - train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AW_2020-11-20_13-43-391uhzi0v1/error_2020-11-20_13-43-48.txt
 - train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWA_2020-11-20_13-43-40kqy5x60d/error_2020-11-20_13-43-53.txt, [4 CPUs, 0 GPUs], [pid=165321], 6 s, 1 iter
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163566], 21 s, 3 iter
 - train_func_18_batch_size_log=6.2657,bayes_feature_DAY(timestamp)=0.525,bayes_feature_HOUR(timestamp)=0.39319,bayes_feature_IS_AWAKE(timestamp)=0.72607,bayes_feature_IS_BUSY_HOURS(timestamp)=0.44228,bayes_feature_IS_WEEKEND(timestamp)=0.60691,bayes_feature_MONTH(timestamp)=0.90781,bayes_feature_WEEKDAY(timestamp)=0.81902,dropout_1=0.32945,dropout_2=0.47667,epochs=5,lr=0.0011228,lstm_1_units_float=87.648,lstm_2_units_float=30.891,past_seq_len=2:	RUNNING
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 2 not shown
 - train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.511,lstm_2_units_float=114.95,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165339], 10 s, 5 iter
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165325], 14 s, 5 iter

[2m[36m(pid=163565)[0m LSTM is selected.
[2m[36m(pid=163530)[0m LSTM is selected.
[2m[36m(pid=163565)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163565)[0m Instructions for updating:
[2m[36m(pid=163565)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163530)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163530)[0m Instructions for updating:
[2m[36m(pid=163530)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163554)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163554)[0m 2020-11-20 13:43:59.641940: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163556)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163556)[0m Instructions for updating:
[2m[36m(pid=163556)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163556)[0m LSTM is selected.
[2m[36m(pid=163554)[0m 2020-11-20 13:43:59.652583: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163554)[0m 2020-11-20 13:43:59.657528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa519104fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163554)[0m 2020-11-20 13:43:59.657577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163565)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163565)[0m Instructions for updating:
[2m[36m(pid=163565)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163530)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163530)[0m Instructions for updating:
[2m[36m(pid=163530)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163556)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163556)[0m Instructions for updating:
[2m[36m(pid=163556)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163565)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163565)[0m 2020-11-20 13:44:00.904328: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163565)[0m 2020-11-20 13:44:00.917488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163565)[0m 2020-11-20 13:44:00.922832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2bf9104fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163565)[0m 2020-11-20 13:44:00.922890: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163530)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163530)[0m 2020-11-20 13:44:00.936929: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163530)[0m 2020-11-20 13:44:00.949277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163530)[0m 2020-11-20 13:44:00.952502: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eedb10eca90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163530)[0m 2020-11-20 13:44:00.952541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163556)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163556)[0m 2020-11-20 13:44:01.257788: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163556)[0m 2020-11-20 13:44:01.268917: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163556)[0m 2020-11-20 13:44:01.274055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb685107ae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163556)[0m 2020-11-20 13:44:01.274100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163554)[0m 2020-11-20 13:44:04,148	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163554)[0m Traceback (most recent call last):
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163554)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163554)[0m     param_dset[:] = val
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163554)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163554)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163554)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163554)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163554)[0m , filename = '/tmp/thalvari/4065562/automl_save_ww3zn6if/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa51a8232f8, total write size = 215672, bytes this sub-write = 215672, bytes actually written = 18446744073709551615, offset = 458752)
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m Traceback (most recent call last):
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163554)[0m     self._entrypoint()
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163554)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163554)[0m     output = train_func(config, reporter)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163554)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163554)[0m     config=config)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163554)[0m     model.save(model_path, config_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163554)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163554)[0m     self.model.save(model_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163554)[0m     signatures)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163554)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163554)[0m     f.close()
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163554)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163554)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163554)[0m , filename = '/tmp/thalvari/4065562/automl_save_ww3zn6if/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa51989bd60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163554)[0m Exception in thread Thread-1:
[2m[36m(pid=163554)[0m Traceback (most recent call last):
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163554)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163554)[0m     param_dset[:] = val
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163554)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163554)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163554)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163554)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163554)[0m , filename = '/tmp/thalvari/4065562/automl_save_ww3zn6if/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa51a8232f8, total write size = 215672, bytes this sub-write = 215672, bytes actually written = 18446744073709551615, offset = 458752)
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m Traceback (most recent call last):
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163554)[0m     self._entrypoint()
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163554)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163554)[0m     output = train_func(config, reporter)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163554)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163554)[0m     config=config)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163554)[0m     model.save(model_path, config_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163554)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163554)[0m     self.model.save(model_path)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163554)[0m     signatures)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163554)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163554)[0m     f.close()
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163554)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163554)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163554)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163554)[0m , filename = '/tmp/thalvari/4065562/automl_save_ww3zn6if/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa51989bd60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m Traceback (most recent call last):
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163554)[0m     self.run()
[2m[36m(pid=163554)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163554)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163554)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163549)[0m 2020-11-20 13:44:04,516	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163549)[0m Traceback (most recent call last):
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163549)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163549)[0m     param_dset[:] = val
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163549)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163549)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163549)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163549)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163549)[0m , filename = '/tmp/thalvari/4065562/automl_save_13rhxyic/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6829757d8, total write size = 125016, bytes this sub-write = 125016, bytes actually written = 18446744073709551615, offset = 696320)
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m Traceback (most recent call last):
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163549)[0m     self._entrypoint()
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163549)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163549)[0m     output = train_func(config, reporter)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163549)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163549)[0m     config=config)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163549)[0m     model.save(model_path, config_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163549)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163549)[0m     self.model.save(model_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163549)[0m     signatures)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163549)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163549)[0m     f.close()
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163549)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163549)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163549)[0m , filename = '/tmp/thalvari/4065562/automl_save_13rhxyic/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa681f22fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163549)[0m Exception in thread Thread-1:
[2m[36m(pid=163549)[0m Traceback (most recent call last):
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163549)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163549)[0m     param_dset[:] = val
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163549)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163549)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163549)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163549)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163549)[0m , filename = '/tmp/thalvari/4065562/automl_save_13rhxyic/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa6829757d8, total write size = 125016, bytes this sub-write = 125016, bytes actually written = 18446744073709551615, offset = 696320)
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m Traceback (most recent call last):
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163549)[0m     self._entrypoint()
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163549)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163549)[0m     output = train_func(config, reporter)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163549)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163549)[0m     config=config)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163549)[0m     model.save(model_path, config_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163549)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163549)[0m     self.model.save(model_path)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163549)[0m     signatures)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163549)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163549)[0m     f.close()
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163549)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163549)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163549)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163549)[0m , filename = '/tmp/thalvari/4065562/automl_save_13rhxyic/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa681f22fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163533)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5381f4c550, total write size = 8824, bytes this sub-write = 8824, bytes actually written = 18446744073709551615, offset = 401408)
[2m[36m(pid=163533)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163533)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5381f4c550, total write size = 8824, bytes this sub-write = 8824, bytes actually written = 18446744073709551615, offset = 401408)
[2m[36m(pid=163533)[0m 2020-11-20 13:44:04,512	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163533)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163533)[0m     param_dset[:] = val
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163533)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163533)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163533)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163533)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5382856810, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 412280)
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163533)[0m     self._entrypoint()
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163533)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163533)[0m     output = train_func(config, reporter)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163533)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163533)[0m     config=config)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163533)[0m     model.save(model_path, config_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163533)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163533)[0m     self.model.save(model_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163533)[0m     signatures)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163533)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163533)[0m     f.close()
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163533)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163533)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f53817aacd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163533)[0m Exception in thread Thread-1:
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163533)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163533)[0m     param_dset[:] = val
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163533)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163533)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163533)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163533)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5382856810, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 412280)
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163533)[0m     self._entrypoint()
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163533)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163533)[0m     output = train_func(config, reporter)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163533)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163533)[0m     config=config)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163533)[0m     model.save(model_path, config_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163533)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163533)[0m     self.model.save(model_path)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163533)[0m     signatures)
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163533)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m Traceback (most recent call last):
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163549)[0m     self.run()
[2m[36m(pid=163549)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163549)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163549)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163533)[0m     f.close()
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163533)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163533)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163533)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163533)[0m , filename = '/tmp/thalvari/4065562/automl_save_56bwid71/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f53817aacd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m Traceback (most recent call last):
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163533)[0m     self.run()
[2m[36m(pid=163533)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163533)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163533)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163556)[0m 2020-11-20 13:44:04,557	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163556)[0m Traceback (most recent call last):
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163556)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163556)[0m     param_dset[:] = val
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163556)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163556)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163556)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163556)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163556)[0m , filename = '/tmp/thalvari/4065562/automl_save_lystunaz/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb686a4f728, total write size = 403000, bytes this sub-write = 403000, bytes actually written = 18446744073709551615, offset = 995328)
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m Traceback (most recent call last):
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163556)[0m     self._entrypoint()
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163556)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163556)[0m     output = train_func(config, reporter)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163556)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163556)[0m     config=config)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163556)[0m     model.save(model_path, config_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163556)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163556)[0m     self.model.save(model_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163556)[0m     signatures)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163556)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163556)[0m     f.close()
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163556)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163556)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163556)[0m , filename = '/tmp/thalvari/4065562/automl_save_lystunaz/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb68552afe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163556)[0m Exception in thread Thread-1:
[2m[36m(pid=163556)[0m Traceback (most recent call last):
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163556)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163556)[0m     param_dset[:] = val
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163556)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163556)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163556)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163556)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163556)[0m , filename = '/tmp/thalvari/4065562/automl_save_lystunaz/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb686a4f728, total write size = 403000, bytes this sub-write = 403000, bytes actually written = 18446744073709551615, offset = 995328)
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m Traceback (most recent call last):
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163556)[0m     self._entrypoint()
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163556)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163556)[0m     output = train_func(config, reporter)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163556)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163556)[0m     config=config)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163556)[0m     model.save(model_path, config_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163556)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163556)[0m     self.model.save(model_path)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163556)[0m     signatures)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163556)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163556)[0m     f.close()
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163556)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163556)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163556)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:04 2020
[2m[36m(pid=163556)[0m , filename = '/tmp/thalvari/4065562/automl_save_lystunaz/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb68552afe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m Traceback (most recent call last):
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163556)[0m     self.run()
[2m[36m(pid=163556)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163556)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163556)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163556)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 20.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 26 ({'TERMINATED': 5, 'ERROR': 11, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAK_2020-11-20_13-43-24rramu4xg/error_2020-11-20_13-43-37.txt
  ... 3 not shown
 - train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AWAKE(timestamp)=0.89278,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46789,bayes_feature_IS_WEEKEND(timestamp)=0.64564,bayes_feature_MONTH(timestamp)=0.73397,bayes_feature_WEEKDAY(timestamp)=0.88029,dropout_1=0.24704,dropout_2=0.20557,epochs=5,lr=0.0016302,lstm_1_units_float=66.361,lstm_2_units_float=80.76,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_13_batch_size_log=5.9771,bayes_feature_DAY(timestamp)=0.70695,bayes_feature_HOUR(timestamp)=0.97901,bayes_feature_IS_AW_2020-11-20_13-43-38rksi7eh0/error_2020-11-20_13-43-50.txt
 - train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AWAKE(timestamp)=0.86333,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4354,bayes_feature_IS_WEEKEND(timestamp)=0.74762,bayes_feature_MONTH(timestamp)=0.66727,bayes_feature_WEEKDAY(timestamp)=0.94737,dropout_1=0.27899,dropout_2=0.21979,epochs=5,lr=0.0076156,lstm_1_units_float=100.66,lstm_2_units_float=116.94,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_15_batch_size_log=8.7638,bayes_feature_DAY(timestamp)=0.34658,bayes_feature_HOUR(timestamp)=0.48222,bayes_feature_IS_AW_2020-11-20_13-43-39938w3q6k/error_2020-11-20_13-43-49.txt
 - train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AWAKE(timestamp)=0.73174,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96431,bayes_feature_IS_WEEKEND(timestamp)=0.96512,bayes_feature_MONTH(timestamp)=0.68966,bayes_feature_WEEKDAY(timestamp)=0.94092,dropout_1=0.39247,dropout_2=0.317,epochs=5,lr=0.0053739,lstm_1_units_float=80.517,lstm_2_units_float=73.946,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_16_batch_size_log=9.6599,bayes_feature_DAY(timestamp)=0.30977,bayes_feature_HOUR(timestamp)=0.46405,bayes_feature_IS_AW_2020-11-20_13-43-391uhzi0v1/error_2020-11-20_13-43-48.txt
 - train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_17_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWA_2020-11-20_13-43-40kqy5x60d/error_2020-11-20_13-43-53.txt, [4 CPUs, 0 GPUs], [pid=165321], 6 s, 1 iter
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163566], 29 s, 4 iter
 - train_func_18_batch_size_log=6.2657,bayes_feature_DAY(timestamp)=0.525,bayes_feature_HOUR(timestamp)=0.39319,bayes_feature_IS_AWAKE(timestamp)=0.72607,bayes_feature_IS_BUSY_HOURS(timestamp)=0.44228,bayes_feature_IS_WEEKEND(timestamp)=0.60691,bayes_feature_MONTH(timestamp)=0.90781,bayes_feature_WEEKDAY(timestamp)=0.81902,dropout_1=0.32945,dropout_2=0.47667,epochs=5,lr=0.0011228,lstm_1_units_float=87.648,lstm_2_units_float=30.891,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165327], 12 s, 2 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 2 not shown
 - train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163554], 5 s, 1 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163565], 5 s, 1 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163530], 6 s, 1 iter
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.511,lstm_2_units_float=114.95,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165339], 10 s, 5 iter
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165325], 14 s, 5 iter

2020-11-20 13:44:05,188	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163554, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:05,193	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163554)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163554)[0m 
[2m[36m(pid=163554)[0m Stack (most recent call first):
[2m[36m(pid=163540)[0m 2020-11-20 13:44:05,960	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163540)[0m Traceback (most recent call last):
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163540)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163540)[0m     param_dset[:] = val
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163540)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163540)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163540)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163540)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:05 2020
[2m[36m(pid=163540)[0m , filename = '/tmp/thalvari/4065562/automl_save_a54fa7k3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4c8aa537d8, total write size = 661592, bytes this sub-write = 661592, bytes actually written = 18446744073709551615, offset = 1216512)
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m Traceback (most recent call last):
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163540)[0m     self._entrypoint()
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163540)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163540)[0m     output = train_func(config, reporter)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163540)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163540)[0m     config=config)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163540)[0m     model.save(model_path, config_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163540)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163540)[0m     self.model.save(model_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163540)[0m     signatures)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163540)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163540)[0m     f.close()
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163540)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163540)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:05 2020
[2m[36m(pid=163540)[0m , filename = '/tmp/thalvari/4065562/automl_save_a54fa7k3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4c89eec410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163540)[0m Exception in thread Thread-1:
[2m[36m(pid=163540)[0m Traceback (most recent call last):
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163540)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163540)[0m     param_dset[:] = val
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163540)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163540)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163540)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163540)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:05 2020
[2m[36m(pid=163540)[0m , filename = '/tmp/thalvari/4065562/automl_save_a54fa7k3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4c8aa537d8, total write size = 661592, bytes this sub-write = 661592, bytes actually written = 18446744073709551615, offset = 1216512)
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m Traceback (most recent call last):
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163540)[0m     self._entrypoint()
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163540)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163540)[0m     output = train_func(config, reporter)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163540)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163540)[0m     config=config)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163540)[0m     model.save(model_path, config_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163540)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163540)[0m     self.model.save(model_path)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163540)[0m     signatures)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163540)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163540)[0m     f.close()
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163540)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163540)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163540)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:05 2020
[2m[36m(pid=163540)[0m , filename = '/tmp/thalvari/4065562/automl_save_a54fa7k3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4c89eec410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m Traceback (most recent call last):
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163540)[0m     self.run()
[2m[36m(pid=163540)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163540)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163540)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163540)[0m 
2020-11-20 13:44:06,253	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163549, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:06,256	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163549)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163549)[0m 
[2m[36m(pid=163549)[0m Stack (most recent call first):
2020-11-20 13:44:06,730	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163556, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:06,732	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.511,lstm_2_units_float=114.95,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163556)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163556)[0m 
[2m[36m(pid=163556)[0m Stack (most recent call first):
2020-11-20 13:44:07,263	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163540, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:07,265	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_20_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163540)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163540)[0m 
[2m[36m(pid=163540)[0m Stack (most recent call first):
2020-11-20 13:44:07,899	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163533, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:07,902	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_22_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163533)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163533)[0m 
[2m[36m(pid=163533)[0m Stack (most recent call first):
[2m[36m(pid=163544)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163544)[0m   agg_primitives: ['count']
[2m[36m(pid=163544)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163544)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165343)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165343)[0m   agg_primitives: ['count']
[2m[36m(pid=165343)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165343)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163544)[0m LSTM is selected.
[2m[36m(pid=165343)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165343)[0m Instructions for updating:
[2m[36m(pid=165343)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165343)[0m LSTM is selected.
[2m[36m(pid=163544)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163544)[0m Instructions for updating:
[2m[36m(pid=163544)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 33 ({'TERMINATED': 7, 'ERROR': 16, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 10 not shown
 - train_func_22_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_22_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-43-52fssyzb3y/error_2020-11-20_13-44-07.txt, [4 CPUs, 0 GPUs], [pid=163533], 7 s, 3 iter
 - train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-43-53x_9y1rmy/error_2020-11-20_13-44-05.txt, [4 CPUs, 0 GPUs], [pid=163554], 5 s, 1 iter
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.511,lstm_2_units_float=114.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-43-55av8uhlve/error_2020-11-20_13-44-06.txt
RUNNING trials:
 - train_func_18_batch_size_log=6.2657,bayes_feature_DAY(timestamp)=0.525,bayes_feature_HOUR(timestamp)=0.39319,bayes_feature_IS_AWAKE(timestamp)=0.72607,bayes_feature_IS_BUSY_HOURS(timestamp)=0.44228,bayes_feature_IS_WEEKEND(timestamp)=0.60691,bayes_feature_MONTH(timestamp)=0.90781,bayes_feature_WEEKDAY(timestamp)=0.81902,dropout_1=0.32945,dropout_2=0.47667,epochs=5,lr=0.0011228,lstm_1_units_float=87.648,lstm_2_units_float=30.891,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165327], 15 s, 3 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163565], 11 s, 3 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=163530], 7 s, 2 iter
  ... 4 not shown
 - train_func_31_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.322,lstm_2_units_float=102.86,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.86,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=73.418,lstm_2_units_float=107.1,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163532], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165339], 10 s, 5 iter
 - train_func_14_batch_size_log=7.8443,bayes_feature_DAY(timestamp)=0.52215,bayes_feature_HOUR(timestamp)=0.99203,bayes_feature_IS_AWAKE(timestamp)=0.70582,bayes_feature_IS_BUSY_HOURS(timestamp)=0.5661,bayes_feature_IS_WEEKEND(timestamp)=0.68566,bayes_feature_MONTH(timestamp)=0.82173,bayes_feature_WEEKDAY(timestamp)=0.76846,dropout_1=0.27948,dropout_2=0.2199,epochs=5,lr=0.0043308,lstm_1_units_float=83.566,lstm_2_units_float=33.221,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=165325], 14 s, 5 iter
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter

[2m[36m(pid=163551)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163551)[0m   agg_primitives: ['count']
[2m[36m(pid=163551)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163551)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163544)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163544)[0m Instructions for updating:
[2m[36m(pid=163544)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165343)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165343)[0m Instructions for updating:
[2m[36m(pid=165343)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163551)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163551)[0m Instructions for updating:
[2m[36m(pid=163551)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163551)[0m LSTM is selected.
[2m[36m(pid=165315)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165315)[0m   agg_primitives: ['count']
[2m[36m(pid=165315)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165315)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163551)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163551)[0m Instructions for updating:
[2m[36m(pid=163551)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165315)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165315)[0m Instructions for updating:
[2m[36m(pid=165315)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165315)[0m LSTM is selected.
[2m[36m(pid=165343)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165343)[0m 2020-11-20 13:44:10.938286: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165343)[0m 2020-11-20 13:44:10.948747: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165343)[0m 2020-11-20 13:44:10.951118: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f11d1107400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165343)[0m 2020-11-20 13:44:10.951141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163544)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163544)[0m 2020-11-20 13:44:10.962721: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163544)[0m 2020-11-20 13:44:10.973376: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163544)[0m 2020-11-20 13:44:10.978065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba85107400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163544)[0m 2020-11-20 13:44:10.978104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163531)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163531)[0m   agg_primitives: ['count']
[2m[36m(pid=163531)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163531)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165315)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165315)[0m Instructions for updating:
[2m[36m(pid=165315)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163551)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163551)[0m 2020-11-20 13:44:11.712592: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163551)[0m 2020-11-20 13:44:11.721358: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163551)[0m 2020-11-20 13:44:11.724842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f413d107620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163551)[0m 2020-11-20 13:44:11.724874: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163531)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163531)[0m Instructions for updating:
[2m[36m(pid=163531)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163531)[0m LSTM is selected.
[2m[36m(pid=163561)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163561)[0m   agg_primitives: ['count']
[2m[36m(pid=163561)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163561)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163553)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163553)[0m   agg_primitives: ['count']
[2m[36m(pid=163553)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163553)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163561)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163561)[0m Instructions for updating:
[2m[36m(pid=163561)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163561)[0m LSTM is selected.
[2m[36m(pid=163553)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163553)[0m Instructions for updating:
[2m[36m(pid=163553)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163553)[0m LSTM is selected.
[2m[36m(pid=165315)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165315)[0m 2020-11-20 13:44:12.426757: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165315)[0m 2020-11-20 13:44:12.434723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165315)[0m 2020-11-20 13:44:12.438331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7781107300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165315)[0m 2020-11-20 13:44:12.438367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163531)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163531)[0m Instructions for updating:
[2m[36m(pid=163531)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163561)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163561)[0m Instructions for updating:
[2m[36m(pid=163561)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163553)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163553)[0m Instructions for updating:
[2m[36m(pid=163553)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163531)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163531)[0m 2020-11-20 13:44:13.589440: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163531)[0m 2020-11-20 13:44:13.600356: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163531)[0m 2020-11-20 13:44:13.602856: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eeeb5107900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163531)[0m 2020-11-20 13:44:13.602891: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163544)[0m 2020-11-20 13:44:13,753	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163544)[0m Traceback (most recent call last):
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163544)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163544)[0m     param_dset[:] = val
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163544)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163544)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163544)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163544)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=163544)[0m , filename = '/tmp/thalvari/4065562/automl_save__v5gg6wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fba868430d8, total write size = 506680, bytes this sub-write = 506680, bytes actually written = 18446744073709551615, offset = 753664)
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m Traceback (most recent call last):
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163544)[0m     self._entrypoint()
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163544)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163544)[0m     output = train_func(config, reporter)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163544)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163544)[0m     config=config)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163544)[0m     model.save(model_path, config_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163544)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163544)[0m     self.model.save(model_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163544)[0m     signatures)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163544)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163544)[0m     f.close()
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163544)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163544)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=163544)[0m , filename = '/tmp/thalvari/4065562/automl_save__v5gg6wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fba86256d30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163544)[0m Exception in thread Thread-1:
[2m[36m(pid=163544)[0m Traceback (most recent call last):
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163544)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163544)[0m     param_dset[:] = val
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163544)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163544)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163544)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163544)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=163544)[0m , filename = '/tmp/thalvari/4065562/automl_save__v5gg6wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fba868430d8, total write size = 506680, bytes this sub-write = 506680, bytes actually written = 18446744073709551615, offset = 753664)
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m Traceback (most recent call last):
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163544)[0m     self._entrypoint()
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163544)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163544)[0m     output = train_func(config, reporter)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163544)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163544)[0m     config=config)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163544)[0m     model.save(model_path, config_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163544)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163544)[0m     self.model.save(model_path)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163544)[0m     signatures)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163544)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163544)[0m     f.close()
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163544)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163544)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163544)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=163544)[0m , filename = '/tmp/thalvari/4065562/automl_save__v5gg6wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fba86256d30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165343)[0m 2020-11-20 13:44:13,762	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165343)[0m Traceback (most recent call last):
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165343)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165343)[0m     param_dset[:] = val
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165343)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165343)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165343)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165343)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=165343)[0m , filename = '/tmp/thalvari/4065562/automl_save_89e1bx6o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f11d28dcc88, total write size = 190008, bytes this sub-write = 190008, bytes actually written = 18446744073709551615, offset = 1208320)
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m Traceback (most recent call last):
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165343)[0m     self._entrypoint()
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165343)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165343)[0m     output = train_func(config, reporter)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165343)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165343)[0m     config=config)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165343)[0m     model.save(model_path, config_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165343)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165343)[0m     self.model.save(model_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165343)[0m     signatures)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165343)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165343)[0m     f.close()
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165343)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165343)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=165343)[0m , filename = '/tmp/thalvari/4065562/automl_save_89e1bx6o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f11d1f54b80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165343)[0m Exception in thread Thread-1:
[2m[36m(pid=165343)[0m Traceback (most recent call last):
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165343)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165343)[0m     param_dset[:] = val
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165343)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165343)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165343)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165343)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=165343)[0m , filename = '/tmp/thalvari/4065562/automl_save_89e1bx6o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f11d28dcc88, total write size = 190008, bytes this sub-write = 190008, bytes actually written = 18446744073709551615, offset = 1208320)
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m Traceback (most recent call last):
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165343)[0m     self._entrypoint()
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165343)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165343)[0m     output = train_func(config, reporter)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165343)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165343)[0m     config=config)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165343)[0m     model.save(model_path, config_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165343)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165343)[0m     self.model.save(model_path)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165343)[0m     signatures)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165343)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165343)[0m     f.close()
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165343)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165343)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165343)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:13 2020
[2m[36m(pid=165343)[0m , filename = '/tmp/thalvari/4065562/automl_save_89e1bx6o/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f11d1f54b80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m Traceback (most recent call last):
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163544)[0m     self.run()
[2m[36m(pid=163544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163544)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163544)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163544)[0m 
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m Traceback (most recent call last):
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165343)[0m     self.run()
[2m[36m(pid=165343)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165343)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165343)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165343)[0m 
[2m[36m(pid=163561)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163561)[0m 2020-11-20 13:44:14.052169: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163553)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163553)[0m 2020-11-20 13:44:14.037843: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163553)[0m 2020-11-20 13:44:14.045687: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163553)[0m 2020-11-20 13:44:14.048617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4251107530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163553)[0m 2020-11-20 13:44:14.048645: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163561)[0m 2020-11-20 13:44:14.064020: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163561)[0m 2020-11-20 13:44:14.065985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f161d1076c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163561)[0m 2020-11-20 13:44:14.066009: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163551)[0m 2020-11-20 13:44:14,616	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163551)[0m Traceback (most recent call last):
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163551)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163551)[0m     param_dset[:] = val
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163551)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163551)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163551)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163551)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:14 2020
[2m[36m(pid=163551)[0m , filename = '/tmp/thalvari/4065562/automl_save_zfrzynbk/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f413ea601d8, total write size = 68408, bytes this sub-write = 68408, bytes actually written = 18446744073709551615, offset = 1191936)
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m Traceback (most recent call last):
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163551)[0m     self._entrypoint()
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163551)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163551)[0m     output = train_func(config, reporter)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163551)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163551)[0m     config=config)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163551)[0m     model.save(model_path, config_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163551)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163551)[0m     self.model.save(model_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163551)[0m     signatures)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163551)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163551)[0m     f.close()
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163551)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163551)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:14 2020
[2m[36m(pid=163551)[0m , filename = '/tmp/thalvari/4065562/automl_save_zfrzynbk/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f413de16fc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163551)[0m Exception in thread Thread-1:
[2m[36m(pid=163551)[0m Traceback (most recent call last):
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163551)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163551)[0m     param_dset[:] = val
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163551)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163551)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163551)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163551)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:14 2020
[2m[36m(pid=163551)[0m , filename = '/tmp/thalvari/4065562/automl_save_zfrzynbk/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f413ea601d8, total write size = 68408, bytes this sub-write = 68408, bytes actually written = 18446744073709551615, offset = 1191936)
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m Traceback (most recent call last):
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163551)[0m     self._entrypoint()
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163551)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163551)[0m     output = train_func(config, reporter)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163551)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163551)[0m     config=config)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163551)[0m     model.save(model_path, config_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163551)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163551)[0m     self.model.save(model_path)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163551)[0m     signatures)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163551)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163551)[0m     f.close()
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163551)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163551)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163551)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:14 2020
[2m[36m(pid=163551)[0m , filename = '/tmp/thalvari/4065562/automl_save_zfrzynbk/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f413de16fc0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m Traceback (most recent call last):
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163551)[0m     self.run()
[2m[36m(pid=163551)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163551)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163551)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163551)[0m 
2020-11-20 13:44:14,952	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163544, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:14,955	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_28_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.85,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 35 ({'TERMINATED': 9, 'ERROR': 17, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 11 not shown
 - train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_23_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-43-53x_9y1rmy/error_2020-11-20_13-44-05.txt, [4 CPUs, 0 GPUs], [pid=163554], 5 s, 1 iter
 - train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.511,lstm_2_units_float=114.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_26_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-43-55av8uhlve/error_2020-11-20_13-44-06.txt
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.85,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_28_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-067jcqedz1/error_2020-11-20_13-44-14.txt
RUNNING trials:
 - train_func_18_batch_size_log=6.2657,bayes_feature_DAY(timestamp)=0.525,bayes_feature_HOUR(timestamp)=0.39319,bayes_feature_IS_AWAKE(timestamp)=0.72607,bayes_feature_IS_BUSY_HOURS(timestamp)=0.44228,bayes_feature_IS_WEEKEND(timestamp)=0.60691,bayes_feature_MONTH(timestamp)=0.90781,bayes_feature_WEEKDAY(timestamp)=0.81902,dropout_1=0.32945,dropout_2=0.47667,epochs=5,lr=0.0011228,lstm_1_units_float=87.648,lstm_2_units_float=30.891,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=165327], 19 s, 4 iter
 - train_func_27_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.515,lstm_2_units_float=114.93,past_seq_len=2:	RUNNING
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.325,lstm_2_units_float=102.85,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=73.418,lstm_2_units_float=107.1,past_seq_len=2:	RUNNING
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=72.374,lstm_2_units_float=112.13,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.188,lstm_2_units_float=77.974,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 3 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

[2m[36m(pid=163544)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163544)[0m 
[2m[36m(pid=163544)[0m Stack (most recent call first):
[2m[36m(pid=165315)[0m 2020-11-20 13:44:15,478	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165315)[0m Traceback (most recent call last):
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165315)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165315)[0m     param_dset[:] = val
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165315)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165315)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165315)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165315)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:15 2020
[2m[36m(pid=165315)[0m , filename = '/tmp/thalvari/4065562/automl_save_8be9tx07/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7782875c18, total write size = 76600, bytes this sub-write = 76600, bytes actually written = 18446744073709551615, offset = 1183744)
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m Traceback (most recent call last):
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165315)[0m     self._entrypoint()
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165315)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165315)[0m     output = train_func(config, reporter)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165315)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165315)[0m     config=config)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165315)[0m     model.save(model_path, config_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165315)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165315)[0m     self.model.save(model_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165315)[0m     signatures)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165315)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165315)[0m     f.close()
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165315)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165315)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:15 2020
[2m[36m(pid=165315)[0m , filename = '/tmp/thalvari/4065562/automl_save_8be9tx07/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7782358210, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165315)[0m Exception in thread Thread-1:
[2m[36m(pid=165315)[0m Traceback (most recent call last):
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165315)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165315)[0m     param_dset[:] = val
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165315)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165315)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165315)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165315)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:15 2020
[2m[36m(pid=165315)[0m , filename = '/tmp/thalvari/4065562/automl_save_8be9tx07/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7782875c18, total write size = 76600, bytes this sub-write = 76600, bytes actually written = 18446744073709551615, offset = 1183744)
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m Traceback (most recent call last):
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165315)[0m     self._entrypoint()
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165315)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165315)[0m     output = train_func(config, reporter)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165315)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165315)[0m     config=config)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165315)[0m     model.save(model_path, config_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165315)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165315)[0m     self.model.save(model_path)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165315)[0m     signatures)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165315)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165315)[0m     f.close()
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165315)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165315)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165315)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:15 2020
[2m[36m(pid=165315)[0m , filename = '/tmp/thalvari/4065562/automl_save_8be9tx07/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7782358210, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m Traceback (most recent call last):
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165315)[0m     self.run()
[2m[36m(pid=165315)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165315)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165315)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165315)[0m 
2020-11-20 13:44:15,903	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163551, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:15,908	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_29_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.325,lstm_2_units_float=102.85,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163551)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163551)[0m 
[2m[36m(pid=163551)[0m Stack (most recent call first):
[2m[36m(pid=165336)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=165336)[0m   agg_primitives: ['count']
[2m[36m(pid=165336)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=165336)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163531)[0m 2020-11-20 13:44:16,499	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163531)[0m Traceback (most recent call last):
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163531)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163531)[0m     param_dset[:] = val
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163531)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163531)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163531)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163531)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163531)[0m , filename = '/tmp/thalvari/4065562/automl_save_3vtv5rc_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eeeb6883cc8, total write size = 84792, bytes this sub-write = 84792, bytes actually written = 18446744073709551615, offset = 1175552)
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m Traceback (most recent call last):
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163531)[0m     self._entrypoint()
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163531)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163531)[0m     output = train_func(config, reporter)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163531)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163531)[0m     config=config)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163531)[0m     model.save(model_path, config_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163531)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163531)[0m     self.model.save(model_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163531)[0m     signatures)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163531)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163531)[0m     f.close()
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163531)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163531)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163531)[0m , filename = '/tmp/thalvari/4065562/automl_save_3vtv5rc_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eeeb5414110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163531)[0m Exception in thread Thread-1:
[2m[36m(pid=163531)[0m Traceback (most recent call last):
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163531)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163531)[0m     param_dset[:] = val
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163531)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163531)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163531)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163531)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163531)[0m , filename = '/tmp/thalvari/4065562/automl_save_3vtv5rc_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eeeb6883cc8, total write size = 84792, bytes this sub-write = 84792, bytes actually written = 18446744073709551615, offset = 1175552)
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m Traceback (most recent call last):
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163531)[0m     self._entrypoint()
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163531)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163531)[0m     output = train_func(config, reporter)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163531)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163531)[0m     config=config)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163531)[0m     model.save(model_path, config_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163531)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163531)[0m     self.model.save(model_path)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163531)[0m     signatures)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163531)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163531)[0m     f.close()
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163531)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163531)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163531)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163531)[0m , filename = '/tmp/thalvari/4065562/automl_save_3vtv5rc_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eeeb5414110, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m Traceback (most recent call last):
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163531)[0m     self.run()
[2m[36m(pid=163531)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163531)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163531)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163553)[0m 2020-11-20 13:44:16,731	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163553)[0m Traceback (most recent call last):
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163553)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163553)[0m     param_dset[:] = val
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163553)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163553)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163553)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163553)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163553)[0m , filename = '/tmp/thalvari/4065562/automl_save_fgp4vfm6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f425289d4d8, total write size = 101176, bytes this sub-write = 101176, bytes actually written = 18446744073709551615, offset = 1159168)
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m Traceback (most recent call last):
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163553)[0m     self._entrypoint()
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163553)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163553)[0m     output = train_func(config, reporter)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163553)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163553)[0m     config=config)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163553)[0m     model.save(model_path, config_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163553)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163553)[0m     self.model.save(model_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163553)[0m     signatures)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163553)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163553)[0m     f.close()
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163553)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163553)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163553)[0m , filename = '/tmp/thalvari/4065562/automl_save_fgp4vfm6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f42520bae20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163553)[0m Exception in thread Thread-1:
[2m[36m(pid=163553)[0m Traceback (most recent call last):
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163553)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163553)[0m     param_dset[:] = val
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163553)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163553)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163553)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163553)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163553)[0m , filename = '/tmp/thalvari/4065562/automl_save_fgp4vfm6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f425289d4d8, total write size = 101176, bytes this sub-write = 101176, bytes actually written = 18446744073709551615, offset = 1159168)
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m Traceback (most recent call last):
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163553)[0m     self._entrypoint()
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163553)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163553)[0m     output = train_func(config, reporter)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163553)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163553)[0m     config=config)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163553)[0m     model.save(model_path, config_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163553)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163553)[0m     self.model.save(model_path)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163553)[0m     signatures)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163553)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163553)[0m     f.close()
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163553)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163553)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163553)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163553)[0m , filename = '/tmp/thalvari/4065562/automl_save_fgp4vfm6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f42520bae20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m Traceback (most recent call last):
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163553)[0m     self.run()
[2m[36m(pid=163553)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163553)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163553)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163561)[0m 2020-11-20 13:44:16,827	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163561)[0m Traceback (most recent call last):
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163561)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163561)[0m     param_dset[:] = val
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163561)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163561)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163561)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163561)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163561)[0m , filename = '/tmp/thalvari/4065562/automl_save_fkglxfrr/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f161ea63ca8, total write size = 148440, bytes this sub-write = 148440, bytes actually written = 18446744073709551615, offset = 1159168)
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m Traceback (most recent call last):
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163561)[0m     self._entrypoint()
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163561)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163561)[0m     output = train_func(config, reporter)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163561)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163561)[0m     config=config)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163561)[0m     model.save(model_path, config_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163561)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163561)[0m     self.model.save(model_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163561)[0m     signatures)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163561)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163561)[0m     f.close()
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163561)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163561)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163561)[0m , filename = '/tmp/thalvari/4065562/automl_save_fkglxfrr/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f161def0a00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163561)[0m Exception in thread Thread-1:
[2m[36m(pid=163561)[0m Traceback (most recent call last):
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=163561)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=163561)[0m     param_dset[:] = val
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163561)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163561)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163561)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163561)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163561)[0m , filename = '/tmp/thalvari/4065562/automl_save_fkglxfrr/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f161ea63ca8, total write size = 148440, bytes this sub-write = 148440, bytes actually written = 18446744073709551615, offset = 1159168)
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m Traceback (most recent call last):
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163561)[0m     self._entrypoint()
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163561)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163561)[0m     output = train_func(config, reporter)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163561)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163561)[0m     config=config)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163561)[0m     model.save(model_path, config_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163561)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163561)[0m     self.model.save(model_path)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163561)[0m     signatures)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163561)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163561)[0m     f.close()
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163561)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163561)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163561)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:16 2020
[2m[36m(pid=163561)[0m , filename = '/tmp/thalvari/4065562/automl_save_fkglxfrr/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f161def0a00, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m Traceback (most recent call last):
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163561)[0m     self.run()
[2m[36m(pid=163561)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163561)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163561)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163561)[0m 
2020-11-20 13:44:16,903	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165343, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:16,905	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_27_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=73.515,lstm_2_units_float=114.93,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165336)[0m LSTM is selected.
[2m[36m(pid=165336)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=165336)[0m Instructions for updating:
[2m[36m(pid=165336)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=165343)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165343)[0m 
[2m[36m(pid=165343)[0m Stack (most recent call first):
[2m[36m(pid=163568)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163568)[0m   agg_primitives: ['count']
[2m[36m(pid=163568)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163568)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165336)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=165336)[0m Instructions for updating:
[2m[36m(pid=165336)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163568)[0m LSTM is selected.
[2m[36m(pid=163568)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163568)[0m Instructions for updating:
[2m[36m(pid=163568)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163568)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163568)[0m Instructions for updating:
[2m[36m(pid=163568)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=165336)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=165336)[0m 2020-11-20 13:44:18.536378: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=165336)[0m 2020-11-20 13:44:18.544075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=165336)[0m 2020-11-20 13:44:18.545966: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2775107900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=165336)[0m 2020-11-20 13:44:18.545985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163563)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163563)[0m   agg_primitives: ['count']
[2m[36m(pid=163563)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163563)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 13:44:19,081	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163531, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:19,084	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_31_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.322,lstm_2_units_float=102.86,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163531)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163531)[0m 
[2m[36m(pid=163531)[0m Stack (most recent call first):
[2m[36m(pid=163568)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163568)[0m 2020-11-20 13:44:19.231905: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163568)[0m 2020-11-20 13:44:19.255570: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163568)[0m 2020-11-20 13:44:19.257992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e15107620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163568)[0m 2020-11-20 13:44:19.258021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163564)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163564)[0m   agg_primitives: ['count']
[2m[36m(pid=163564)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163564)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163563)[0m LSTM is selected.
[2m[36m(pid=163563)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163563)[0m Instructions for updating:
[2m[36m(pid=163563)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163564)[0m LSTM is selected.
[2m[36m(pid=163564)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163564)[0m Instructions for updating:
[2m[36m(pid=163564)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163563)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163563)[0m Instructions for updating:
[2m[36m(pid=163563)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 40 ({'TERMINATED': 10, 'ERROR': 20, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 14 not shown
 - train_func_28_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.85,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_28_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-067jcqedz1/error_2020-11-20_13-44-14.txt
 - train_func_29_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.325,lstm_2_units_float=102.85,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_29_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-0685dlmoo9/error_2020-11-20_13-44-15.txt
 - train_func_31_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.322,lstm_2_units_float=102.86,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_31_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-0771w9q53y/error_2020-11-20_13-44-19.txt
RUNNING trials:
 - train_func_30_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.323,lstm_2_units_float=102.86,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.86,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=73.418,lstm_2_units_float=107.1,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.183,lstm_2_units_float=77.972,past_seq_len=2:	RUNNING
 - train_func_39_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 13:44:20,206	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163561, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:20,213	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=73.418,lstm_2_units_float=107.1,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163561)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163561)[0m 
[2m[36m(pid=163561)[0m Stack (most recent call first):
[2m[36m(pid=163564)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163564)[0m Instructions for updating:
[2m[36m(pid=163564)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163560)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163560)[0m   agg_primitives: ['count']
[2m[36m(pid=163560)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163560)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=165336)[0m 2020-11-20 13:44:20,957	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=165336)[0m Traceback (most recent call last):
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165336)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165336)[0m     param_dset[:] = val
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165336)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165336)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165336)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165336)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:20 2020
[2m[36m(pid=165336)[0m , filename = '/tmp/thalvari/4065562/automl_save_0ghccb29/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2776815468, total write size = 217048, bytes this sub-write = 217048, bytes actually written = 18446744073709551615, offset = 1150976)
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m Traceback (most recent call last):
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165336)[0m     self._entrypoint()
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165336)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165336)[0m     output = train_func(config, reporter)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165336)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165336)[0m     config=config)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165336)[0m     model.save(model_path, config_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165336)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165336)[0m     self.model.save(model_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165336)[0m     signatures)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165336)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165336)[0m     f.close()
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165336)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165336)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:20 2020
[2m[36m(pid=165336)[0m , filename = '/tmp/thalvari/4065562/automl_save_0ghccb29/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277579cf90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165336)[0m Exception in thread Thread-1:
[2m[36m(pid=165336)[0m Traceback (most recent call last):
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=165336)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=165336)[0m     param_dset[:] = val
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=165336)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=165336)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=165336)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=165336)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:20 2020
[2m[36m(pid=165336)[0m , filename = '/tmp/thalvari/4065562/automl_save_0ghccb29/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2776815468, total write size = 217048, bytes this sub-write = 217048, bytes actually written = 18446744073709551615, offset = 1150976)
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m Traceback (most recent call last):
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=165336)[0m     self._entrypoint()
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=165336)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=165336)[0m     output = train_func(config, reporter)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=165336)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=165336)[0m     config=config)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=165336)[0m     model.save(model_path, config_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=165336)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=165336)[0m     self.model.save(model_path)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=165336)[0m     signatures)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=165336)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=165336)[0m     f.close()
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=165336)[0m     h5i.dec_ref(id_)
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=165336)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=165336)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:20 2020
[2m[36m(pid=165336)[0m , filename = '/tmp/thalvari/4065562/automl_save_0ghccb29/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f277579cf90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m Traceback (most recent call last):
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=165336)[0m     self.run()
[2m[36m(pid=165336)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=165336)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=165336)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=165336)[0m 
[2m[36m(pid=163563)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163563)[0m 2020-11-20 13:44:21.090065: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163563)[0m 2020-11-20 13:44:21.100267: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163563)[0m 2020-11-20 13:44:21.102300: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3705107220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163563)[0m 2020-11-20 13:44:21.102323: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163560)[0m LSTM is selected.
[2m[36m(pid=163564)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163564)[0m 2020-11-20 13:44:21.390326: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163564)[0m 2020-11-20 13:44:21.399761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163564)[0m 2020-11-20 13:44:21.402513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca5d1076c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163564)[0m 2020-11-20 13:44:21.402541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163560)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163560)[0m Instructions for updating:
[2m[36m(pid=163560)[0m If using Keras pass *_constraint arguments to layers.
2020-11-20 13:44:21,618	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163553, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:21,621	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.324,lstm_2_units_float=102.86,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163568)[0m 2020-11-20 13:44:21,650	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163568)[0m Traceback (most recent call last):
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163568)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163568)[0m     param_dset[:] = val
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163568)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163568)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163568)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163568)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:21 2020
[2m[36m(pid=163568)[0m , filename = '/tmp/thalvari/4065562/automl_save_5my3ydgd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e15f89a08, total write size = 3016, bytes this sub-write = 3016, bytes actually written = 18446744073709551615, offset = 1146880)
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m Traceback (most recent call last):
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163568)[0m     self._entrypoint()
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163568)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163568)[0m     output = train_func(config, reporter)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163568)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163568)[0m     config=config)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163568)[0m     model.save(model_path, config_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163568)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163568)[0m     self.model.save(model_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163568)[0m     signatures)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163568)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163568)[0m     f.close()
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163568)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163568)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:21 2020
[2m[36m(pid=163568)[0m , filename = '/tmp/thalvari/4065562/automl_save_5my3ydgd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e16394c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163568)[0m Exception in thread Thread-1:
[2m[36m(pid=163568)[0m Traceback (most recent call last):
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163568)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163568)[0m     param_dset[:] = val
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163568)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163568)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163568)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163568)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:21 2020
[2m[36m(pid=163568)[0m , filename = '/tmp/thalvari/4065562/automl_save_5my3ydgd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e15f89a08, total write size = 3016, bytes this sub-write = 3016, bytes actually written = 18446744073709551615, offset = 1146880)
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m Traceback (most recent call last):
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163568)[0m     self._entrypoint()
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163568)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163568)[0m     output = train_func(config, reporter)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163568)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163568)[0m     config=config)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163568)[0m     model.save(model_path, config_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163568)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163568)[0m     self.model.save(model_path)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163568)[0m     signatures)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163568)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163568)[0m     f.close()
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163568)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163568)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163568)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:21 2020
[2m[36m(pid=163568)[0m , filename = '/tmp/thalvari/4065562/automl_save_5my3ydgd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8e16394c30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m Traceback (most recent call last):
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163568)[0m     self.run()
[2m[36m(pid=163568)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163568)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163568)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163553)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163553)[0m 
[2m[36m(pid=163553)[0m Stack (most recent call first):
[2m[36m(pid=163560)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163560)[0m Instructions for updating:
[2m[36m(pid=163560)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163557)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163557)[0m   agg_primitives: ['count']
[2m[36m(pid=163557)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163557)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163557)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163557)[0m Instructions for updating:
[2m[36m(pid=163557)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163557)[0m LSTM is selected.
[2m[36m(pid=163560)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163560)[0m 2020-11-20 13:44:22.982445: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163560)[0m 2020-11-20 13:44:22.991169: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163560)[0m 2020-11-20 13:44:22.993176: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1d6d107400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163560)[0m 2020-11-20 13:44:22.993209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 13:44:23,059	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165336, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:23,064	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=72.374,lstm_2_units_float=112.13,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165336)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165336)[0m 
[2m[36m(pid=165336)[0m Stack (most recent call first):
[2m[36m(pid=163557)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163557)[0m Instructions for updating:
[2m[36m(pid=163557)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163547)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163547)[0m   agg_primitives: ['count']
[2m[36m(pid=163547)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163547)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163563)[0m 2020-11-20 13:44:23,685	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163563)[0m Traceback (most recent call last):
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163563)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163563)[0m     param_dset[:] = val
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163563)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163563)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163563)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163563)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163563)[0m , filename = '/tmp/thalvari/4065562/automl_save_8uko6sp9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3705f13988, total write size = 19400, bytes this sub-write = 19400, bytes actually written = 18446744073709551615, offset = 1130496)
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m Traceback (most recent call last):
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163563)[0m     self._entrypoint()
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163563)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163563)[0m     output = train_func(config, reporter)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163563)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163563)[0m     config=config)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163563)[0m     model.save(model_path, config_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163563)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163563)[0m     self.model.save(model_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163563)[0m     signatures)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163563)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163563)[0m     f.close()
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163563)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163563)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163563)[0m , filename = '/tmp/thalvari/4065562/automl_save_8uko6sp9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3705d666f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163563)[0m Exception in thread Thread-1:
[2m[36m(pid=163563)[0m Traceback (most recent call last):
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163563)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163563)[0m     param_dset[:] = val
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163563)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163563)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163563)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163563)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163563)[0m , filename = '/tmp/thalvari/4065562/automl_save_8uko6sp9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3705f13988, total write size = 19400, bytes this sub-write = 19400, bytes actually written = 18446744073709551615, offset = 1130496)
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m Traceback (most recent call last):
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163563)[0m     self._entrypoint()
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163563)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163563)[0m     output = train_func(config, reporter)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163563)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163563)[0m     config=config)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163563)[0m     model.save(model_path, config_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163563)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163563)[0m     self.model.save(model_path)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163563)[0m     signatures)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163563)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163563)[0m     f.close()
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163563)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163563)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163563)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163563)[0m , filename = '/tmp/thalvari/4065562/automl_save_8uko6sp9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3705d666f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m Traceback (most recent call last):
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163563)[0m     self.run()
[2m[36m(pid=163563)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163563)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163563)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163563)[0m 
2020-11-20 13:44:23,783	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=165315, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:23,785	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_30_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=77.323,lstm_2_units_float=102.86,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=165315)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=165315)[0m 
[2m[36m(pid=165315)[0m Stack (most recent call first):
[2m[36m(pid=163547)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163547)[0m Instructions for updating:
[2m[36m(pid=163547)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163547)[0m LSTM is selected.
[2m[36m(pid=163564)[0m 2020-11-20 13:44:23,939	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163564)[0m Traceback (most recent call last):
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163564)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163564)[0m     param_dset[:] = val
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163564)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163564)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163564)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163564)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163564)[0m , filename = '/tmp/thalvari/4065562/automl_save_2vadxu3l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fca5e416018, total write size = 19400, bytes this sub-write = 19400, bytes actually written = 18446744073709551615, offset = 1130496)
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m Traceback (most recent call last):
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163564)[0m     self._entrypoint()
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163564)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163564)[0m     output = train_func(config, reporter)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163564)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163564)[0m     config=config)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163564)[0m     model.save(model_path, config_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163564)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163564)[0m     self.model.save(model_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163564)[0m     signatures)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163564)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163564)[0m     f.close()
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163564)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163564)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163564)[0m , filename = '/tmp/thalvari/4065562/automl_save_2vadxu3l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fca5df770a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163564)[0m Exception in thread Thread-1:
[2m[36m(pid=163564)[0m Traceback (most recent call last):
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163564)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163564)[0m     param_dset[:] = val
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163564)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163564)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163564)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163564)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163564)[0m , filename = '/tmp/thalvari/4065562/automl_save_2vadxu3l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fca5e416018, total write size = 19400, bytes this sub-write = 19400, bytes actually written = 18446744073709551615, offset = 1130496)
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m Traceback (most recent call last):
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163564)[0m     self._entrypoint()
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163564)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163564)[0m     output = train_func(config, reporter)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163564)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163564)[0m     config=config)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163564)[0m     model.save(model_path, config_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163564)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163564)[0m     self.model.save(model_path)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163564)[0m     signatures)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163564)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163564)[0m     f.close()
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163564)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163564)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163564)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:23 2020
[2m[36m(pid=163564)[0m , filename = '/tmp/thalvari/4065562/automl_save_2vadxu3l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fca5df770a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m Traceback (most recent call last):
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163564)[0m     self.run()
[2m[36m(pid=163564)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163564)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163564)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163557)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163557)[0m 2020-11-20 13:44:24.349515: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163557)[0m 2020-11-20 13:44:24.358154: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163557)[0m 2020-11-20 13:44:24.360061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac290be620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163557)[0m 2020-11-20 13:44:24.360085: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163547)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163547)[0m Instructions for updating:
[2m[36m(pid=163547)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 13:44:24,704	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163568, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:24,707	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.188,lstm_2_units_float=77.974,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163545)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163545)[0m   agg_primitives: ['count']
[2m[36m(pid=163545)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163545)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163568)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163568)[0m 
[2m[36m(pid=163568)[0m Stack (most recent call first):
[2m[36m(pid=163545)[0m LSTM is selected.
[2m[36m(pid=163545)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163545)[0m Instructions for updating:
[2m[36m(pid=163545)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163547)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163547)[0m 2020-11-20 13:44:25.443379: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163547)[0m 2020-11-20 13:44:25.450794: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163547)[0m 2020-11-20 13:44:25.452845: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f30610bec60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163547)[0m 2020-11-20 13:44:25.452869: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163560)[0m 2020-11-20 13:44:25,519	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163560)[0m Traceback (most recent call last):
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163560)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163560)[0m     param_dset[:] = val
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163560)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163560)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163560)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163560)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:25 2020
[2m[36m(pid=163560)[0m , filename = '/tmp/thalvari/4065562/automl_save_6nd3rrxy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d6e5bfa38, total write size = 27592, bytes this sub-write = 27592, bytes actually written = 18446744073709551615, offset = 1122304)
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m Traceback (most recent call last):
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163560)[0m     self._entrypoint()
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163560)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163560)[0m     output = train_func(config, reporter)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163560)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163560)[0m     config=config)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163560)[0m     model.save(model_path, config_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163560)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163560)[0m     self.model.save(model_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163560)[0m     signatures)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163560)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163560)[0m     f.close()
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163560)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163560)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:25 2020
[2m[36m(pid=163560)[0m , filename = '/tmp/thalvari/4065562/automl_save_6nd3rrxy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d6de16320, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163560)[0m Exception in thread Thread-1:
[2m[36m(pid=163560)[0m Traceback (most recent call last):
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163560)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163560)[0m     param_dset[:] = val
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163560)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163560)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163560)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163560)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:25 2020
[2m[36m(pid=163560)[0m , filename = '/tmp/thalvari/4065562/automl_save_6nd3rrxy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d6e5bfa38, total write size = 27592, bytes this sub-write = 27592, bytes actually written = 18446744073709551615, offset = 1122304)
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m Traceback (most recent call last):
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163560)[0m     self._entrypoint()
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163560)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163560)[0m     output = train_func(config, reporter)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163560)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163560)[0m     config=config)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163560)[0m     model.save(model_path, config_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163560)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163560)[0m     self.model.save(model_path)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163560)[0m     signatures)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163560)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163560)[0m     f.close()
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163560)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163560)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163560)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:25 2020
[2m[36m(pid=163560)[0m , filename = '/tmp/thalvari/4065562/automl_save_6nd3rrxy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1d6de16320, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m Traceback (most recent call last):
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163560)[0m     self.run()
[2m[36m(pid=163560)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163560)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163560)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163560)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 45 ({'TERMINATED': 10, 'ERROR': 25, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 19 not shown
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=73.418,lstm_2_units_float=107.1,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-09qqzys2l6/error_2020-11-20_13-44-20.txt
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=72.374,lstm_2_units_float=112.13,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-126m9gmz_f/error_2020-11-20_13-44-23.txt
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.188,lstm_2_units_float=77.974,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-13ne3wofb7/error_2020-11-20_13-44-24.txt
RUNNING trials:
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.192,lstm_2_units_float=77.975,past_seq_len=2:	RUNNING
 - train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.189,lstm_2_units_float=77.975,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.183,lstm_2_units_float=77.972,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 13:44:25,568	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163563, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:25,570	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.192,lstm_2_units_float=77.975,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163563)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163563)[0m 
[2m[36m(pid=163563)[0m Stack (most recent call first):
[2m[36m(pid=163545)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163545)[0m Instructions for updating:
[2m[36m(pid=163545)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163548)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163548)[0m   agg_primitives: ['count']
[2m[36m(pid=163548)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163548)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163546)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163546)[0m   agg_primitives: ['count']
[2m[36m(pid=163546)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163546)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163548)[0m LSTM is selected.
2020-11-20 13:44:26,800	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163560, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:26,802	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.183,lstm_2_units_float=77.972,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163548)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163548)[0m Instructions for updating:
[2m[36m(pid=163548)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163557)[0m 2020-11-20 13:44:26,761	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163557)[0m Traceback (most recent call last):
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163557)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163557)[0m     param_dset[:] = val
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163557)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163557)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163557)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163557)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:26 2020
[2m[36m(pid=163557)[0m , filename = '/tmp/thalvari/4065562/automl_save_1f4i8125/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac2a710408, total write size = 445432, bytes this sub-write = 445432, bytes actually written = 18446744073709551615, offset = 1110016)
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m Traceback (most recent call last):
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163557)[0m     self._entrypoint()
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163557)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163557)[0m     output = train_func(config, reporter)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163557)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163557)[0m     config=config)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163557)[0m     model.save(model_path, config_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163557)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163557)[0m     self.model.save(model_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163557)[0m     signatures)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163557)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163557)[0m     f.close()
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163557)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163557)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:26 2020
[2m[36m(pid=163557)[0m , filename = '/tmp/thalvari/4065562/automl_save_1f4i8125/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac2a1a2700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163557)[0m Exception in thread Thread-1:
[2m[36m(pid=163557)[0m Traceback (most recent call last):
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163557)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163557)[0m     param_dset[:] = val
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163557)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163557)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163557)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163557)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:26 2020
[2m[36m(pid=163557)[0m , filename = '/tmp/thalvari/4065562/automl_save_1f4i8125/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac2a710408, total write size = 445432, bytes this sub-write = 445432, bytes actually written = 18446744073709551615, offset = 1110016)
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m Traceback (most recent call last):
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163557)[0m     self._entrypoint()
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163557)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163557)[0m     output = train_func(config, reporter)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163557)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163557)[0m     config=config)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163557)[0m     model.save(model_path, config_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163557)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163557)[0m     self.model.save(model_path)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163557)[0m     signatures)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163557)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163557)[0m     f.close()
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163557)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163557)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163557)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:26 2020
[2m[36m(pid=163557)[0m , filename = '/tmp/thalvari/4065562/automl_save_1f4i8125/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fac2a1a2700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163545)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163545)[0m 2020-11-20 13:44:26.794416: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163545)[0m 2020-11-20 13:44:26.802169: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163545)[0m 2020-11-20 13:44:26.804400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4ed0be400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163545)[0m 2020-11-20 13:44:26.804427: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m Traceback (most recent call last):
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163557)[0m     self.run()
[2m[36m(pid=163557)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163557)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163557)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163546)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163546)[0m Instructions for updating:
[2m[36m(pid=163546)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163546)[0m LSTM is selected.
[2m[36m(pid=163560)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163560)[0m 
[2m[36m(pid=163560)[0m Stack (most recent call first):
[2m[36m(pid=163548)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163548)[0m Instructions for updating:
[2m[36m(pid=163548)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163546)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163546)[0m Instructions for updating:
[2m[36m(pid=163546)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 13:44:27,847	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163564, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:27,849	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.189,lstm_2_units_float=77.975,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163570)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163570)[0m   agg_primitives: ['count']
[2m[36m(pid=163570)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163570)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163564)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163564)[0m 
[2m[36m(pid=163564)[0m Stack (most recent call first):
[2m[36m(pid=163547)[0m 2020-11-20 13:44:28,078	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163547)[0m Traceback (most recent call last):
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163547)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163547)[0m     param_dset[:] = val
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163547)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163547)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163547)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163547)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:28 2020
[2m[36m(pid=163547)[0m , filename = '/tmp/thalvari/4065562/automl_save_vftztqyv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f30626ae058, total write size = 453624, bytes this sub-write = 453624, bytes actually written = 18446744073709551615, offset = 1101824)
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m Traceback (most recent call last):
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163547)[0m     self._entrypoint()
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163547)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163547)[0m     output = train_func(config, reporter)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163547)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163547)[0m     config=config)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163547)[0m     model.save(model_path, config_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163547)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163547)[0m     self.model.save(model_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163547)[0m     signatures)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163547)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163547)[0m     f.close()
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163547)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163547)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:28 2020
[2m[36m(pid=163547)[0m , filename = '/tmp/thalvari/4065562/automl_save_vftztqyv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f30624d66d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163547)[0m Exception in thread Thread-1:
[2m[36m(pid=163547)[0m Traceback (most recent call last):
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163547)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163547)[0m     param_dset[:] = val
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163547)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163547)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163547)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163547)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:28 2020
[2m[36m(pid=163547)[0m , filename = '/tmp/thalvari/4065562/automl_save_vftztqyv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f30626ae058, total write size = 453624, bytes this sub-write = 453624, bytes actually written = 18446744073709551615, offset = 1101824)
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m Traceback (most recent call last):
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163547)[0m     self._entrypoint()
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163547)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163547)[0m     output = train_func(config, reporter)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163547)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163547)[0m     config=config)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163547)[0m     model.save(model_path, config_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163547)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163547)[0m     self.model.save(model_path)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163547)[0m     signatures)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163547)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163547)[0m     f.close()
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163547)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163547)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163547)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:28 2020
[2m[36m(pid=163547)[0m , filename = '/tmp/thalvari/4065562/automl_save_vftztqyv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f30624d66d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m Traceback (most recent call last):
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163547)[0m     self.run()
[2m[36m(pid=163547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163547)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163547)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163548)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163548)[0m 2020-11-20 13:44:28.375548: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163548)[0m 2020-11-20 13:44:28.385274: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163548)[0m 2020-11-20 13:44:28.387407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6850befb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163548)[0m 2020-11-20 13:44:28.387442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163546)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163546)[0m 2020-11-20 13:44:28.388456: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163546)[0m 2020-11-20 13:44:28.396344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163546)[0m 2020-11-20 13:44:28.398048: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f63ed0bfa70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163546)[0m 2020-11-20 13:44:28.398069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163570)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163570)[0m Instructions for updating:
[2m[36m(pid=163570)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163570)[0m LSTM is selected.
2020-11-20 13:44:28,704	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163557, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:28,707	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_39_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163557)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163557)[0m 
[2m[36m(pid=163557)[0m Stack (most recent call first):
[2m[36m(pid=163542)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163542)[0m   agg_primitives: ['count']
[2m[36m(pid=163542)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163542)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163570)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163570)[0m Instructions for updating:
[2m[36m(pid=163570)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163545)[0m 2020-11-20 13:44:29,223	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163545)[0m Traceback (most recent call last):
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163545)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163545)[0m     param_dset[:] = val
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163545)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163545)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163545)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163545)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:29 2020
[2m[36m(pid=163545)[0m , filename = '/tmp/thalvari/4065562/automl_save_0hqrkjmk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ee628d58, total write size = 461816, bytes this sub-write = 461816, bytes actually written = 18446744073709551615, offset = 1093632)
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m Traceback (most recent call last):
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163545)[0m     self._entrypoint()
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163545)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163545)[0m     output = train_func(config, reporter)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163545)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163545)[0m     config=config)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163545)[0m     model.save(model_path, config_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163545)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163545)[0m     self.model.save(model_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163545)[0m     signatures)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163545)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163545)[0m     f.close()
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163545)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163545)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:29 2020
[2m[36m(pid=163545)[0m , filename = '/tmp/thalvari/4065562/automl_save_0hqrkjmk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ed6c68b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163545)[0m Exception in thread Thread-1:
[2m[36m(pid=163545)[0m Traceback (most recent call last):
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163545)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163545)[0m     param_dset[:] = val
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163545)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163545)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163545)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163545)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:29 2020
[2m[36m(pid=163545)[0m , filename = '/tmp/thalvari/4065562/automl_save_0hqrkjmk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ee628d58, total write size = 461816, bytes this sub-write = 461816, bytes actually written = 18446744073709551615, offset = 1093632)
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m Traceback (most recent call last):
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163545)[0m     self._entrypoint()
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163545)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163545)[0m     output = train_func(config, reporter)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163545)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163545)[0m     config=config)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163545)[0m     model.save(model_path, config_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163545)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163545)[0m     self.model.save(model_path)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163545)[0m     signatures)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163545)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163545)[0m     f.close()
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163545)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163545)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163545)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:29 2020
[2m[36m(pid=163545)[0m , filename = '/tmp/thalvari/4065562/automl_save_0hqrkjmk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4ed6c68b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m Traceback (most recent call last):
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163545)[0m     self.run()
[2m[36m(pid=163545)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163545)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163545)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163542)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163542)[0m Instructions for updating:
[2m[36m(pid=163542)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163542)[0m LSTM is selected.
[2m[36m(pid=163570)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163570)[0m 2020-11-20 13:44:29.942558: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163570)[0m 2020-11-20 13:44:29.950850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163570)[0m 2020-11-20 13:44:29.955297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f55610beee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163570)[0m 2020-11-20 13:44:29.955341: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163542)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163542)[0m Instructions for updating:
[2m[36m(pid=163542)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163559)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163559)[0m   agg_primitives: ['count']
[2m[36m(pid=163559)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163559)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 13:44:30,186	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163547, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:30,190	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163547)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163547)[0m 
[2m[36m(pid=163547)[0m Stack (most recent call first):
[2m[36m(pid=163559)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163559)[0m Instructions for updating:
[2m[36m(pid=163559)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163559)[0m LSTM is selected.
[2m[36m(pid=163548)[0m 2020-11-20 13:44:30,829	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163548)[0m Traceback (most recent call last):
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163548)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163548)[0m     param_dset[:] = val
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163548)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163548)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163548)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163548)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163548)[0m , filename = '/tmp/thalvari/4065562/automl_save_rigwzpar/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb686333038, total write size = 71160, bytes this sub-write = 71160, bytes actually written = 18446744073709551615, offset = 823296)
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m Traceback (most recent call last):
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163548)[0m     self._entrypoint()
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163548)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163548)[0m     output = train_func(config, reporter)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163548)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163548)[0m     config=config)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163548)[0m     model.save(model_path, config_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163548)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163548)[0m     self.model.save(model_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163548)[0m     signatures)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163548)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163548)[0m     f.close()
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163548)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163548)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163548)[0m , filename = '/tmp/thalvari/4065562/automl_save_rigwzpar/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6863b3070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163548)[0m Exception in thread Thread-1:
[2m[36m(pid=163548)[0m Traceback (most recent call last):
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163548)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163548)[0m     param_dset[:] = val
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163548)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163548)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163548)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163548)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163548)[0m , filename = '/tmp/thalvari/4065562/automl_save_rigwzpar/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb686333038, total write size = 71160, bytes this sub-write = 71160, bytes actually written = 18446744073709551615, offset = 823296)
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m Traceback (most recent call last):
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163548)[0m     self._entrypoint()
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163548)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163548)[0m     output = train_func(config, reporter)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163548)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163548)[0m     config=config)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163548)[0m     model.save(model_path, config_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163548)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163548)[0m     self.model.save(model_path)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163548)[0m     signatures)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163548)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163548)[0m     f.close()
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163548)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163548)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163548)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163548)[0m , filename = '/tmp/thalvari/4065562/automl_save_rigwzpar/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6863b3070, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m Traceback (most recent call last):
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163548)[0m     self.run()
[2m[36m(pid=163548)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163548)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163548)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163546)[0m 2020-11-20 13:44:30,901	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163546)[0m Traceback (most recent call last):
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163546)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163546)[0m     param_dset[:] = val
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163546)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163546)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163546)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163546)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163546)[0m , filename = '/tmp/thalvari/4065562/automl_save_m2od6ujt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63ee7374d8, total write size = 478200, bytes this sub-write = 478200, bytes actually written = 18446744073709551615, offset = 1077248)
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m Traceback (most recent call last):
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163546)[0m     self._entrypoint()
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163546)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163546)[0m     output = train_func(config, reporter)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163546)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163546)[0m     config=config)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163546)[0m     model.save(model_path, config_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163546)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163546)[0m     self.model.save(model_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163546)[0m     signatures)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163546)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163546)[0m     f.close()
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163546)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163546)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163546)[0m , filename = '/tmp/thalvari/4065562/automl_save_m2od6ujt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63ed638380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163546)[0m Exception in thread Thread-1:
[2m[36m(pid=163546)[0m Traceback (most recent call last):
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163546)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163546)[0m     param_dset[:] = val
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163546)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163546)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163546)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163546)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163546)[0m , filename = '/tmp/thalvari/4065562/automl_save_m2od6ujt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63ee7374d8, total write size = 478200, bytes this sub-write = 478200, bytes actually written = 18446744073709551615, offset = 1077248)
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m Traceback (most recent call last):
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163546)[0m     self._entrypoint()
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163546)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163546)[0m     output = train_func(config, reporter)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163546)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163546)[0m     config=config)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163546)[0m     model.save(model_path, config_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163546)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163546)[0m     self.model.save(model_path)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163546)[0m     signatures)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163546)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163546)[0m     f.close()
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163546)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163546)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163546)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:30 2020
[2m[36m(pid=163546)[0m , filename = '/tmp/thalvari/4065562/automl_save_m2od6ujt/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63ed638380, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m Traceback (most recent call last):
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163546)[0m     self.run()
[2m[36m(pid=163546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163546)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163546)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163542)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163542)[0m 2020-11-20 13:44:31.034303: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163542)[0m 2020-11-20 13:44:31.041715: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163558)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163558)[0m   agg_primitives: ['count']
[2m[36m(pid=163558)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163558)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163542)[0m 2020-11-20 13:44:31.043800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ea50befb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163542)[0m 2020-11-20 13:44:31.043819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163559)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163559)[0m Instructions for updating:
[2m[36m(pid=163559)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 50 ({'TERMINATED': 10, 'ERROR': 30, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 24 not shown
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=74.183,lstm_2_units_float=77.972,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-17jltd7p0x/error_2020-11-20_13-44-26.txt
 - train_func_39_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_39_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-19eb3cyotd/error_2020-11-20_13-44-28.txt
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-206umzwhnx/error_2020-11-20_13-44-30.txt
RUNNING trials:
 - train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_42_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 13:44:31,366	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163545, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:31,369	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163558)[0m LSTM is selected.
[2m[36m(pid=163558)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163558)[0m Instructions for updating:
[2m[36m(pid=163558)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163545)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163545)[0m 
[2m[36m(pid=163545)[0m Stack (most recent call first):
[2m[36m(pid=163539)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163539)[0m   agg_primitives: ['count']
[2m[36m(pid=163539)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163539)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163558)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163558)[0m Instructions for updating:
[2m[36m(pid=163558)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163559)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163559)[0m 2020-11-20 13:44:32.097672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163559)[0m 2020-11-20 13:44:32.105168: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163559)[0m 2020-11-20 13:44:32.107212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f63290beee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163559)[0m 2020-11-20 13:44:32.107234: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163539)[0m LSTM is selected.
[2m[36m(pid=163539)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163539)[0m Instructions for updating:
[2m[36m(pid=163539)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163570)[0m 2020-11-20 13:44:32,325	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163570)[0m Traceback (most recent call last):
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163570)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163570)[0m     param_dset[:] = val
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163570)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163570)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163570)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163570)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:32 2020
[2m[36m(pid=163570)[0m , filename = '/tmp/thalvari/4065562/automl_save_8g077pef/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5562702288, total write size = 486392, bytes this sub-write = 486392, bytes actually written = 18446744073709551615, offset = 1069056)
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m Traceback (most recent call last):
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163570)[0m     self._entrypoint()
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163570)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163570)[0m     output = train_func(config, reporter)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163570)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163570)[0m     config=config)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163570)[0m     model.save(model_path, config_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163570)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163570)[0m     self.model.save(model_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163570)[0m     signatures)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163570)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163570)[0m     f.close()
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163570)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163570)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:32 2020
[2m[36m(pid=163570)[0m , filename = '/tmp/thalvari/4065562/automl_save_8g077pef/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556251e040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163570)[0m Exception in thread Thread-1:
[2m[36m(pid=163570)[0m Traceback (most recent call last):
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163570)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163570)[0m     param_dset[:] = val
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163570)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163570)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163570)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163570)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:32 2020
[2m[36m(pid=163570)[0m , filename = '/tmp/thalvari/4065562/automl_save_8g077pef/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5562702288, total write size = 486392, bytes this sub-write = 486392, bytes actually written = 18446744073709551615, offset = 1069056)
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m Traceback (most recent call last):
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163570)[0m     self._entrypoint()
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163570)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163570)[0m     output = train_func(config, reporter)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163570)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163570)[0m     config=config)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163570)[0m     model.save(model_path, config_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163570)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163570)[0m     self.model.save(model_path)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163570)[0m     signatures)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163570)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163570)[0m     f.close()
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163570)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163570)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163570)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:32 2020
[2m[36m(pid=163570)[0m , filename = '/tmp/thalvari/4065562/automl_save_8g077pef/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f556251e040, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m Traceback (most recent call last):
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163570)[0m     self.run()
[2m[36m(pid=163570)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163570)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163570)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163570)[0m 
2020-11-20 13:44:32,587	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163548, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:32,591	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_42_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163548)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163548)[0m 
[2m[36m(pid=163548)[0m Stack (most recent call first):
[2m[36m(pid=163539)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163539)[0m Instructions for updating:
[2m[36m(pid=163539)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163558)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163558)[0m 2020-11-20 13:44:33.033962: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163558)[0m 2020-11-20 13:44:33.042685: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163558)[0m 2020-11-20 13:44:33.044665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f612d0be6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163558)[0m 2020-11-20 13:44:33.044696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 13:44:33,419	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163570, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:33,421	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163570)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163570)[0m 
[2m[36m(pid=163570)[0m Stack (most recent call first):
[2m[36m(pid=163542)[0m 2020-11-20 13:44:33,713	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163542)[0m Traceback (most recent call last):
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163542)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163542)[0m     param_dset[:] = val
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163542)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163542)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163542)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163542)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:33 2020
[2m[36m(pid=163542)[0m , filename = '/tmp/thalvari/4065562/automl_save__4spk_cm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ea682bf08, total write size = 494584, bytes this sub-write = 494584, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m Traceback (most recent call last):
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163542)[0m     self._entrypoint()
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163542)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163542)[0m     output = train_func(config, reporter)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163542)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163542)[0m     config=config)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163542)[0m     model.save(model_path, config_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163542)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163542)[0m     self.model.save(model_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163542)[0m     signatures)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163542)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163542)[0m     f.close()
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163542)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163542)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:33 2020
[2m[36m(pid=163542)[0m , filename = '/tmp/thalvari/4065562/automl_save__4spk_cm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ea60d5fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163542)[0m Exception in thread Thread-1:
[2m[36m(pid=163542)[0m Traceback (most recent call last):
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=163542)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=163542)[0m     param_dset[:] = val
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=163542)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=163542)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=163542)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=163542)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 13:44:33 2020
[2m[36m(pid=163542)[0m , filename = '/tmp/thalvari/4065562/automl_save__4spk_cm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ea682bf08, total write size = 494584, bytes this sub-write = 494584, bytes actually written = 18446744073709551615, offset = 1060864)
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m Traceback (most recent call last):
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163542)[0m     self._entrypoint()
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163542)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163542)[0m     output = train_func(config, reporter)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163542)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163542)[0m     config=config)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=163542)[0m     model.save(model_path, config_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=163542)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=163542)[0m     self.model.save(model_path)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=163542)[0m     signatures)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=163542)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=163542)[0m     f.close()
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=163542)[0m     h5i.dec_ref(id_)
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=163542)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=163542)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 13:44:33 2020
[2m[36m(pid=163542)[0m , filename = '/tmp/thalvari/4065562/automl_save__4spk_cm/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9ea60d5fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m Traceback (most recent call last):
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=163542)[0m     self.run()
[2m[36m(pid=163542)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=163542)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=163542)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163552)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163552)[0m   agg_primitives: ['count']
[2m[36m(pid=163552)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163552)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163539)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163539)[0m 2020-11-20 13:44:33.937846: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163539)[0m 2020-11-20 13:44:33.946493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163539)[0m 2020-11-20 13:44:33.948599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0590be860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163539)[0m 2020-11-20 13:44:33.948632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163552)[0m LSTM is selected.
[2m[36m(pid=163552)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163552)[0m Instructions for updating:
[2m[36m(pid=163552)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=174242)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=174241)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=174240)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=174240)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=174242)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=174241)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=163537)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163537)[0m   agg_primitives: ['count']
[2m[36m(pid=163537)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163537)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 13:44:34,709	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163546, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:34,715	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163559)[0m Traceback (most recent call last):
[2m[36m(pid=163559)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163559)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:44:34 2020
[2m[36m(pid=163559)[0m , filename = '/tmp/thalvari/4065562/automl_save_lb1q5pau/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f632a0021d0, total write size = 13432, bytes this sub-write = 13432, bytes actually written = 18446744073709551615, offset = 1028096)
[2m[36m(pid=163559)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=163559)[0m Traceback (most recent call last):
[2m[36m(pid=163559)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=163559)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 13:44:34 2020
[2m[36m(pid=163559)[0m , filename = '/tmp/thalvari/4065562/automl_save_lb1q5pau/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f632a0021d0, total write size = 13432, bytes this sub-write = 13432, bytes actually written = 18446744073709551615, offset = 1028096)
[2m[36m(pid=163559)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163559)[0m 
[2m[36m(pid=163559)[0m Stack (most recent call first):
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=163559)[0m   File "/projappl/project_2003107/anaconda3/e
2020-11-20 13:44:34,794	ERROR worker.py:1672 -- A worker died or was killed while executing task 8f9c27a0fa86d0cbf445efa54128b30d.
[2m[36m(pid=163552)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163552)[0m Instructions for updating:
[2m[36m(pid=163552)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163546)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163546)[0m 
[2m[36m(pid=163546)[0m Stack (most recent call first):
[2m[36m(pid=163537)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163537)[0m Instructions for updating:
[2m[36m(pid=163537)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163537)[0m LSTM is selected.
[2m[36m(pid=163558)[0m 2020-11-20 13:44:35,426	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163558)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163558)[0m 
[2m[36m(pid=163558)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163558)[0m 
[2m[36m(pid=163558)[0m Traceback (most recent call last):
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163558)[0m     self._entrypoint()
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163558)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163558)[0m     output = train_func(config, reporter)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163558)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163558)[0m     config=config)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=163558)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=163558)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=163558)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=163558)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163558)[0m Exception in thread Thread-1:
[2m[36m(pid=163558)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163558)[0m 
[2m[36m(pid=163558)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163558)[0m 
[2m[36m(pid=163558)[0m Traceback (most recent call last):
[2m[36m(pid=163558)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=163537)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163537)[0m Instructions for updating:
[2m[36m(pid=163537)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163552)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163552)[0m 2020-11-20 13:44:35.910940: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163552)[0m 2020-11-20 13:44:35.919013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163552)[0m 2020-11-20 13:44:35.920999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d810bec60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163552)[0m 2020-11-20 13:44:35.921021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 13:44:35,989	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2020-11-20 13:44:35,992	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163539)[0m 2020-11-20 13:44:36,204	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163539)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163539)[0m 
[2m[36m(pid=163539)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163539)[0m 
[2m[36m(pid=163539)[0m Traceback (most recent call last):
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163539)[0m     self._entrypoint()
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163539)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163539)[0m     output = train_func(config, reporter)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163539)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163539)[0m     config=config)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=163539)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=163539)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=163539)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=163539)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163539)[0m Exception in thread Thread-1:
[2m[36m(pid=163539)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163539)[0m 
[2m[36m(pid=163539)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163539)[0m 
[2m[36m(pid=163539)[0m Traceback (most recent call last):
[2m[36m(pid=163539)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=163567)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=163567)[0m   agg_primitives: ['count']
[2m[36m(pid=163567)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=163567)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=163537)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163537)[0m 2020-11-20 13:44:36.648670: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163537)[0m 2020-11-20 13:44:36.656059: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163537)[0m 2020-11-20 13:44:36.658046: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b390befb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163537)[0m 2020-11-20 13:44:36.658066: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163567)[0m LSTM is selected.
[2m[36m(pid=163567)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=163567)[0m Instructions for updating:
[2m[36m(pid=163567)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=163567)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=163567)[0m Instructions for updating:
[2m[36m(pid=163567)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 55 ({'TERMINATED': 10, 'ERROR': 35, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 29 not shown
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-23n1xctz9u/error_2020-11-20_13-44-34.txt
 - train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-24j3h2tvzh/error_2020-11-20_13-44-33.txt
 - train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-26s2dtpb1v/error_2020-11-20_13-44-35.txt
RUNNING trials:
 - train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.433,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_53_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.433,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_54_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_55_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 13:44:37,489	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163539, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:37,491	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163552)[0m 2020-11-20 13:44:38,053	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163552)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163552)[0m 
[2m[36m(pid=163552)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163552)[0m 
[2m[36m(pid=163552)[0m Traceback (most recent call last):
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163552)[0m     self._entrypoint()
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163552)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163552)[0m     output = train_func(config, reporter)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163552)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163552)[0m     config=config)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=163552)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=163552)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=163552)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=163552)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163552)[0m Exception in thread Thread-1:
[2m[36m(pid=163552)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163552)[0m 
[2m[36m(pid=163552)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163552)[0m 
[2m[36m(pid=163552)[0m Traceback (most recent call last):
[2m[36m(pid=163552)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=163567)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=163567)[0m 2020-11-20 13:44:38.367393: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=163567)[0m 2020-11-20 13:44:38.376052: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=163567)[0m 2020-11-20 13:44:38.377753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4890beae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=163567)[0m 2020-11-20 13:44:38.377776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=163537)[0m 2020-11-20 13:44:38,799	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163537)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163537)[0m 
[2m[36m(pid=163537)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163537)[0m 
[2m[36m(pid=163537)[0m Traceback (most recent call last):
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163537)[0m     self._entrypoint()
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163537)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163537)[0m     output = train_func(config, reporter)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163537)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163537)[0m     config=config)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=163537)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=163537)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=163537)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=163537)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163537)[0m Exception in thread Thread-1:
[2m[36m(pid=163537)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163537)[0m 
[2m[36m(pid=163537)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163537)[0m 
[2m[36m(pid=163537)[0m Traceback (most recent call last):
[2m[36m(pid=163537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=174242)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=174242)[0m   agg_primitives: ['count']
[2m[36m(pid=174242)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=174242)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=174241)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=174241)[0m   agg_primitives: ['count']
[2m[36m(pid=174241)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=174241)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=174240)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=174240)[0m   agg_primitives: ['count']
[2m[36m(pid=174240)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=174240)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 13:44:39,322	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163542, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:39,327	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=163542)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=163542)[0m 
[2m[36m(pid=163542)[0m Stack (most recent call first):
[2m[36m(pid=174242)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=174242)[0m Instructions for updating:
[2m[36m(pid=174242)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=174242)[0m LSTM is selected.
[2m[36m(pid=174241)[0m LSTM is selected.
[2m[36m(pid=174241)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=174241)[0m Instructions for updating:
[2m[36m(pid=174241)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=174240)[0m LSTM is selected.
[2m[36m(pid=174240)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=174240)[0m Instructions for updating:
[2m[36m(pid=174240)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=174242)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=174242)[0m Instructions for updating:
[2m[36m(pid=174242)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=174241)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=174241)[0m Instructions for updating:
[2m[36m(pid=174241)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 13:44:40,297	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163537, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:40,299	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=174240)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=174240)[0m Instructions for updating:
[2m[36m(pid=174240)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=163567)[0m 2020-11-20 13:44:40,836	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=163567)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163567)[0m 
[2m[36m(pid=163567)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163567)[0m 
[2m[36m(pid=163567)[0m Traceback (most recent call last):
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=163567)[0m     self._entrypoint()
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=163567)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=163567)[0m     output = train_func(config, reporter)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=163567)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=163567)[0m     config=config)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=163567)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=163567)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=163567)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=163567)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163567)[0m Exception in thread Thread-1:
[2m[36m(pid=163567)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=163567)[0m 
[2m[36m(pid=163567)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=163567)[0m 
[2m[36m(pid=163567)[0m Traceback (most recent call last):
[2m[36m(pid=163567)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=174242)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=174242)[0m 2020-11-20 13:44:41.305020: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=174242)[0m 2020-11-20 13:44:41.312218: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=174242)[0m 2020-11-20 13:44:41.314150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f20890be620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=174242)[0m 2020-11-20 13:44:41.314172: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=174241)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=174241)[0m 2020-11-20 13:44:41.390023: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=174241)[0m 2020-11-20 13:44:41.397647: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=174241)[0m 2020-11-20 13:44:41.399544: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f68290bea90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=174241)[0m 2020-11-20 13:44:41.399563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=174240)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=174240)[0m 2020-11-20 13:44:41.528632: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=174240)[0m 2020-11-20 13:44:41.536384: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=174240)[0m 2020-11-20 13:44:41.538337: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2aad0bea70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=174240)[0m 2020-11-20 13:44:41.538357: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 13:44:41,792	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163552, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:41,794	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 59 ({'TERMINATED': 10, 'ERROR': 39, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 33 not shown
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-28rhmv63pq/error_2020-11-20_13-44-37.txt
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-30zngw9_l_/error_2020-11-20_13-44-41.txt
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-31kyokkq4a/error_2020-11-20_13-44-40.txt
RUNNING trials:
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.433,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_57_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_58_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_59_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 13:44:42,967	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163567, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:42,970	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 13:44:44,169	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=163558, host=r04c26.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 13:44:44,171	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.433,lstm_2_units_float=62.106,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_2xem8yv7/automl
Number of trials: 61 ({'TERMINATED': 10, 'ERROR': 41, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_13-43-248z3lp_jd/error_2020-11-20_13-43-38.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_13-43-24uo37235r/error_2020-11-20_13-43-38.txt
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWA_2020-11-20_13-43-24g941ay59/error_2020-11-20_13-43-39.txt
  ... 35 not shown
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-30zngw9_l_/error_2020-11-20_13-44-41.txt
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-31kyokkq4a/error_2020-11-20_13-44-40.txt
 - train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_2xem8yv7/automl/train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_13-44-32kg4mvgf3/error_2020-11-20_13-44-42.txt
RUNNING trials:
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=174241], 8 s, 3 iter
 - train_func_53_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.433,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=174242], 9 s, 4 iter
 - train_func_54_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=174240], 9 s, 4 iter
  ... 4 not shown
 - train_func_59_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
 - train_func_61_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=78.432,lstm_2_units_float=62.106,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163534], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163566], 35 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163536], 22 s, 5 iter
  ... 4 not shown
 - train_func_21_batch_size_log=8.3731,bayes_feature_DAY(timestamp)=0.82851,bayes_feature_HOUR(timestamp)=0.39207,bayes_feature_IS_AWAKE(timestamp)=0.50424,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36575,bayes_feature_IS_WEEKEND(timestamp)=0.87015,bayes_feature_MONTH(timestamp)=0.92968,bayes_feature_WEEKDAY(timestamp)=0.53432,dropout_1=0.46284,dropout_2=0.43251,epochs=5,lr=0.0069958,lstm_1_units_float=93.028,lstm_2_units_float=32.889,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163543], 11 s, 5 iter
 - train_func_24_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=128.0,lstm_2_units_float=8.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163565], 13 s, 5 iter
 - train_func_25_batch_size_log=8.2439,bayes_feature_DAY(timestamp)=0.4099,bayes_feature_HOUR(timestamp)=0.42068,bayes_feature_IS_AWAKE(timestamp)=0.60835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72323,bayes_feature_IS_WEEKEND(timestamp)=0.73597,bayes_feature_MONTH(timestamp)=0.56924,bayes_feature_WEEKDAY(timestamp)=0.6029,dropout_1=0.43664,dropout_2=0.35006,epochs=5,lr=0.0029476,lstm_1_units_float=57.514,lstm_2_units_float=15.484,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=163530], 14 s, 5 iter

2020-11-20 20:11:11,542	ERROR worker.py:1672 -- The reporter on node r04c26.bullx failed with the following error:
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/206834/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 176, in run
    self.perform_iteration()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 165, in perform_iteration
    stats = self.get_all_stats()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 156, in get_all_stats
    "workers": self.get_workers(),
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in get_workers
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in <listcomp>
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/__init__.py", line 634, in name
    name = self._proc.name()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1610, in name
    name = self._parse_stat_file()['name']
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=206834, name='sleep')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 218, in <module>
    reporter.run()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 178, in run
    traceback.print_exc()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 105, in print_exception
    print(line, file=file, end="")
OSError: [Errno 28] No space left on device

