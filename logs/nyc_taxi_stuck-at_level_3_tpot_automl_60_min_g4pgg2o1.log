30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   8%|▊         | 8/100 [00:46<08:52,  5.79s/pipeline]Optimization Progress:  88%|████████▊ | 88/100 [03:24<00:55,  4.64s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [03:25<00:00,  4.64s/pipeline]Optimization Progress: 100%|██████████| 100/100 [03:25<00:00,  3.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [03:26<00:00,  3.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [03:28<00:00,  3.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [03:28<00:00,  3.28s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [03:30<04:32,  2.81s/pipeline]Optimization Progress:  52%|█████▏    | 104/200 [05:32<1:01:48, 38.63s/pipeline]Optimization Progress:  92%|█████████▏| 184/200 [05:36<07:12, 27.06s/pipeline]  
Generation 1 - Current Pareto front scores:
-1	-839363940.4874575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [05:36<00:00, 27.06s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [05:37<00:00, 27.06s/pipeline]Optimization Progress: 100%|██████████| 200/200 [05:37<00:00, 18.94s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [05:40<00:00, 18.94s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [05:42<00:00, 18.94s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [05:42<00:00, 18.94s/pipeline]Optimization Progress:  68%|██████▊   | 205/300 [05:45<21:49, 13.78s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 205/300 [05:45<21:49, 13.78s/pipeline]Optimization Progress:  69%|██████▉   | 207/300 [05:50<16:02, 10.35s/pipeline]Optimization Progress:  95%|█████████▌| 286/300 [06:10<02:24, 10.35s/pipeline]Optimization Progress:  96%|█████████▌| 287/300 [06:27<01:35,  7.38s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-839363940.4874575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [06:28<00:00,  7.38s/pipeline]Optimization Progress: 100%|██████████| 300/300 [06:28<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 300/300 [06:30<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [06:30<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [06:32<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [06:32<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [06:33<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 300/300 [06:34<00:00,  5.21s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 300/300 [06:34<00:00,  5.21s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  75%|███████▌  | 300/400 [06:34<08:40,  5.21s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [06:34<08:50,  5.35s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  75%|███████▌  | 301/400 [06:34<08:50,  5.35s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [07:18<16:46, 10.37s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [07:21<02:03,  7.27s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-839363940.4874575	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:22<00:00,  7.27s/pipeline]Optimization Progress: 100%|██████████| 400/400 [07:22<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:25<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [07:25<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:26<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:26<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:26<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:26<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:27<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [07:27<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 400/400 [07:27<00:00,  5.10s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [07:27<00:00,  5.10s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 401/500 [07:29<08:25,  5.10s/pipeline]Optimization Progress:  80%|████████  | 402/500 [07:29<07:34,  4.64s/pipeline]Optimization Progress:  81%|████████  | 403/500 [07:48<14:18,  8.85s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [08:09<01:46,  6.27s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-838350155.9736335	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [14:44:34] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f31d9804dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f31d9915669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f31d9922f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f31d9909cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f31d97f6f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f27e75b19dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f27e75b1067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f27e75c927e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f27e75c9cb4]

.
Optimization Progress: 100%|██████████| 500/500 [08:12<00:00,  6.27s/pipeline]Optimization Progress: 100%|██████████| 500/500 [08:12<00:00,  4.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 500/500 [08:12<00:00,  4.44s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [08:12<00:00,  4.44s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [08:17<05:52,  3.64s/pipeline]Optimization Progress:  84%|████████▍ | 504/600 [09:05<26:55, 16.83s/pipeline]Optimization Progress:  97%|█████████▋| 584/600 [09:11<03:08, 11.81s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-837993279.8355553	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [09:15<00:00, 11.81s/pipeline]Optimization Progress: 100%|██████████| 600/600 [09:15<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [09:17<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [09:17<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 600/600 [09:18<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [09:19<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 600/600 [09:19<00:00,  8.34s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [09:19<00:00,  8.34s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [10:06<34:56, 21.17s/pipeline]Optimization Progress:  97%|█████████▋| 681/700 [10:12<04:42, 14.84s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-836685397.8615515	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-836139853.3772297	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.9000000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [10:13<00:00, 14.84s/pipeline]Optimization Progress: 100%|██████████| 700/700 [10:13<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [10:13<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [10:15<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [10:16<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 700/700 [10:16<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [10:17<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [10:18<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [10:19<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 700/700 [10:20<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [10:22<00:00, 10.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [10:22<00:00, 10.40s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [10:23<14:27,  8.85s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [10:23<14:27,  8.85s/pipeline]Optimization Progress:  88%|████████▊ | 704/800 [10:46<15:27,  9.66s/pipeline]Optimization Progress:  98%|█████████▊| 784/800 [12:04<01:52,  7.06s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-836685397.8615515	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-836139853.3772297	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.9000000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [12:05<00:00,  7.06s/pipeline]Optimization Progress: 100%|██████████| 800/800 [12:05<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 800/800 [12:08<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [12:08<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [12:08<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 800/800 [12:10<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [12:10<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [12:12<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [12:15<00:00,  4.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [12:16<00:00,  4.96s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [12:16<06:48,  4.26s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 804/900 [12:16<06:48,  4.26s/pipeline]Optimization Progress:  90%|████████▉ | 806/900 [13:53<27:28, 17.54s/pipeline]Optimization Progress:  98%|█████████▊| 886/900 [14:04<02:52, 12.32s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-836685397.8615515	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-836139853.3772297	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.9000000000000001, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-835929812.1514515	GradientBoostingRegressor(SGDRegressor(ZeroCount(input_matrix), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [14:05<00:00, 12.32s/pipeline]Optimization Progress: 100%|██████████| 900/900 [14:05<00:00,  8.65s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [14:06<00:00,  8.65s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [14:06<00:00,  8.65s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [14:08<00:00,  8.65s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 900/900 [14:09<00:00,  8.65s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [14:11<00:00,  8.65s/pipeline]Optimization Progress:  90%|█████████ | 901/1000 [14:23<18:35, 11.27s/pipeline]Optimization Progress:  98%|█████████▊| 981/1000 [14:26<02:30,  7.90s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-834938910.4042983	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=5, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1000/1000 [14:27<00:00,  7.90s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [14:27<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [14:27<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [14:29<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 1000/1000 [14:30<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [14:30<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 1000/1000 [14:32<00:00,  5.54s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 1000/1000 [14:33<00:00,  5.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1000/1100 [14:34<09:14,  5.54s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [14:34<09:08,  5.54s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [14:34<08:15,  5.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [14:35<08:15,  5.06s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [14:40<06:57,  4.35s/pipeline]Optimization Progress:  99%|█████████▊| 1084/1100 [14:45<00:49,  3.06s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-834520154.4167511	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [14:49<00:00,  3.06s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [14:49<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [14:49<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [14:50<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [14:52<00:00,  2.22s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [14:54<05:06,  3.09s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [15:01<07:05,  4.34s/pipeline]Optimization Progress:  98%|█████████▊| 1182/1200 [15:06<00:55,  3.06s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-834520154.4167511	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:08<00:00,  3.06s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [15:08<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:13<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [15:13<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [15:14<00:00,  2.17s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [15:15<05:58,  3.62s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  92%|█████████▏| 1201/1300 [15:15<05:58,  3.62s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [15:19<05:12,  3.22s/pipeline]Optimization Progress:  99%|█████████▊| 1283/1300 [15:23<00:38,  2.27s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [15:23<00:00,  2.27s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [15:23<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [15:23<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1300/1300 [15:28<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [15:28<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1300/1300 [15:28<00:00,  1.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [15:31<00:00,  1.59s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [15:38<04:06,  2.54s/pipeline]Optimization Progress:  99%|█████████▉| 1383/1400 [15:42<00:30,  1.79s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [15:43<00:00,  1.79s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [15:43<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [15:44<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [15:45<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1400/1400 [15:46<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 1400/1400 [15:49<00:00,  1.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [15:49<00:00,  1.28s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [15:51<05:13,  3.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1401/1500 [15:51<05:13,  3.17s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [15:54<04:32,  2.81s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [15:59<00:33,  1.98s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 1500/1500 [16:02<00:00,  1.98s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [16:02<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:02<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:03<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1500/1500 [16:03<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1500/1500 [16:03<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:04<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1500/1500 [16:05<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:05<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:06<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [16:06<00:00,  1.44s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [16:08<02:32,  1.57s/pipeline]Optimization Progress:  94%|█████████▍| 1504/1600 [16:13<04:28,  2.80s/pipeline]Optimization Progress:  99%|█████████▉| 1584/1600 [16:17<00:31,  1.97s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:18<00:00,  1.97s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [16:18<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [16:19<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [16:19<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1600/1600 [16:20<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 1600/1600 [16:22<00:00,  1.39s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [16:26<02:19,  1.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1605/1700 [16:26<02:19,  1.46s/pipeline]Optimization Progress:  95%|█████████▍| 1607/1700 [16:32<02:55,  1.89s/pipeline]Optimization Progress:  99%|█████████▉| 1687/1700 [16:35<00:17,  1.33s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 1700/1700 [16:37<00:00,  1.33s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [16:37<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [16:39<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:40<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:40<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:41<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:42<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:43<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:44<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1700/1700 [16:44<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [16:44<00:00,  1.02pipeline/s]Optimization Progress:  94%|█████████▍| 1700/1800 [16:50<01:38,  1.02pipeline/s]Optimization Progress:  94%|█████████▍| 1701/1800 [16:52<08:34,  5.20s/pipeline]Optimization Progress:  99%|█████████▉| 1781/1800 [16:54<01:09,  3.64s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [16:56<00:00,  3.64s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [16:56<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [16:56<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [16:56<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1800/1800 [16:59<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [16:59<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [17:02<00:00,  2.58s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▍| 1800/1900 [17:03<04:18,  2.58s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [17:09<06:15,  3.83s/pipeline]Optimization Progress:  99%|█████████▉| 1882/1900 [17:13<00:48,  2.69s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:13<00:00,  2.69s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [17:13<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:13<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:15<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [17:15<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 1900/1900 [17:17<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [17:17<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 1900/1900 [17:17<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 1900/1900 [17:18<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 1900/1900 [17:18<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1900/1900 [17:20<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [17:20<00:00,  1.89s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Cosine affinity cannot be used when X contains zero vectors.
Optimization Progress: 100%|██████████| 1900/1900 [17:21<00:00,  1.89s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [17:28<03:53,  2.43s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [17:32<00:30,  1.72s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-832857534.0318801	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=20, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-809557582.9315252	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2000/2000 [17:33<00:00,  1.72s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [17:33<00:00,  1.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 2000/2000 [17:40<00:00,  1.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2000/2000 [17:41<00:00,  1.22s/pipeline]Optimization Progress:  95%|█████████▌| 2001/2100 [17:41<05:28,  3.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▌| 2001/2100 [17:41<05:28,  3.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  95%|█████████▌| 2002/2100 [17:41<05:25,  3.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [17:41<05:21,  3.32s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [18:26<09:00,  5.69s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [18:30<00:59,  3.99s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-800676940.9417177	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00100.
Optimization Progress: 100%|██████████| 2100/2100 [18:30<00:00,  3.99s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [18:30<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [18:31<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [18:31<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:34<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:36<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:36<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:38<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:39<00:00,  2.80s/pipeline]Optimization Progress:  96%|█████████▌| 2104/2200 [18:45<04:54,  3.06s/pipeline]Optimization Progress:  99%|█████████▉| 2181/2200 [18:49<00:41,  2.16s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-800676940.9417177	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:49<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2200/2200 [18:50<00:00,  2.16s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [18:50<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:51<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:53<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2200/2200 [18:54<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:54<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [18:56<00:00,  1.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [18:58<02:30,  1.52s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [18:58<03:38,  2.23s/pipeline]Optimization Progress:  96%|█████████▌| 2203/2300 [19:07<07:00,  4.34s/pipeline]Optimization Progress:  99%|█████████▉| 2283/2300 [19:10<00:51,  3.05s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-800676940.9417177	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:12<00:00,  3.05s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [19:12<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:12<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:14<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 2300/2300 [19:14<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [19:15<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [19:18<00:00,  2.16s/pipeline]Optimization Progress:  96%|█████████▌| 2303/2400 [19:19<03:37,  2.24s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [19:24<04:51,  3.04s/pipeline]Optimization Progress:  99%|█████████▉| 2384/2400 [19:32<00:34,  2.16s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-832645811.2535312	GradientBoostingRegressor(FastICA(input_matrix, FastICA__tol=0.1), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-800465692.0510451	GradientBoostingRegressor(RBFSampler(VarianceThreshold(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-796466884.0785414	GradientBoostingRegressor(RBFSampler(VarianceThreshold(PolynomialFeatures(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.55), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 2400/2400 [19:33<00:00,  2.16s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [19:33<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [19:34<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:35<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:36<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:39<00:00,  1.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:39<00:00,  1.52s/pipeline]Optimization Progress:  96%|█████████▌| 2402/2500 [19:46<04:55,  3.02s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  99%|█████████▉| 2482/2500 [24:48<00:58,  3.25s/pipeline]                                                                                Skipped pipeline #2497 due to time out. Continuing to the next pipeline.
Optimization Progress: 100%|█████████▉| 2497/2500 [24:48<00:09,  3.25s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-800465692.0510451	GradientBoostingRegressor(RBFSampler(VarianceThreshold(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-796466884.0785414	GradientBoostingRegressor(RBFSampler(VarianceThreshold(PolynomialFeatures(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.55), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2501pipeline [24:51,  3.25s/pipeline]Optimization Progress: 2501pipeline [24:51,  2.32s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 2501pipeline [24:52,  2.32s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [24:57<03:58,  2.46s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [25:17<12:14,  7.65s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [25:19<01:25,  5.36s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-797226247.849611	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-796466884.0785414	GradientBoostingRegressor(RBFSampler(VarianceThreshold(PolynomialFeatures(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.55), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 2601pipeline [25:20,  5.36s/pipeline]Optimization Progress: 2601pipeline [25:20,  3.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 2601pipeline [25:21,  3.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [25:22,  3.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [25:22,  3.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2601pipeline [25:25,  3.76s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2601pipeline [25:27,  3.76s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [25:40<06:08,  3.76s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [26:56<27:29, 17.01s/pipeline]Optimization Progress:  99%|█████████▉| 2683/2700 [27:14<03:23, 11.98s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-797226247.849611	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-785714896.0389936	GradientBoostingRegressor(RBFSampler(RBFSampler(PCA(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), RBFSampler__gamma=0.45), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [27:15, 11.98s/pipeline]Optimization Progress: 2701pipeline [27:15,  8.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [27:17,  8.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [27:20,  8.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [27:20,  8.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [27:21,  8.40s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [27:28<15:52,  9.71s/pipeline]Optimization Progress:  99%|█████████▉| 2782/2800 [28:37<02:07,  7.06s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-797226247.849611	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-785714896.0389936	GradientBoostingRegressor(RBFSampler(RBFSampler(PCA(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), RBFSampler__gamma=0.45), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2801pipeline [28:38,  7.06s/pipeline]Optimization Progress: 2801pipeline [28:38,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2801pipeline [28:39,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [28:39,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 2801pipeline [28:40,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 2801pipeline [28:40,  4.96s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 2801pipeline [28:41,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2801pipeline [28:43,  4.96s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [28:44<08:42,  5.33s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [29:23<25:05, 15.52s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [29:26<03:04, 10.88s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-797226247.849611	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-785714896.0389936	GradientBoostingRegressor(RBFSampler(RBFSampler(PCA(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), RBFSampler__gamma=0.45), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 2901pipeline [29:27, 10.88s/pipeline]Optimization Progress: 2901pipeline [29:27,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [29:29,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [29:29,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 2901pipeline [29:29,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [29:30,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [29:32,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2901pipeline [29:32,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [29:34,  7.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2901pipeline [29:34,  7.63s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 2902/3000 [29:34<12:27,  7.63s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [29:34<10:24,  6.44s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [30:07<22:50, 14.28s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [30:23<02:40, 10.06s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-791790859.5700477	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-785714896.0389936	GradientBoostingRegressor(RBFSampler(RBFSampler(PCA(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), RBFSampler__gamma=0.45), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:24, 10.06s/pipeline]Optimization Progress: 3001pipeline [30:24,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [30:25,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [30:26,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:27,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:27,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:27,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:29,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [30:29,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [30:30,  7.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [30:30,  7.05s/pipeline]Optimization Progress:  97%|█████████▋| 3003/3100 [30:32<09:51,  6.10s/pipeline]Optimization Progress:  97%|█████████▋| 3004/3100 [30:53<16:48, 10.50s/pipeline]Optimization Progress:  99%|█████████▉| 3084/3100 [30:56<01:57,  7.36s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-791790859.5700477	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-785714896.0389936	GradientBoostingRegressor(RBFSampler(RBFSampler(PCA(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), RBFSampler__gamma=0.45), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [30:57,  7.36s/pipeline]Optimization Progress: 3101pipeline [30:57,  5.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3101pipeline [30:58,  5.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [30:59,  5.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3101pipeline [31:00,  5.18s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [31:04<07:40,  4.75s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [31:04<07:40,  4.75s/pipeline]Optimization Progress:  97%|█████████▋| 3105/3200 [31:42<14:17,  9.03s/pipeline]Optimization Progress: 100%|█████████▉| 3185/3200 [32:01<01:35,  6.39s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-791790859.5700477	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-772229749.5750612	GradientBoostingRegressor(RBFSampler(VarianceThreshold(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [32:05,  6.39s/pipeline]Optimization Progress: 3201pipeline [32:05,  4.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [32:06,  4.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 3201pipeline [32:09,  4.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3201pipeline [32:09,  4.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3201pipeline [32:09,  4.55s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3201/3300 [32:09<07:30,  4.55s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [32:09<07:15,  4.45s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [32:10<07:15,  4.45s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [34:09<33:43, 21.07s/pipeline]Optimization Progress: 100%|█████████▉| 3284/3300 [34:25<03:56, 14.81s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-810428329.1412646	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-791790859.5700477	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-785163768.5900792	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-772229749.5750612	GradientBoostingRegressor(RBFSampler(VarianceThreshold(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 3301pipeline [34:25, 14.81s/pipeline]Optimization Progress: 3301pipeline [34:25, 10.37s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [34:34<14:00,  8.67s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [34:50<14:00,  8.67s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [35:33<37:48, 23.63s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [35:41<04:25, 16.57s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-791455664.3287728	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-783710638.3907726	GradientBoostingRegressor(RBFSampler(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-772229749.5750612	GradientBoostingRegressor(RBFSampler(VarianceThreshold(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3401pipeline [35:42, 16.57s/pipeline]Optimization Progress: 3401pipeline [35:42, 11.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3401pipeline [35:43, 11.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3401pipeline [35:44, 11.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 3401pipeline [35:50, 11.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [35:52, 11.60s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [36:00<18:57, 11.60s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [36:50<29:42, 18.37s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [36:55<03:38, 12.88s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-783710638.3907726	GradientBoostingRegressor(RBFSampler(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-772229749.5750612	GradientBoostingRegressor(RBFSampler(VarianceThreshold(RobustScaler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False)), VarianceThreshold__threshold=0.05), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [36:55, 12.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [36:56, 12.88s/pipeline]Optimization Progress: 3501pipeline [36:56,  9.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [37:00,  9.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [37:01,  9.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [37:02,  9.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3501pipeline [37:03,  9.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3501pipeline [37:03,  9.03s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [37:04<14:29,  8.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [37:04<14:29,  8.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [37:04<14:20,  8.87s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3504/3600 [37:04<14:11,  8.87s/pipeline]Optimization Progress:  97%|█████████▋| 3506/3600 [37:57<15:57, 10.19s/pipeline]Optimization Progress: 100%|█████████▉| 3586/3600 [38:30<01:41,  7.26s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-832697965.9973075	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [38:31,  7.26s/pipeline]Optimization Progress: 3601pipeline [38:31,  5.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 3601pipeline [38:31,  5.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 3601pipeline [38:32,  5.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3601pipeline [38:37,  5.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [38:38,  5.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 3601pipeline [38:40,  5.08s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [38:42<08:20,  5.16s/pipeline]Optimization Progress:  97%|█████████▋| 3604/3700 [39:02<15:49,  9.89s/pipeline]Optimization Progress: 100%|█████████▉| 3684/3700 [39:08<01:51,  6.94s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-756600484.0711442	GradientBoostingRegressor(RBFSampler(PCA(VarianceThreshold(RobustScaler(LassoLarsCV(PolynomialFeatures(input_matrix, PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=True)), VarianceThreshold__threshold=0.05), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.7000000000000001), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 3701pipeline [39:11,  6.94s/pipeline]Optimization Progress: 3701pipeline [39:11,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [39:12,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [39:12,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 3701pipeline [39:12,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [39:12,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3701pipeline [39:12,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3701pipeline [39:13,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 3701pipeline [39:14,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [39:15,  4.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 3701pipeline [39:15,  4.92s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [39:17<07:00,  4.33s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3703/3800 [39:17<07:00,  4.33s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [39:17<06:55,  4.33s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3705/3800 [39:17<06:51,  4.33s/pipeline]Optimization Progress:  98%|█████████▊| 3707/3800 [39:57<09:20,  6.02s/pipeline]Optimization Progress: 100%|█████████▉| 3787/3800 [40:03<00:55,  4.24s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-829184756.0127928	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.6500000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [40:03,  4.24s/pipeline]Optimization Progress: 3801pipeline [40:03,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [40:05,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 3801pipeline [40:05,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [40:06,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [40:08,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [40:08,  2.98s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3801pipeline [40:09,  2.98s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [40:12<04:54,  2.98s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [40:12<04:51,  2.98s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [40:12<05:25,  3.36s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3803/3900 [40:12<05:25,  3.36s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3804/3900 [40:12<05:22,  3.36s/pipeline]Optimization Progress:  98%|█████████▊| 3806/3900 [40:59<11:09,  7.13s/pipeline]Optimization Progress: 100%|█████████▉| 3886/3900 [41:06<01:10,  5.01s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 3901pipeline [41:07,  5.01s/pipeline]Optimization Progress: 3901pipeline [41:07,  3.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [41:09,  3.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [41:11,  3.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 3901pipeline [41:11,  3.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 3901pipeline [41:12,  3.52s/pipeline]Optimization Progress:  98%|█████████▊| 3901/4000 [41:20<05:48,  3.52s/pipeline]Optimization Progress:  98%|█████████▊| 3902/4000 [44:12<1:34:39, 57.96s/pipeline]Optimization Progress: 100%|█████████▉| 3982/4000 [44:35<12:11, 40.66s/pipeline]  
Generation 39 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [44:39, 40.66s/pipeline]Optimization Progress: 4001pipeline [44:39, 28.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 4001pipeline [44:45, 28.52s/pipeline]Optimization Progress:  98%|█████████▊| 4005/4100 [44:46<32:21, 20.44s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4005/4100 [44:46<32:21, 20.44s/pipeline]Optimization Progress:  98%|█████████▊| 4007/4100 [45:09<27:39, 17.84s/pipeline]Optimization Progress: 100%|█████████▉| 4087/4100 [45:21<02:42, 12.53s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-804437644.541836	GradientBoostingRegressor(RBFSampler(RobustScaler(input_matrix), RBFSampler__gamma=0.75), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-790514329.4083412	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.4, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 4101pipeline [45:21, 12.53s/pipeline]Optimization Progress: 4101pipeline [45:21,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [45:21,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [45:23,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 4101pipeline [45:23,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [45:24,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 4101pipeline [45:24,  8.79s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [45:27,  8.79s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4101/4200 [45:30<14:29,  8.79s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [45:40<14:21,  8.79s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [47:27<40:19, 24.95s/pipeline]Optimization Progress: 100%|█████████▉| 4183/4200 [47:41<04:57, 17.52s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [47:41, 17.52s/pipeline]Optimization Progress: 4201pipeline [47:41, 12.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [47:42, 12.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [47:42, 12.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [47:43, 12.27s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [47:49<19:49, 12.27s/pipeline]Optimization Progress:  98%|█████████▊| 4204/4300 [47:49<15:01,  9.39s/pipeline]Optimization Progress:  98%|█████████▊| 4204/4300 [48:00<15:01,  9.39s/pipeline]Optimization Progress:  98%|█████████▊| 4205/4300 [51:44<2:01:49, 76.94s/pipeline]Optimization Progress: 100%|█████████▉| 4285/4300 [51:53<13:28, 53.90s/pipeline]  
Generation 42 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 4301pipeline [51:54, 53.90s/pipeline]Optimization Progress: 4301pipeline [51:54, 37.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [51:55, 37.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [52:04, 37.75s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [52:05<48:31, 29.71s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [52:46<53:23, 33.03s/pipeline]Optimization Progress: 100%|█████████▉| 4383/4400 [53:04<06:34, 23.18s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 4401pipeline [53:08, 23.18s/pipeline]Optimization Progress: 4401pipeline [53:08, 16.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4401pipeline [53:09, 16.30s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 4401pipeline [53:10, 16.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [53:12, 16.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [53:14, 16.30s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [53:15<20:03, 12.41s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4403/4500 [53:15<20:03, 12.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4404/4500 [53:15<19:51, 12.41s/pipeline]Optimization Progress:  98%|█████████▊| 4406/4500 [53:46<18:25, 11.76s/pipeline]Optimization Progress: 100%|█████████▉| 4486/4500 [53:48<01:55,  8.24s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-769171163.2098025	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-6	-768890369.851005	GradientBoostingRegressor(RBFSampler(PolynomialFeatures(RobustScaler(ElasticNetCV(LassoLarsCV(input_matrix, LassoLarsCV__normalize=True), ElasticNetCV__l1_ratio=0.7000000000000001, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), RBFSampler__gamma=0.2), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4501pipeline [53:48,  8.24s/pipeline]Optimization Progress: 4501pipeline [53:48,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [53:48,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [53:52,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [53:52,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [53:53,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 4501pipeline [53:55,  5.77s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4501pipeline [53:57,  5.77s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [53:57<07:24,  4.68s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [54:10<07:24,  4.68s/pipeline]Optimization Progress:  98%|█████████▊| 4506/4600 [58:34<2:15:18, 86.36s/pipeline]Optimization Progress: 100%|█████████▉| 4586/4600 [58:48<14:07, 60.51s/pipeline]  
Generation 45 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-755035893.3692139	GradientBoostingRegressor(PCA(RBFSampler(RobustScaler(CombineDFs(input_matrix, input_matrix)), RBFSampler__gamma=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:48, 60.51s/pipeline]Optimization Progress: 4601pipeline [58:48, 42.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:50, 42.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [58:53, 42.37s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [58:57<47:55, 30.27s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4605/4700 [58:57<47:55, 30.27s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4606/4700 [58:57<47:25, 30.27s/pipeline]Optimization Progress:  98%|█████████▊| 4608/4700 [59:49<40:27, 26.38s/pipeline]Optimization Progress: 100%|█████████▉| 4688/4700 [59:51<03:41, 18.48s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-832208329.1216514	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=16, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-828071472.4767622	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.9000000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-772061633.8508623	GradientBoostingRegressor(Nystroem(SGDRegressor(input_matrix, SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=constant, SGDRegressor__loss=epsilon_insensitive, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), Nystroem__gamma=0.9, Nystroem__kernel=cosine, Nystroem__n_components=9), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=20, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-755035893.3692139	GradientBoostingRegressor(PCA(RBFSampler(RobustScaler(CombineDFs(input_matrix, input_matrix)), RBFSampler__gamma=0.55), PCA__iterated_power=8, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=14, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-7	-754736926.7643775	GradientBoostingRegressor(RBFSampler(PCA(AdaBoostRegressor(RobustScaler(VarianceThreshold(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=1.0, AdaBoostRegressor__loss=square, AdaBoostRegressor__n_estimators=100), VarianceThreshold__threshold=0.1)), AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), PCA__iterated_power=8, PCA__svd_solver=randomized), RBFSampler__gamma=0.4), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=7, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 4701pipeline [59:52, 18.48s/pipeline]Optimization Progress: 4701pipeline [59:52, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:53, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:53, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:55, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:57, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:57, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:57, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4701pipeline [59:57, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:58, 12.95s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [1:00:00, 12.95s/pipeline]                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [1:00:00, 12.95s/pipeline]                                                              
Optimization Progress:  98%|█████████▊| 4702/4800 [1:00:01<21:08, 12.95s/pipeline]                                                                                  60.12 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress:  98%|█████████▊| 4702/4800 [1:00:01<21:08, 12.95s/pipeline]                                                                                  
Optimization Progress:  98%|█████████▊| 4702/4800 [1:00:01<21:08, 12.95s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress:  98%|█████████▊| 4702/4800 [1:00:01<21:08, 12.95s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=AdaBoostRegressor(loss='square', n_estimators=100))
1. VarianceThreshold(threshold=0.1)
2. RobustScaler()
3. StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001,
                                              loss='exponential',
                                              n_estimators=100))
4. PCA(iterated_power=8, svd_solver='randomized')
5. RBFSampler(gamma=0.4)
6. GradientBoostingRegressor(alpha=0.99, learning_rate=0.01, loss='lad',
                          max_depth=7, max_features=0.45, min_samples_leaf=18,
                          min_samples_split=7, subsample=0.05)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
