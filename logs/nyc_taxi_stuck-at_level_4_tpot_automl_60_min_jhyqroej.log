30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   6%|▌         | 6/100 [00:06<01:40,  1.07s/pipeline]Optimization Progress:  86%|████████▌ | 86/100 [00:09<00:10,  1.31pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.74pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.74pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  1.74pipeline/s]Optimization Progress:  54%|█████▎    | 107/200 [00:15<00:52,  1.76pipeline/s]Optimization Progress:  54%|█████▍    | 108/200 [00:20<03:00,  1.97s/pipeline]Optimization Progress:  94%|█████████▍| 188/200 [00:21<00:16,  1.38s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-565313716.4431636	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:22<00:00,  1.38s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:22<00:00,  1.01pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 200/200 [00:22<00:00,  1.01pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:24<00:00,  1.01pipeline/s]                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:25<00:00,  1.01pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [00:28<01:36,  1.01pipeline/s]Optimization Progress:  68%|██████▊   | 203/300 [00:28<02:08,  1.32s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 203/300 [00:28<02:08,  1.32s/pipeline]Optimization Progress:  68%|██████▊   | 205/300 [00:36<03:17,  2.08s/pipeline]Optimization Progress:  95%|█████████▌| 285/300 [00:40<00:22,  1.47s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-565313716.4431636	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:42<00:00,  1.47s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:42<00:00,  1.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 300/300 [00:43<00:00,  1.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 300/300 [00:43<00:00,  1.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 300/300 [00:43<00:00,  1.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:46<00:00,  1.07s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [00:48<00:00,  1.07s/pipeline]Optimization Progress:  75%|███████▌  | 300/400 [01:00<01:46,  1.07s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [05:48<2:33:05, 92.78s/pipeline]                                                                                Skipped pipeline #346 due to time out. Continuing to the next pipeline.
Optimization Progress:  86%|████████▋ | 346/400 [05:48<1:23:30, 92.78s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress:  96%|█████████▌| 382/400 [05:53<19:29, 64.96s/pipeline]  
Generation 3 - Current Pareto front scores:
-1	-565313716.4431636	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-548841870.4605548	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 401pipeline [05:53, 64.96s/pipeline]Optimization Progress: 401pipeline [05:53, 45.48s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 401pipeline [05:54, 45.48s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 401pipeline [05:55, 45.48s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 401pipeline [05:56, 45.48s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                           Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 402/500 [06:02<1:14:17, 45.48s/pipeline]Optimization Progress:  81%|████████  | 403/500 [06:02<53:40, 33.20s/pipeline]  Optimization Progress:  81%|████████  | 404/500 [06:11<41:33, 25.98s/pipeline]Optimization Progress:  97%|█████████▋| 484/500 [06:16<04:51, 18.20s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-565313716.4431636	XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.8500000000000001)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-519561296.0093748	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.9000000000000001, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 501pipeline [06:21, 18.20s/pipeline]Optimization Progress: 501pipeline [06:21, 12.82s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 501pipeline [06:22, 12.82s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 501pipeline [06:23, 12.82s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 501pipeline [06:23, 12.82s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [06:25<16:43, 10.24s/pipeline]Optimization Progress:  84%|████████▍ | 503/600 [06:32<14:58,  9.27s/pipeline]Optimization Progress:  97%|█████████▋| 583/600 [06:40<01:50,  6.51s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-518267789.0738556	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 601pipeline [06:40,  6.51s/pipeline]Optimization Progress: 601pipeline [06:40,  4.57s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 601pipeline [06:40,  4.57s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 601pipeline [06:42,  4.57s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 601pipeline [06:42,  4.57s/pipeline]Optimization Progress:  87%|████████▋ | 607/700 [06:49<05:40,  3.66s/pipeline]Optimization Progress:  87%|████████▋ | 609/700 [06:57<05:32,  3.65s/pipeline]Optimization Progress:  98%|█████████▊| 688/700 [07:05<00:31,  2.59s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-518267789.0738556	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 701pipeline [07:06,  2.59s/pipeline]Optimization Progress: 701pipeline [07:06,  1.83s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 701pipeline [07:06,  1.83s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 701pipeline [07:17,  1.83s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 701pipeline [07:18,  1.83s/pipeline]                                                           Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [07:19<03:00,  1.83s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [07:20<02:59,  1.83s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [07:36<09:17,  5.75s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [08:11<01:10,  4.15s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-518267789.0738556	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [08:11,  4.15s/pipeline]Optimization Progress: 801pipeline [08:11,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 801pipeline [08:11,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 801pipeline [08:12,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [08:12,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [08:13,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [08:13,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 801pipeline [08:15,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 801pipeline [08:22,  2.92s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 801pipeline [08:22,  2.92s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [08:24<06:29,  4.02s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 803/900 [08:25<06:29,  4.02s/pipeline]Optimization Progress:  89%|████████▉ | 805/900 [08:34<06:40,  4.22s/pipeline]Optimization Progress:  98%|█████████▊| 885/900 [08:39<00:44,  2.97s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-510051906.15954196	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 901pipeline [08:39,  2.97s/pipeline]Optimization Progress: 901pipeline [08:39,  2.09s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 901pipeline [08:43,  2.09s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 901pipeline [08:46,  2.09s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 901pipeline [08:47,  2.09s/pipeline]                                                           _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 901pipeline [08:48,  2.09s/pipeline]Optimization Progress: 901pipeline [08:50,  2.09s/pipeline]Optimization Progress:  90%|█████████ | 904/1000 [08:51<04:13,  2.64s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 904/1000 [08:51<04:13,  2.64s/pipeline]Optimization Progress:  91%|█████████ | 906/1000 [08:59<04:53,  3.12s/pipeline]Optimization Progress:  99%|█████████▊| 986/1000 [09:06<00:30,  2.21s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-510051906.15954196	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1001pipeline [09:08,  2.21s/pipeline]Optimization Progress: 1001pipeline [09:08,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 1001pipeline [09:13,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 1001pipeline [09:17,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:18,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1001pipeline [09:18,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1001pipeline [09:18,  1.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 1001pipeline [09:20,  1.59s/pipeline]Optimization Progress:  91%|█████████▏| 1004/1100 [09:21<03:49,  2.39s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [10:09<25:31, 16.12s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [10:12<02:49, 11.30s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-561225466.4910653	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-550722660.5147921	ExtraTreesRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=15), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=19, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-3	-510051906.15954196	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-5	-509729503.1151105	ExtraTreesRegressor(LassoLarsCV(Normalizer(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), Normalizer__norm=l1), LassoLarsCV__normalize=True), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1101pipeline [10:12, 11.30s/pipeline]Optimization Progress: 1101pipeline [10:26,  8.18s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [11:32<25:14, 15.61s/pipeline]Optimization Progress:  99%|█████████▊| 1183/1200 [11:40<03:06, 10.96s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-538918153.3812927	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-507030483.241477	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-497757874.8004652	ExtraTreesRegressor(FastICA(XGBRegressor(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 1201pipeline [11:40, 10.96s/pipeline]Optimization Progress: 1201pipeline [11:40,  7.68s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [14:20:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 1201pipeline [11:50,  7.68s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1201pipeline [11:52,  7.68s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [11:55<12:20,  7.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1203/1300 [11:55<12:20,  7.63s/pipeline]Optimization Progress:  93%|█████████▎| 1205/1300 [12:04<10:35,  6.69s/pipeline]Optimization Progress:  99%|█████████▉| 1285/1300 [12:09<01:10,  4.70s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-538918153.3812927	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-507030483.241477	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-497757874.8004652	ExtraTreesRegressor(FastICA(XGBRegressor(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [12:11,  4.70s/pipeline]Optimization Progress: 1301pipeline [12:11,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:14,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 1301pipeline [12:14,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1301pipeline [12:16,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:16,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:17,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:18,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:22,  3.33s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1301pipeline [12:23,  3.33s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [12:24<05:45,  3.60s/pipeline]Optimization Progress:  93%|█████████▎| 1305/1400 [13:12<26:54, 16.99s/pipeline]Optimization Progress:  99%|█████████▉| 1385/1400 [13:20<02:58, 11.92s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-534871595.6459915	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-507030483.241477	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=9, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-497757874.8004652	ExtraTreesRegressor(FastICA(XGBRegressor(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1401pipeline [13:23, 11.92s/pipeline]Optimization Progress: 1401pipeline [13:23,  8.42s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1401pipeline [13:24,  8.42s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1401pipeline [13:27,  8.42s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 1401pipeline [13:32,  8.42s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1401pipeline [13:36,  8.42s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [13:37<16:09,  9.89s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [17:36<2:07:16, 78.73s/pipeline]Optimization Progress:  99%|█████████▉| 1483/1500 [17:42<15:37, 55.13s/pipeline]  
Generation 14 - Current Pareto front scores:
-1	-534871595.6459915	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-534618633.801462	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.5, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=15, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-503176955.2655546	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=5, XGBRegressor__min_child_weight=9, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-497757874.8004652	ExtraTreesRegressor(FastICA(XGBRegressor(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1501pipeline [17:43, 55.13s/pipeline]Optimization Progress: 1501pipeline [17:43, 38.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [14:25:59] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 1501pipeline [17:43, 38.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 1501pipeline [17:44, 38.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1501pipeline [17:53, 38.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [17:53, 38.60s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1501pipeline [17:54, 38.60s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [18:00<1:03:02, 38.60s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [18:06<49:25, 30.57s/pipeline]  Optimization Progress:  99%|█████████▉| 1583/1600 [18:13<06:04, 21.42s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-534871595.6459915	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-533778090.60886306	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=2, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1601pipeline [18:13, 21.42s/pipeline]Optimization Progress: 1601pipeline [18:13, 15.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1601pipeline [18:17, 15.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1601pipeline [18:22, 15.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 1601pipeline [18:24, 15.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1601pipeline [18:25, 15.00s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 1601pipeline [18:25, 15.00s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [18:30<24:45, 15.00s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [21:58<2:07:35, 78.12s/pipeline]Optimization Progress:  99%|█████████▉| 1682/1700 [22:08<16:24, 54.72s/pipeline]  
Generation 16 - Current Pareto front scores:
-1	-534871595.6459915	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-532947902.11776483	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [22:08, 54.72s/pipeline]Optimization Progress: 1701pipeline [22:08, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1701pipeline [22:11, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [22:11, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1701pipeline [22:13, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1701pipeline [22:14, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [22:14, 38.31s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 1701pipeline [22:14, 38.31s/pipeline]Optimization Progress: 1701pipeline [22:20, 38.31s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [22:23<46:51, 28.99s/pipeline]Optimization Progress:  95%|█████████▍| 1704/1800 [22:50<45:43, 28.58s/pipeline]Optimization Progress:  99%|█████████▉| 1784/1800 [23:00<05:20, 20.05s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-532947902.11776483	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1801pipeline [23:02, 20.05s/pipeline]Optimization Progress: 1801pipeline [23:02, 14.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 1801pipeline [23:07, 14.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 1801pipeline [23:07, 14.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1801pipeline [23:08, 14.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1801pipeline [23:12, 14.05s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [23:20<22:56, 14.05s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [23:29<22:27, 13.89s/pipeline]Optimization Progress:  99%|█████████▉| 1883/1900 [23:38<02:45,  9.76s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-532947902.11776483	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-493307883.31271756	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1901pipeline [23:39,  9.76s/pipeline]Optimization Progress: 1901pipeline [23:39,  6.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 1901pipeline [23:46,  6.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 1901pipeline [23:47,  6.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 1901pipeline [23:50,  6.85s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [23:54<15:11,  9.30s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [24:24<24:50, 15.37s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [24:28<03:03, 10.78s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-532947902.11776483	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-493307883.31271756	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2001pipeline [24:33, 10.78s/pipeline]Optimization Progress: 2001pipeline [24:33,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [24:33,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2001pipeline [24:35,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [24:37,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [24:38,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2001pipeline [24:41,  7.61s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2001pipeline [24:41,  7.61s/pipeline]Optimization Progress:  95%|█████████▌| 2003/2100 [24:44<11:19,  7.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2003/2100 [24:44<11:19,  7.01s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [25:12<14:22,  9.08s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [25:18<01:35,  6.38s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-531047949.1832198	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2101pipeline [25:21,  6.38s/pipeline]Optimization Progress: 2101pipeline [25:21,  4.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2101pipeline [25:21,  4.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2101pipeline [25:29,  4.52s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2101pipeline [25:33,  4.52s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [25:49<19:01, 11.65s/pipeline]Optimization Progress:  99%|█████████▉| 2182/2200 [25:56<02:27,  8.18s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-531047949.1832198	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.7500000000000001, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2201pipeline [26:03,  8.18s/pipeline]Optimization Progress: 2201pipeline [26:03,  5.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [26:03,  5.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2201pipeline [26:04,  5.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 2201pipeline [26:06,  5.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2201pipeline [26:08,  5.83s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [26:22<15:56,  9.76s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [26:29<02:03,  6.86s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-530010254.58509237	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2301pipeline [26:31,  6.86s/pipeline]Optimization Progress: 2301pipeline [26:31,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:34,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [26:34,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2301pipeline [26:34,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 2301pipeline [26:35,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:37,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 2301pipeline [26:38,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2301pipeline [26:38,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [26:38,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2301pipeline [26:39,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:43,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:43,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 2301pipeline [26:43,  4.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2301pipeline [26:44,  4.83s/pipeline]Optimization Progress:  96%|█████████▌| 2304/2400 [26:44<07:27,  4.66s/pipeline]Optimization Progress:  96%|█████████▌| 2305/2400 [29:34<1:25:58, 54.30s/pipeline]Optimization Progress:  99%|█████████▉| 2385/2400 [29:42<09:30, 38.04s/pipeline]  
Generation 23 - Current Pareto front scores:
-1	-534015882.53373945	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-530010254.58509237	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=12, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2401pipeline [29:42, 38.04s/pipeline]Optimization Progress: 2401pipeline [29:42, 26.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [14:38:05] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 2401pipeline [29:49, 26.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2401pipeline [29:51, 26.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2401pipeline [29:54, 26.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 2401pipeline [29:54, 26.63s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 2401pipeline [29:55, 26.63s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [29:57<43:30, 26.63s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [29:57<33:37, 20.80s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [30:09<29:23, 18.37s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [30:17<03:26, 12.89s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-533699284.13718957	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=9, GradientBoostingRegressor__min_samples_split=17, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-529836671.1134733	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2501pipeline [30:19, 12.89s/pipeline]Optimization Progress: 2501pipeline [30:19,  9.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 2501pipeline [30:22,  9.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 2501pipeline [30:24,  9.06s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2501pipeline [30:28,  9.06s/pipeline]Optimization Progress:  96%|█████████▋| 2504/2600 [30:33<12:16,  7.67s/pipeline]Optimization Progress:  96%|█████████▋| 2505/2600 [30:46<14:59,  9.47s/pipeline]Optimization Progress:  99%|█████████▉| 2585/2600 [30:54<01:39,  6.65s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-533513377.1527605	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529836671.1134733	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 2601pipeline [31:00,  6.65s/pipeline]Optimization Progress: 2601pipeline [31:00,  4.77s/pipeline]Optimization Progress:  96%|█████████▋| 2603/2700 [31:10<07:50,  4.85s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [31:23<11:41,  7.31s/pipeline]Optimization Progress:  99%|█████████▉| 2684/2700 [31:32<01:22,  5.15s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-533391785.975821	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529836671.1134733	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 2701pipeline [31:34,  5.15s/pipeline]Optimization Progress: 2701pipeline [31:34,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 [14:39:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 2701pipeline [31:34,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [31:37,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [31:37,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [31:37,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 2701pipeline [31:39,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2701pipeline [31:39,  3.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 2701pipeline [31:42,  3.64s/pipeline]Optimization Progress:  97%|█████████▋| 2704/2800 [31:48<06:20,  3.96s/pipeline]Optimization Progress:  97%|█████████▋| 2705/2800 [32:00<10:05,  6.37s/pipeline]Optimization Progress:  99%|█████████▉| 2785/2800 [32:33<01:08,  4.58s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-533391785.975821	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529836671.1134733	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2801pipeline [32:35,  4.58s/pipeline]Optimization Progress: 2801pipeline [32:35,  3.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 2801pipeline [32:40,  3.25s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 2801pipeline [32:40,  3.25s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [32:49<10:25,  6.38s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [33:07<16:20, 10.10s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [33:15<02:00,  7.10s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-533391785.975821	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-529836671.1134733	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 2901pipeline [33:21,  7.10s/pipeline]Optimization Progress: 2901pipeline [33:21,  5.07s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 2901pipeline [33:28,  5.07s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [33:30<10:26,  6.39s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [33:43<13:15,  8.20s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [33:49<01:38,  5.77s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-528382462.36561	GradientBoostingRegressor(ExtraTreesRegressor(input_matrix, ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.1, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=8, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=7, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3001pipeline [33:52,  5.77s/pipeline]Optimization Progress: 3001pipeline [33:52,  4.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3001pipeline [33:55,  4.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [33:58,  4.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3001pipeline [33:58,  4.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 3001pipeline [34:02,  4.08s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 3001pipeline [34:06,  4.08s/pipeline]Optimization Progress:  97%|█████████▋| 3007/3100 [34:06<05:32,  3.58s/pipeline]Optimization Progress:  97%|█████████▋| 3008/3100 [34:53<25:22, 16.55s/pipeline]Optimization Progress: 100%|█████████▉| 3088/3100 [35:18<02:20, 11.68s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-526798243.84384644	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3101pipeline [35:24, 11.68s/pipeline]Optimization Progress: 3101pipeline [35:24,  8.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3101pipeline [35:26,  8.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 3101pipeline [35:28,  8.30s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3101pipeline [35:28,  8.30s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [35:33<11:47,  7.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [35:33<11:47,  7.29s/pipeline]Optimization Progress:  97%|█████████▋| 3105/3200 [36:19<18:59, 12.00s/pipeline]Optimization Progress: 100%|█████████▉| 3185/3200 [36:26<02:06,  8.42s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-526798243.84384644	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [36:28,  8.42s/pipeline]Optimization Progress: 3201pipeline [36:28,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [36:28,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 3201pipeline [36:29,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [36:32,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3201pipeline [36:34,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 3201pipeline [36:37,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [36:37,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3201pipeline [36:38,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [36:41,  5.92s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3201pipeline [36:42,  5.92s/pipeline]Optimization Progress:  97%|█████████▋| 3204/3300 [36:42<08:54,  5.56s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [36:55<12:16,  7.75s/pipeline]Optimization Progress: 100%|█████████▉| 3285/3300 [37:06<01:21,  5.47s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-526697038.50820434	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-497372848.6709839	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 3301pipeline [37:15,  5.47s/pipeline]Optimization Progress: 3301pipeline [37:15,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3301pipeline [37:17,  3.99s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 3301pipeline [37:18,  3.99s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [37:21<07:38,  4.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3302/3400 [37:21<07:38,  4.68s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [39:39<38:29, 24.06s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [39:48<04:29, 16.87s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-526697038.50820434	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=13, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-496157998.71723443	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.5), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [39:48, 16.87s/pipeline]Optimization Progress: 3401pipeline [39:48, 11.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3401pipeline [39:50, 11.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [14:48:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 3401pipeline [39:50, 11.82s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3401pipeline [39:58, 11.82s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3401pipeline [39:59, 11.82s/pipeline]Optimization Progress: 3401pipeline [40:00, 11.82s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [40:04<21:22, 13.09s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [40:39<31:31, 19.50s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [41:08<03:53, 13.76s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-496157998.71723443	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.5), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [41:09, 13.76s/pipeline]Optimization Progress: 3501pipeline [41:09,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [41:10,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 3501pipeline [41:10,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 3501pipeline [41:12,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3501pipeline [41:15,  9.64s/pipeline]Optimization Progress: 3501pipeline [41:20,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3501pipeline [41:20,  9.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 3501pipeline [41:22,  9.64s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [41:22<17:30, 10.72s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [41:33<17:45, 10.98s/pipeline]Optimization Progress: 100%|█████████▉| 3583/3600 [42:01<02:12,  7.79s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-491343663.9940602	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.5), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=6, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3601pipeline [42:03,  7.79s/pipeline]Optimization Progress: 3601pipeline [42:03,  5.48s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [42:09,  5.48s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [42:10,  5.48s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 3601pipeline [42:15,  5.48s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [42:17<13:11,  8.07s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [42:28<14:30,  8.98s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [42:58<01:48,  6.39s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-491343663.9940602	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=8, XGBRegressor__min_child_weight=2, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.5), FastICA__tol=0.45), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=6, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3701pipeline [43:04,  6.39s/pipeline]Optimization Progress: 3701pipeline [43:04,  4.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 3701pipeline [43:08,  4.59s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [43:09,  4.59s/pipeline]Optimization Progress:  97%|█████████▋| 3703/3800 [43:14<07:36,  4.70s/pipeline]Optimization Progress:  97%|█████████▋| 3704/3800 [44:25<39:18, 24.57s/pipeline]Optimization Progress: 100%|█████████▉| 3784/3800 [44:33<04:35, 17.23s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-533349736.03755444	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [44:45, 17.23s/pipeline]Optimization Progress: 3801pipeline [44:45, 12.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [44:47, 12.27s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [44:49, 12.27s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [44:50<14:29,  9.05s/pipeline]Optimization Progress:  98%|█████████▊| 3805/3900 [46:06<46:19, 29.25s/pipeline]Optimization Progress: 100%|█████████▉| 3885/3900 [46:13<05:07, 20.51s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-533264192.9617922	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 3901pipeline [46:14, 20.51s/pipeline]Optimization Progress: 3901pipeline [46:14, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [46:16, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [46:16, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [46:17, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 3901pipeline [46:18, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [46:20, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 3901pipeline [46:20, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [46:26, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 3901pipeline [46:28, 14.36s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 3901pipeline [46:29, 14.36s/pipeline]Optimization Progress: 3901pipeline [46:30, 14.36s/pipeline]Optimization Progress:  98%|█████████▊| 3905/4000 [46:30<17:48, 11.25s/pipeline]Optimization Progress:  98%|█████████▊| 3906/4000 [46:42<17:55, 11.44s/pipeline]Optimization Progress: 100%|█████████▉| 3986/4000 [46:51<01:52,  8.05s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-533264192.9617922	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [46:51,  8.05s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4001pipeline [46:55,  8.05s/pipeline]Optimization Progress: 4001pipeline [46:55,  5.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [47:01,  5.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [47:05,  5.71s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 4001pipeline [47:07,  5.71s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [47:09<13:03,  8.00s/pipeline]Optimization Progress:  98%|█████████▊| 4003/4100 [48:25<46:01, 28.47s/pipeline]Optimization Progress: 100%|█████████▉| 4083/4100 [48:33<05:39, 19.96s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-533264192.9617922	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=1.0, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4101pipeline [48:37, 19.96s/pipeline]Optimization Progress: 4101pipeline [48:37, 14.03s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4101pipeline [48:43, 14.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [48:43, 14.03s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4101pipeline [48:47, 14.03s/pipeline]Optimization Progress:  98%|█████████▊| 4102/4200 [48:49<22:03, 13.51s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [51:00<1:18:42, 48.68s/pipeline]Optimization Progress: 100%|█████████▉| 4183/4200 [51:09<09:39, 34.11s/pipeline]  
Generation 41 - Current Pareto front scores:
-1	-533260032.9365064	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [51:12, 34.11s/pipeline]Optimization Progress: 4201pipeline [51:12, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [51:13, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [51:17, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4201pipeline [51:22, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.
Optimization Progress: 4201pipeline [51:22, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [51:24, 23.93s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [51:25, 23.93s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [51:26<34:25, 21.08s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [51:44<32:23, 20.04s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [51:51<03:58, 14.05s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-533260032.9365064	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.25, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4301pipeline [51:51, 14.05s/pipeline]Optimization Progress: 4301pipeline [51:51,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [51:52,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 4301pipeline [51:55,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [51:55,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 4301pipeline [51:55,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4301pipeline [52:00,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 4301pipeline [52:03,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [52:05,  9.85s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [52:07,  9.85s/pipeline]Optimization Progress:  98%|█████████▊| 4301/4400 [52:10<16:14,  9.85s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [52:19<24:55, 15.27s/pipeline]Optimization Progress: 100%|█████████▉| 4382/4400 [52:27<03:12, 10.71s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-533229972.0322391	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [52:30, 10.71s/pipeline]Optimization Progress: 4401pipeline [52:30,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [52:31,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [52:31,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4401pipeline [52:32,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [52:34,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4401pipeline [52:35,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [52:39,  7.55s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [52:41,  7.55s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4401/4500 [52:43<12:27,  7.55s/pipeline]Optimization Progress:  98%|█████████▊| 4402/4500 [52:43<14:53,  9.11s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [53:23<29:57, 18.53s/pipeline]Optimization Progress: 100%|█████████▉| 4483/4500 [55:41<03:49, 13.48s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-533229972.0322391	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4501pipeline [55:44, 13.48s/pipeline]Optimization Progress: 4501pipeline [55:44,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [55:48,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 [15:04:04] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fcd63072dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fcd63183669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fcd63190f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fcd63177cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fcd63064f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fc370e1f9dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fc370e1f067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fc370e3727e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fc370e37cb4]

.
Optimization Progress: 4501pipeline [55:48,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [55:49,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [55:51,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [55:54,  9.50s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4501pipeline [55:56,  9.50s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [56:23<29:31, 18.08s/pipeline]Optimization Progress: 100%|█████████▉| 4582/4600 [56:31<03:48, 12.68s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-533229972.0322391	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 4601pipeline [56:32, 12.68s/pipeline]Optimization Progress: 4601pipeline [56:32,  8.90s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [56:42,  8.90s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4601pipeline [56:47,  8.90s/pipeline]Optimization Progress:  98%|█████████▊| 4602/4700 [56:48<17:52, 10.94s/pipeline]Optimization Progress:  98%|█████████▊| 4603/4700 [58:56<1:14:43, 46.22s/pipeline]Optimization Progress: 100%|█████████▉| 4683/4700 [59:06<09:10, 32.39s/pipeline]  
Generation 46 - Current Pareto front scores:
-1	-533229972.0322391	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=9, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-524642383.0250144	GradientBoostingRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.35000000000000003, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.01, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=17, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-3	-490251407.6930359	ExtraTreesRegressor(FastICA(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9500000000000001), FastICA__tol=0.35000000000000003), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.35000000000000003, ExtraTreesRegressor__min_samples_leaf=10, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)
-4	-475031299.72345763	ExtraTreesRegressor(Nystroem(FastICA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=6, DecisionTreeRegressor__min_samples_leaf=6, DecisionTreeRegressor__min_samples_split=5), FastICA__tol=0.45), Nystroem__gamma=0.45, Nystroem__kernel=linear, Nystroem__n_components=7), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.4, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=10, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:13, 32.39s/pipeline]Optimization Progress: 4701pipeline [59:13, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:13, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:13, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:13, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 4701pipeline [59:13, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:15, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:15, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:15, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4701pipeline [59:16, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [59:16, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [59:20, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4701pipeline [59:21, 22.78s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 4701pipeline [59:23, 22.78s/pipeline]Optimization Progress:  98%|█████████▊| 4702/4800 [59:23<31:08, 19.06s/pipeline]Optimization Progress:  98%|█████████▊| 4703/4800 [1:00:41<59:29, 36.80s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4782/4800 [1:00:41<11:02, 36.80s/pipeline]                                                                                  60.78 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 4782/4800 [1:00:41<11:02, 36.80s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4782/4800 [1:00:41<11:02, 36.80s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 4782/4800 [1:00:41<11:02, 36.80s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=DecisionTreeRegressor(max_depth=6,
                                                  min_samples_leaf=6,
                                                  min_samples_split=5))
1. FastICA(tol=0.45)
2. Nystroem(gamma=0.45, kernel='linear', n_components=7)
3. ExtraTreesRegressor(max_features=0.4, min_samples_leaf=2, min_samples_split=10)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
