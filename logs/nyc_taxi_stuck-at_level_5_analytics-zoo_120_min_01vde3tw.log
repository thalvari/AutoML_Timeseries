Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
Adding /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/lib/analytics-zoo-bigdl_0.10.0-spark_2.4.3-0.8.1-jar-with-dependencies.jar to BIGDL_JARS
Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
Current pyspark location is : /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/__init__.py
Start to getOrCreate SparkContext
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/scratch/project_2003107
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/pyspark/jars/spark-unsafe_2.11-2.4.3.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2020-11-20 11:43:05 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).

User settings:

   KMP_AFFINITY=granularity=fine,compact,1,0
   KMP_BLOCKTIME=0
   KMP_DUPLICATE_LIB_OK=True
   KMP_INIT_AT_FORK=FALSE
   KMP_SETTINGS=1
   OMP_NUM_THREADS=40

Effective settings:

   KMP_ABORT_DELAY=0
   KMP_ADAPTIVE_LOCK_PROPS='1,1024'
   KMP_ALIGN_ALLOC=64
   KMP_ALL_THREADPRIVATE=160
   KMP_ATOMIC_MODE=2
   KMP_BLOCKTIME=0
   KMP_CPUINFO_FILE: value is not defined
   KMP_DETERMINISTIC_REDUCTION=false
   KMP_DEVICE_THREAD_LIMIT=2147483647
   KMP_DISP_HAND_THREAD=false
   KMP_DISP_NUM_BUFFERS=7
   KMP_DUPLICATE_LIB_OK=true
   KMP_FORCE_REDUCTION: value is not defined
   KMP_FOREIGN_THREADS_THREADPRIVATE=true
   KMP_FORKJOIN_BARRIER='2,2'
   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'
   KMP_FORKJOIN_FRAMES=true
   KMP_FORKJOIN_FRAMES_MODE=3
   KMP_GTID_MODE=3
   KMP_HANDLE_SIGNALS=false
   KMP_HOT_TEAMS_MAX_LEVEL=1
   KMP_HOT_TEAMS_MODE=0
   KMP_INIT_AT_FORK=true
   KMP_INIT_WAIT=2048
   KMP_ITT_PREPARE_DELAY=0
   KMP_LIBRARY=throughput
   KMP_LOCK_KIND=queuing
   KMP_MALLOC_POOL_INCR=1M
   KMP_NEXT_WAIT=1024
   KMP_NUM_LOCKS_IN_BLOCK=1
   KMP_PLAIN_BARRIER='2,2'
   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'
   KMP_REDUCTION_BARRIER='1,1'
   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'
   KMP_SCHEDULE='static,balanced;guided,iterative'
   KMP_SETTINGS=true
   KMP_SPIN_BACKOFF_PARAMS='4096,100'
   KMP_STACKOFFSET=64
   KMP_STACKPAD=0
   KMP_STACKSIZE=4M
   KMP_STORAGE_MAP=false
   KMP_TASKING=2
   KMP_TASKLOOP_MIN_TASKS=0
   KMP_TASK_STEALING_CONSTRAINT=1
   KMP_TEAMS_THREAD_LIMIT=40
   KMP_TOPOLOGY_METHOD=all
   KMP_USER_LEVEL_MWAIT=false
   KMP_VERSION=false
   KMP_WARNINGS=true
   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'
   OMP_ALLOCATOR=omp_default_mem_alloc
   OMP_CANCELLATION=false
   OMP_DEFAULT_DEVICE=0
   OMP_DISPLAY_AFFINITY=false
   OMP_DISPLAY_ENV=false
   OMP_DYNAMIC=false
   OMP_MAX_ACTIVE_LEVELS=2147483647
   OMP_MAX_TASK_PRIORITY=0
   OMP_NESTED=false
   OMP_NUM_THREADS='40'
   OMP_PLACES: value is not defined
   OMP_PROC_BIND='intel'
   OMP_SCHEDULE='static'
   OMP_STACKSIZE=4M
   OMP_TARGET_OFFLOAD=DEFAULT
   OMP_THREAD_LIMIT=2147483647
   OMP_TOOL=enabled
   OMP_TOOL_LIBRARIES: value is not defined
   OMP_WAIT_POLICY=PASSIVE
   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'

cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult
BigDLBasePickler registering: bigdl.util.common  EvaluatedResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
cls.getname: com.intel.analytics.bigdl.python.api.JActivity
BigDLBasePickler registering: bigdl.util.common  JActivity
Successfully got a SparkContext
2020-11-20 11:43:08,186	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2020-11-20 11:43:08,187	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-11-20_11-43-08_186976_130593/logs.
2020-11-20 11:43:08,301	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:11566 to respond...
2020-11-20 11:43:08,416	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:61558 to respond...
2020-11-20 11:43:08,417	INFO services.py:806 -- Starting Redis shard with 10.0 GB max memory.
2020-11-20 11:43:08,503	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-11-20_11-43-08_186976_130593/logs.
2020-11-20 11:43:08,503	WARNING services.py:1298 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.
2020-11-20 11:43:08,503	INFO services.py:1446 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.
2020-11-20 11:43:08,809	WARNING bayesopt.py:69 -- `reward_attr` is deprecated and will be removed in a future version of Tune. Setting `metric=reward_metric` and `mode=max`.
2020-11-20 11:43:09,133	INFO tune.py:65 -- Did not find checkpoint file in /scratch/project_2003107/ray_results_9otbxs6t/automl.
2020-11-20 11:43:09,133	INFO tune.py:233 -- Starting a new experiment.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/40 CPUs, 0/0 GPUs
Memory usage on this node: 11.8/200.9 GB

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/40 CPUs, 0/0 GPUs
Memory usage on this node: 11.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 10 ({'RUNNING': 1, 'PENDING': 9})
PENDING trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	PENDING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	PENDING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	PENDING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	PENDING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	PENDING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	PENDING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	PENDING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	PENDING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	PENDING
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING

[2m[36m(pid=130909)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130900)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130929)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130902)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130919)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130917)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130907)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130909)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130915)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130908)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130903)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130929)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130902)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130897)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130905)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130918)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130906)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130936)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130911)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130912)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130910)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130931)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130931)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130919)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130916)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130916)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130901)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130901)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130917)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130907)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130915)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130908)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130900)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130903)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130897)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130933)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130899)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130922)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130922)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130924)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130924)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130937)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130937)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130905)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130920)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130913)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130913)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130918)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130935)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130935)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130914)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130914)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130906)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130926)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130936)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130911)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130934)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130934)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130904)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130904)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130932)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130932)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130912)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130910)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130925)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130920)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130933)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130899)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130926)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130927)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130927)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130925)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130898)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130923)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130923)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130928)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=130928)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130898)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132682)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132682)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132696)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132705)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132687)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132687)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132679)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132699)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132699)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132697)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132697)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132695)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132695)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132696)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132705)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132693)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132693)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132679)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=132702)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=132702)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130917)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130917)[0m   agg_primitives: ['count']
[2m[36m(pid=130917)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130917)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130907)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130907)[0m   agg_primitives: ['count']
[2m[36m(pid=130907)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130907)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130909)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130909)[0m   agg_primitives: ['count']
[2m[36m(pid=130909)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130909)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130915)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130915)[0m   agg_primitives: ['count']
[2m[36m(pid=130915)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130915)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130908)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130908)[0m   agg_primitives: ['count']
[2m[36m(pid=130908)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130908)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130900)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130900)[0m   agg_primitives: ['count']
[2m[36m(pid=130900)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130900)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130903)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130903)[0m   agg_primitives: ['count']
[2m[36m(pid=130903)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130903)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130929)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130929)[0m   agg_primitives: ['count']
[2m[36m(pid=130929)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130929)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130902)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130902)[0m   agg_primitives: ['count']
[2m[36m(pid=130902)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130902)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130897)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130897)[0m   agg_primitives: ['count']
[2m[36m(pid=130897)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130897)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130917)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130917)[0m Instructions for updating:
[2m[36m(pid=130917)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130917)[0m LSTM is selected.
[2m[36m(pid=130907)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130907)[0m Instructions for updating:
[2m[36m(pid=130907)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130907)[0m LSTM is selected.
[2m[36m(pid=130909)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130909)[0m Instructions for updating:
[2m[36m(pid=130909)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130909)[0m LSTM is selected.
[2m[36m(pid=130915)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130915)[0m Instructions for updating:
[2m[36m(pid=130915)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130915)[0m LSTM is selected.
[2m[36m(pid=130908)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130908)[0m Instructions for updating:
[2m[36m(pid=130908)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130908)[0m LSTM is selected.
[2m[36m(pid=130900)[0m LSTM is selected.
[2m[36m(pid=130929)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130929)[0m Instructions for updating:
[2m[36m(pid=130929)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130929)[0m LSTM is selected.
[2m[36m(pid=130902)[0m LSTM is selected.
[2m[36m(pid=130897)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130897)[0m Instructions for updating:
[2m[36m(pid=130897)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130897)[0m LSTM is selected.
[2m[36m(pid=130900)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130900)[0m Instructions for updating:
[2m[36m(pid=130900)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130903)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130903)[0m Instructions for updating:
[2m[36m(pid=130903)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130903)[0m LSTM is selected.
[2m[36m(pid=130902)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130902)[0m Instructions for updating:
[2m[36m(pid=130902)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130917)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130917)[0m Instructions for updating:
[2m[36m(pid=130917)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130907)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130907)[0m Instructions for updating:
[2m[36m(pid=130907)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130909)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130909)[0m Instructions for updating:
[2m[36m(pid=130909)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130915)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130915)[0m Instructions for updating:
[2m[36m(pid=130915)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130908)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130908)[0m Instructions for updating:
[2m[36m(pid=130908)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130929)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130929)[0m Instructions for updating:
[2m[36m(pid=130929)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130897)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130897)[0m Instructions for updating:
[2m[36m(pid=130897)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130900)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130900)[0m Instructions for updating:
[2m[36m(pid=130900)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130902)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130902)[0m Instructions for updating:
[2m[36m(pid=130902)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130903)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130903)[0m Instructions for updating:
[2m[36m(pid=130903)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130917)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130917)[0m 2020-11-20 11:43:17.529251: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130917)[0m 2020-11-20 11:43:17.536778: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130917)[0m 2020-11-20 11:43:17.538596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f32ad0a3a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130917)[0m 2020-11-20 11:43:17.538615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130907)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130907)[0m 2020-11-20 11:43:17.546478: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130907)[0m 2020-11-20 11:43:17.554100: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130907)[0m 2020-11-20 11:43:17.556256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4250d7220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130907)[0m 2020-11-20 11:43:17.556278: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130915)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130915)[0m 2020-11-20 11:43:17.528829: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130915)[0m 2020-11-20 11:43:17.536095: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130915)[0m 2020-11-20 11:43:17.537986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f89c9107860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130915)[0m 2020-11-20 11:43:17.538007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130908)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130908)[0m 2020-11-20 11:43:17.546151: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130908)[0m 2020-11-20 11:43:17.553457: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130908)[0m 2020-11-20 11:43:17.555684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f31b90ef5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130908)[0m 2020-11-20 11:43:17.555707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130897)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130897)[0m 2020-11-20 11:43:17.535490: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130897)[0m 2020-11-20 11:43:17.542870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130897)[0m 2020-11-20 11:43:17.544960: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f32950d7300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130897)[0m 2020-11-20 11:43:17.544983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130909)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130909)[0m 2020-11-20 11:43:17.569288: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130909)[0m 2020-11-20 11:43:17.577112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130909)[0m 2020-11-20 11:43:17.579198: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f56c10eefb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130909)[0m 2020-11-20 11:43:17.579221: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130900)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130900)[0m 2020-11-20 11:43:17.566612: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130900)[0m 2020-11-20 11:43:17.574503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130900)[0m 2020-11-20 11:43:17.576855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0dd50d3fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130900)[0m 2020-11-20 11:43:17.576878: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130929)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130929)[0m 2020-11-20 11:43:17.566897: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130929)[0m 2020-11-20 11:43:17.574615: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130929)[0m 2020-11-20 11:43:17.576750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80210e9c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130929)[0m 2020-11-20 11:43:17.576775: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130902)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130902)[0m 2020-11-20 11:43:17.579113: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130902)[0m 2020-11-20 11:43:17.586173: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130902)[0m 2020-11-20 11:43:17.588073: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf9d0beee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130902)[0m 2020-11-20 11:43:17.588096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130903)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130903)[0m 2020-11-20 11:43:17.720396: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130903)[0m 2020-11-20 11:43:17.727919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130903)[0m 2020-11-20 11:43:17.729836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fabcd0d3fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130903)[0m 2020-11-20 11:43:17.729863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/logger.py:119: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 20.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 10 ({'RUNNING': 10})
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	RUNNING
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	RUNNING
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	RUNNING
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	RUNNING
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130917], 5 s, 1 iter

[2m[36m(pid=130929)[0m 2020-11-20 11:43:21,026	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130929)[0m Traceback (most recent call last):
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130929)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130929)[0m     param_dset[:] = val
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130929)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130929)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130929)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130929)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130929)[0m , filename = '/tmp/thalvari/4065561/automl_save_v5r9vx5p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80222640e8, total write size = 300456, bytes this sub-write = 300456, bytes actually written = 18446744073709551615, offset = 1507328)
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m Traceback (most recent call last):
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130929)[0m     self._entrypoint()
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130929)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130929)[0m     output = train_func(config, reporter)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130929)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130929)[0m     config=config)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130929)[0m     model.save(model_path, config_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130929)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130929)[0m     self.model.save(model_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130929)[0m     signatures)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130929)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130929)[0m     f.close()
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130929)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130929)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130929)[0m , filename = '/tmp/thalvari/4065561/automl_save_v5r9vx5p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f802200f5d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130929)[0m Exception in thread Thread-1:
[2m[36m(pid=130929)[0m Traceback (most recent call last):
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130929)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130929)[0m     param_dset[:] = val
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130929)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130929)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130929)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130929)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130929)[0m , filename = '/tmp/thalvari/4065561/automl_save_v5r9vx5p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f80222640e8, total write size = 300456, bytes this sub-write = 300456, bytes actually written = 18446744073709551615, offset = 1507328)
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m Traceback (most recent call last):
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130929)[0m     self._entrypoint()
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130929)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130929)[0m     output = train_func(config, reporter)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130929)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130929)[0m     config=config)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130929)[0m     model.save(model_path, config_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130929)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130929)[0m     self.model.save(model_path)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130929)[0m     signatures)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130929)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130929)[0m     f.close()
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130929)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130929)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130929)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130929)[0m , filename = '/tmp/thalvari/4065561/automl_save_v5r9vx5p/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f802200f5d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m Traceback (most recent call last):
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130929)[0m     self.run()
[2m[36m(pid=130929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130929)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130929)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130897)[0m 2020-11-20 11:43:21,044	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130897)[0m Traceback (most recent call last):
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130897)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130897)[0m     param_dset[:] = val
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130897)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130897)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130897)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130897)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130897)[0m , filename = '/tmp/thalvari/4065561/automl_save_ut5x2964/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3296902738, total write size = 102968, bytes this sub-write = 102968, bytes actually written = 18446744073709551615, offset = 3112960)
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m Traceback (most recent call last):
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130897)[0m     self._entrypoint()
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130897)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130897)[0m     output = train_func(config, reporter)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130897)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130897)[0m     config=config)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130897)[0m     model.save(model_path, config_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130897)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130897)[0m     self.model.save(model_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130897)[0m     signatures)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130897)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130897)[0m     f.close()
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130897)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130897)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130897)[0m , filename = '/tmp/thalvari/4065561/automl_save_ut5x2964/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3295475fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130897)[0m Exception in thread Thread-1:
[2m[36m(pid=130897)[0m Traceback (most recent call last):
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130897)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130897)[0m     param_dset[:] = val
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130897)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130897)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130897)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130897)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130897)[0m , filename = '/tmp/thalvari/4065561/automl_save_ut5x2964/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3296902738, total write size = 102968, bytes this sub-write = 102968, bytes actually written = 18446744073709551615, offset = 3112960)
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m Traceback (most recent call last):
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130897)[0m     self._entrypoint()
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130897)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130897)[0m     output = train_func(config, reporter)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130897)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130897)[0m     config=config)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130897)[0m     model.save(model_path, config_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130897)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130897)[0m     self.model.save(model_path)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130897)[0m     signatures)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130897)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130897)[0m     f.close()
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130897)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130897)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130897)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:21 2020
[2m[36m(pid=130897)[0m , filename = '/tmp/thalvari/4065561/automl_save_ut5x2964/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3295475fb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m Traceback (most recent call last):
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130897)[0m     self.run()
[2m[36m(pid=130897)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130897)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130897)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130897)[0m 
2020-11-20 11:43:22,099	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130897, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:22,107	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 11:43:22,186	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130929, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:22,191	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130897)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130897)[0m 
[2m[36m(pid=130897)[0m Stack (most recent call first):
[2m[36m(pid=130929)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130929)[0m 
[2m[36m(pid=130929)[0m Stack (most recent call first):
[2m[36m(pid=130907)[0m 2020-11-20 11:43:23,389	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130907)[0m Traceback (most recent call last):
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130907)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130907)[0m     param_dset[:] = val
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130907)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130907)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130907)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130907)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130907)[0m , filename = '/tmp/thalvari/4065561/automl_save_h4r3ihki/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4267c7468, total write size = 526392, bytes this sub-write = 526392, bytes actually written = 18446744073709551615, offset = 2080768)
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m Traceback (most recent call last):
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130907)[0m     self._entrypoint()
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130907)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130907)[0m     output = train_func(config, reporter)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130907)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130907)[0m     config=config)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130907)[0m     model.save(model_path, config_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130907)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130907)[0m     self.model.save(model_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130907)[0m     signatures)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130907)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130907)[0m     f.close()
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130907)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130907)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130907)[0m , filename = '/tmp/thalvari/4065561/automl_save_h4r3ihki/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa425d439e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130907)[0m Exception in thread Thread-1:
[2m[36m(pid=130907)[0m Traceback (most recent call last):
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130907)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130907)[0m     param_dset[:] = val
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130907)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130907)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130907)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130907)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130907)[0m , filename = '/tmp/thalvari/4065561/automl_save_h4r3ihki/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa4267c7468, total write size = 526392, bytes this sub-write = 526392, bytes actually written = 18446744073709551615, offset = 2080768)
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m Traceback (most recent call last):
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130907)[0m     self._entrypoint()
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130907)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130907)[0m     output = train_func(config, reporter)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130907)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130907)[0m     config=config)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130907)[0m     model.save(model_path, config_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130907)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130907)[0m     self.model.save(model_path)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130907)[0m     signatures)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130907)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130907)[0m     f.close()
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130907)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130907)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130907)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130907)[0m , filename = '/tmp/thalvari/4065561/automl_save_h4r3ihki/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa425d439e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130909)[0m 2020-11-20 11:43:23,389	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130909)[0m Traceback (most recent call last):
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130909)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130909)[0m     param_dset[:] = val
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130909)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130909)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130909)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130909)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130909)[0m , filename = '/tmp/thalvari/4065561/automl_save_9fjfvkkf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56c26d57e8, total write size = 90040, bytes this sub-write = 90040, bytes actually written = 18446744073709551615, offset = 1028096)
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m Traceback (most recent call last):
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130909)[0m     self._entrypoint()
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130909)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130909)[0m     output = train_func(config, reporter)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130909)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130909)[0m     config=config)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130909)[0m     model.save(model_path, config_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130909)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130909)[0m     self.model.save(model_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130909)[0m     signatures)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130909)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130909)[0m     f.close()
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130909)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130909)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130909)[0m , filename = '/tmp/thalvari/4065561/automl_save_9fjfvkkf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56c1e8c700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130909)[0m Exception in thread Thread-1:
[2m[36m(pid=130909)[0m Traceback (most recent call last):
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130909)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130909)[0m     param_dset[:] = val
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130909)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130909)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130909)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130909)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130909)[0m , filename = '/tmp/thalvari/4065561/automl_save_9fjfvkkf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56c26d57e8, total write size = 90040, bytes this sub-write = 90040, bytes actually written = 18446744073709551615, offset = 1028096)
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m Traceback (most recent call last):
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130909)[0m     self._entrypoint()
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130909)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130909)[0m     output = train_func(config, reporter)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130909)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130909)[0m     config=config)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130909)[0m     model.save(model_path, config_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130909)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130909)[0m     self.model.save(model_path)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130909)[0m     signatures)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130909)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130909)[0m     f.close()
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130909)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130909)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130909)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:23 2020
[2m[36m(pid=130909)[0m , filename = '/tmp/thalvari/4065561/automl_save_9fjfvkkf/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f56c1e8c700, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m Traceback (most recent call last):
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130907)[0m     self.run()
[2m[36m(pid=130907)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130907)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130907)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m Traceback (most recent call last):
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130909)[0m     self.run()
[2m[36m(pid=130909)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130909)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130909)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130909)[0m 
2020-11-20 11:43:24,460	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130909, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:24,465	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 11:43:24,559	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130907, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:24,564	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130909)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130909)[0m 
[2m[36m(pid=130909)[0m Stack (most recent call first):
[2m[36m(pid=130907)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130907)[0m 
[2m[36m(pid=130907)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 15 ({'RUNNING': 9, 'ERROR': 4, 'TERMINATED': 2})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130902], 9 s, 2 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130900], 9 s, 1 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130908], 8 s, 2 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130915], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130917], 8 s, 5 iter

[2m[36m(pid=132679)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132679)[0m   agg_primitives: ['count']
[2m[36m(pid=132679)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132679)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132702)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132702)[0m   agg_primitives: ['count']
[2m[36m(pid=132702)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132702)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132679)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132679)[0m Instructions for updating:
[2m[36m(pid=132679)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132679)[0m LSTM is selected.
[2m[36m(pid=132702)[0m LSTM is selected.
[2m[36m(pid=132702)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132702)[0m Instructions for updating:
[2m[36m(pid=132702)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132679)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132679)[0m Instructions for updating:
[2m[36m(pid=132679)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132702)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132702)[0m Instructions for updating:
[2m[36m(pid=132702)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132705)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132705)[0m   agg_primitives: ['count']
[2m[36m(pid=132705)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132705)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132697)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132697)[0m   agg_primitives: ['count']
[2m[36m(pid=132697)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132697)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132695)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132695)[0m   agg_primitives: ['count']
[2m[36m(pid=132695)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132695)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132697)[0m LSTM is selected.
[2m[36m(pid=132705)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132705)[0m Instructions for updating:
[2m[36m(pid=132705)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132705)[0m LSTM is selected.
[2m[36m(pid=132697)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132697)[0m Instructions for updating:
[2m[36m(pid=132697)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132695)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132695)[0m Instructions for updating:
[2m[36m(pid=132695)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132695)[0m LSTM is selected.
[2m[36m(pid=132679)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132679)[0m 2020-11-20 11:43:28.287411: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132679)[0m 2020-11-20 11:43:28.297741: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132679)[0m 2020-11-20 11:43:28.301561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f04d90a3a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132679)[0m 2020-11-20 11:43:28.301597: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132702)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132702)[0m 2020-11-20 11:43:28.270510: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132702)[0m 2020-11-20 11:43:28.278709: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132702)[0m 2020-11-20 11:43:28.281946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f31350e9530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132702)[0m 2020-11-20 11:43:28.281974: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132705)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132705)[0m Instructions for updating:
[2m[36m(pid=132705)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132697)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132697)[0m Instructions for updating:
[2m[36m(pid=132697)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132695)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132695)[0m Instructions for updating:
[2m[36m(pid=132695)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132705)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132705)[0m 2020-11-20 11:43:29.428028: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132705)[0m 2020-11-20 11:43:29.437364: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132705)[0m 2020-11-20 11:43:29.441232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f77e50cb620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132705)[0m 2020-11-20 11:43:29.441265: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132695)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132695)[0m 2020-11-20 11:43:29.425588: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132695)[0m 2020-11-20 11:43:29.435880: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132695)[0m 2020-11-20 11:43:29.438632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efaed104900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132695)[0m 2020-11-20 11:43:29.438676: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132697)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132697)[0m 2020-11-20 11:43:29.447705: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132697)[0m 2020-11-20 11:43:29.457284: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132697)[0m 2020-11-20 11:43:29.459994: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f04c50ef900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132697)[0m 2020-11-20 11:43:29.460021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132682)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132682)[0m   agg_primitives: ['count']
[2m[36m(pid=132682)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132682)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 16 ({'RUNNING': 9, 'ERROR': 4, 'TERMINATED': 3})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
RUNNING trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130902], 13 s, 4 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130903], 11 s, 1 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130900], 12 s, 2 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	RUNNING
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	RUNNING
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130908], 15 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130915], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130917], 8 s, 5 iter

[2m[36m(pid=132682)[0m LSTM is selected.
[2m[36m(pid=132682)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132682)[0m Instructions for updating:
[2m[36m(pid=132682)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132682)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132682)[0m Instructions for updating:
[2m[36m(pid=132682)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132682)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132682)[0m 2020-11-20 11:43:32.614868: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132682)[0m 2020-11-20 11:43:32.626123: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132682)[0m 2020-11-20 11:43:32.632615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc85508e6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132682)[0m 2020-11-20 11:43:32.632662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130927)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130927)[0m   agg_primitives: ['count']
[2m[36m(pid=130927)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130927)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132696)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132696)[0m   agg_primitives: ['count']
[2m[36m(pid=132696)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132696)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 18 ({'TERMINATED': 4, 'ERROR': 4, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130903], 17 s, 2 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130900], 15 s, 3 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132702], 9 s, 4 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132679], 9 s, 1 iter
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132705], 7 s, 2 iter
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132695], 8 s, 2 iter
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132697], 9 s, 3 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	RUNNING
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130908], 15 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130915], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130917], 8 s, 5 iter

[2m[36m(pid=130927)[0m LSTM is selected.
[2m[36m(pid=130927)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130927)[0m Instructions for updating:
[2m[36m(pid=130927)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132696)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132696)[0m Instructions for updating:
[2m[36m(pid=132696)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132696)[0m LSTM is selected.
[2m[36m(pid=130927)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130927)[0m Instructions for updating:
[2m[36m(pid=130927)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132696)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132696)[0m Instructions for updating:
[2m[36m(pid=132696)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130927)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130927)[0m 2020-11-20 11:43:38.071688: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130927)[0m 2020-11-20 11:43:38.082255: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130927)[0m 2020-11-20 11:43:38.086250: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f69ad08b860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130927)[0m 2020-11-20 11:43:38.086287: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132696)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132696)[0m 2020-11-20 11:43:38.105617: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132696)[0m 2020-11-20 11:43:38.116850: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132696)[0m 2020-11-20 11:43:38.120627: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f515d0bbfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132696)[0m 2020-11-20 11:43:38.120669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 22 ({'TERMINATED': 8, 'ERROR': 4, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130903], 23 s, 3 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132679], 9 s, 1 iter
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132695], 13 s, 4 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 2 not shown
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0030039,lstm_1_units_float=84.803,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	RUNNING
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=62.03,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130908], 15 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130915], 10 s, 5 iter
 - train_func_10_batch_size_log=9.6151,bayes_feature_DAY(timestamp)=0.79807,bayes_feature_HOUR(timestamp)=0.38699,bayes_feature_IS_AWAKE(timestamp)=0.31392,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31835,bayes_feature_IS_WEEKEND(timestamp)=0.31981,bayes_feature_MONTH(timestamp)=0.47235,bayes_feature_WEEKDAY(timestamp)=0.90202,dropout_1=0.36165,dropout_2=0.36585,epochs=5,lr=0.0085783,lstm_1_units_float=22.901,lstm_2_units_float=41.502,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130917], 8 s, 5 iter
 - train_func_11_batch_size_log=7.9288,bayes_feature_DAY(timestamp)=0.97872,bayes_feature_HOUR(timestamp)=0.69272,bayes_feature_IS_AWAKE(timestamp)=0.31305,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86044,bayes_feature_IS_WEEKEND(timestamp)=0.46308,bayes_feature_MONTH(timestamp)=0.86497,bayes_feature_WEEKDAY(timestamp)=0.5715,dropout_1=0.45906,dropout_2=0.42414,epochs=5,lr=0.0060062,lstm_1_units_float=24.375,lstm_2_units_float=15.19,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132702], 11 s, 5 iter
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132705], 13 s, 5 iter
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter

[2m[36m(pid=130925)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130925)[0m   agg_primitives: ['count']
[2m[36m(pid=130925)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130925)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130925)[0m LSTM is selected.
[2m[36m(pid=130925)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130925)[0m Instructions for updating:
[2m[36m(pid=130925)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132682)[0m 2020-11-20 11:43:43,422	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=132682)[0m Traceback (most recent call last):
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132682)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132682)[0m     param_dset[:] = val
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132682)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132682)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132682)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132682)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:43 2020
[2m[36m(pid=132682)[0m , filename = '/tmp/thalvari/4065561/automl_save_roo_gjw5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc856a55188, total write size = 663672, bytes this sub-write = 663672, bytes actually written = 18446744073709551615, offset = 3084288)
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m Traceback (most recent call last):
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132682)[0m     self._entrypoint()
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132682)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132682)[0m     output = train_func(config, reporter)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132682)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132682)[0m     config=config)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132682)[0m     model.save(model_path, config_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132682)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132682)[0m     self.model.save(model_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132682)[0m     signatures)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132682)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132682)[0m     f.close()
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132682)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132682)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:43 2020
[2m[36m(pid=132682)[0m , filename = '/tmp/thalvari/4065561/automl_save_roo_gjw5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc856342a10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132682)[0m Exception in thread Thread-1:
[2m[36m(pid=132682)[0m Traceback (most recent call last):
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132682)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132682)[0m     param_dset[:] = val
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132682)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132682)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132682)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132682)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:43 2020
[2m[36m(pid=132682)[0m , filename = '/tmp/thalvari/4065561/automl_save_roo_gjw5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc856a55188, total write size = 663672, bytes this sub-write = 663672, bytes actually written = 18446744073709551615, offset = 3084288)
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m Traceback (most recent call last):
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132682)[0m     self._entrypoint()
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132682)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132682)[0m     output = train_func(config, reporter)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132682)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132682)[0m     config=config)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132682)[0m     model.save(model_path, config_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132682)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132682)[0m     self.model.save(model_path)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132682)[0m     signatures)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132682)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132682)[0m     f.close()
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132682)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132682)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132682)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:43 2020
[2m[36m(pid=132682)[0m , filename = '/tmp/thalvari/4065561/automl_save_roo_gjw5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fc856342a10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m Traceback (most recent call last):
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=132682)[0m     self.run()
[2m[36m(pid=132682)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=132682)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=132682)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=132682)[0m 
[2m[36m(pid=130925)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130925)[0m Instructions for updating:
[2m[36m(pid=130925)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130923)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130923)[0m   agg_primitives: ['count']
[2m[36m(pid=130923)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130923)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130923)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130923)[0m Instructions for updating:
[2m[36m(pid=130923)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130923)[0m LSTM is selected.
[2m[36m(pid=130925)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130925)[0m 2020-11-20 11:43:44.461530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130925)[0m 2020-11-20 11:43:44.469942: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130925)[0m 2020-11-20 11:43:44.473380: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd790a6a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130925)[0m 2020-11-20 11:43:44.473422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:43:44,541	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=132682, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:44,545	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130928)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130928)[0m   agg_primitives: ['count']
[2m[36m(pid=130928)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130928)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132682)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=132682)[0m 
[2m[36m(pid=132682)[0m Stack (most recent call first):
[2m[36m(pid=130923)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130923)[0m Instructions for updating:
[2m[36m(pid=130923)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130928)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130928)[0m Instructions for updating:
[2m[36m(pid=130928)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130928)[0m LSTM is selected.
[2m[36m(pid=130928)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130928)[0m Instructions for updating:
[2m[36m(pid=130928)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130933)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130933)[0m   agg_primitives: ['count']
[2m[36m(pid=130933)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130933)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130923)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130923)[0m 2020-11-20 11:43:45.902115: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130923)[0m 2020-11-20 11:43:45.912817: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130923)[0m 2020-11-20 11:43:45.916210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0d190efa00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130923)[0m 2020-11-20 11:43:45.916251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132693)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132693)[0m   agg_primitives: ['count']
[2m[36m(pid=132693)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132693)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130933)[0m LSTM is selected.
[2m[36m(pid=130933)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130933)[0m Instructions for updating:
[2m[36m(pid=130933)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132693)[0m LSTM is selected.
[2m[36m(pid=132693)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132693)[0m Instructions for updating:
[2m[36m(pid=132693)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130928)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130928)[0m 2020-11-20 11:43:46.709794: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130928)[0m 2020-11-20 11:43:46.719658: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130928)[0m 2020-11-20 11:43:46.721790: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9bfd0a3900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130928)[0m 2020-11-20 11:43:46.721818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130933)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130933)[0m Instructions for updating:
[2m[36m(pid=130933)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132693)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132693)[0m Instructions for updating:
[2m[36m(pid=132693)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 24 ({'TERMINATED': 10, 'ERROR': 5, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-26tr0cfz7k/error_2020-11-20_11-43-44.txt
RUNNING trials:
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130903], 29 s, 4 iter
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132679], 15 s, 2 iter
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 11 s, 1 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0030039,lstm_1_units_float=84.803,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 1 not shown
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=62.03,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130908], 15 s, 5 iter
 - train_func_7_batch_size_log=8.7541,bayes_feature_DAY(timestamp)=0.8082,bayes_feature_HOUR(timestamp)=0.91831,bayes_feature_IS_AWAKE(timestamp)=0.73657,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82566,bayes_feature_IS_WEEKEND(timestamp)=0.54423,bayes_feature_MONTH(timestamp)=0.48895,bayes_feature_WEEKDAY(timestamp)=0.92712,dropout_1=0.32843,dropout_2=0.48945,epochs=5,lr=0.006971,lstm_1_units_float=82.603,lstm_2_units_float=21.77,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130915], 10 s, 5 iter
  ... 2 not shown
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132705], 13 s, 5 iter
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132695], 14 s, 5 iter
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter

[2m[36m(pid=130933)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130933)[0m 2020-11-20 11:43:47.881197: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130933)[0m 2020-11-20 11:43:47.892319: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130933)[0m 2020-11-20 11:43:47.897246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eedc10d7620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130933)[0m 2020-11-20 11:43:47.897298: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132693)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132693)[0m 2020-11-20 11:43:48.133162: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132693)[0m 2020-11-20 11:43:48.143692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132693)[0m 2020-11-20 11:43:48.147680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f06650ef530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132693)[0m 2020-11-20 11:43:48.147720: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130899)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130899)[0m   agg_primitives: ['count']
[2m[36m(pid=130899)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130899)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130899)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130899)[0m Instructions for updating:
[2m[36m(pid=130899)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130899)[0m LSTM is selected.
[2m[36m(pid=130899)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130899)[0m Instructions for updating:
[2m[36m(pid=130899)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130899)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130899)[0m 2020-11-20 11:43:51.712347: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130899)[0m 2020-11-20 11:43:51.724875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130899)[0m 2020-11-20 11:43:51.730388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca690ef6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130899)[0m 2020-11-20 11:43:51.730449: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130930)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130930)[0m   agg_primitives: ['count']
[2m[36m(pid=130930)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130930)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130930)[0m Instructions for updating:
[2m[36m(pid=130930)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130930)[0m LSTM is selected.
[2m[36m(pid=130930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130930)[0m Instructions for updating:
[2m[36m(pid=130930)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 26 ({'TERMINATED': 11, 'ERROR': 5, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-26tr0cfz7k/error_2020-11-20_11-43-44.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132679], 27 s, 4 iter
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 11 s, 1 iter
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0030039,lstm_1_units_float=84.803,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130923], 8 s, 2 iter
  ... 2 not shown
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
 - train_func_6_batch_size_log=7.6795,bayes_feature_DAY(timestamp)=0.76466,bayes_feature_HOUR(timestamp)=0.66042,bayes_feature_IS_AWAKE(timestamp)=0.96122,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71059,bayes_feature_IS_WEEKEND(timestamp)=0.93238,bayes_feature_MONTH(timestamp)=0.39623,bayes_feature_WEEKDAY(timestamp)=0.39749,dropout_1=0.44222,dropout_2=0.3193,epochs=5,lr=0.0024882,lstm_1_units_float=119.3,lstm_2_units_float=49.732,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130908], 15 s, 5 iter
  ... 3 not shown
 - train_func_13_batch_size_log=7.4332,bayes_feature_DAY(timestamp)=0.8626,bayes_feature_HOUR(timestamp)=0.46466,bayes_feature_IS_AWAKE(timestamp)=0.5369,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37391,bayes_feature_IS_WEEKEND(timestamp)=0.92007,bayes_feature_MONTH(timestamp)=0.46177,bayes_feature_WEEKDAY(timestamp)=0.64351,dropout_1=0.33842,dropout_2=0.39094,epochs=5,lr=0.0035658,lstm_1_units_float=14.253,lstm_2_units_float=11.91,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132705], 13 s, 5 iter
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132695], 14 s, 5 iter
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter

[2m[36m(pid=130930)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130930)[0m 2020-11-20 11:43:54.326645: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130930)[0m 2020-11-20 11:43:54.338483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130930)[0m 2020-11-20 11:43:54.342571: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22bd0ef5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130930)[0m 2020-11-20 11:43:54.342613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130925)[0m 2020-11-20 11:43:54,538	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130925)[0m Traceback (most recent call last):
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130925)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130925)[0m     param_dset[:] = val
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130925)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130925)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130925)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130925)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:54 2020
[2m[36m(pid=130925)[0m , filename = '/tmp/thalvari/4065561/automl_save_sotfoa_j/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fdd7a8a1ce8, total write size = 190968, bytes this sub-write = 190968, bytes actually written = 18446744073709551615, offset = 3076096)
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m Traceback (most recent call last):
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130925)[0m     self._entrypoint()
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130925)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130925)[0m     output = train_func(config, reporter)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130925)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130925)[0m     config=config)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130925)[0m     model.save(model_path, config_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130925)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130925)[0m     self.model.save(model_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130925)[0m     signatures)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130925)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130925)[0m     f.close()
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130925)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130925)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:54 2020
[2m[36m(pid=130925)[0m , filename = '/tmp/thalvari/4065561/automl_save_sotfoa_j/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fdd7a5b65a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130925)[0m Exception in thread Thread-1:
[2m[36m(pid=130925)[0m Traceback (most recent call last):
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130925)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130925)[0m     param_dset[:] = val
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130925)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130925)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130925)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130925)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:54 2020
[2m[36m(pid=130925)[0m , filename = '/tmp/thalvari/4065561/automl_save_sotfoa_j/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fdd7a8a1ce8, total write size = 190968, bytes this sub-write = 190968, bytes actually written = 18446744073709551615, offset = 3076096)
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m Traceback (most recent call last):
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130925)[0m     self._entrypoint()
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130925)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130925)[0m     output = train_func(config, reporter)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130925)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130925)[0m     config=config)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130925)[0m     model.save(model_path, config_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130925)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130925)[0m     self.model.save(model_path)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130925)[0m     signatures)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130925)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130925)[0m     f.close()
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130925)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130925)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130925)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:54 2020
[2m[36m(pid=130925)[0m , filename = '/tmp/thalvari/4065561/automl_save_sotfoa_j/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fdd7a5b65a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m Traceback (most recent call last):
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130925)[0m     self.run()
[2m[36m(pid=130925)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130925)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130925)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130925)[0m 
2020-11-20 11:43:55,656	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130925, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:55,661	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0030039,lstm_1_units_float=84.803,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130925)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130925)[0m 
[2m[36m(pid=130925)[0m Stack (most recent call first):
[2m[36m(pid=130912)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130912)[0m   agg_primitives: ['count']
[2m[36m(pid=130912)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130912)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130912)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130912)[0m Instructions for updating:
[2m[36m(pid=130912)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130912)[0m LSTM is selected.
[2m[36m(pid=130930)[0m 2020-11-20 11:43:57,598	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130930)[0m Traceback (most recent call last):
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130930)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130930)[0m     param_dset[:] = val
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130930)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130930)[0m , filename = '/tmp/thalvari/4065561/automl_save_963d5w8g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22bea52a88, total write size = 60136, bytes this sub-write = 60136, bytes actually written = 18446744073709551615, offset = 2592768)
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m Traceback (most recent call last):
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130930)[0m     self._entrypoint()
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130930)[0m     output = train_func(config, reporter)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130930)[0m     config=config)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130930)[0m     model.save(model_path, config_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130930)[0m     self.model.save(model_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130930)[0m     signatures)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130930)[0m     f.close()
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130930)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130930)[0m , filename = '/tmp/thalvari/4065561/automl_save_963d5w8g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22bd66db60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130930)[0m Exception in thread Thread-1:
[2m[36m(pid=130930)[0m Traceback (most recent call last):
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130930)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130930)[0m     param_dset[:] = val
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130930)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130930)[0m , filename = '/tmp/thalvari/4065561/automl_save_963d5w8g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22bea52a88, total write size = 60136, bytes this sub-write = 60136, bytes actually written = 18446744073709551615, offset = 2592768)
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m Traceback (most recent call last):
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130930)[0m     self._entrypoint()
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130930)[0m     output = train_func(config, reporter)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130930)[0m     config=config)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130930)[0m     model.save(model_path, config_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130930)[0m     self.model.save(model_path)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130930)[0m     signatures)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130930)[0m     f.close()
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130930)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130930)[0m , filename = '/tmp/thalvari/4065561/automl_save_963d5w8g/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f22bd66db60, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m Traceback (most recent call last):
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130930)[0m     self.run()
[2m[36m(pid=130930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130930)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130930)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130928)[0m 2020-11-20 11:43:57,685	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130928)[0m Traceback (most recent call last):
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130928)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130928)[0m     param_dset[:] = val
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130928)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130928)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130928)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130928)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130928)[0m , filename = '/tmp/thalvari/4065561/automl_save_f_iqfe1q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9bfe8deae8, total write size = 11144, bytes this sub-write = 11144, bytes actually written = 18446744073709551615, offset = 3059712)
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m Traceback (most recent call last):
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130928)[0m     self._entrypoint()
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130928)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130928)[0m     output = train_func(config, reporter)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130928)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130928)[0m     config=config)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130928)[0m     model.save(model_path, config_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130928)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130928)[0m     self.model.save(model_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130928)[0m     signatures)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130928)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130928)[0m     f.close()
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130928)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130928)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130928)[0m , filename = '/tmp/thalvari/4065561/automl_save_f_iqfe1q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9bfdfea470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130928)[0m Exception in thread Thread-1:
[2m[36m(pid=130928)[0m Traceback (most recent call last):
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130928)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130928)[0m     param_dset[:] = val
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130928)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130928)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130928)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130928)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130928)[0m , filename = '/tmp/thalvari/4065561/automl_save_f_iqfe1q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9bfe8deae8, total write size = 11144, bytes this sub-write = 11144, bytes actually written = 18446744073709551615, offset = 3059712)
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m Traceback (most recent call last):
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130928)[0m     self._entrypoint()
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130928)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130928)[0m     output = train_func(config, reporter)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130928)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130928)[0m     config=config)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130928)[0m     model.save(model_path, config_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130928)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130928)[0m     self.model.save(model_path)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130928)[0m     signatures)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130928)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130928)[0m     f.close()
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130928)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130928)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130928)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:57 2020
[2m[36m(pid=130928)[0m , filename = '/tmp/thalvari/4065561/automl_save_f_iqfe1q/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9bfdfea470, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m Traceback (most recent call last):
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130928)[0m     self.run()
[2m[36m(pid=130928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130928)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130928)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130912)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130912)[0m Instructions for updating:
[2m[36m(pid=130912)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:43:58,703	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130928, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:58,707	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=62.03,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 27 ({'TERMINATED': 11, 'ERROR': 7, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
 - train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWAKE(timestamp)=0.95061,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78363,bayes_feature_IS_WEEKEND(timestamp)=0.99813,bayes_feature_MONTH(timestamp)=0.42064,bayes_feature_WEEKDAY(timestamp)=0.396,dropout_1=0.47978,dropout_2=0.40905,epochs=5,lr=0.001594,lstm_1_units_float=98.656,lstm_2_units_float=98.465,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_9_batch_size_log=9.5427,bayes_feature_DAY(timestamp)=0.73635,bayes_feature_HOUR(timestamp)=0.31107,bayes_feature_IS_AWA_2020-11-20_11-43-09c7xc6n2g/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130907], 6 s, 2 iter
 - train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_16_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-26tr0cfz7k/error_2020-11-20_11-43-44.txt
 - train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0030039,lstm_1_units_float=84.803,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_19_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-38utnycjwe/error_2020-11-20_11-43-55.txt
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=62.03,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-41a3hlwit9/error_2020-11-20_11-43-58.txt
RUNNING trials:
 - train_func_12_batch_size_log=5.6067,bayes_feature_DAY(timestamp)=0.33119,bayes_feature_HOUR(timestamp)=0.37525,bayes_feature_IS_AWAKE(timestamp)=0.458,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79909,bayes_feature_IS_WEEKEND(timestamp)=0.6918,bayes_feature_MONTH(timestamp)=0.30879,bayes_feature_WEEKDAY(timestamp)=0.35038,dropout_1=0.49018,dropout_2=0.37043,epochs=5,lr=0.0028296,lstm_1_units_float=38.279,lstm_2_units_float=97.259,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132679], 27 s, 4 iter
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 19 s, 2 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130923], 13 s, 4 iter
  ... 3 not shown
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	RUNNING
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.687,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 5 not shown
 - train_func_14_batch_size_log=7.3573,bayes_feature_DAY(timestamp)=0.49282,bayes_feature_HOUR(timestamp)=0.7905,bayes_feature_IS_AWAKE(timestamp)=0.84508,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89396,bayes_feature_IS_WEEKEND(timestamp)=0.67771,bayes_feature_MONTH(timestamp)=0.79895,bayes_feature_WEEKDAY(timestamp)=0.98214,dropout_1=0.32178,dropout_2=0.32914,epochs=5,lr=0.0022964,lstm_1_units_float=27.561,lstm_2_units_float=54.28,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132695], 14 s, 5 iter
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter

[2m[36m(pid=130928)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130928)[0m 
[2m[36m(pid=130928)[0m Stack (most recent call first):
[2m[36m(pid=130912)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130912)[0m 2020-11-20 11:43:58.993725: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130912)[0m 2020-11-20 11:43:59.004484: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130912)[0m 2020-11-20 11:43:59.008568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8ae50eec40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130912)[0m 2020-11-20 11:43:59.008613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130933)[0m 2020-11-20 11:43:59,071	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130933)[0m Traceback (most recent call last):
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130933)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130933)[0m     param_dset[:] = val
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130933)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130933)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130933)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130933)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:59 2020
[2m[36m(pid=130933)[0m , filename = '/tmp/thalvari/4065561/automl_save_zz1qefsv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eedc27e1dd8, total write size = 27464, bytes this sub-write = 27464, bytes actually written = 18446744073709551615, offset = 3055616)
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m Traceback (most recent call last):
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130933)[0m     self._entrypoint()
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130933)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130933)[0m     output = train_func(config, reporter)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130933)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130933)[0m     config=config)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130933)[0m     model.save(model_path, config_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130933)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130933)[0m     self.model.save(model_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130933)[0m     signatures)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130933)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130933)[0m     f.close()
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130933)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130933)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:59 2020
[2m[36m(pid=130933)[0m , filename = '/tmp/thalvari/4065561/automl_save_zz1qefsv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eedc1f5c520, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130933)[0m Exception in thread Thread-1:
[2m[36m(pid=130933)[0m Traceback (most recent call last):
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130933)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130933)[0m     param_dset[:] = val
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130933)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130933)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130933)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130933)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:43:59 2020
[2m[36m(pid=130933)[0m , filename = '/tmp/thalvari/4065561/automl_save_zz1qefsv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eedc27e1dd8, total write size = 27464, bytes this sub-write = 27464, bytes actually written = 18446744073709551615, offset = 3055616)
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m Traceback (most recent call last):
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130933)[0m     self._entrypoint()
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130933)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130933)[0m     output = train_func(config, reporter)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130933)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130933)[0m     config=config)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130933)[0m     model.save(model_path, config_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130933)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130933)[0m     self.model.save(model_path)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130933)[0m     signatures)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130933)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130933)[0m     f.close()
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130933)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130933)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130933)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:43:59 2020
[2m[36m(pid=130933)[0m , filename = '/tmp/thalvari/4065561/automl_save_zz1qefsv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eedc1f5c520, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m Traceback (most recent call last):
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130933)[0m     self.run()
[2m[36m(pid=130933)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130933)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130933)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130933)[0m 
2020-11-20 11:43:59,618	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130930, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:43:59,620	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130930)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130930)[0m 
[2m[36m(pid=130930)[0m Stack (most recent call first):
2020-11-20 11:44:00,374	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130933, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:00,378	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130933)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130933)[0m 
[2m[36m(pid=130933)[0m Stack (most recent call first):
[2m[36m(pid=130936)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130936)[0m   agg_primitives: ['count']
[2m[36m(pid=130936)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130936)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130936)[0m LSTM is selected.
[2m[36m(pid=130936)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130936)[0m Instructions for updating:
[2m[36m(pid=130936)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130936)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130936)[0m Instructions for updating:
[2m[36m(pid=130936)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130906)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130906)[0m   agg_primitives: ['count']
[2m[36m(pid=130906)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130906)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130936)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130936)[0m 2020-11-20 11:44:02.732970: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130936)[0m 2020-11-20 11:44:02.742771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130936)[0m 2020-11-20 11:44:02.745799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f37d10ef080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130936)[0m 2020-11-20 11:44:02.745831: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130906)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130906)[0m Instructions for updating:
[2m[36m(pid=130906)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130906)[0m LSTM is selected.
[2m[36m(pid=130898)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130898)[0m   agg_primitives: ['count']
[2m[36m(pid=130898)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130898)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130906)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130906)[0m Instructions for updating:
[2m[36m(pid=130906)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130898)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130898)[0m Instructions for updating:
[2m[36m(pid=130898)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130898)[0m LSTM is selected.
[2m[36m(pid=130918)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130918)[0m   agg_primitives: ['count']
[2m[36m(pid=130918)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130918)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130904)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130904)[0m   agg_primitives: ['count']
[2m[36m(pid=130904)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130904)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130898)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130898)[0m Instructions for updating:
[2m[36m(pid=130898)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130918)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130918)[0m Instructions for updating:
[2m[36m(pid=130918)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130918)[0m LSTM is selected.
[2m[36m(pid=130906)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130906)[0m 2020-11-20 11:44:04.574421: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130906)[0m 2020-11-20 11:44:04.583952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130906)[0m 2020-11-20 11:44:04.588157: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb1010ef220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130906)[0m 2020-11-20 11:44:04.588195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130904)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130904)[0m Instructions for updating:
[2m[36m(pid=130904)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130904)[0m LSTM is selected.
[2m[36m(pid=132687)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132687)[0m   agg_primitives: ['count']
[2m[36m(pid=132687)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132687)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130918)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130918)[0m Instructions for updating:
[2m[36m(pid=130918)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130904)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130904)[0m Instructions for updating:
[2m[36m(pid=130904)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130898)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130898)[0m 2020-11-20 11:44:05.275131: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130898)[0m 2020-11-20 11:44:05.285035: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130898)[0m 2020-11-20 11:44:05.288678: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f58f90d4620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130898)[0m 2020-11-20 11:44:05.288721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132687)[0m LSTM is selected.
[2m[36m(pid=132687)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132687)[0m Instructions for updating:
[2m[36m(pid=132687)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130918)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130918)[0m 2020-11-20 11:44:06.205443: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130918)[0m 2020-11-20 11:44:06.217478: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130918)[0m 2020-11-20 11:44:06.221298: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eee390d4900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130918)[0m 2020-11-20 11:44:06.221343: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130904)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130904)[0m 2020-11-20 11:44:06.231482: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130904)[0m 2020-11-20 11:44:06.241299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132687)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132687)[0m Instructions for updating:
[2m[36m(pid=132687)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130904)[0m 2020-11-20 11:44:06.245864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e9d0d4080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130904)[0m 2020-11-20 11:44:06.245911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=132687)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132687)[0m 2020-11-20 11:44:07.266810: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132687)[0m 2020-11-20 11:44:07.280869: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132687)[0m 2020-11-20 11:44:07.287171: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa11d0d6ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132687)[0m 2020-11-20 11:44:07.287218: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 32 ({'TERMINATED': 13, 'ERROR': 9, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 3 not shown
 - train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=62.03,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_21_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-41a3hlwit9/error_2020-11-20_11-43-58.txt
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-42aqgs_pd6/error_2020-11-20_11-44-00.txt
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AW_2020-11-20_11-43-474zgbgs4n/error_2020-11-20_11-43-59.txt
RUNNING trials:
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 27 s, 3 iter
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132693], 21 s, 2 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130899], 13 s, 1 iter
  ... 4 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 7 not shown
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter

[2m[36m(pid=132687)[0m 2020-11-20 11:44:10,570	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=132687)[0m Traceback (most recent call last):
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132687)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132687)[0m     param_dset[:] = val
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132687)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132687)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132687)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132687)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:10 2020
[2m[36m(pid=132687)[0m , filename = '/tmp/thalvari/4065561/automl_save_7mjsrwd3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa11e887ac8, total write size = 712824, bytes this sub-write = 712824, bytes actually written = 18446744073709551615, offset = 3047424)
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m Traceback (most recent call last):
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132687)[0m     self._entrypoint()
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132687)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132687)[0m     output = train_func(config, reporter)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132687)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132687)[0m     config=config)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132687)[0m     model.save(model_path, config_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132687)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132687)[0m     self.model.save(model_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132687)[0m     signatures)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132687)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132687)[0m     f.close()
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132687)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132687)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:10 2020
[2m[36m(pid=132687)[0m , filename = '/tmp/thalvari/4065561/automl_save_7mjsrwd3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa11e62f670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132687)[0m Exception in thread Thread-1:
[2m[36m(pid=132687)[0m Traceback (most recent call last):
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132687)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132687)[0m     param_dset[:] = val
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132687)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132687)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132687)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132687)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:10 2020
[2m[36m(pid=132687)[0m , filename = '/tmp/thalvari/4065561/automl_save_7mjsrwd3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa11e887ac8, total write size = 712824, bytes this sub-write = 712824, bytes actually written = 18446744073709551615, offset = 3047424)
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m Traceback (most recent call last):
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132687)[0m     self._entrypoint()
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132687)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132687)[0m     output = train_func(config, reporter)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132687)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132687)[0m     config=config)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132687)[0m     model.save(model_path, config_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132687)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132687)[0m     self.model.save(model_path)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132687)[0m     signatures)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132687)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132687)[0m     f.close()
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132687)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132687)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132687)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:10 2020
[2m[36m(pid=132687)[0m , filename = '/tmp/thalvari/4065561/automl_save_7mjsrwd3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa11e62f670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m Traceback (most recent call last):
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=132687)[0m     self.run()
[2m[36m(pid=132687)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=132687)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=132687)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=132687)[0m 
2020-11-20 11:44:11,776	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=132687, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:11,781	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=132687)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=132687)[0m 
[2m[36m(pid=132687)[0m Stack (most recent call first):
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 33 ({'TERMINATED': 13, 'ERROR': 10, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 4 not shown
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-42aqgs_pd6/error_2020-11-20_11-44-00.txt
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AW_2020-11-20_11-43-474zgbgs4n/error_2020-11-20_11-43-59.txt
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-01jnfgj3b5/error_2020-11-20_11-44-11.txt
RUNNING trials:
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 27 s, 3 iter
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132693], 21 s, 2 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130899], 21 s, 2 iter
  ... 4 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 7 not shown
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter

[2m[36m(pid=132693)[0m 2020-11-20 11:44:17,264	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=132693)[0m Traceback (most recent call last):
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132693)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132693)[0m     param_dset[:] = val
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132693)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132693)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132693)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132693)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:17 2020
[2m[36m(pid=132693)[0m , filename = '/tmp/thalvari/4065561/automl_save__v8eif2z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f066673bcf8, total write size = 236200, bytes this sub-write = 236200, bytes actually written = 18446744073709551615, offset = 1646592)
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m Traceback (most recent call last):
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132693)[0m     self._entrypoint()
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132693)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132693)[0m     output = train_func(config, reporter)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132693)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132693)[0m     config=config)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132693)[0m     model.save(model_path, config_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132693)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132693)[0m     self.model.save(model_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132693)[0m     signatures)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132693)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132693)[0m     f.close()
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132693)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132693)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:17 2020
[2m[36m(pid=132693)[0m , filename = '/tmp/thalvari/4065561/automl_save__v8eif2z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0666084980, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132693)[0m Exception in thread Thread-1:
[2m[36m(pid=132693)[0m Traceback (most recent call last):
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132693)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132693)[0m     param_dset[:] = val
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132693)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132693)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132693)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132693)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:17 2020
[2m[36m(pid=132693)[0m , filename = '/tmp/thalvari/4065561/automl_save__v8eif2z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f066673bcf8, total write size = 236200, bytes this sub-write = 236200, bytes actually written = 18446744073709551615, offset = 1646592)
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m Traceback (most recent call last):
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132693)[0m     self._entrypoint()
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132693)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132693)[0m     output = train_func(config, reporter)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132693)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132693)[0m     config=config)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132693)[0m     model.save(model_path, config_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132693)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132693)[0m     self.model.save(model_path)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132693)[0m     signatures)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132693)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132693)[0m     f.close()
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132693)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132693)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132693)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:17 2020
[2m[36m(pid=132693)[0m , filename = '/tmp/thalvari/4065561/automl_save__v8eif2z/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0666084980, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m Traceback (most recent call last):
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=132693)[0m     self.run()
[2m[36m(pid=132693)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=132693)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=132693)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=132693)[0m 
[2m[36m(pid=130910)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130910)[0m   agg_primitives: ['count']
[2m[36m(pid=130910)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130910)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 33 ({'TERMINATED': 13, 'ERROR': 10, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 4 not shown
 - train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.5,epochs=5,lr=0.001,lstm_1_units_float=63.182,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_22_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-42aqgs_pd6/error_2020-11-20_11-44-00.txt
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AW_2020-11-20_11-43-474zgbgs4n/error_2020-11-20_11-43-59.txt
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-01jnfgj3b5/error_2020-11-20_11-44-11.txt
RUNNING trials:
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130927], 36 s, 4 iter
 - train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=132693], 21 s, 2 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130899], 21 s, 2 iter
  ... 4 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130904], 13 s, 1 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130918], 13 s, 1 iter
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 7 not shown
 - train_func_15_batch_size_log=8.1182,bayes_feature_DAY(timestamp)=0.85468,bayes_feature_HOUR(timestamp)=0.54187,bayes_feature_IS_AWAKE(timestamp)=0.36377,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67525,bayes_feature_IS_WEEKEND(timestamp)=0.9603,bayes_feature_MONTH(timestamp)=0.60275,bayes_feature_WEEKDAY(timestamp)=0.42529,dropout_1=0.25307,dropout_2=0.40386,epochs=5,lr=0.0095668,lstm_1_units_float=97.842,lstm_2_units_float=67.5,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132697], 13 s, 5 iter
 - train_func_17_batch_size_log=9.0657,bayes_feature_DAY(timestamp)=0.30329,bayes_feature_HOUR(timestamp)=0.44144,bayes_feature_IS_AWAKE(timestamp)=0.67474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.93301,bayes_feature_IS_WEEKEND(timestamp)=0.55692,bayes_feature_MONTH(timestamp)=0.46078,bayes_feature_WEEKDAY(timestamp)=0.44276,dropout_1=0.33679,dropout_2=0.30664,epochs=5,lr=0.0050162,lstm_1_units_float=127.68,lstm_2_units_float=9.1537,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=132696], 11 s, 5 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter

[2m[36m(pid=130910)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130910)[0m Instructions for updating:
[2m[36m(pid=130910)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130910)[0m LSTM is selected.
2020-11-20 11:44:18,444	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=132693, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:18,450	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_23_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.112,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=132693)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=132693)[0m 
[2m[36m(pid=132693)[0m Stack (most recent call first):
[2m[36m(pid=130910)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130910)[0m Instructions for updating:
[2m[36m(pid=130910)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130910)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130910)[0m 2020-11-20 11:44:19.984122: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130910)[0m 2020-11-20 11:44:19.996426: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130910)[0m 2020-11-20 11:44:20.004862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f273d0d7400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130910)[0m 2020-11-20 11:44:20.004917: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130936)[0m 2020-11-20 11:44:23,392	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130936)[0m Traceback (most recent call last):
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=130936)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=130936)[0m     param_dset[:] = val
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130936)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130936)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130936)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130936)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130936)[0m , filename = '/tmp/thalvari/4065561/automl_save_y57_ckgr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37d2a6ec98, total write size = 331720, bytes this sub-write = 331720, bytes actually written = 18446744073709551615, offset = 1138688)
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m Traceback (most recent call last):
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130936)[0m     self._entrypoint()
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130936)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130936)[0m     output = train_func(config, reporter)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130936)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130936)[0m     config=config)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130936)[0m     model.save(model_path, config_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130936)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130936)[0m     self.model.save(model_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130936)[0m     signatures)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130936)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130936)[0m     f.close()
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130936)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130936)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130936)[0m , filename = '/tmp/thalvari/4065561/automl_save_y57_ckgr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37d26688a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130936)[0m Exception in thread Thread-1:
[2m[36m(pid=130936)[0m Traceback (most recent call last):
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=130936)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=130936)[0m     param_dset[:] = val
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130936)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130936)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130936)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130936)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130936)[0m , filename = '/tmp/thalvari/4065561/automl_save_y57_ckgr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37d2a6ec98, total write size = 331720, bytes this sub-write = 331720, bytes actually written = 18446744073709551615, offset = 1138688)
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m Traceback (most recent call last):
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130936)[0m     self._entrypoint()
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130936)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130936)[0m     output = train_func(config, reporter)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130936)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130936)[0m     config=config)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130936)[0m     model.save(model_path, config_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130936)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130936)[0m     self.model.save(model_path)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130936)[0m     signatures)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130936)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130936)[0m     f.close()
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130936)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130936)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130936)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130936)[0m , filename = '/tmp/thalvari/4065561/automl_save_y57_ckgr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37d26688a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130910)[0m 2020-11-20 11:44:23,412	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130910)[0m Traceback (most recent call last):
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130910)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130910)[0m     param_dset[:] = val
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130910)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130910)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130910)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130910)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130910)[0m , filename = '/tmp/thalvari/4065561/automl_save_zidp1i62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f273e8af1c8, total write size = 737400, bytes this sub-write = 737400, bytes actually written = 18446744073709551615, offset = 3022848)
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m Traceback (most recent call last):
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130910)[0m     self._entrypoint()
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130910)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130910)[0m     output = train_func(config, reporter)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130910)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130910)[0m     config=config)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130910)[0m     model.save(model_path, config_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130910)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130910)[0m     self.model.save(model_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130910)[0m     signatures)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130910)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130910)[0m     f.close()
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130910)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130910)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130910)[0m , filename = '/tmp/thalvari/4065561/automl_save_zidp1i62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f273de03b80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130910)[0m Exception in thread Thread-1:
[2m[36m(pid=130910)[0m Traceback (most recent call last):
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130910)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130910)[0m     param_dset[:] = val
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130910)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130910)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130910)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130910)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130910)[0m , filename = '/tmp/thalvari/4065561/automl_save_zidp1i62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f273e8af1c8, total write size = 737400, bytes this sub-write = 737400, bytes actually written = 18446744073709551615, offset = 3022848)
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m Traceback (most recent call last):
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130910)[0m     self._entrypoint()
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130910)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130910)[0m     output = train_func(config, reporter)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130910)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130910)[0m     config=config)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130910)[0m     model.save(model_path, config_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130910)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130910)[0m     self.model.save(model_path)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130910)[0m     signatures)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130910)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130910)[0m     f.close()
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130910)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130910)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130910)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:23 2020
[2m[36m(pid=130910)[0m , filename = '/tmp/thalvari/4065561/automl_save_zidp1i62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f273de03b80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m Traceback (most recent call last):
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130936)[0m     self.run()
[2m[36m(pid=130936)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130936)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130936)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m Traceback (most recent call last):
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130910)[0m     self.run()
[2m[36m(pid=130910)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130910)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130910)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130910)[0m 
[2m[36m(pid=132699)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=132699)[0m   agg_primitives: ['count']
[2m[36m(pid=132699)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=132699)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:44:24,560	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130936, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:24,565	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_27_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.687,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 36 ({'TERMINATED': 15, 'ERROR': 12, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 6 not shown
 - train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AWAKE(timestamp)=0.52196,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36908,bayes_feature_IS_WEEKEND(timestamp)=0.72689,bayes_feature_MONTH(timestamp)=0.33411,bayes_feature_WEEKDAY(timestamp)=0.60685,dropout_1=0.43933,dropout_2=0.34073,epochs=5,lr=0.0036575,lstm_1_units_float=51.081,lstm_2_units_float=115.21,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_25_batch_size_log=9.8582,bayes_feature_DAY(timestamp)=0.56238,bayes_feature_HOUR(timestamp)=0.89064,bayes_feature_IS_AW_2020-11-20_11-43-474zgbgs4n/error_2020-11-20_11-43-59.txt
 - train_func_27_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.687,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_27_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-43-565bt0t6ju/error_2020-11-20_11-44-24.txt, [4 CPUs, 0 GPUs], [pid=130936], 13 s, 1 iter
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-01jnfgj3b5/error_2020-11-20_11-44-11.txt
RUNNING trials:
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130899], 30 s, 3 iter
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130912], 21 s, 2 iter
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130898], 13 s, 1 iter
  ... 3 not shown
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 9 not shown
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130927], 46 s, 5 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter
 - train_func_28_batch_size_log=7.2672,bayes_feature_DAY(timestamp)=0.9954,bayes_feature_HOUR(timestamp)=0.32481,bayes_feature_IS_AWAKE(timestamp)=0.53627,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67619,bayes_feature_IS_WEEKEND(timestamp)=0.61211,bayes_feature_MONTH(timestamp)=0.36325,bayes_feature_WEEKDAY(timestamp)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130906], 18 s, 5 iter

[2m[36m(pid=130936)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130936)[0m 
[2m[36m(pid=130936)[0m Stack (most recent call first):
[2m[36m(pid=132699)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=132699)[0m Instructions for updating:
[2m[36m(pid=132699)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=132699)[0m LSTM is selected.
2020-11-20 11:44:25,304	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130910, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:25,307	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130910)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130910)[0m 
[2m[36m(pid=130910)[0m Stack (most recent call first):
[2m[36m(pid=130931)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130931)[0m   agg_primitives: ['count']
[2m[36m(pid=130931)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130931)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132699)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=132699)[0m Instructions for updating:
[2m[36m(pid=132699)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130931)[0m LSTM is selected.
[2m[36m(pid=130931)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130931)[0m Instructions for updating:
[2m[36m(pid=130931)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130931)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130931)[0m Instructions for updating:
[2m[36m(pid=130931)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=132699)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=132699)[0m 2020-11-20 11:44:26.525108: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=132699)[0m 2020-11-20 11:44:26.535334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=132699)[0m 2020-11-20 11:44:26.539544: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd5d0d6900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=132699)[0m 2020-11-20 11:44:26.539579: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130919)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130919)[0m   agg_primitives: ['count']
[2m[36m(pid=130919)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130919)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130919)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130919)[0m Instructions for updating:
[2m[36m(pid=130919)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130919)[0m LSTM is selected.
[2m[36m(pid=130931)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130931)[0m 2020-11-20 11:44:27.551095: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130931)[0m 2020-11-20 11:44:27.561737: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130931)[0m 2020-11-20 11:44:27.566185: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6cc10d7620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130931)[0m 2020-11-20 11:44:27.566227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130919)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130919)[0m Instructions for updating:
[2m[36m(pid=130919)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130919)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130919)[0m 2020-11-20 11:44:28.983382: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130919)[0m 2020-11-20 11:44:28.993047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130919)[0m 2020-11-20 11:44:28.996931: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b450d7900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130919)[0m 2020-11-20 11:44:28.996981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130922)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130922)[0m   agg_primitives: ['count']
[2m[36m(pid=130922)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130922)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130916)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130916)[0m   agg_primitives: ['count']
[2m[36m(pid=130916)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130916)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=132699)[0m 2020-11-20 11:44:29,723	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=132699)[0m Traceback (most recent call last):
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132699)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132699)[0m     param_dset[:] = val
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132699)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132699)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132699)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132699)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:29 2020
[2m[36m(pid=132699)[0m , filename = '/tmp/thalvari/4065561/automl_save_puxzm2rb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcd5e86fa08, total write size = 745592, bytes this sub-write = 745592, bytes actually written = 18446744073709551615, offset = 3014656)
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m Traceback (most recent call last):
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132699)[0m     self._entrypoint()
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132699)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132699)[0m     output = train_func(config, reporter)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132699)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132699)[0m     config=config)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132699)[0m     model.save(model_path, config_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132699)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132699)[0m     self.model.save(model_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132699)[0m     signatures)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132699)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132699)[0m     f.close()
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132699)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132699)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:29 2020
[2m[36m(pid=132699)[0m , filename = '/tmp/thalvari/4065561/automl_save_puxzm2rb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcd5d9065b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132699)[0m Exception in thread Thread-1:
[2m[36m(pid=132699)[0m Traceback (most recent call last):
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=132699)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=132699)[0m     param_dset[:] = val
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=132699)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=132699)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=132699)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=132699)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:29 2020
[2m[36m(pid=132699)[0m , filename = '/tmp/thalvari/4065561/automl_save_puxzm2rb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcd5e86fa08, total write size = 745592, bytes this sub-write = 745592, bytes actually written = 18446744073709551615, offset = 3014656)
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m Traceback (most recent call last):
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=132699)[0m     self._entrypoint()
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=132699)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=132699)[0m     output = train_func(config, reporter)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=132699)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=132699)[0m     config=config)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=132699)[0m     model.save(model_path, config_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=132699)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=132699)[0m     self.model.save(model_path)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=132699)[0m     signatures)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=132699)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=132699)[0m     f.close()
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=132699)[0m     h5i.dec_ref(id_)
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=132699)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=132699)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:29 2020
[2m[36m(pid=132699)[0m , filename = '/tmp/thalvari/4065561/automl_save_puxzm2rb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcd5d9065b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m Traceback (most recent call last):
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=132699)[0m     self.run()
[2m[36m(pid=132699)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=132699)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=132699)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=132699)[0m 
[2m[36m(pid=130922)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130922)[0m Instructions for updating:
[2m[36m(pid=130922)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130922)[0m LSTM is selected.
[2m[36m(pid=130916)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130916)[0m Instructions for updating:
[2m[36m(pid=130916)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130916)[0m LSTM is selected.
[2m[36m(pid=130922)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130922)[0m Instructions for updating:
[2m[36m(pid=130922)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130916)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130916)[0m Instructions for updating:
[2m[36m(pid=130916)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:44:30,793	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=132699, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:30,797	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 18.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 38 ({'TERMINATED': 15, 'ERROR': 14, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 8 not shown
 - train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_32_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-01jnfgj3b5/error_2020-11-20_11-44-11.txt
 - train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_33_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-12xihm94se/error_2020-11-20_11-44-25.txt
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-19xu17g0zb/error_2020-11-20_11-44-30.txt
RUNNING trials:
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130899], 38 s, 4 iter
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130912], 29 s, 3 iter
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130898], 21 s, 2 iter
  ... 3 not shown
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 9 not shown
 - train_func_18_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=47.578,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130927], 46 s, 5 iter
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter
 - train_func_28_batch_size_log=7.2672,bayes_feature_DAY(timestamp)=0.9954,bayes_feature_HOUR(timestamp)=0.32481,bayes_feature_IS_AWAKE(timestamp)=0.53627,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67619,bayes_feature_IS_WEEKEND(timestamp)=0.61211,bayes_feature_MONTH(timestamp)=0.36325,bayes_feature_WEEKDAY(timestamp)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130906], 18 s, 5 iter

[2m[36m(pid=130931)[0m 2020-11-20 11:44:30,838	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130931)[0m Traceback (most recent call last):
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130931)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130931)[0m     param_dset[:] = val
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130931)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130931)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130931)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130931)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:30 2020
[2m[36m(pid=130931)[0m , filename = '/tmp/thalvari/4065561/automl_save_ttnopdsb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6cc28ac878, total write size = 753784, bytes this sub-write = 753784, bytes actually written = 18446744073709551615, offset = 3006464)
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m Traceback (most recent call last):
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130931)[0m     self._entrypoint()
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130931)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130931)[0m     output = train_func(config, reporter)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130931)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130931)[0m     config=config)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130931)[0m     model.save(model_path, config_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130931)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130931)[0m     self.model.save(model_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130931)[0m     signatures)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130931)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130931)[0m     f.close()
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130931)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130931)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:30 2020
[2m[36m(pid=130931)[0m , filename = '/tmp/thalvari/4065561/automl_save_ttnopdsb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6cc2544e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130931)[0m Exception in thread Thread-1:
[2m[36m(pid=130931)[0m Traceback (most recent call last):
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130931)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130931)[0m     param_dset[:] = val
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130931)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130931)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130931)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130931)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:30 2020
[2m[36m(pid=130931)[0m , filename = '/tmp/thalvari/4065561/automl_save_ttnopdsb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6cc28ac878, total write size = 753784, bytes this sub-write = 753784, bytes actually written = 18446744073709551615, offset = 3006464)
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m Traceback (most recent call last):
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130931)[0m     self._entrypoint()
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130931)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130931)[0m     output = train_func(config, reporter)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130931)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130931)[0m     config=config)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130931)[0m     model.save(model_path, config_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130931)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130931)[0m     self.model.save(model_path)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130931)[0m     signatures)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130931)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130931)[0m     f.close()
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130931)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130931)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130931)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:30 2020
[2m[36m(pid=130931)[0m , filename = '/tmp/thalvari/4065561/automl_save_ttnopdsb/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6cc2544e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m Traceback (most recent call last):
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130931)[0m     self.run()
[2m[36m(pid=130931)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130931)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130931)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130931)[0m 
[2m[36m(pid=132699)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=132699)[0m 
[2m[36m(pid=132699)[0m Stack (most recent call first):
[2m[36m(pid=130922)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130922)[0m 2020-11-20 11:44:31.614105: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130922)[0m 2020-11-20 11:44:31.624558: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130922)[0m 2020-11-20 11:44:31.630419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f681d0d7230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130922)[0m 2020-11-20 11:44:31.630450: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130916)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130916)[0m 2020-11-20 11:44:31.613536: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130916)[0m 2020-11-20 11:44:31.624324: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130916)[0m 2020-11-20 11:44:31.629363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6f450d7400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130916)[0m 2020-11-20 11:44:31.629412: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:44:31,938	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130931, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:31,942	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130931)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130931)[0m 
[2m[36m(pid=130931)[0m Stack (most recent call first):
[2m[36m(pid=130919)[0m 2020-11-20 11:44:32,462	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130919)[0m Traceback (most recent call last):
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130919)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130919)[0m     param_dset[:] = val
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130919)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130919)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130919)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130919)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:32 2020
[2m[36m(pid=130919)[0m , filename = '/tmp/thalvari/4065561/automl_save_paj9c5s2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1b46865fe8, total write size = 761976, bytes this sub-write = 761976, bytes actually written = 18446744073709551615, offset = 2998272)
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m Traceback (most recent call last):
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130919)[0m     self._entrypoint()
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130919)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130919)[0m     output = train_func(config, reporter)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130919)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130919)[0m     config=config)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130919)[0m     model.save(model_path, config_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130919)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130919)[0m     self.model.save(model_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130919)[0m     signatures)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130919)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130919)[0m     f.close()
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130919)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130919)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:32 2020
[2m[36m(pid=130919)[0m , filename = '/tmp/thalvari/4065561/automl_save_paj9c5s2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1b457183c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130919)[0m Exception in thread Thread-1:
[2m[36m(pid=130919)[0m Traceback (most recent call last):
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130919)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130919)[0m     param_dset[:] = val
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130919)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130919)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130919)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130919)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:32 2020
[2m[36m(pid=130919)[0m , filename = '/tmp/thalvari/4065561/automl_save_paj9c5s2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1b46865fe8, total write size = 761976, bytes this sub-write = 761976, bytes actually written = 18446744073709551615, offset = 2998272)
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m Traceback (most recent call last):
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130919)[0m     self._entrypoint()
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130919)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130919)[0m     output = train_func(config, reporter)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130919)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130919)[0m     config=config)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130919)[0m     model.save(model_path, config_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130919)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130919)[0m     self.model.save(model_path)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130919)[0m     signatures)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130919)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130919)[0m     f.close()
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130919)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130919)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130919)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:32 2020
[2m[36m(pid=130919)[0m , filename = '/tmp/thalvari/4065561/automl_save_paj9c5s2/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1b457183c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m Traceback (most recent call last):
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130919)[0m     self.run()
[2m[36m(pid=130919)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130919)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130919)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130919)[0m 
2020-11-20 11:44:33,675	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130919, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:33,679	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130919)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130919)[0m 
[2m[36m(pid=130919)[0m Stack (most recent call first):
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=130916)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f461e9340, total write size = 120, bytes this sub-write = 120, bytes actually written = 18446744073709551615, offset = 2170880)
[2m[36m(pid=130916)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=130916)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f461e9340, total write size = 120, bytes this sub-write = 120, bytes actually written = 18446744073709551615, offset = 2170880)
[2m[36m(pid=130916)[0m 2020-11-20 11:44:34,941	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130916)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130916)[0m     param_dset[:] = val
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130916)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130916)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130916)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130916)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f469e3d40, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 2173048)
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130916)[0m     self._entrypoint()
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130916)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130916)[0m     output = train_func(config, reporter)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130916)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130916)[0m     config=config)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130916)[0m     model.save(model_path, config_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130916)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130916)[0m     self.model.save(model_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130916)[0m     signatures)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130916)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130916)[0m     f.close()
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130916)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130916)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f464ee9e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130916)[0m Exception in thread Thread-1:
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130916)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130916)[0m     param_dset[:] = val
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130916)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130916)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130916)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130916)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f469e3d40, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 2173048)
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130916)[0m     self._entrypoint()
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130916)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130916)[0m     output = train_func(config, reporter)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130916)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130916)[0m     config=config)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130916)[0m     model.save(model_path, config_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130916)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130916)[0m     self.model.save(model_path)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130916)[0m     signatures)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130916)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130916)[0m     f.close()
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130916)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130916)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130916)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:34 2020
[2m[36m(pid=130916)[0m , filename = '/tmp/thalvari/4065561/automl_save_um3ad241/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6f464ee9e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m Traceback (most recent call last):
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130916)[0m     self.run()
[2m[36m(pid=130916)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130916)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130916)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130922)[0m 2020-11-20 11:44:35,033	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130922)[0m Traceback (most recent call last):
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130922)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130922)[0m     param_dset[:] = val
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130922)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130922)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130922)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130922)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:35 2020
[2m[36m(pid=130922)[0m , filename = '/tmp/thalvari/4065561/automl_save_uralkv42/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f681ea210b8, total write size = 782456, bytes this sub-write = 782456, bytes actually written = 18446744073709551615, offset = 2977792)
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m Traceback (most recent call last):
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130922)[0m     self._entrypoint()
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130922)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130922)[0m     output = train_func(config, reporter)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130922)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130922)[0m     config=config)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130922)[0m     model.save(model_path, config_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130922)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130922)[0m     self.model.save(model_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130922)[0m     signatures)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130922)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130922)[0m     f.close()
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130922)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130922)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:35 2020
[2m[36m(pid=130922)[0m , filename = '/tmp/thalvari/4065561/automl_save_uralkv42/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f681d5e47b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130922)[0m Exception in thread Thread-1:
[2m[36m(pid=130922)[0m Traceback (most recent call last):
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130922)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130922)[0m     param_dset[:] = val
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130922)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130922)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130922)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130922)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:35 2020
[2m[36m(pid=130922)[0m , filename = '/tmp/thalvari/4065561/automl_save_uralkv42/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f681ea210b8, total write size = 782456, bytes this sub-write = 782456, bytes actually written = 18446744073709551615, offset = 2977792)
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m Traceback (most recent call last):
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130922)[0m     self._entrypoint()
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130922)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130922)[0m     output = train_func(config, reporter)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130922)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130922)[0m     config=config)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130922)[0m     model.save(model_path, config_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130922)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130922)[0m     self.model.save(model_path)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130922)[0m     signatures)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130922)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130922)[0m     f.close()
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130922)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130922)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130922)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:35 2020
[2m[36m(pid=130922)[0m , filename = '/tmp/thalvari/4065561/automl_save_uralkv42/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f681d5e47b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m Traceback (most recent call last):
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130922)[0m     self.run()
[2m[36m(pid=130922)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130922)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130922)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130934)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130934)[0m   agg_primitives: ['count']
[2m[36m(pid=130934)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130934)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130901)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130901)[0m   agg_primitives: ['count']
[2m[36m(pid=130901)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130901)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 42 ({'TERMINATED': 16, 'ERROR': 16, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 10 not shown
 - train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_34_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-19xu17g0zb/error_2020-11-20_11-44-30.txt
 - train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_35_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-21xnks7g9o/error_2020-11-20_11-44-31.txt
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-2215eo9ze1/error_2020-11-20_11-44-33.txt
RUNNING trials:
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130912], 38 s, 4 iter
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130898], 31 s, 3 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130904], 30 s, 3 iter
  ... 4 not shown
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_42_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 10 not shown
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130899], 46 s, 5 iter
 - train_func_28_batch_size_log=7.2672,bayes_feature_DAY(timestamp)=0.9954,bayes_feature_HOUR(timestamp)=0.32481,bayes_feature_IS_AWAKE(timestamp)=0.53627,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67619,bayes_feature_IS_WEEKEND(timestamp)=0.61211,bayes_feature_MONTH(timestamp)=0.36325,bayes_feature_WEEKDAY(timestamp)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130906], 18 s, 5 iter

2020-11-20 11:44:36,419	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130922, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:36,423	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130922)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130922)[0m 
[2m[36m(pid=130922)[0m Stack (most recent call first):
[2m[36m(pid=130934)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130934)[0m Instructions for updating:
[2m[36m(pid=130934)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130934)[0m LSTM is selected.
[2m[36m(pid=130901)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130901)[0m Instructions for updating:
[2m[36m(pid=130901)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130901)[0m LSTM is selected.
2020-11-20 11:44:37,204	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130916, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:37,209	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130934)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130934)[0m Instructions for updating:
[2m[36m(pid=130934)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130901)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130901)[0m Instructions for updating:
[2m[36m(pid=130901)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130916)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130916)[0m 
[2m[36m(pid=130916)[0m Stack (most recent call first):
[2m[36m(pid=130937)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130937)[0m   agg_primitives: ['count']
[2m[36m(pid=130937)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130937)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130901)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130901)[0m 2020-11-20 11:44:38.435230: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130934)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130934)[0m 2020-11-20 11:44:38.473934: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130934)[0m 2020-11-20 11:44:38.483569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130934)[0m 2020-11-20 11:44:38.488736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f21ed0d7860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130934)[0m 2020-11-20 11:44:38.488781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130901)[0m 2020-11-20 11:44:38.445730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130901)[0m 2020-11-20 11:44:38.450691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f030d0d6c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130901)[0m 2020-11-20 11:44:38.450724: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130937)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130937)[0m Instructions for updating:
[2m[36m(pid=130937)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130937)[0m LSTM is selected.
[2m[36m(pid=130937)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130937)[0m Instructions for updating:
[2m[36m(pid=130937)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130937)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130937)[0m 2020-11-20 11:44:40.221189: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130937)[0m 2020-11-20 11:44:40.231239: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130937)[0m 2020-11-20 11:44:40.234756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2ddd0d6a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130937)[0m 2020-11-20 11:44:40.234806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130926)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130926)[0m   agg_primitives: ['count']
[2m[36m(pid=130926)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130926)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130911)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130911)[0m   agg_primitives: ['count']
[2m[36m(pid=130911)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130911)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130926)[0m LSTM is selected.
[2m[36m(pid=130911)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130911)[0m Instructions for updating:
[2m[36m(pid=130911)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130911)[0m LSTM is selected.
[2m[36m(pid=130926)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130926)[0m Instructions for updating:
[2m[36m(pid=130926)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130926)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130926)[0m Instructions for updating:
[2m[36m(pid=130926)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130911)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130911)[0m Instructions for updating:
[2m[36m(pid=130911)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130934)[0m 2020-11-20 11:44:41,667	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130934)[0m Traceback (most recent call last):
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=130934)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=130934)[0m     param_dset[:] = val
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130934)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130934)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130934)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130934)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130934)[0m , filename = '/tmp/thalvari/4065561/automl_save_o8_i72py/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21eea22df8, total write size = 798808, bytes this sub-write = 798808, bytes actually written = 18446744073709551615, offset = 1077248)
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m Traceback (most recent call last):
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130934)[0m     self._entrypoint()
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130934)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130934)[0m     output = train_func(config, reporter)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130934)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130934)[0m     config=config)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130934)[0m     model.save(model_path, config_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130934)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130934)[0m     self.model.save(model_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130934)[0m     signatures)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130934)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130934)[0m     f.close()
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130934)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130934)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130934)[0m , filename = '/tmp/thalvari/4065561/automl_save_o8_i72py/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21ee5f4600, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130934)[0m Exception in thread Thread-1:
[2m[36m(pid=130934)[0m Traceback (most recent call last):
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=130934)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=130934)[0m     param_dset[:] = val
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130934)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130934)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130934)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130934)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130934)[0m , filename = '/tmp/thalvari/4065561/automl_save_o8_i72py/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21eea22df8, total write size = 798808, bytes this sub-write = 798808, bytes actually written = 18446744073709551615, offset = 1077248)
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m Traceback (most recent call last):
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130934)[0m     self._entrypoint()
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130934)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130934)[0m     output = train_func(config, reporter)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130934)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130934)[0m     config=config)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130934)[0m     model.save(model_path, config_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130934)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130934)[0m     self.model.save(model_path)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130934)[0m     signatures)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130934)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130934)[0m     f.close()
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130934)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130934)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130934)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130934)[0m , filename = '/tmp/thalvari/4065561/automl_save_o8_i72py/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f21ee5f4600, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m Traceback (most recent call last):
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130934)[0m     self.run()
[2m[36m(pid=130934)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130934)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130934)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130934)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 17.1/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 44 ({'TERMINATED': 16, 'ERROR': 18, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 12 not shown
 - train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_36_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-2215eo9ze1/error_2020-11-20_11-44-33.txt
 - train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_37_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-25s_ksant_/error_2020-11-20_11-44-36.txt
 - train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_38_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-2600pb6mjx/error_2020-11-20_11-44-37.txt
RUNNING trials:
 - train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130912], 38 s, 4 iter
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130898], 31 s, 3 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130904], 30 s, 3 iter
  ... 4 not shown
 - train_func_42_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 10 not shown
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130899], 46 s, 5 iter
 - train_func_28_batch_size_log=7.2672,bayes_feature_DAY(timestamp)=0.9954,bayes_feature_HOUR(timestamp)=0.32481,bayes_feature_IS_AWAKE(timestamp)=0.53627,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67619,bayes_feature_IS_WEEKEND(timestamp)=0.61211,bayes_feature_MONTH(timestamp)=0.36325,bayes_feature_WEEKDAY(timestamp)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130906], 18 s, 5 iter

[2m[36m(pid=130901)[0m 2020-11-20 11:44:41,696	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130901)[0m Traceback (most recent call last):
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130901)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130901)[0m     param_dset[:] = val
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130901)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130901)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130901)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130901)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130901)[0m , filename = '/tmp/thalvari/4065561/automl_save_co7wvekn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f030e8946f8, total write size = 807032, bytes this sub-write = 807032, bytes actually written = 18446744073709551615, offset = 2953216)
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m Traceback (most recent call last):
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130901)[0m     self._entrypoint()
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130901)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130901)[0m     output = train_func(config, reporter)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130901)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130901)[0m     config=config)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130901)[0m     model.save(model_path, config_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130901)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130901)[0m     self.model.save(model_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130901)[0m     signatures)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130901)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130901)[0m     f.close()
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130901)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130901)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130901)[0m , filename = '/tmp/thalvari/4065561/automl_save_co7wvekn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f030e1bb970, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130901)[0m Exception in thread Thread-1:
[2m[36m(pid=130901)[0m Traceback (most recent call last):
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130901)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130901)[0m     param_dset[:] = val
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130901)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130901)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130901)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130901)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130901)[0m , filename = '/tmp/thalvari/4065561/automl_save_co7wvekn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f030e8946f8, total write size = 807032, bytes this sub-write = 807032, bytes actually written = 18446744073709551615, offset = 2953216)
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m Traceback (most recent call last):
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130901)[0m     self._entrypoint()
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130901)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130901)[0m     output = train_func(config, reporter)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130901)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130901)[0m     config=config)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130901)[0m     model.save(model_path, config_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130901)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130901)[0m     self.model.save(model_path)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130901)[0m     signatures)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130901)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130901)[0m     f.close()
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130901)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130901)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130901)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:41 2020
[2m[36m(pid=130901)[0m , filename = '/tmp/thalvari/4065561/automl_save_co7wvekn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f030e1bb970, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m Traceback (most recent call last):
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130901)[0m     self.run()
[2m[36m(pid=130901)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130901)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130901)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=130912)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae61dd2c0, total write size = 6888, bytes this sub-write = 6888, bytes actually written = 18446744073709551615, offset = 2949120)
[2m[36m(pid=130912)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=130912)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae61dd2c0, total write size = 6888, bytes this sub-write = 6888, bytes actually written = 18446744073709551615, offset = 2949120)
[2m[36m(pid=130912)[0m 2020-11-20 11:44:42,087	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=130912)[0m     f.flush()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=130912)[0m     h5f.flush(self.id)
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=130912)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae6606d50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130912)[0m     self._entrypoint()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130912)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130912)[0m     output = train_func(config, reporter)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130912)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130912)[0m     config=config)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130912)[0m     model.save(model_path, config_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130912)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130912)[0m     self.model.save(model_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130912)[0m     signatures)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130912)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130912)[0m     f.close()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130912)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130912)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae6606d50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130912)[0m Exception in thread Thread-1:
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 111, in save_model_to_hdf5
[2m[36m(pid=130912)[0m     f.flush()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 452, in flush
[2m[36m(pid=130912)[0m     h5f.flush(self.id)
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/h5f.pyx", line 146, in h5py.h5f.flush
[2m[36m(pid=130912)[0m RuntimeError: Unable to flush file's cached information (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae6606d50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130912)[0m     self._entrypoint()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130912)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130912)[0m     output = train_func(config, reporter)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130912)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130912)[0m     config=config)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130912)[0m     model.save(model_path, config_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130912)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130912)[0m     self.model.save(model_path)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130912)[0m     signatures)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130912)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130912)[0m     f.close()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130912)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130912)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130912)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:42 2020
[2m[36m(pid=130912)[0m , filename = '/tmp/thalvari/4065561/automl_save_3echuoc5/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ae6606d50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m Traceback (most recent call last):
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130912)[0m     self.run()
[2m[36m(pid=130912)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130912)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130912)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130932)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130932)[0m   agg_primitives: ['count']
[2m[36m(pid=130932)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130932)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130911)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130911)[0m 2020-11-20 11:44:42.568397: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130911)[0m 2020-11-20 11:44:42.577895: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130911)[0m 2020-11-20 11:44:42.581651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfb90ef240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130911)[0m 2020-11-20 11:44:42.581708: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130926)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130926)[0m 2020-11-20 11:44:42.637561: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130926)[0m 2020-11-20 11:44:42.645733: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130926)[0m 2020-11-20 11:44:42.649123: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f04850ef6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130926)[0m 2020-11-20 11:44:42.649165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:44:42,695	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130934, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:42,699	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130934)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130934)[0m 
[2m[36m(pid=130934)[0m Stack (most recent call first):
[2m[36m(pid=130932)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130932)[0m Instructions for updating:
[2m[36m(pid=130932)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130932)[0m LSTM is selected.
[2m[36m(pid=130937)[0m 2020-11-20 11:44:43,299	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130937)[0m Traceback (most recent call last):
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130937)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130937)[0m     param_dset[:] = val
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130937)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130937)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130937)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130937)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:43 2020
[2m[36m(pid=130937)[0m , filename = '/tmp/thalvari/4065561/automl_save_ljdraugw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dde8a2868, total write size = 815224, bytes this sub-write = 815224, bytes actually written = 18446744073709551615, offset = 2945024)
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m Traceback (most recent call last):
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130937)[0m     self._entrypoint()
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130937)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130937)[0m     output = train_func(config, reporter)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130937)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130937)[0m     config=config)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130937)[0m     model.save(model_path, config_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130937)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130937)[0m     self.model.save(model_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130937)[0m     signatures)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130937)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130937)[0m     f.close()
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130937)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130937)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:43 2020
[2m[36m(pid=130937)[0m , filename = '/tmp/thalvari/4065561/automl_save_ljdraugw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dde864440, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130937)[0m Exception in thread Thread-1:
[2m[36m(pid=130937)[0m Traceback (most recent call last):
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130937)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130937)[0m     param_dset[:] = val
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130937)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130937)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130937)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130937)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:43 2020
[2m[36m(pid=130937)[0m , filename = '/tmp/thalvari/4065561/automl_save_ljdraugw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dde8a2868, total write size = 815224, bytes this sub-write = 815224, bytes actually written = 18446744073709551615, offset = 2945024)
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m Traceback (most recent call last):
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130937)[0m     self._entrypoint()
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130937)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130937)[0m     output = train_func(config, reporter)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130937)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130937)[0m     config=config)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130937)[0m     model.save(model_path, config_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130937)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130937)[0m     self.model.save(model_path)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130937)[0m     signatures)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130937)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130937)[0m     f.close()
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130937)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130937)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130937)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:43 2020
[2m[36m(pid=130937)[0m , filename = '/tmp/thalvari/4065561/automl_save_ljdraugw/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2dde864440, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m Traceback (most recent call last):
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130937)[0m     self.run()
[2m[36m(pid=130937)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130937)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130937)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130932)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130932)[0m Instructions for updating:
[2m[36m(pid=130932)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:44:43,734	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130912, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:43,737	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_26_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.685,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130912)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130912)[0m 
[2m[36m(pid=130912)[0m Stack (most recent call first):
[2m[36m(pid=130932)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130932)[0m 2020-11-20 11:44:44.587769: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130932)[0m 2020-11-20 11:44:44.602968: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130932)[0m 2020-11-20 11:44:44.605440: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f286d0ef620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130932)[0m 2020-11-20 11:44:44.605478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:44:44,672	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130937, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:44,677	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130937)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130937)[0m 
[2m[36m(pid=130937)[0m Stack (most recent call first):
2020-11-20 11:44:45,595	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130901, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:45,601	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_39_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130901)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130901)[0m 
[2m[36m(pid=130901)[0m Stack (most recent call first):
[2m[36m(pid=130926)[0m 2020-11-20 11:44:45,945	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130926)[0m Traceback (most recent call last):
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130926)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130926)[0m     param_dset[:] = val
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130926)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130926)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130926)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130926)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:45 2020
[2m[36m(pid=130926)[0m , filename = '/tmp/thalvari/4065561/automl_save_80p2zxfk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0486877568, total write size = 839800, bytes this sub-write = 839800, bytes actually written = 18446744073709551615, offset = 2924544)
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m Traceback (most recent call last):
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130926)[0m     self._entrypoint()
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130926)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130926)[0m     output = train_func(config, reporter)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130926)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130926)[0m     config=config)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130926)[0m     model.save(model_path, config_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130926)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130926)[0m     self.model.save(model_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130926)[0m     signatures)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130926)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130926)[0m     f.close()
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130926)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130926)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:45 2020
[2m[36m(pid=130926)[0m , filename = '/tmp/thalvari/4065561/automl_save_80p2zxfk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f04865cb650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130926)[0m Exception in thread Thread-1:
[2m[36m(pid=130926)[0m Traceback (most recent call last):
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130926)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130926)[0m     param_dset[:] = val
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130926)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130926)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130926)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130926)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:45 2020
[2m[36m(pid=130926)[0m , filename = '/tmp/thalvari/4065561/automl_save_80p2zxfk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0486877568, total write size = 839800, bytes this sub-write = 839800, bytes actually written = 18446744073709551615, offset = 2924544)
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m Traceback (most recent call last):
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130926)[0m     self._entrypoint()
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130926)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130926)[0m     output = train_func(config, reporter)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130926)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130926)[0m     config=config)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130926)[0m     model.save(model_path, config_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130926)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130926)[0m     self.model.save(model_path)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130926)[0m     signatures)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130926)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130926)[0m     f.close()
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130926)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130926)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130926)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:45 2020
[2m[36m(pid=130926)[0m , filename = '/tmp/thalvari/4065561/automl_save_80p2zxfk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f04865cb650, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m Traceback (most recent call last):
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130926)[0m     self.run()
[2m[36m(pid=130926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130926)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130926)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130911)[0m 2020-11-20 11:44:46,103	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130911)[0m Traceback (most recent call last):
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130911)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130911)[0m     param_dset[:] = val
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130911)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130911)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130911)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130911)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:46 2020
[2m[36m(pid=130911)[0m , filename = '/tmp/thalvari/4065561/automl_save_0smdsfjn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfba87ed98, total write size = 839800, bytes this sub-write = 839800, bytes actually written = 18446744073709551615, offset = 2924544)
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m Traceback (most recent call last):
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130911)[0m     self._entrypoint()
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130911)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130911)[0m     output = train_func(config, reporter)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130911)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130911)[0m     config=config)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130911)[0m     model.save(model_path, config_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130911)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130911)[0m     self.model.save(model_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130911)[0m     signatures)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130911)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130911)[0m     f.close()
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130911)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130911)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:46 2020
[2m[36m(pid=130911)[0m , filename = '/tmp/thalvari/4065561/automl_save_0smdsfjn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfba4c9670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130911)[0m Exception in thread Thread-1:
[2m[36m(pid=130911)[0m Traceback (most recent call last):
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130911)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130911)[0m     param_dset[:] = val
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130911)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130911)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130911)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130911)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:46 2020
[2m[36m(pid=130911)[0m , filename = '/tmp/thalvari/4065561/automl_save_0smdsfjn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfba87ed98, total write size = 839800, bytes this sub-write = 839800, bytes actually written = 18446744073709551615, offset = 2924544)
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m Traceback (most recent call last):
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130911)[0m     self._entrypoint()
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130911)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130911)[0m     output = train_func(config, reporter)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130911)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130911)[0m     config=config)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130911)[0m     model.save(model_path, config_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130911)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130911)[0m     self.model.save(model_path)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130911)[0m     signatures)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130911)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130911)[0m     f.close()
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130911)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130911)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130911)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:46 2020
[2m[36m(pid=130911)[0m , filename = '/tmp/thalvari/4065561/automl_save_0smdsfjn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdfba4c9670, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m Traceback (most recent call last):
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130911)[0m     self.run()
[2m[36m(pid=130911)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130911)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130911)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130911)[0m 
2020-11-20 11:44:47,105	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130926, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:47,110	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 48 ({'TERMINATED': 16, 'ERROR': 23, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 17 not shown
 - train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_40_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-32co7rf2wa/error_2020-11-20_11-44-42.txt
 - train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_41_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-34_6gr3kz5/error_2020-11-20_11-44-44.txt
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-378bf0flbh/error_2020-11-20_11-44-47.txt
RUNNING trials:
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130898], 39 s, 4 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130904], 38 s, 4 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=130918], 38 s, 4 iter
  ... 3 not shown
 - train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 10 not shown
 - train_func_20_batch_size_log=7.6229,bayes_feature_DAY(timestamp)=0.62896,bayes_feature_HOUR(timestamp)=0.48147,bayes_feature_IS_AWAKE(timestamp)=0.51346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31633,bayes_feature_IS_WEEKEND(timestamp)=0.71829,bayes_feature_MONTH(timestamp)=0.96882,bayes_feature_WEEKDAY(timestamp)=0.86579,dropout_1=0.47602,dropout_2=0.4388,epochs=5,lr=0.0051644,lstm_1_units_float=96.867,lstm_2_units_float=69.027,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130923], 15 s, 5 iter
 - train_func_24_batch_size_log=5.0,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.2,epochs=5,lr=0.001,lstm_1_units_float=45.035,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130899], 46 s, 5 iter
 - train_func_28_batch_size_log=7.2672,bayes_feature_DAY(timestamp)=0.9954,bayes_feature_HOUR(timestamp)=0.32481,bayes_feature_IS_AWAKE(timestamp)=0.53627,bayes_feature_IS_BUSY_HOURS(timestamp)=0.67619,bayes_feature_IS_WEEKEND(timestamp)=0.61211,bayes_feature_MONTH(timestamp)=0.36325,bayes_feature_WEEKDAY(timestamp)=0.95761,dropout_1=0.44942,dropout_2=0.34712,epochs=5,lr=0.0074688,lstm_1_units_float=108.44,lstm_2_units_float=26.145,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130906], 18 s, 5 iter

[2m[36m(pid=130926)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130926)[0m 
[2m[36m(pid=130926)[0m Stack (most recent call first):
[2m[36m(pid=130932)[0m 2020-11-20 11:44:47,884	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130932)[0m Traceback (most recent call last):
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130932)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130932)[0m     param_dset[:] = val
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130932)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130932)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130932)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130932)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:47 2020
[2m[36m(pid=130932)[0m , filename = '/tmp/thalvari/4065561/automl_save_8gvs3tpu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f286e8a9bc8, total write size = 847992, bytes this sub-write = 847992, bytes actually written = 18446744073709551615, offset = 2916352)
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m Traceback (most recent call last):
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130932)[0m     self._entrypoint()
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130932)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130932)[0m     output = train_func(config, reporter)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130932)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130932)[0m     config=config)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130932)[0m     model.save(model_path, config_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130932)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130932)[0m     self.model.save(model_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130932)[0m     signatures)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130932)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130932)[0m     f.close()
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130932)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130932)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:47 2020
[2m[36m(pid=130932)[0m , filename = '/tmp/thalvari/4065561/automl_save_8gvs3tpu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f286e32cfb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130932)[0m Exception in thread Thread-1:
[2m[36m(pid=130932)[0m Traceback (most recent call last):
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130932)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130932)[0m     param_dset[:] = val
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130932)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130932)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130932)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130932)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:47 2020
[2m[36m(pid=130932)[0m , filename = '/tmp/thalvari/4065561/automl_save_8gvs3tpu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f286e8a9bc8, total write size = 847992, bytes this sub-write = 847992, bytes actually written = 18446744073709551615, offset = 2916352)
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m Traceback (most recent call last):
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130932)[0m     self._entrypoint()
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130932)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130932)[0m     output = train_func(config, reporter)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130932)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130932)[0m     config=config)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130932)[0m     model.save(model_path, config_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130932)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130932)[0m     self.model.save(model_path)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130932)[0m     signatures)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130932)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130932)[0m     f.close()
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130932)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130932)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130932)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:47 2020
[2m[36m(pid=130932)[0m , filename = '/tmp/thalvari/4065561/automl_save_8gvs3tpu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f286e32cfb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m Traceback (most recent call last):
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130932)[0m     self.run()
[2m[36m(pid=130932)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130932)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130932)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130932)[0m 
2020-11-20 11:44:48,033	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130911, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:48,036	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_42_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130935)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130935)[0m   agg_primitives: ['count']
[2m[36m(pid=130935)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130935)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130914)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130914)[0m   agg_primitives: ['count']
[2m[36m(pid=130914)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130914)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130911)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130911)[0m 
[2m[36m(pid=130911)[0m Stack (most recent call first):
[2m[36m(pid=130935)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130935)[0m Instructions for updating:
[2m[36m(pid=130935)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130914)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130914)[0m Instructions for updating:
[2m[36m(pid=130914)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130935)[0m LSTM is selected.
[2m[36m(pid=130914)[0m LSTM is selected.
[2m[36m(pid=130935)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130935)[0m Instructions for updating:
[2m[36m(pid=130935)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130914)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130914)[0m Instructions for updating:
[2m[36m(pid=130914)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130924)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130924)[0m   agg_primitives: ['count']
[2m[36m(pid=130924)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130924)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130924)[0m LSTM is selected.
[2m[36m(pid=130924)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130924)[0m Instructions for updating:
[2m[36m(pid=130924)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130913)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130913)[0m   agg_primitives: ['count']
[2m[36m(pid=130913)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130913)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130935)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130935)[0m 2020-11-20 11:44:50.093954: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130935)[0m 2020-11-20 11:44:50.101664: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130914)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130914)[0m 2020-11-20 11:44:50.104612: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130935)[0m 2020-11-20 11:44:50.131604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eecb10ef900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130935)[0m 2020-11-20 11:44:50.131622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130914)[0m 2020-11-20 11:44:50.128348: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130914)[0m 2020-11-20 11:44:50.130303: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f814d0efa70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130914)[0m 2020-11-20 11:44:50.130319: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130924)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130924)[0m Instructions for updating:
[2m[36m(pid=130924)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130913)[0m LSTM is selected.
[2m[36m(pid=130913)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130913)[0m Instructions for updating:
[2m[36m(pid=130913)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141164)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141205)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141205)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2020-11-20 11:44:50,907	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130932, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:50,910	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130913)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130913)[0m Instructions for updating:
[2m[36m(pid=130913)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130932)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130932)[0m 
[2m[36m(pid=130932)[0m Stack (most recent call first):
[2m[36m(pid=130924)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130924)[0m 2020-11-20 11:44:51.392005: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130924)[0m 2020-11-20 11:44:51.400087: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130924)[0m 2020-11-20 11:44:51.402059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2e2d0ef6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130924)[0m 2020-11-20 11:44:51.402079: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130920)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130920)[0m   agg_primitives: ['count']
[2m[36m(pid=130920)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130920)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141503)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141500)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141503)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141500)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130913)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130913)[0m 2020-11-20 11:44:52.050412: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130913)[0m 2020-11-20 11:44:52.095229: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130913)[0m 2020-11-20 11:44:52.097548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f18c10ef300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130913)[0m 2020-11-20 11:44:52.097569: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130920)[0m LSTM is selected.
[2m[36m(pid=130920)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130920)[0m Instructions for updating:
[2m[36m(pid=130920)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141587)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141587)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130905)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=130905)[0m   agg_primitives: ['count']
[2m[36m(pid=130905)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=130905)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141631)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141632)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130920)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130920)[0m Instructions for updating:
[2m[36m(pid=130920)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141881)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141881)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141887)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141884)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141884)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141887)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141886)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141886)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141885)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=141885)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=130905)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=130905)[0m Instructions for updating:
[2m[36m(pid=130905)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130905)[0m LSTM is selected.
[2m[36m(pid=130914)[0m 2020-11-20 11:44:53,208	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130914)[0m Traceback (most recent call last):
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130914)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130914)[0m     param_dset[:] = val
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130914)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130914)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130914)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130914)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130914)[0m , filename = '/tmp/thalvari/4065561/automl_save_06_pgw62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f814d4d0348, total write size = 188536, bytes this sub-write = 188536, bytes actually written = 18446744073709551615, offset = 1982464)
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m Traceback (most recent call last):
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130914)[0m     self._entrypoint()
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130914)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130914)[0m     output = train_func(config, reporter)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130914)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130914)[0m     config=config)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130914)[0m     model.save(model_path, config_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130914)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130914)[0m     self.model.save(model_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130914)[0m     signatures)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130914)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130914)[0m     f.close()
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130914)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130914)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130914)[0m , filename = '/tmp/thalvari/4065561/automl_save_06_pgw62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f814e0845f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130914)[0m Exception in thread Thread-1:
[2m[36m(pid=130914)[0m Traceback (most recent call last):
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130914)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130914)[0m     param_dset[:] = val
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130914)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130914)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130914)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130914)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130914)[0m , filename = '/tmp/thalvari/4065561/automl_save_06_pgw62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f814d4d0348, total write size = 188536, bytes this sub-write = 188536, bytes actually written = 18446744073709551615, offset = 1982464)
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m Traceback (most recent call last):
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130914)[0m     self._entrypoint()
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130914)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130914)[0m     output = train_func(config, reporter)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130914)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130914)[0m     config=config)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130914)[0m     model.save(model_path, config_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130914)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130914)[0m     self.model.save(model_path)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130914)[0m     signatures)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130914)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130914)[0m     f.close()
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130914)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130914)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130914)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130914)[0m , filename = '/tmp/thalvari/4065561/automl_save_06_pgw62/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f814e0845f0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m Traceback (most recent call last):
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130914)[0m     self.run()
[2m[36m(pid=130914)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130914)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130914)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130935)[0m 2020-11-20 11:44:53,318	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130935)[0m Traceback (most recent call last):
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130935)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130935)[0m     param_dset[:] = val
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130935)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130935)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130935)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130935)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130935)[0m , filename = '/tmp/thalvari/4065561/automl_save_73t11vai/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eecb2a702f8, total write size = 970872, bytes this sub-write = 970872, bytes actually written = 18446744073709551615, offset = 2793472)
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m Traceback (most recent call last):
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130935)[0m     self._entrypoint()
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130935)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130935)[0m     output = train_func(config, reporter)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130935)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130935)[0m     config=config)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130935)[0m     model.save(model_path, config_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130935)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130935)[0m     self.model.save(model_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130935)[0m     signatures)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130935)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130935)[0m     f.close()
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130935)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130935)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130935)[0m , filename = '/tmp/thalvari/4065561/automl_save_73t11vai/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eecb1891240, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130935)[0m Exception in thread Thread-1:
[2m[36m(pid=130935)[0m Traceback (most recent call last):
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130935)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130935)[0m     param_dset[:] = val
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130935)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130935)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130935)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130935)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130935)[0m , filename = '/tmp/thalvari/4065561/automl_save_73t11vai/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eecb2a702f8, total write size = 970872, bytes this sub-write = 970872, bytes actually written = 18446744073709551615, offset = 2793472)
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m Traceback (most recent call last):
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130935)[0m     self._entrypoint()
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130935)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130935)[0m     output = train_func(config, reporter)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130935)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130935)[0m     config=config)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130935)[0m     model.save(model_path, config_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130935)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130935)[0m     self.model.save(model_path)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130935)[0m     signatures)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130935)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130935)[0m     f.close()
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130935)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130935)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130935)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:53 2020
[2m[36m(pid=130935)[0m , filename = '/tmp/thalvari/4065561/automl_save_73t11vai/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eecb1891240, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m Traceback (most recent call last):
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130935)[0m     self.run()
[2m[36m(pid=130935)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130935)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130935)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130905)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=130905)[0m Instructions for updating:
[2m[36m(pid=130905)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:44:54,271	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130914, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:54,274	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 54 ({'TERMINATED': 19, 'ERROR': 26, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 20 not shown
 - train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_43_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-378bf0flbh/error_2020-11-20_11-44-47.txt
 - train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_44_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-38zdywc8c1/error_2020-11-20_11-44-50.txt
 - train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_45_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-43law_1igk/error_2020-11-20_11-44-54.txt
RUNNING trials:
 - train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=9.8345,bayes_feature_DAY(timestamp)=0.31559,bayes_feature_HOUR(timestamp)=0.81405,bayes_feature_IS_AWAKE(timestamp)=0.67453,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79362,bayes_feature_IS_WEEKEND(timestamp)=0.64146,bayes_feature_MONTH(timestamp)=0.45536,bayes_feature_WEEKDAY(timestamp)=0.59415,dropout_1=0.25181,dropout_2=0.31196,epochs=5,lr=0.0027393,lstm_1_units_float=96.699,lstm_2_units_float=68.993,past_seq_len=2:	RUNNING
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 13 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130898], 47 s, 5 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter

[2m[36m(pid=130920)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130920)[0m 2020-11-20 11:44:54.261869: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130920)[0m 2020-11-20 11:44:54.272971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130920)[0m 2020-11-20 11:44:54.275230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f44890ef620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130920)[0m 2020-11-20 11:44:54.275254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130914)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130914)[0m 
[2m[36m(pid=130914)[0m Stack (most recent call first):
2020-11-20 11:44:54,482	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130935, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:54,486	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_46_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130935)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130935)[0m 
[2m[36m(pid=130935)[0m Stack (most recent call first):
[2m[36m(pid=130924)[0m 2020-11-20 11:44:54,720	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130924)[0m Traceback (most recent call last):
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130924)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130924)[0m     param_dset[:] = val
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130924)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130924)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130924)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130924)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:54 2020
[2m[36m(pid=130924)[0m , filename = '/tmp/thalvari/4065561/automl_save_qpc6ei1l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2e2e89a808, total write size = 979064, bytes this sub-write = 979064, bytes actually written = 18446744073709551615, offset = 2785280)
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m Traceback (most recent call last):
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130924)[0m     self._entrypoint()
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130924)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130924)[0m     output = train_func(config, reporter)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130924)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130924)[0m     config=config)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130924)[0m     model.save(model_path, config_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130924)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130924)[0m     self.model.save(model_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130924)[0m     signatures)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130924)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130924)[0m     f.close()
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130924)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130924)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:54 2020
[2m[36m(pid=130924)[0m , filename = '/tmp/thalvari/4065561/automl_save_qpc6ei1l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2e2d96b1a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130924)[0m Exception in thread Thread-1:
[2m[36m(pid=130924)[0m Traceback (most recent call last):
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130924)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130924)[0m     param_dset[:] = val
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130924)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130924)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130924)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130924)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:54 2020
[2m[36m(pid=130924)[0m , filename = '/tmp/thalvari/4065561/automl_save_qpc6ei1l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2e2e89a808, total write size = 979064, bytes this sub-write = 979064, bytes actually written = 18446744073709551615, offset = 2785280)
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m Traceback (most recent call last):
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130924)[0m     self._entrypoint()
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130924)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130924)[0m     output = train_func(config, reporter)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130924)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130924)[0m     config=config)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130924)[0m     model.save(model_path, config_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130924)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130924)[0m     self.model.save(model_path)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130924)[0m     signatures)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130924)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130924)[0m     f.close()
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130924)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130924)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130924)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:54 2020
[2m[36m(pid=130924)[0m , filename = '/tmp/thalvari/4065561/automl_save_qpc6ei1l/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2e2d96b1a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m Traceback (most recent call last):
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130924)[0m     self.run()
[2m[36m(pid=130924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130924)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130924)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130905)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=130905)[0m 2020-11-20 11:44:54.976855: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=130905)[0m 2020-11-20 11:44:54.985658: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=130905)[0m 2020-11-20 11:44:54.987491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb5f90ef400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=130905)[0m 2020-11-20 11:44:54.987514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=130913)[0m 2020-11-20 11:44:55,418	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130913)[0m Traceback (most recent call last):
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130913)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130913)[0m     param_dset[:] = val
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130913)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130913)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130913)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130913)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:55 2020
[2m[36m(pid=130913)[0m , filename = '/tmp/thalvari/4065561/automl_save_02fifg8_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18c284e298, total write size = 987256, bytes this sub-write = 987256, bytes actually written = 18446744073709551615, offset = 2777088)
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m Traceback (most recent call last):
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130913)[0m     self._entrypoint()
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130913)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130913)[0m     output = train_func(config, reporter)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130913)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130913)[0m     config=config)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130913)[0m     model.save(model_path, config_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130913)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130913)[0m     self.model.save(model_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130913)[0m     signatures)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130913)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130913)[0m     f.close()
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130913)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130913)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:55 2020
[2m[36m(pid=130913)[0m , filename = '/tmp/thalvari/4065561/automl_save_02fifg8_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18c2668a70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130913)[0m Exception in thread Thread-1:
[2m[36m(pid=130913)[0m Traceback (most recent call last):
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130913)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130913)[0m     param_dset[:] = val
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130913)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130913)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130913)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130913)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:55 2020
[2m[36m(pid=130913)[0m , filename = '/tmp/thalvari/4065561/automl_save_02fifg8_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18c284e298, total write size = 987256, bytes this sub-write = 987256, bytes actually written = 18446744073709551615, offset = 2777088)
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m Traceback (most recent call last):
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130913)[0m     self._entrypoint()
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130913)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130913)[0m     output = train_func(config, reporter)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130913)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130913)[0m     config=config)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130913)[0m     model.save(model_path, config_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130913)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130913)[0m     self.model.save(model_path)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130913)[0m     signatures)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130913)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130913)[0m     f.close()
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130913)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130913)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130913)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:55 2020
[2m[36m(pid=130913)[0m , filename = '/tmp/thalvari/4065561/automl_save_02fifg8_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f18c2668a70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m Traceback (most recent call last):
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130913)[0m     self.run()
[2m[36m(pid=130913)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130913)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130913)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130913)[0m 
2020-11-20 11:44:55,839	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130924, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:55,843	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_47_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=130924)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130924)[0m 
[2m[36m(pid=130924)[0m Stack (most recent call first):
[2m[36m(pid=141205)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141205)[0m   agg_primitives: ['count']
[2m[36m(pid=141205)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141205)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141164)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141164)[0m   agg_primitives: ['count']
[2m[36m(pid=141164)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141164)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:44:56,561	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130913, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:56,564	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141205)[0m LSTM is selected.
[2m[36m(pid=130913)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130913)[0m 
[2m[36m(pid=130913)[0m Stack (most recent call first):
[2m[36m(pid=141164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141164)[0m Instructions for updating:
[2m[36m(pid=141164)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141164)[0m LSTM is selected.
[2m[36m(pid=141205)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141205)[0m Instructions for updating:
[2m[36m(pid=141205)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141503)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141503)[0m   agg_primitives: ['count']
[2m[36m(pid=141503)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141503)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141500)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141500)[0m   agg_primitives: ['count']
[2m[36m(pid=141500)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141500)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130920)[0m 2020-11-20 11:44:57,309	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130920)[0m Traceback (most recent call last):
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130920)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130920)[0m     param_dset[:] = val
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130920)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130920)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130920)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130920)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130920)[0m , filename = '/tmp/thalvari/4065561/automl_save_4x_zmtbu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f448aa05ce8, total write size = 995448, bytes this sub-write = 995448, bytes actually written = 18446744073709551615, offset = 2768896)
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m Traceback (most recent call last):
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130920)[0m     self._entrypoint()
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130920)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130920)[0m     output = train_func(config, reporter)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130920)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130920)[0m     config=config)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130920)[0m     model.save(model_path, config_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130920)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130920)[0m     self.model.save(model_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130920)[0m     signatures)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130920)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130920)[0m     f.close()
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130920)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130920)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130920)[0m , filename = '/tmp/thalvari/4065561/automl_save_4x_zmtbu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f44893c8010, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130920)[0m Exception in thread Thread-1:
[2m[36m(pid=130920)[0m Traceback (most recent call last):
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130920)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130920)[0m     param_dset[:] = val
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130920)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130920)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130920)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130920)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130920)[0m , filename = '/tmp/thalvari/4065561/automl_save_4x_zmtbu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f448aa05ce8, total write size = 995448, bytes this sub-write = 995448, bytes actually written = 18446744073709551615, offset = 2768896)
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m Traceback (most recent call last):
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130920)[0m     self._entrypoint()
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130920)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130920)[0m     output = train_func(config, reporter)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130920)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130920)[0m     config=config)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130920)[0m     model.save(model_path, config_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130920)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130920)[0m     self.model.save(model_path)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130920)[0m     signatures)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130920)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130920)[0m     f.close()
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130920)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130920)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130920)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130920)[0m , filename = '/tmp/thalvari/4065561/automl_save_4x_zmtbu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f44893c8010, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141164)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141164)[0m Instructions for updating:
[2m[36m(pid=141164)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141205)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141205)[0m Instructions for updating:
[2m[36m(pid=141205)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m Traceback (most recent call last):
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130920)[0m     self.run()
[2m[36m(pid=130920)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130920)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130920)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130920)[0m 
[2m[36m(pid=141500)[0m LSTM is selected.
[2m[36m(pid=141500)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141500)[0m Instructions for updating:
[2m[36m(pid=141500)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141503)[0m LSTM is selected.
[2m[36m(pid=130905)[0m 2020-11-20 11:44:57,651	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=130905)[0m Traceback (most recent call last):
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130905)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130905)[0m     param_dset[:] = val
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130905)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130905)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130905)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130905)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130905)[0m , filename = '/tmp/thalvari/4065561/automl_save_wu2pi986/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5fa86fc08, total write size = 1003640, bytes this sub-write = 1003640, bytes actually written = 18446744073709551615, offset = 2760704)
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m Traceback (most recent call last):
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130905)[0m     self._entrypoint()
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130905)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130905)[0m     output = train_func(config, reporter)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130905)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130905)[0m     config=config)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130905)[0m     model.save(model_path, config_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130905)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130905)[0m     self.model.save(model_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130905)[0m     signatures)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130905)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130905)[0m     f.close()
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130905)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130905)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130905)[0m , filename = '/tmp/thalvari/4065561/automl_save_wu2pi986/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5fa5d2e80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=130905)[0m Exception in thread Thread-1:
[2m[36m(pid=130905)[0m Traceback (most recent call last):
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=130905)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=130905)[0m     param_dset[:] = val
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=130905)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=130905)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=130905)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=130905)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130905)[0m , filename = '/tmp/thalvari/4065561/automl_save_wu2pi986/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5fa86fc08, total write size = 1003640, bytes this sub-write = 1003640, bytes actually written = 18446744073709551615, offset = 2760704)
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m Traceback (most recent call last):
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=130905)[0m     self._entrypoint()
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=130905)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=130905)[0m     output = train_func(config, reporter)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=130905)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=130905)[0m     config=config)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=130905)[0m     model.save(model_path, config_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=130905)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=130905)[0m     self.model.save(model_path)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=130905)[0m     signatures)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=130905)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=130905)[0m     f.close()
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=130905)[0m     h5i.dec_ref(id_)
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=130905)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=130905)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:44:57 2020
[2m[36m(pid=130905)[0m , filename = '/tmp/thalvari/4065561/automl_save_wu2pi986/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb5fa5d2e80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141503)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141503)[0m Instructions for updating:
[2m[36m(pid=141503)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m Traceback (most recent call last):
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=130905)[0m     self.run()
[2m[36m(pid=130905)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=130905)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=130905)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=130905)[0m 
[2m[36m(pid=141886)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141886)[0m   agg_primitives: ['count']
[2m[36m(pid=141886)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141886)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141500)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141500)[0m Instructions for updating:
[2m[36m(pid=141500)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141503)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141503)[0m Instructions for updating:
[2m[36m(pid=141503)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141164)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141164)[0m 2020-11-20 11:44:58.241720: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141164)[0m 2020-11-20 11:44:58.249263: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141164)[0m 2020-11-20 11:44:58.251300: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f66ed0ef530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141164)[0m 2020-11-20 11:44:58.251325: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141205)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141205)[0m 2020-11-20 11:44:58.276422: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141886)[0m LSTM is selected.
[2m[36m(pid=141886)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141886)[0m Instructions for updating:
[2m[36m(pid=141886)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141205)[0m 2020-11-20 11:44:58.283844: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141205)[0m 2020-11-20 11:44:58.285561: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef4550ef300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141205)[0m 2020-11-20 11:44:58.285580: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:44:58,357	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130920, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:58,360	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141881)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141881)[0m   agg_primitives: ['count']
[2m[36m(pid=141881)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141881)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=130920)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130920)[0m 
[2m[36m(pid=130920)[0m Stack (most recent call first):
2020-11-20 11:44:58,795	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=130905, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:44:58,798	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141886)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141886)[0m Instructions for updating:
[2m[36m(pid=141886)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=130905)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=130905)[0m 
[2m[36m(pid=130905)[0m Stack (most recent call first):
[2m[36m(pid=141881)[0m LSTM is selected.
[2m[36m(pid=141881)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141881)[0m Instructions for updating:
[2m[36m(pid=141881)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141500)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141500)[0m 2020-11-20 11:44:59.097044: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141500)[0m 2020-11-20 11:44:59.104521: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141500)[0m 2020-11-20 11:44:59.106600: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eed490d4900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141500)[0m 2020-11-20 11:44:59.106625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141503)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141503)[0m 2020-11-20 11:44:59.182837: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141503)[0m 2020-11-20 11:44:59.190578: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141503)[0m 2020-11-20 11:44:59.192600: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f78450efee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141503)[0m 2020-11-20 11:44:59.192620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141887)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141887)[0m   agg_primitives: ['count']
[2m[36m(pid=141887)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141887)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141885)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141885)[0m   agg_primitives: ['count']
[2m[36m(pid=141885)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141885)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141881)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141881)[0m Instructions for updating:
[2m[36m(pid=141881)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 60 ({'TERMINATED': 19, 'ERROR': 31, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 25 not shown
 - train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_48_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-461igp5kw0/error_2020-11-20_11-44-56.txt
 - train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_49_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-484a0d0jjz/error_2020-11-20_11-44-58.txt
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-486941nz4p/error_2020-11-20_11-44-58.txt
RUNNING trials:
 - train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_53_batch_size_log=9.8345,bayes_feature_DAY(timestamp)=0.31559,bayes_feature_HOUR(timestamp)=0.81405,bayes_feature_IS_AWAKE(timestamp)=0.67453,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79362,bayes_feature_IS_WEEKEND(timestamp)=0.64146,bayes_feature_MONTH(timestamp)=0.45536,bayes_feature_WEEKDAY(timestamp)=0.59415,dropout_1=0.25181,dropout_2=0.31196,epochs=5,lr=0.0027393,lstm_1_units_float=96.699,lstm_2_units_float=68.993,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AWAKE(timestamp)=0.70444,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96688,bayes_feature_IS_WEEKEND(timestamp)=0.52891,bayes_feature_MONTH(timestamp)=0.681,bayes_feature_WEEKDAY(timestamp)=0.73349,dropout_1=0.43057,dropout_2=0.47671,epochs=5,lr=0.0011025,lstm_1_units_float=97.924,lstm_2_units_float=66.817,past_seq_len=2:	RUNNING
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	RUNNING
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 13 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130898], 47 s, 5 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter

[2m[36m(pid=141886)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141886)[0m 2020-11-20 11:44:59.914802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141886)[0m 2020-11-20 11:44:59.924469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141886)[0m 2020-11-20 11:44:59.927808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f549111ca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141886)[0m 2020-11-20 11:44:59.927842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141887)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141887)[0m Instructions for updating:
[2m[36m(pid=141887)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141887)[0m LSTM is selected.
[2m[36m(pid=141885)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141885)[0m Instructions for updating:
[2m[36m(pid=141885)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141885)[0m LSTM is selected.
[2m[36m(pid=141887)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141887)[0m Instructions for updating:
[2m[36m(pid=141887)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141885)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141885)[0m Instructions for updating:
[2m[36m(pid=141885)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141881)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141881)[0m 2020-11-20 11:45:00.589009: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141881)[0m 2020-11-20 11:45:00.612277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141881)[0m 2020-11-20 11:45:00.614655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9329101c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141881)[0m 2020-11-20 11:45:00.614680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141205)[0m 2020-11-20 11:45:00,986	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141205)[0m Traceback (most recent call last):
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=141205)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=141205)[0m     param_dset[:] = val
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141205)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141205)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141205)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141205)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:00 2020
[2m[36m(pid=141205)[0m , filename = '/tmp/thalvari/4065561/automl_save_5v7mpc2h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef45686b2f8, total write size = 1013848, bytes this sub-write = 1013848, bytes actually written = 18446744073709551615, offset = 864256)
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m Traceback (most recent call last):
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141205)[0m     self._entrypoint()
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141205)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141205)[0m     output = train_func(config, reporter)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141205)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141205)[0m     config=config)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141205)[0m     model.save(model_path, config_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141205)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141205)[0m     self.model.save(model_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141205)[0m     signatures)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141205)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141205)[0m     f.close()
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141205)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141205)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:00 2020
[2m[36m(pid=141205)[0m , filename = '/tmp/thalvari/4065561/automl_save_5v7mpc2h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef45543fc40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141205)[0m Exception in thread Thread-1:
[2m[36m(pid=141205)[0m Traceback (most recent call last):
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=141205)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=141205)[0m     param_dset[:] = val
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141205)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141205)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141205)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141205)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:00 2020
[2m[36m(pid=141205)[0m , filename = '/tmp/thalvari/4065561/automl_save_5v7mpc2h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef45686b2f8, total write size = 1013848, bytes this sub-write = 1013848, bytes actually written = 18446744073709551615, offset = 864256)
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m Traceback (most recent call last):
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141205)[0m     self._entrypoint()
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141205)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141205)[0m     output = train_func(config, reporter)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141205)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141205)[0m     config=config)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141205)[0m     model.save(model_path, config_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141205)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141205)[0m     self.model.save(model_path)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141205)[0m     signatures)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141205)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141205)[0m     f.close()
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141205)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141205)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141205)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:00 2020
[2m[36m(pid=141205)[0m , filename = '/tmp/thalvari/4065561/automl_save_5v7mpc2h/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef45543fc40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m Traceback (most recent call last):
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141205)[0m     self.run()
[2m[36m(pid=141205)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141205)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141205)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141164)[0m 2020-11-20 11:45:01,004	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141164)[0m Traceback (most recent call last):
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141164)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141164)[0m     param_dset[:] = val
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141164)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:01 2020
[2m[36m(pid=141164)[0m , filename = '/tmp/thalvari/4065561/automl_save_n4gjyyba/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66eea05de8, total write size = 1020024, bytes this sub-write = 1020024, bytes actually written = 18446744073709551615, offset = 2744320)
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m Traceback (most recent call last):
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141164)[0m     self._entrypoint()
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141164)[0m     output = train_func(config, reporter)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141164)[0m     config=config)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141164)[0m     model.save(model_path, config_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141164)[0m     self.model.save(model_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141164)[0m     signatures)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141164)[0m     f.close()
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141164)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:01 2020
[2m[36m(pid=141164)[0m , filename = '/tmp/thalvari/4065561/automl_save_n4gjyyba/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66ed7302b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141164)[0m Exception in thread Thread-1:
[2m[36m(pid=141164)[0m Traceback (most recent call last):
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141164)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141164)[0m     param_dset[:] = val
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141164)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141164)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141164)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141164)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:01 2020
[2m[36m(pid=141164)[0m , filename = '/tmp/thalvari/4065561/automl_save_n4gjyyba/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66eea05de8, total write size = 1020024, bytes this sub-write = 1020024, bytes actually written = 18446744073709551615, offset = 2744320)
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m Traceback (most recent call last):
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141164)[0m     self._entrypoint()
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141164)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141164)[0m     output = train_func(config, reporter)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141164)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141164)[0m     config=config)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141164)[0m     model.save(model_path, config_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141164)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141164)[0m     self.model.save(model_path)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141164)[0m     signatures)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141164)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141164)[0m     f.close()
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141164)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141164)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141164)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:01 2020
[2m[36m(pid=141164)[0m , filename = '/tmp/thalvari/4065561/automl_save_n4gjyyba/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f66ed7302b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m Traceback (most recent call last):
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141164)[0m     self.run()
[2m[36m(pid=141164)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141164)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141164)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141887)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141887)[0m 2020-11-20 11:45:01.583159: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141887)[0m 2020-11-20 11:45:01.592699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141887)[0m 2020-11-20 11:45:01.595331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9995107300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141887)[0m 2020-11-20 11:45:01.595374: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141885)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141885)[0m 2020-11-20 11:45:01.602578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141885)[0m 2020-11-20 11:45:01.610568: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141885)[0m 2020-11-20 11:45:01.612586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9131101fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141885)[0m 2020-11-20 11:45:01.612617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:45:02,070	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141205, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:02,074	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141205)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141205)[0m 
[2m[36m(pid=141205)[0m Stack (most recent call first):
[2m[36m(pid=141884)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141884)[0m   agg_primitives: ['count']
[2m[36m(pid=141884)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141884)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:45:02,742	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141164, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:02,746	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141884)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141884)[0m Instructions for updating:
[2m[36m(pid=141884)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141884)[0m LSTM is selected.
[2m[36m(pid=141164)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141164)[0m 
[2m[36m(pid=141164)[0m Stack (most recent call first):
[2m[36m(pid=141632)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141632)[0m   agg_primitives: ['count']
[2m[36m(pid=141632)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141632)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141884)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141884)[0m Instructions for updating:
[2m[36m(pid=141884)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141632)[0m LSTM is selected.
[2m[36m(pid=141632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141632)[0m Instructions for updating:
[2m[36m(pid=141632)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141632)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141632)[0m Instructions for updating:
[2m[36m(pid=141632)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141884)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141884)[0m 2020-11-20 11:45:04.479091: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141884)[0m 2020-11-20 11:45:04.491784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141884)[0m 2020-11-20 11:45:04.498774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5d51049c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141884)[0m 2020-11-20 11:45:04.498870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 62 ({'TERMINATED': 19, 'ERROR': 33, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 27 not shown
 - train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_50_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-486941nz4p/error_2020-11-20_11-44-58.txt
 - train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_51_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-49u4f578qi/error_2020-11-20_11-45-02.txt
 - train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_52_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-505a3_ziu5/error_2020-11-20_11-45-02.txt
RUNNING trials:
 - train_func_53_batch_size_log=9.8345,bayes_feature_DAY(timestamp)=0.31559,bayes_feature_HOUR(timestamp)=0.81405,bayes_feature_IS_AWAKE(timestamp)=0.67453,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79362,bayes_feature_IS_WEEKEND(timestamp)=0.64146,bayes_feature_MONTH(timestamp)=0.45536,bayes_feature_WEEKDAY(timestamp)=0.59415,dropout_1=0.25181,dropout_2=0.31196,epochs=5,lr=0.0027393,lstm_1_units_float=96.699,lstm_2_units_float=68.993,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141503], 7 s, 3 iter
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING
 - train_func_55_batch_size_log=8.1238,bayes_feature_DAY(timestamp)=0.80011,bayes_feature_HOUR(timestamp)=0.65552,bayes_feature_IS_AWAKE(timestamp)=0.5123,bayes_feature_IS_BUSY_HOURS(timestamp)=0.81212,bayes_feature_IS_WEEKEND(timestamp)=0.91564,bayes_feature_MONTH(timestamp)=0.74329,bayes_feature_WEEKDAY(timestamp)=0.72329,dropout_1=0.32974,dropout_2=0.33492,epochs=5,lr=0.0033309,lstm_1_units_float=27.322,lstm_2_units_float=53.967,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141886], 7 s, 2 iter
  ... 4 not shown
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWAKE(timestamp)=0.45868,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73227,bayes_feature_IS_WEEKEND(timestamp)=0.34628,bayes_feature_MONTH(timestamp)=0.91535,bayes_feature_WEEKDAY(timestamp)=0.51754,dropout_1=0.30008,dropout_2=0.45771,epochs=5,lr=0.0015535,lstm_1_units_float=8.788,lstm_2_units_float=126.38,past_seq_len=2:	RUNNING
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 13 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130898], 47 s, 5 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter

[2m[36m(pid=141632)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141632)[0m 2020-11-20 11:45:05.237672: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141632)[0m 2020-11-20 11:45:05.250451: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141632)[0m 2020-11-20 11:45:05.254517: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ef7b10ef220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141632)[0m 2020-11-20 11:45:05.254568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141886)[0m Traceback (most recent call last):
[2m[36m(pid=141886)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=141886)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141886)[0m , filename = '/tmp/thalvari/4065561/automl_save_t8cpxwyp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5491799748, total write size = 22896, bytes this sub-write = 22896, bytes actually written = 18446744073709551615, offset = 31592)
[2m[36m(pid=141886)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=141886)[0m Traceback (most recent call last):
[2m[36m(pid=141886)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=141886)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141886)[0m , filename = '/tmp/thalvari/4065561/automl_save_t8cpxwyp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5491799748, total write size = 22896, bytes this sub-write = 22896, bytes actually written = 18446744073709551615, offset = 31592)
[2m[36m(pid=141886)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141886)[0m 
[2m[36m(pid=141886)[0m Stack (most recent call first):
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 439 in close
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114 in save_model_to_hdf5
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109 in save_model
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171 in save
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163 in save
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122 in save
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120 in save
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135 in save_zip
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340 in train_func
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262 in _trainable_func
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143 in entrypoint
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92 in run
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916 in _bootstrap_inner
[2m[36m(pid=141886)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 884 in _bootstrap
[2m[36m(pid=141885)[0m 2020-11-20 11:45:06,311	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141885)[0m Traceback (most recent call last):
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141885)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141885)[0m     param_dset[:] = val
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141885)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141885)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141885)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141885)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141885)[0m , filename = '/tmp/thalvari/4065561/automl_save_wa2had9t/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9132b13e78, total write size = 178312, bytes this sub-write = 178312, bytes actually written = 18446744073709551615, offset = 2469888)
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m Traceback (most recent call last):
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141885)[0m     self._entrypoint()
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141885)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141885)[0m     output = train_func(config, reporter)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141885)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141885)[0m     config=config)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141885)[0m     model.save(model_path, config_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141885)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141885)[0m     self.model.save(model_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141885)[0m     signatures)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141885)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141885)[0m     f.close()
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141885)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141885)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141885)[0m , filename = '/tmp/thalvari/4065561/automl_save_wa2had9t/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f913167c6a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141885)[0m Exception in thread Thread-1:
[2m[36m(pid=141885)[0m Traceback (most recent call last):
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141885)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141885)[0m     param_dset[:] = val
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141885)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141885)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141885)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141885)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141885)[0m , filename = '/tmp/thalvari/4065561/automl_save_wa2had9t/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9132b13e78, total write size = 178312, bytes this sub-write = 178312, bytes actually written = 18446744073709551615, offset = 2469888)
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m Traceback (most recent call last):
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141885)[0m     self._entrypoint()
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141885)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141885)[0m     output = train_func(config, reporter)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141885)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141885)[0m     config=config)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141885)[0m     model.save(model_path, config_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141885)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141885)[0m     self.model.save(model_path)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141885)[0m     signatures)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141885)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141885)[0m     f.close()
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141885)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141885)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141885)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141885)[0m , filename = '/tmp/thalvari/4065561/automl_save_wa2had9t/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f913167c6a0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m Traceback (most recent call last):
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141885)[0m     self.run()
[2m[36m(pid=141885)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141885)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141885)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141885)[0m 
2020-11-20 11:45:06,391	ERROR worker.py:1672 -- A worker died or was killed while executing task e1338ffe21429b79fa64522adffc7f01.
2020-11-20 11:45:06,392	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2020-11-20 11:45:06,395	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_55_batch_size_log=8.1238,bayes_feature_DAY(timestamp)=0.80011,bayes_feature_HOUR(timestamp)=0.65552,bayes_feature_IS_AWAKE(timestamp)=0.5123,bayes_feature_IS_BUSY_HOURS(timestamp)=0.81212,bayes_feature_IS_WEEKEND(timestamp)=0.91564,bayes_feature_MONTH(timestamp)=0.74329,bayes_feature_WEEKDAY(timestamp)=0.72329,dropout_1=0.32974,dropout_2=0.33492,epochs=5,lr=0.0033309,lstm_1_units_float=27.322,lstm_2_units_float=53.967,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141503)[0m 2020-11-20 11:45:06,578	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141503)[0m Traceback (most recent call last):
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141503)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141503)[0m     param_dset[:] = val
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141503)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141503)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141503)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141503)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141503)[0m , filename = '/tmp/thalvari/4065561/automl_save_99cd0_bi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78467e92c8, total write size = 210040, bytes this sub-write = 210040, bytes actually written = 18446744073709551615, offset = 1634304)
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m Traceback (most recent call last):
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141503)[0m     self._entrypoint()
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141503)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141503)[0m     output = train_func(config, reporter)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141503)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141503)[0m     config=config)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141503)[0m     model.save(model_path, config_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141503)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141503)[0m     self.model.save(model_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141503)[0m     signatures)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141503)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141503)[0m     f.close()
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141503)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141503)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141503)[0m , filename = '/tmp/thalvari/4065561/automl_save_99cd0_bi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78462252d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141503)[0m Exception in thread Thread-1:
[2m[36m(pid=141503)[0m Traceback (most recent call last):
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141503)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141503)[0m     param_dset[:] = val
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141503)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141503)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141503)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141503)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141503)[0m , filename = '/tmp/thalvari/4065561/automl_save_99cd0_bi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78467e92c8, total write size = 210040, bytes this sub-write = 210040, bytes actually written = 18446744073709551615, offset = 1634304)
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m Traceback (most recent call last):
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141503)[0m     self._entrypoint()
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141503)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141503)[0m     output = train_func(config, reporter)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141503)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141503)[0m     config=config)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141503)[0m     model.save(model_path, config_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141503)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141503)[0m     self.model.save(model_path)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141503)[0m     signatures)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141503)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141503)[0m     f.close()
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141503)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141503)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141503)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:06 2020
[2m[36m(pid=141503)[0m , filename = '/tmp/thalvari/4065561/automl_save_99cd0_bi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f78462252d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m Traceback (most recent call last):
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141503)[0m     self.run()
[2m[36m(pid=141503)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141503)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141503)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141631)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141631)[0m   agg_primitives: ['count']
[2m[36m(pid=141631)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141631)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141634)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141634)[0m   agg_primitives: ['count']
[2m[36m(pid=141634)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141634)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141887)[0m 2020-11-20 11:45:07,308	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141887)[0m Traceback (most recent call last):
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141887)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141887)[0m     param_dset[:] = val
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141887)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141887)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141887)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141887)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:07 2020
[2m[36m(pid=141887)[0m , filename = '/tmp/thalvari/4065561/automl_save_kf0glhp3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f999624e1c8, total write size = 177976, bytes this sub-write = 177976, bytes actually written = 18446744073709551615, offset = 1630208)
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m Traceback (most recent call last):
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141887)[0m     self._entrypoint()
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141887)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141887)[0m     output = train_func(config, reporter)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141887)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141887)[0m     config=config)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141887)[0m     model.save(model_path, config_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141887)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141887)[0m     self.model.save(model_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141887)[0m     signatures)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141887)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141887)[0m     f.close()
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141887)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141887)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:07 2020
[2m[36m(pid=141887)[0m , filename = '/tmp/thalvari/4065561/automl_save_kf0glhp3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9995451920, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141887)[0m Exception in thread Thread-1:
[2m[36m(pid=141887)[0m Traceback (most recent call last):
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141887)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141887)[0m     param_dset[:] = val
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141887)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141887)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141887)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141887)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:07 2020
[2m[36m(pid=141887)[0m , filename = '/tmp/thalvari/4065561/automl_save_kf0glhp3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f999624e1c8, total write size = 177976, bytes this sub-write = 177976, bytes actually written = 18446744073709551615, offset = 1630208)
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m Traceback (most recent call last):
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141887)[0m     self._entrypoint()
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141887)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141887)[0m     output = train_func(config, reporter)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141887)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141887)[0m     config=config)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141887)[0m     model.save(model_path, config_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141887)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141887)[0m     self.model.save(model_path)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141887)[0m     signatures)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141887)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141887)[0m     f.close()
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141887)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141887)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141887)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:07 2020
[2m[36m(pid=141887)[0m , filename = '/tmp/thalvari/4065561/automl_save_kf0glhp3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f9995451920, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m Traceback (most recent call last):
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141887)[0m     self.run()
[2m[36m(pid=141887)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141887)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141887)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141887)[0m 
2020-11-20 11:45:07,380	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141885, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:07,384	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_57_batch_size_log=7.139,bayes_feature_DAY(timestamp)=0.80168,bayes_feature_HOUR(timestamp)=0.72053,bayes_feature_IS_AWAKE(timestamp)=0.41515,bayes_feature_IS_BUSY_HOURS(timestamp)=0.88519,bayes_feature_IS_WEEKEND(timestamp)=0.98464,bayes_feature_MONTH(timestamp)=0.55433,bayes_feature_WEEKDAY(timestamp)=0.50945,dropout_1=0.42965,dropout_2=0.21416,epochs=5,lr=0.0035407,lstm_1_units_float=8.8542,lstm_2_units_float=125.95,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141631)[0m Instructions for updating:
[2m[36m(pid=141631)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141631)[0m LSTM is selected.
[2m[36m(pid=141634)[0m LSTM is selected.
[2m[36m(pid=141634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141634)[0m Instructions for updating:
[2m[36m(pid=141634)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141885)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141885)[0m 
[2m[36m(pid=141885)[0m Stack (most recent call first):
2020-11-20 11:45:07,687	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141503, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:07,695	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_53_batch_size_log=9.8345,bayes_feature_DAY(timestamp)=0.31559,bayes_feature_HOUR(timestamp)=0.81405,bayes_feature_IS_AWAKE(timestamp)=0.67453,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79362,bayes_feature_IS_WEEKEND(timestamp)=0.64146,bayes_feature_MONTH(timestamp)=0.45536,bayes_feature_WEEKDAY(timestamp)=0.59415,dropout_1=0.25181,dropout_2=0.31196,epochs=5,lr=0.0027393,lstm_1_units_float=96.699,lstm_2_units_float=68.993,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=141503)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141503)[0m 
[2m[36m(pid=141503)[0m Stack (most recent call first):
[2m[36m(pid=141631)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141631)[0m Instructions for updating:
[2m[36m(pid=141631)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141634)[0m Instructions for updating:
[2m[36m(pid=141634)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141632)[0m 2020-11-20 11:45:08,489	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141632)[0m Traceback (most recent call last):
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=141632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=141632)[0m     param_dset[:] = val
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141632)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141632)[0m , filename = '/tmp/thalvari/4065561/automl_save__j2ygm5k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef7b283f4e8, total write size = 268376, bytes this sub-write = 268376, bytes actually written = 18446744073709551615, offset = 1609728)
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m Traceback (most recent call last):
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141632)[0m     self._entrypoint()
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141632)[0m     output = train_func(config, reporter)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141632)[0m     config=config)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141632)[0m     model.save(model_path, config_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141632)[0m     self.model.save(model_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141632)[0m     signatures)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141632)[0m     f.close()
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141632)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141632)[0m , filename = '/tmp/thalvari/4065561/automl_save__j2ygm5k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef7b24f7f90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141632)[0m Exception in thread Thread-1:
[2m[36m(pid=141632)[0m Traceback (most recent call last):
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=141632)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=141632)[0m     param_dset[:] = val
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141632)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141632)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141632)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141632)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141632)[0m , filename = '/tmp/thalvari/4065561/automl_save__j2ygm5k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef7b283f4e8, total write size = 268376, bytes this sub-write = 268376, bytes actually written = 18446744073709551615, offset = 1609728)
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m Traceback (most recent call last):
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141632)[0m     self._entrypoint()
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141632)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141632)[0m     output = train_func(config, reporter)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141632)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141632)[0m     config=config)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141632)[0m     model.save(model_path, config_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141632)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141632)[0m     self.model.save(model_path)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141632)[0m     signatures)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141632)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141632)[0m     f.close()
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141632)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141632)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141632)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141632)[0m , filename = '/tmp/thalvari/4065561/automl_save__j2ygm5k/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7ef7b24f7f90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m Traceback (most recent call last):
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141632)[0m     self.run()
[2m[36m(pid=141632)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141632)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141632)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141632)[0m 
[2m[36m(pid=144547)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144545)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144544)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144546)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144547)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144545)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144544)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144546)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141881)[0m 2020-11-20 11:45:08,892	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141881)[0m Traceback (most recent call last):
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141881)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141881)[0m     param_dset[:] = val
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141881)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141881)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141881)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141881)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141881)[0m , filename = '/tmp/thalvari/4065561/automl_save_yhdno2bp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f932a3b2018, total write size = 62152, bytes this sub-write = 62152, bytes actually written = 18446744073709551615, offset = 1581056)
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m Traceback (most recent call last):
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141881)[0m     self._entrypoint()
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141881)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141881)[0m     output = train_func(config, reporter)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141881)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141881)[0m     config=config)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141881)[0m     model.save(model_path, config_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141881)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141881)[0m     self.model.save(model_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141881)[0m     signatures)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141881)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141881)[0m     f.close()
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141881)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141881)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141881)[0m , filename = '/tmp/thalvari/4065561/automl_save_yhdno2bp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f93293e8f20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141881)[0m Exception in thread Thread-1:
[2m[36m(pid=141881)[0m Traceback (most recent call last):
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141881)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141881)[0m     param_dset[:] = val
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141881)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141881)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141881)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141881)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141881)[0m , filename = '/tmp/thalvari/4065561/automl_save_yhdno2bp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f932a3b2018, total write size = 62152, bytes this sub-write = 62152, bytes actually written = 18446744073709551615, offset = 1581056)
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m Traceback (most recent call last):
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141881)[0m     self._entrypoint()
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141881)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141881)[0m     output = train_func(config, reporter)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141881)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141881)[0m     config=config)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141881)[0m     model.save(model_path, config_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141881)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141881)[0m     self.model.save(model_path)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141881)[0m     signatures)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141881)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141881)[0m     f.close()
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141881)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141881)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141881)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:08 2020
[2m[36m(pid=141881)[0m , filename = '/tmp/thalvari/4065561/automl_save_yhdno2bp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f93293e8f20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m Traceback (most recent call last):
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141881)[0m     self.run()
[2m[36m(pid=141881)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141881)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141881)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141631)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141631)[0m 2020-11-20 11:45:09.217110: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141631)[0m 2020-11-20 11:45:09.225108: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141631)[0m 2020-11-20 11:45:09.227308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb390e9a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141631)[0m 2020-11-20 11:45:09.227337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141634)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141634)[0m 2020-11-20 11:45:09.273275: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141634)[0m 2020-11-20 11:45:09.280941: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141634)[0m 2020-11-20 11:45:09.283027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8add0d1530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141634)[0m 2020-11-20 11:45:09.283047: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144708)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144708)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2020-11-20 11:45:09,394	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141887, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:09,398	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AWAKE(timestamp)=0.70444,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96688,bayes_feature_IS_WEEKEND(timestamp)=0.52891,bayes_feature_MONTH(timestamp)=0.681,bayes_feature_WEEKDAY(timestamp)=0.73349,dropout_1=0.43057,dropout_2=0.47671,epochs=5,lr=0.0011025,lstm_1_units_float=97.924,lstm_2_units_float=66.817,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144758)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144749)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144749)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144755)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144758)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144755)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141887)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141887)[0m 
[2m[36m(pid=141887)[0m Stack (most recent call first):
2020-11-20 11:45:09,623	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141632, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:09,628	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144759)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=144759)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=141632)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141632)[0m 
[2m[36m(pid=141632)[0m Stack (most recent call first):
2020-11-20 11:45:10,139	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141881, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:10,141	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_56_batch_size_log=6.5851,bayes_feature_DAY(timestamp)=0.9078,bayes_feature_HOUR(timestamp)=0.68562,bayes_feature_IS_AWAKE(timestamp)=0.3669,bayes_feature_IS_BUSY_HOURS(timestamp)=0.78049,bayes_feature_IS_WEEKEND(timestamp)=0.82635,bayes_feature_MONTH(timestamp)=0.92529,bayes_feature_WEEKDAY(timestamp)=0.52791,dropout_1=0.37726,dropout_2=0.37791,epochs=5,lr=0.0070288,lstm_1_units_float=8.5013,lstm_2_units_float=127.4,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 67 ({'TERMINATED': 19, 'ERROR': 39, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 33 not shown
 - train_func_57_batch_size_log=7.139,bayes_feature_DAY(timestamp)=0.80168,bayes_feature_HOUR(timestamp)=0.72053,bayes_feature_IS_AWAKE(timestamp)=0.41515,bayes_feature_IS_BUSY_HOURS(timestamp)=0.88519,bayes_feature_IS_WEEKEND(timestamp)=0.98464,bayes_feature_MONTH(timestamp)=0.55433,bayes_feature_WEEKDAY(timestamp)=0.50945,dropout_1=0.42965,dropout_2=0.21416,epochs=5,lr=0.0035407,lstm_1_units_float=8.8542,lstm_2_units_float=125.95,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_57_batch_size_log=7.139,bayes_feature_DAY(timestamp)=0.80168,bayes_feature_HOUR(timestamp)=0.72053,bayes_feature_IS_AWA_2020-11-20_11-44-56uybfqa0n/error_2020-11-20_11-45-07.txt
 - train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AWAKE(timestamp)=0.70444,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96688,bayes_feature_IS_WEEKEND(timestamp)=0.52891,bayes_feature_MONTH(timestamp)=0.681,bayes_feature_WEEKDAY(timestamp)=0.73349,dropout_1=0.43057,dropout_2=0.47671,epochs=5,lr=0.0011025,lstm_1_units_float=97.924,lstm_2_units_float=66.817,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AW_2020-11-20_11-44-56fy42y86b/error_2020-11-20_11-45-09.txt, [4 CPUs, 0 GPUs], [pid=141887], 6 s, 1 iter
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-59b5uco_7m/error_2020-11-20_11-45-09.txt
RUNNING trials:
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141500], 9 s, 1 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141884], 6 s, 1 iter
 - train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWAKE(timestamp)=0.45868,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73227,bayes_feature_IS_WEEKEND(timestamp)=0.34628,bayes_feature_MONTH(timestamp)=0.91535,bayes_feature_WEEKDAY(timestamp)=0.51754,dropout_1=0.30008,dropout_2=0.45771,epochs=5,lr=0.0015535,lstm_1_units_float=8.788,lstm_2_units_float=126.38,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_65_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_66_batch_size_log=7.8048,bayes_feature_DAY(timestamp)=0.49107,bayes_feature_HOUR(timestamp)=0.64696,bayes_feature_IS_AWAKE(timestamp)=0.57638,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37166,bayes_feature_IS_WEEKEND(timestamp)=0.99988,bayes_feature_MONTH(timestamp)=0.32452,bayes_feature_WEEKDAY(timestamp)=0.93091,dropout_1=0.44372,dropout_2=0.40918,epochs=5,lr=0.0079159,lstm_1_units_float=98.173,lstm_2_units_float=67.126,past_seq_len=2:	RUNNING
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 13 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130898], 47 s, 5 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter

[2m[36m(pid=141881)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141881)[0m 
[2m[36m(pid=141881)[0m Stack (most recent call first):
[2m[36m(pid=141587)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=141587)[0m   agg_primitives: ['count']
[2m[36m(pid=141587)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=141587)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141587)[0m LSTM is selected.
[2m[36m(pid=141587)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=141587)[0m Instructions for updating:
[2m[36m(pid=141587)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=141587)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=141587)[0m Instructions for updating:
[2m[36m(pid=141587)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=141587)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=141587)[0m 2020-11-20 11:45:12.839866: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=141587)[0m 2020-11-20 11:45:12.848891: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=141587)[0m 2020-11-20 11:45:12.851748: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7d0111cc40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=141587)[0m 2020-11-20 11:45:12.851796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141631)[0m 2020-11-20 11:45:13,364	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141631)[0m Traceback (most recent call last):
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141631)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141631)[0m     param_dset[:] = val
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141631)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:13 2020
[2m[36m(pid=141631)[0m , filename = '/tmp/thalvari/4065561/automl_save_rnlg97b0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbb394bd2f8, total write size = 98792, bytes this sub-write = 98792, bytes actually written = 18446744073709551615, offset = 1527808)
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m Traceback (most recent call last):
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141631)[0m     self._entrypoint()
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141631)[0m     output = train_func(config, reporter)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141631)[0m     config=config)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141631)[0m     model.save(model_path, config_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141631)[0m     self.model.save(model_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141631)[0m     signatures)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141631)[0m     f.close()
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141631)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:13 2020
[2m[36m(pid=141631)[0m , filename = '/tmp/thalvari/4065561/automl_save_rnlg97b0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbb3a870610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141631)[0m Exception in thread Thread-1:
[2m[36m(pid=141631)[0m Traceback (most recent call last):
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141631)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141631)[0m     param_dset[:] = val
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141631)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141631)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141631)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141631)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:13 2020
[2m[36m(pid=141631)[0m , filename = '/tmp/thalvari/4065561/automl_save_rnlg97b0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbb394bd2f8, total write size = 98792, bytes this sub-write = 98792, bytes actually written = 18446744073709551615, offset = 1527808)
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m Traceback (most recent call last):
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141631)[0m     self._entrypoint()
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141631)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141631)[0m     output = train_func(config, reporter)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141631)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141631)[0m     config=config)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141631)[0m     model.save(model_path, config_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141631)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141631)[0m     self.model.save(model_path)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141631)[0m     signatures)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141631)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141631)[0m     f.close()
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141631)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141631)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141631)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:13 2020
[2m[36m(pid=141631)[0m , filename = '/tmp/thalvari/4065561/automl_save_rnlg97b0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fbb3a870610, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m Traceback (most recent call last):
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141631)[0m     self.run()
[2m[36m(pid=141631)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141631)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141631)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141631)[0m 
[2m[36m(pid=144545)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144545)[0m   agg_primitives: ['count']
[2m[36m(pid=144545)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144545)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144708)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144708)[0m   agg_primitives: ['count']
[2m[36m(pid=144708)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144708)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144758)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144758)[0m   agg_primitives: ['count']
[2m[36m(pid=144758)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144758)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144759)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144759)[0m   agg_primitives: ['count']
[2m[36m(pid=144759)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144759)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144749)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144749)[0m   agg_primitives: ['count']
[2m[36m(pid=144749)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144749)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:45:14,548	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141631, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:14,551	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWAKE(timestamp)=0.45868,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73227,bayes_feature_IS_WEEKEND(timestamp)=0.34628,bayes_feature_MONTH(timestamp)=0.91535,bayes_feature_WEEKDAY(timestamp)=0.51754,dropout_1=0.30008,dropout_2=0.45771,epochs=5,lr=0.0015535,lstm_1_units_float=8.788,lstm_2_units_float=126.38,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144545)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144545)[0m Instructions for updating:
[2m[36m(pid=144545)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144545)[0m LSTM is selected.
[2m[36m(pid=144708)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144708)[0m Instructions for updating:
[2m[36m(pid=144708)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144708)[0m LSTM is selected.
[2m[36m(pid=144758)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144758)[0m Instructions for updating:
[2m[36m(pid=144758)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144758)[0m LSTM is selected.
[2m[36m(pid=144759)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144759)[0m Instructions for updating:
[2m[36m(pid=144759)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144759)[0m LSTM is selected.
[2m[36m(pid=141631)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141631)[0m 
[2m[36m(pid=141631)[0m Stack (most recent call first):
[2m[36m(pid=144749)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144749)[0m Instructions for updating:
[2m[36m(pid=144749)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144749)[0m LSTM is selected.
[2m[36m(pid=144759)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144759)[0m Instructions for updating:
[2m[36m(pid=144759)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144545)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144545)[0m Instructions for updating:
[2m[36m(pid=144545)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144758)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144758)[0m Instructions for updating:
[2m[36m(pid=144758)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144708)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144708)[0m Instructions for updating:
[2m[36m(pid=144708)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144749)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144749)[0m Instructions for updating:
[2m[36m(pid=144749)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.2/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 69 ({'TERMINATED': 19, 'ERROR': 40, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 34 not shown
 - train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AWAKE(timestamp)=0.70444,bayes_feature_IS_BUSY_HOURS(timestamp)=0.96688,bayes_feature_IS_WEEKEND(timestamp)=0.52891,bayes_feature_MONTH(timestamp)=0.681,bayes_feature_WEEKDAY(timestamp)=0.73349,dropout_1=0.43057,dropout_2=0.47671,epochs=5,lr=0.0011025,lstm_1_units_float=97.924,lstm_2_units_float=66.817,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_58_batch_size_log=8.1882,bayes_feature_DAY(timestamp)=0.40237,bayes_feature_HOUR(timestamp)=0.87149,bayes_feature_IS_AW_2020-11-20_11-44-56fy42y86b/error_2020-11-20_11-45-09.txt, [4 CPUs, 0 GPUs], [pid=141887], 6 s, 1 iter
 - train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_60_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-44-59b5uco_7m/error_2020-11-20_11-45-09.txt
 - train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWAKE(timestamp)=0.45868,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73227,bayes_feature_IS_WEEKEND(timestamp)=0.34628,bayes_feature_MONTH(timestamp)=0.91535,bayes_feature_WEEKDAY(timestamp)=0.51754,dropout_1=0.30008,dropout_2=0.45771,epochs=5,lr=0.0015535,lstm_1_units_float=8.788,lstm_2_units_float=126.38,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWA_2020-11-20_11-45-02w893gzaf/error_2020-11-20_11-45-14.txt
RUNNING trials:
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141500], 19 s, 3 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141884], 12 s, 4 iter
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	RUNNING
 - train_func_68_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AWAKE(timestamp)=0.97779,bayes_feature_IS_BUSY_HOURS(timestamp)=0.39868,bayes_feature_IS_WEEKEND(timestamp)=0.70966,bayes_feature_MONTH(timestamp)=0.84148,bayes_feature_WEEKDAY(timestamp)=0.66771,dropout_1=0.48592,dropout_2=0.20627,epochs=5,lr=0.0080283,lstm_1_units_float=96.576,lstm_2_units_float=69.405,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 13 not shown
 - train_func_29_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.958,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130898], 47 s, 5 iter
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter

[2m[36m(pid=144759)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144759)[0m 2020-11-20 11:45:16.123467: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144759)[0m 2020-11-20 11:45:16.132229: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144759)[0m 2020-11-20 11:45:16.135932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0810d6a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144759)[0m 2020-11-20 11:45:16.135976: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144545)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144545)[0m 2020-11-20 11:45:16.202965: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144758)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144758)[0m 2020-11-20 11:45:16.168145: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144758)[0m 2020-11-20 11:45:16.176437: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144758)[0m 2020-11-20 11:45:16.180677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4f19104c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144758)[0m 2020-11-20 11:45:16.180724: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144545)[0m 2020-11-20 11:45:16.213021: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144545)[0m 2020-11-20 11:45:16.216075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cf90ecc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144545)[0m 2020-11-20 11:45:16.216100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144708)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144708)[0m 2020-11-20 11:45:16.254903: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144708)[0m 2020-11-20 11:45:16.263349: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144708)[0m 2020-11-20 11:45:16.266257: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9cdd0ef220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144708)[0m 2020-11-20 11:45:16.266297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144749)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144749)[0m 2020-11-20 11:45:16.287262: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144749)[0m 2020-11-20 11:45:16.295929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144749)[0m 2020-11-20 11:45:16.298418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efbd10ef300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144749)[0m 2020-11-20 11:45:16.298452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=141634)[0m 2020-11-20 11:45:18,331	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=141634)[0m Traceback (most recent call last):
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141634)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141634)[0m     param_dset[:] = val
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141634)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:18 2020
[2m[36m(pid=141634)[0m , filename = '/tmp/thalvari/4065561/automl_save_igdlqwdl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ade0fd488, total write size = 136168, bytes this sub-write = 136168, bytes actually written = 18446744073709551615, offset = 1523712)
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m Traceback (most recent call last):
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141634)[0m     self._entrypoint()
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141634)[0m     output = train_func(config, reporter)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141634)[0m     config=config)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141634)[0m     model.save(model_path, config_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141634)[0m     self.model.save(model_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141634)[0m     signatures)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141634)[0m     f.close()
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141634)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:18 2020
[2m[36m(pid=141634)[0m , filename = '/tmp/thalvari/4065561/automl_save_igdlqwdl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ade363900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=141634)[0m Exception in thread Thread-1:
[2m[36m(pid=141634)[0m Traceback (most recent call last):
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=141634)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=141634)[0m     param_dset[:] = val
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=141634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=141634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=141634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=141634)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:18 2020
[2m[36m(pid=141634)[0m , filename = '/tmp/thalvari/4065561/automl_save_igdlqwdl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ade0fd488, total write size = 136168, bytes this sub-write = 136168, bytes actually written = 18446744073709551615, offset = 1523712)
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m Traceback (most recent call last):
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=141634)[0m     self._entrypoint()
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=141634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=141634)[0m     output = train_func(config, reporter)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=141634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=141634)[0m     config=config)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=141634)[0m     model.save(model_path, config_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=141634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=141634)[0m     self.model.save(model_path)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=141634)[0m     signatures)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=141634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=141634)[0m     f.close()
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=141634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=141634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=141634)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:18 2020
[2m[36m(pid=141634)[0m , filename = '/tmp/thalvari/4065561/automl_save_igdlqwdl/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8ade363900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144755)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144755)[0m   agg_primitives: ['count']
[2m[36m(pid=144755)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144755)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m Traceback (most recent call last):
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=141634)[0m     self.run()
[2m[36m(pid=141634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=141634)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=141634)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=141634)[0m 
[2m[36m(pid=144755)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144755)[0m Instructions for updating:
[2m[36m(pid=144755)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144755)[0m LSTM is selected.
[2m[36m(pid=144749)[0m 2020-11-20 11:45:19,272	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144749)[0m Traceback (most recent call last):
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144749)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144749)[0m     param_dset[:] = val
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144749)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144749)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144749)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144749)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144749)[0m , filename = '/tmp/thalvari/4065561/automl_save_4rgtn6do/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efbd289b8b8, total write size = 374872, bytes this sub-write = 374872, bytes actually written = 18446744073709551615, offset = 1503232)
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m Traceback (most recent call last):
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144749)[0m     self._entrypoint()
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144749)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144749)[0m     output = train_func(config, reporter)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144749)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144749)[0m     config=config)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144749)[0m     model.save(model_path, config_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144749)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144749)[0m     self.model.save(model_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144749)[0m     signatures)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144749)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144749)[0m     f.close()
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144749)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144749)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144749)[0m , filename = '/tmp/thalvari/4065561/automl_save_4rgtn6do/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efbd2076410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144749)[0m Exception in thread Thread-1:
[2m[36m(pid=144749)[0m Traceback (most recent call last):
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144749)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144749)[0m     param_dset[:] = val
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144749)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144749)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144749)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144749)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144749)[0m , filename = '/tmp/thalvari/4065561/automl_save_4rgtn6do/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efbd289b8b8, total write size = 374872, bytes this sub-write = 374872, bytes actually written = 18446744073709551615, offset = 1503232)
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m Traceback (most recent call last):
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144749)[0m     self._entrypoint()
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144749)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144749)[0m     output = train_func(config, reporter)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144749)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144749)[0m     config=config)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144749)[0m     model.save(model_path, config_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144749)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144749)[0m     self.model.save(model_path)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144749)[0m     signatures)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144749)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144749)[0m     f.close()
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144749)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144749)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144749)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144749)[0m , filename = '/tmp/thalvari/4065561/automl_save_4rgtn6do/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efbd2076410, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m Traceback (most recent call last):
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144749)[0m     self.run()
[2m[36m(pid=144749)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144749)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144749)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144755)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144755)[0m Instructions for updating:
[2m[36m(pid=144755)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:19,463	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=141634, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:19,467	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_62_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144708)[0m 2020-11-20 11:45:19,572	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144708)[0m Traceback (most recent call last):
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144708)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144708)[0m     param_dset[:] = val
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144708)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144708)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144708)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144708)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144708)[0m , filename = '/tmp/thalvari/4065561/automl_save_r86aaf9w/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cde899888, total write size = 383064, bytes this sub-write = 383064, bytes actually written = 18446744073709551615, offset = 1495040)
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m Traceback (most recent call last):
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144708)[0m     self._entrypoint()
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144708)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144708)[0m     output = train_func(config, reporter)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144708)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144708)[0m     config=config)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144708)[0m     model.save(model_path, config_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144708)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144708)[0m     self.model.save(model_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144708)[0m     signatures)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144708)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144708)[0m     f.close()
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144708)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144708)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144708)[0m , filename = '/tmp/thalvari/4065561/automl_save_r86aaf9w/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cddefdb40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144708)[0m Exception in thread Thread-1:
[2m[36m(pid=144708)[0m Traceback (most recent call last):
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144708)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144708)[0m     param_dset[:] = val
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144708)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144708)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144708)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144708)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144708)[0m , filename = '/tmp/thalvari/4065561/automl_save_r86aaf9w/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cde899888, total write size = 383064, bytes this sub-write = 383064, bytes actually written = 18446744073709551615, offset = 1495040)
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m Traceback (most recent call last):
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144708)[0m     self._entrypoint()
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144708)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144708)[0m     output = train_func(config, reporter)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144708)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144708)[0m     config=config)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144708)[0m     model.save(model_path, config_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144708)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144708)[0m     self.model.save(model_path)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144708)[0m     signatures)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144708)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144708)[0m     f.close()
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144708)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144708)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144708)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144708)[0m , filename = '/tmp/thalvari/4065561/automl_save_r86aaf9w/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f9cddefdb40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m Traceback (most recent call last):
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144708)[0m     self.run()
[2m[36m(pid=144708)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144708)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144708)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144708)[0m 
[2m[36m(pid=141634)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=141634)[0m 
[2m[36m(pid=141634)[0m Stack (most recent call first):
[2m[36m(pid=141587)[0m Traceback (most recent call last):
[2m[36m(pid=141587)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=141587)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=141587)[0m , filename = '/tmp/thalvari/4065561/automl_save_g0x0kwdr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d02623ee0, total write size = 3288, bytes this sub-write = 3288, bytes actually written = 18446744073709551615, offset = 569344)
[2m[36m(pid=141587)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=141587)[0m Traceback (most recent call last):
[2m[36m(pid=141587)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=141587)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=141587)[0m , filename = '/tmp/thalvari/4065561/automl_save_g0x0kwdr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d02623ee0, total write size = 3288, bytes this sub-write = 3288, bytes actually written = 18446744073709551615, offset = 569344)
[2m[36m(pid=141587)[0m Traceback (most recent call last):
[2m[36m(pid=141587)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
2020-11-20 11:45:19,960	ERROR worker.py:1672 -- A worker died or was killed while executing task ade85b540f6e7d73a7eb4272ad284f9f.
[2m[36m(pid=141587)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=141587)[0m , filename = '/tmp/thalvari/4065561/automl_save_g0x0kwdr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d01e71e08, total write size = 22896, bytes this sub-write = 22896, bytes actually written = 18446744073709551615, offset = 575528)
[2m[36m(pid=141587)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=141587)[0m Traceback (most recent call last):
[2m[36m(pid=141587)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=141587)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=141587)[0m , filename = '/tmp/thalvari/4065561/automl_save_g0x0kwdr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7d01e71e08, total write size = 22896, bytes this sub-write = 22896, bytes actually written = 18446744073
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=144759)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa082034a08, total write size = 7840, bytes this sub-write = 7840, bytes actually written = 18446744073709551615, offset = 928520)
[2m[36m(pid=144759)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=144759)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa082034a08, total write size = 7840, bytes this sub-write = 7840, bytes actually written = 18446744073709551615, offset = 928520)
[2m[36m(pid=144759)[0m 2020-11-20 11:45:19,873	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=144759)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=144759)[0m     param_dset[:] = val
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144759)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144759)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144759)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144759)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0814f8e80, total write size = 153664, bytes this sub-write = 153664, bytes actually written = 18446744073709551615, offset = 938408)
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144759)[0m     self._entrypoint()
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144759)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144759)[0m     output = train_func(config, reporter)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144759)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144759)[0m     config=config)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144759)[0m     model.save(model_path, config_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144759)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144759)[0m     self.model.save(model_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144759)[0m     signatures)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144759)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144759)[0m     f.close()
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144759)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144759)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa08225c990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144759)[0m Exception in thread Thread-1:
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 109, in save_model_to_hdf5
[2m[36m(pid=144759)[0m     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 586, in save_optimizer_weights_to_hdf5_group
[2m[36m(pid=144759)[0m     param_dset[:] = val
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144759)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144759)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144759)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144759)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa0814f8e80, total write size = 153664, bytes this sub-write = 153664, bytes actually written = 18446744073709551615, offset = 938408)
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144759)[0m     self._entrypoint()
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144759)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144759)[0m     output = train_func(config, reporter)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144759)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144759)[0m     config=config)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144759)[0m     model.save(model_path, config_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144759)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144759)[0m     self.model.save(model_path)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144759)[0m     signatures)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144759)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144759)[0m     f.close()
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144759)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144759)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144759)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:19 2020
[2m[36m(pid=144759)[0m , filename = '/tmp/thalvari/4065561/automl_save_oe6luu26/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa08225c990, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m Traceback (most recent call last):
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144759)[0m     self.run()
[2m[36m(pid=144759)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144759)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144759)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144759)[0m 
2020-11-20 11:45:20,268	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2020-11-20 11:45:20,272	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_63_batch_size_log=6.9276,bayes_feature_DAY(timestamp)=0.5132,bayes_feature_HOUR(timestamp)=0.51346,bayes_feature_IS_AWAKE(timestamp)=0.89002,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82114,bayes_feature_IS_WEEKEND(timestamp)=0.55521,bayes_feature_MONTH(timestamp)=0.71893,bayes_feature_WEEKDAY(timestamp)=0.89829,dropout_1=0.42323,dropout_2=0.29765,epochs=5,lr=0.0047207,lstm_1_units_float=27.884,lstm_2_units_float=53.491,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144755)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144755)[0m 2020-11-20 11:45:20.414248: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144755)[0m 2020-11-20 11:45:20.430042: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144755)[0m 2020-11-20 11:45:20.433875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0cd1107900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144755)[0m 2020-11-20 11:45:20.433950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 72 ({'TERMINATED': 20, 'ERROR': 42, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 36 not shown
 - train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWAKE(timestamp)=0.45868,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73227,bayes_feature_IS_WEEKEND(timestamp)=0.34628,bayes_feature_MONTH(timestamp)=0.91535,bayes_feature_WEEKDAY(timestamp)=0.51754,dropout_1=0.30008,dropout_2=0.45771,epochs=5,lr=0.0015535,lstm_1_units_float=8.788,lstm_2_units_float=126.38,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_61_batch_size_log=7.4954,bayes_feature_DAY(timestamp)=0.72423,bayes_feature_HOUR(timestamp)=0.7924,bayes_feature_IS_AWA_2020-11-20_11-45-02w893gzaf/error_2020-11-20_11-45-14.txt
 - train_func_62_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_62_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timesta_2020-11-20_11-45-03b239bssz/error_2020-11-20_11-45-19.txt
 - train_func_63_batch_size_log=6.9276,bayes_feature_DAY(timestamp)=0.5132,bayes_feature_HOUR(timestamp)=0.51346,bayes_feature_IS_AWAKE(timestamp)=0.89002,bayes_feature_IS_BUSY_HOURS(timestamp)=0.82114,bayes_feature_IS_WEEKEND(timestamp)=0.55521,bayes_feature_MONTH(timestamp)=0.71893,bayes_feature_WEEKDAY(timestamp)=0.89829,dropout_1=0.42323,dropout_2=0.29765,epochs=5,lr=0.0047207,lstm_1_units_float=27.884,lstm_2_units_float=53.491,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_63_batch_size_log=6.9276,bayes_feature_DAY(timestamp)=0.5132,bayes_feature_HOUR(timestamp)=0.51346,bayes_feature_IS_AWA_2020-11-20_11-45-06u9gz2yo3/error_2020-11-20_11-45-20.txt, [4 CPUs, 0 GPUs], [pid=141587], 6 s, 1 iter
RUNNING trials:
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141500], 19 s, 3 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	RUNNING
 - train_func_65_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWAKE(timestamp)=0.47949,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59739,bayes_feature_IS_WEEKEND(timestamp)=0.59274,bayes_feature_MONTH(timestamp)=0.66045,bayes_feature_WEEKDAY(timestamp)=0.46461,dropout_1=0.33974,dropout_2=0.28978,epochs=5,lr=0.0082858,lstm_1_units_float=8.289,lstm_2_units_float=126.82,past_seq_len=2:	RUNNING
 - train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AWAKE(timestamp)=0.34367,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34334,bayes_feature_IS_WEEKEND(timestamp)=0.88485,bayes_feature_MONTH(timestamp)=0.82678,bayes_feature_WEEKDAY(timestamp)=0.72573,dropout_1=0.4421,dropout_2=0.31291,epochs=5,lr=0.0016994,lstm_1_units_float=8.286,lstm_2_units_float=123.28,past_seq_len=2:	RUNNING
 - train_func_72_batch_size_log=6.1457,bayes_feature_DAY(timestamp)=0.62164,bayes_feature_HOUR(timestamp)=0.44418,bayes_feature_IS_AWAKE(timestamp)=0.56496,bayes_feature_IS_BUSY_HOURS(timestamp)=0.6562,bayes_feature_IS_WEEKEND(timestamp)=0.32952,bayes_feature_MONTH(timestamp)=0.64414,bayes_feature_WEEKDAY(timestamp)=0.5235,dropout_1=0.47649,dropout_2=0.23285,epochs=5,lr=0.0092651,lstm_1_units_float=8.1384,lstm_2_units_float=124.8,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 14 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter

2020-11-20 11:45:21,157	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144749, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:21,159	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_68_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144547)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144547)[0m   agg_primitives: ['count']
[2m[36m(pid=144547)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144547)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144749)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144749)[0m 
[2m[36m(pid=144749)[0m Stack (most recent call first):
[2m[36m(pid=144547)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144547)[0m Instructions for updating:
[2m[36m(pid=144547)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144547)[0m LSTM is selected.
2020-11-20 11:45:22,155	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144759, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:22,159	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_66_batch_size_log=7.8048,bayes_feature_DAY(timestamp)=0.49107,bayes_feature_HOUR(timestamp)=0.64696,bayes_feature_IS_AWAKE(timestamp)=0.57638,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37166,bayes_feature_IS_WEEKEND(timestamp)=0.99988,bayes_feature_MONTH(timestamp)=0.32452,bayes_feature_WEEKDAY(timestamp)=0.93091,dropout_1=0.44372,dropout_2=0.40918,epochs=5,lr=0.0079159,lstm_1_units_float=98.173,lstm_2_units_float=67.126,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144547)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144547)[0m Instructions for updating:
[2m[36m(pid=144547)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144759)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144759)[0m 
[2m[36m(pid=144759)[0m Stack (most recent call first):
2020-11-20 11:45:23,091	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144708, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:23,095	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_65_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144708)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144708)[0m 
[2m[36m(pid=144708)[0m Stack (most recent call first):
[2m[36m(pid=146490)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146489)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146491)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146490)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146489)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146491)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144547)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144547)[0m 2020-11-20 11:45:23.692851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144547)[0m 2020-11-20 11:45:23.704462: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144547)[0m 2020-11-20 11:45:23.707463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2210e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144547)[0m 2020-11-20 11:45:23.707491: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=144755)[0m 2020-11-20 11:45:23,731	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144755)[0m Traceback (most recent call last):
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144755)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144755)[0m     param_dset[:] = val
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144755)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144755)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144755)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144755)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:23 2020
[2m[36m(pid=144755)[0m , filename = '/tmp/thalvari/4065561/automl_save_d72c3_ak/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0cd1460158, total write size = 43816, bytes this sub-write = 43816, bytes actually written = 18446744073709551615, offset = 888832)
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m Traceback (most recent call last):
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144755)[0m     self._entrypoint()
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144755)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144755)[0m     output = train_func(config, reporter)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144755)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144755)[0m     config=config)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144755)[0m     model.save(model_path, config_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144755)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144755)[0m     self.model.save(model_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144755)[0m     signatures)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144755)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144755)[0m     f.close()
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144755)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144755)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:23 2020
[2m[36m(pid=144755)[0m , filename = '/tmp/thalvari/4065561/automl_save_d72c3_ak/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0cd1d626b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144755)[0m Exception in thread Thread-1:
[2m[36m(pid=144755)[0m Traceback (most recent call last):
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144755)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144755)[0m     param_dset[:] = val
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144755)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144755)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144755)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144755)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:23 2020
[2m[36m(pid=144755)[0m , filename = '/tmp/thalvari/4065561/automl_save_d72c3_ak/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0cd1460158, total write size = 43816, bytes this sub-write = 43816, bytes actually written = 18446744073709551615, offset = 888832)
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m Traceback (most recent call last):
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144755)[0m     self._entrypoint()
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144755)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144755)[0m     output = train_func(config, reporter)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144755)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144755)[0m     config=config)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144755)[0m     model.save(model_path, config_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144755)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144755)[0m     self.model.save(model_path)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144755)[0m     signatures)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144755)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144755)[0m     f.close()
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144755)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144755)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144755)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:23 2020
[2m[36m(pid=144755)[0m , filename = '/tmp/thalvari/4065561/automl_save_d72c3_ak/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f0cd1d626b0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m Traceback (most recent call last):
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144755)[0m     self.run()
[2m[36m(pid=144755)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144755)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144755)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144546)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144546)[0m   agg_primitives: ['count']
[2m[36m(pid=144546)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144546)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146614)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146614)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146616)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146616)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146615)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146615)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146617)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146617)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146619)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146619)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146628)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146628)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146621)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146621)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146624)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146629)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146629)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146613)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=146613)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=144546)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144546)[0m Instructions for updating:
[2m[36m(pid=144546)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144546)[0m LSTM is selected.
2020-11-20 11:45:24,823	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144755, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:24,829	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AWAKE(timestamp)=0.97779,bayes_feature_IS_BUSY_HOURS(timestamp)=0.39868,bayes_feature_IS_WEEKEND(timestamp)=0.70966,bayes_feature_MONTH(timestamp)=0.84148,bayes_feature_WEEKDAY(timestamp)=0.66771,dropout_1=0.48592,dropout_2=0.20627,epochs=5,lr=0.0080283,lstm_1_units_float=96.576,lstm_2_units_float=69.405,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144755)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144755)[0m 
[2m[36m(pid=144755)[0m Stack (most recent call first):
[2m[36m(pid=144544)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=144544)[0m   agg_primitives: ['count']
[2m[36m(pid=144544)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=144544)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144546)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144546)[0m Instructions for updating:
[2m[36m(pid=144546)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144544)[0m LSTM is selected.
[2m[36m(pid=144544)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=144544)[0m Instructions for updating:
[2m[36m(pid=144544)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=144544)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=144544)[0m Instructions for updating:
[2m[36m(pid=144544)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144546)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144546)[0m 2020-11-20 11:45:26.317915: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144546)[0m 2020-11-20 11:45:26.326799: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144546)[0m 2020-11-20 11:45:26.328925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98fd0d0ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144546)[0m 2020-11-20 11:45:26.328956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 76 ({'TERMINATED': 20, 'ERROR': 46, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 40 not shown
 - train_func_66_batch_size_log=7.8048,bayes_feature_DAY(timestamp)=0.49107,bayes_feature_HOUR(timestamp)=0.64696,bayes_feature_IS_AWAKE(timestamp)=0.57638,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37166,bayes_feature_IS_WEEKEND(timestamp)=0.99988,bayes_feature_MONTH(timestamp)=0.32452,bayes_feature_WEEKDAY(timestamp)=0.93091,dropout_1=0.44372,dropout_2=0.40918,epochs=5,lr=0.0079159,lstm_1_units_float=98.173,lstm_2_units_float=67.126,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_66_batch_size_log=7.8048,bayes_feature_DAY(timestamp)=0.49107,bayes_feature_HOUR(timestamp)=0.64696,bayes_feature_IS_AW_2020-11-20_11-45-09xfpfpvlg/error_2020-11-20_11-45-22.txt
 - train_func_68_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=128.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_68_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-45-11y_uhz3de/error_2020-11-20_11-45-21.txt
 - train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AWAKE(timestamp)=0.97779,bayes_feature_IS_BUSY_HOURS(timestamp)=0.39868,bayes_feature_IS_WEEKEND(timestamp)=0.70966,bayes_feature_MONTH(timestamp)=0.84148,bayes_feature_WEEKDAY(timestamp)=0.66771,dropout_1=0.48592,dropout_2=0.20627,epochs=5,lr=0.0080283,lstm_1_units_float=96.576,lstm_2_units_float=69.405,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AW_2020-11-20_11-45-14gyob_y9g/error_2020-11-20_11-45-24.txt
RUNNING trials:
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=141500], 24 s, 4 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=144545], 12 s, 2 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=144758], 11 s, 2 iter
  ... 4 not shown
 - train_func_74_batch_size_log=5.5261,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87693,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.34703,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=127.64,past_seq_len=2:	RUNNING
 - train_func_75_batch_size_log=5.9057,bayes_feature_DAY(timestamp)=0.76037,bayes_feature_HOUR(timestamp)=0.58205,bayes_feature_IS_AWAKE(timestamp)=0.31517,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79659,bayes_feature_IS_WEEKEND(timestamp)=0.30667,bayes_feature_MONTH(timestamp)=0.99752,bayes_feature_WEEKDAY(timestamp)=0.84306,dropout_1=0.33453,dropout_2=0.23942,epochs=5,lr=0.003121,lstm_1_units_float=8.1982,lstm_2_units_float=123.99,past_seq_len=2:	RUNNING
 - train_func_76_batch_size_log=5.2465,bayes_feature_DAY(timestamp)=0.93288,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.35146,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.88211,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 14 not shown
 - train_func_30_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.94,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130904], 45 s, 5 iter
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter

[2m[36m(pid=144547)[0m 2020-11-20 11:45:26,736	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144547)[0m Traceback (most recent call last):
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144547)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144547)[0m     param_dset[:] = val
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144547)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144547)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144547)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144547)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:26 2020
[2m[36m(pid=144547)[0m , filename = '/tmp/thalvari/4065561/automl_save_55tonkz1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa2227de308, total write size = 550488, bytes this sub-write = 550488, bytes actually written = 18446744073709551615, offset = 782336)
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m Traceback (most recent call last):
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144547)[0m     self._entrypoint()
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144547)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144547)[0m     output = train_func(config, reporter)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144547)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144547)[0m     config=config)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144547)[0m     model.save(model_path, config_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144547)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144547)[0m     self.model.save(model_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144547)[0m     signatures)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144547)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144547)[0m     f.close()
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144547)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144547)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:26 2020
[2m[36m(pid=144547)[0m , filename = '/tmp/thalvari/4065561/automl_save_55tonkz1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa221bae240, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144547)[0m Exception in thread Thread-1:
[2m[36m(pid=144547)[0m Traceback (most recent call last):
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144547)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144547)[0m     param_dset[:] = val
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144547)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144547)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144547)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144547)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:26 2020
[2m[36m(pid=144547)[0m , filename = '/tmp/thalvari/4065561/automl_save_55tonkz1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa2227de308, total write size = 550488, bytes this sub-write = 550488, bytes actually written = 18446744073709551615, offset = 782336)
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m Traceback (most recent call last):
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144547)[0m     self._entrypoint()
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144547)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144547)[0m     output = train_func(config, reporter)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144547)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144547)[0m     config=config)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144547)[0m     model.save(model_path, config_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144547)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144547)[0m     self.model.save(model_path)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144547)[0m     signatures)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144547)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144547)[0m     f.close()
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144547)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144547)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144547)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:26 2020
[2m[36m(pid=144547)[0m , filename = '/tmp/thalvari/4065561/automl_save_55tonkz1/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa221bae240, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m Traceback (most recent call last):
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144547)[0m     self.run()
[2m[36m(pid=144547)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144547)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144547)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144544)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=144544)[0m 2020-11-20 11:45:27.267233: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=144544)[0m 2020-11-20 11:45:27.274948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=144544)[0m 2020-11-20 11:45:27.277146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7ab50e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=144544)[0m 2020-11-20 11:45:27.277174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:45:28,220	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144547, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:28,222	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWAKE(timestamp)=0.47949,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59739,bayes_feature_IS_WEEKEND(timestamp)=0.59274,bayes_feature_MONTH(timestamp)=0.66045,bayes_feature_WEEKDAY(timestamp)=0.46461,dropout_1=0.33974,dropout_2=0.28978,epochs=5,lr=0.0082858,lstm_1_units_float=8.289,lstm_2_units_float=126.82,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144547)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144547)[0m 
[2m[36m(pid=144547)[0m Stack (most recent call first):
[2m[36m(pid=146490)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146490)[0m   agg_primitives: ['count']
[2m[36m(pid=146490)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146490)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146489)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146489)[0m   agg_primitives: ['count']
[2m[36m(pid=146489)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146489)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146491)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146491)[0m   agg_primitives: ['count']
[2m[36m(pid=146491)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146491)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146614)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146614)[0m   agg_primitives: ['count']
[2m[36m(pid=146614)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146614)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146490)[0m LSTM is selected.
[2m[36m(pid=146490)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146490)[0m Instructions for updating:
[2m[36m(pid=146490)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146489)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146489)[0m Instructions for updating:
[2m[36m(pid=146489)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146489)[0m LSTM is selected.
[2m[36m(pid=146491)[0m LSTM is selected.
[2m[36m(pid=146491)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146491)[0m Instructions for updating:
[2m[36m(pid=146491)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146614)[0m LSTM is selected.
[2m[36m(pid=146614)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146614)[0m Instructions for updating:
[2m[36m(pid=146614)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146490)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146490)[0m Instructions for updating:
[2m[36m(pid=146490)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146489)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146489)[0m Instructions for updating:
[2m[36m(pid=146489)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146491)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146491)[0m Instructions for updating:
[2m[36m(pid=146491)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146614)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146614)[0m Instructions for updating:
[2m[36m(pid=146614)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=144546)[0m 2020-11-20 11:45:30,505	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144546)[0m Traceback (most recent call last):
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144546)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144546)[0m     param_dset[:] = val
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144546)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144546)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144546)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144546)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:30 2020
[2m[36m(pid=144546)[0m , filename = '/tmp/thalvari/4065561/automl_save_h5ghmcz3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98fea3c228, total write size = 521576, bytes this sub-write = 521576, bytes actually written = 18446744073709551615, offset = 774144)
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m Traceback (most recent call last):
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144546)[0m     self._entrypoint()
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144546)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144546)[0m     output = train_func(config, reporter)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144546)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144546)[0m     config=config)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144546)[0m     model.save(model_path, config_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144546)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144546)[0m     self.model.save(model_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144546)[0m     signatures)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144546)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144546)[0m     f.close()
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144546)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144546)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:30 2020
[2m[36m(pid=144546)[0m , filename = '/tmp/thalvari/4065561/automl_save_h5ghmcz3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98fe2dc3d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144546)[0m Exception in thread Thread-1:
[2m[36m(pid=144546)[0m Traceback (most recent call last):
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144546)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144546)[0m     param_dset[:] = val
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144546)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144546)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144546)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144546)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:30 2020
[2m[36m(pid=144546)[0m , filename = '/tmp/thalvari/4065561/automl_save_h5ghmcz3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98fea3c228, total write size = 521576, bytes this sub-write = 521576, bytes actually written = 18446744073709551615, offset = 774144)
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m Traceback (most recent call last):
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144546)[0m     self._entrypoint()
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144546)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144546)[0m     output = train_func(config, reporter)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144546)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144546)[0m     config=config)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144546)[0m     model.save(model_path, config_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144546)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144546)[0m     self.model.save(model_path)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144546)[0m     signatures)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144546)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144546)[0m     f.close()
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144546)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144546)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144546)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:30 2020
[2m[36m(pid=144546)[0m , filename = '/tmp/thalvari/4065561/automl_save_h5ghmcz3/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f98fe2dc3d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m Traceback (most recent call last):
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144546)[0m     self.run()
[2m[36m(pid=144546)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144546)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144546)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144546)[0m 
[2m[36m(pid=146490)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146490)[0m 2020-11-20 11:45:30.624007: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146490)[0m 2020-11-20 11:45:30.631853: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146490)[0m 2020-11-20 11:45:30.634105: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efcc50e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146490)[0m 2020-11-20 11:45:30.634130: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146489)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146489)[0m 2020-11-20 11:45:30.655314: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146489)[0m 2020-11-20 11:45:30.663334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146489)[0m 2020-11-20 11:45:30.665646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f47410d1c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146489)[0m 2020-11-20 11:45:30.665677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146491)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146491)[0m 2020-11-20 11:45:30.688765: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146491)[0m 2020-11-20 11:45:30.696999: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146491)[0m 2020-11-20 11:45:30.699548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f37650e9230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146491)[0m 2020-11-20 11:45:30.699586: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146614)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146614)[0m 2020-11-20 11:45:30.740646: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146614)[0m 2020-11-20 11:45:30.748547: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146614)[0m 2020-11-20 11:45:30.751608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd60d0e9900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146614)[0m 2020-11-20 11:45:30.751646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146616)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146616)[0m   agg_primitives: ['count']
[2m[36m(pid=146616)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146616)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:45:31,666	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144546, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:31,670	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AWAKE(timestamp)=0.34367,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34334,bayes_feature_IS_WEEKEND(timestamp)=0.88485,bayes_feature_MONTH(timestamp)=0.82678,bayes_feature_WEEKDAY(timestamp)=0.72573,dropout_1=0.4421,dropout_2=0.31291,epochs=5,lr=0.0016994,lstm_1_units_float=8.286,lstm_2_units_float=123.28,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 78 ({'TERMINATED': 21, 'ERROR': 48, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 42 not shown
 - train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AWAKE(timestamp)=0.97779,bayes_feature_IS_BUSY_HOURS(timestamp)=0.39868,bayes_feature_IS_WEEKEND(timestamp)=0.70966,bayes_feature_MONTH(timestamp)=0.84148,bayes_feature_WEEKDAY(timestamp)=0.66771,dropout_1=0.48592,dropout_2=0.20627,epochs=5,lr=0.0080283,lstm_1_units_float=96.576,lstm_2_units_float=69.405,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_69_batch_size_log=7.7609,bayes_feature_DAY(timestamp)=0.88265,bayes_feature_HOUR(timestamp)=0.92674,bayes_feature_IS_AW_2020-11-20_11-45-14gyob_y9g/error_2020-11-20_11-45-24.txt
 - train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWAKE(timestamp)=0.47949,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59739,bayes_feature_IS_WEEKEND(timestamp)=0.59274,bayes_feature_MONTH(timestamp)=0.66045,bayes_feature_WEEKDAY(timestamp)=0.46461,dropout_1=0.33974,dropout_2=0.28978,epochs=5,lr=0.0082858,lstm_1_units_float=8.289,lstm_2_units_float=126.82,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWA_2020-11-20_11-45-17hl13d1kx/error_2020-11-20_11-45-28.txt
 - train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AWAKE(timestamp)=0.34367,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34334,bayes_feature_IS_WEEKEND(timestamp)=0.88485,bayes_feature_MONTH(timestamp)=0.82678,bayes_feature_WEEKDAY(timestamp)=0.72573,dropout_1=0.4421,dropout_2=0.31291,epochs=5,lr=0.0016994,lstm_1_units_float=8.286,lstm_2_units_float=123.28,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AW_2020-11-20_11-45-20plryjp_4/error_2020-11-20_11-45-31.txt
RUNNING trials:
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=144545], 16 s, 3 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=144758], 15 s, 3 iter
 - train_func_72_batch_size_log=6.1457,bayes_feature_DAY(timestamp)=0.62164,bayes_feature_HOUR(timestamp)=0.44418,bayes_feature_IS_AWAKE(timestamp)=0.56496,bayes_feature_IS_BUSY_HOURS(timestamp)=0.6562,bayes_feature_IS_WEEKEND(timestamp)=0.32952,bayes_feature_MONTH(timestamp)=0.64414,bayes_feature_WEEKDAY(timestamp)=0.5235,dropout_1=0.47649,dropout_2=0.23285,epochs=5,lr=0.0092651,lstm_1_units_float=8.1384,lstm_2_units_float=124.8,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_76_batch_size_log=5.2465,bayes_feature_DAY(timestamp)=0.93288,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.35146,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.88211,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_77_batch_size_log=9.2682,bayes_feature_DAY(timestamp)=0.5553,bayes_feature_HOUR(timestamp)=0.75266,bayes_feature_IS_AWAKE(timestamp)=0.87437,bayes_feature_IS_BUSY_HOURS(timestamp)=0.63206,bayes_feature_IS_WEEKEND(timestamp)=0.87921,bayes_feature_MONTH(timestamp)=0.38305,bayes_feature_WEEKDAY(timestamp)=0.3115,dropout_1=0.4448,dropout_2=0.30068,epochs=5,lr=0.0062949,lstm_1_units_float=9.0407,lstm_2_units_float=122.61,past_seq_len=2:	RUNNING
 - train_func_78_batch_size_log=8.9535,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.73088,bayes_feature_IS_AWAKE(timestamp)=0.34201,bayes_feature_IS_BUSY_HOURS(timestamp)=0.7469,bayes_feature_IS_WEEKEND(timestamp)=0.97158,bayes_feature_MONTH(timestamp)=0.34303,bayes_feature_WEEKDAY(timestamp)=0.30025,dropout_1=0.20887,dropout_2=0.2038,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=124.87,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 15 not shown
 - train_func_31_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=16.946,lstm_2_units_float=128.0,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130918], 45 s, 5 iter
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141500], 30 s, 5 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter

[2m[36m(pid=146615)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146615)[0m   agg_primitives: ['count']
[2m[36m(pid=146615)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146615)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=144546)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144546)[0m 
[2m[36m(pid=144546)[0m Stack (most recent call first):
[2m[36m(pid=144544)[0m 2020-11-20 11:45:32,162	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=144544)[0m Traceback (most recent call last):
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144544)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144544)[0m     param_dset[:] = val
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144544)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144544)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144544)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144544)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:32 2020
[2m[36m(pid=144544)[0m , filename = '/tmp/thalvari/4065561/automl_save_08g7s_84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7ab5eb1ff8, total write size = 542104, bytes this sub-write = 542104, bytes actually written = 18446744073709551615, offset = 765952)
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m Traceback (most recent call last):
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144544)[0m     self._entrypoint()
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144544)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144544)[0m     output = train_func(config, reporter)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144544)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144544)[0m     config=config)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144544)[0m     model.save(model_path, config_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144544)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144544)[0m     self.model.save(model_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144544)[0m     signatures)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144544)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144544)[0m     f.close()
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144544)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144544)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:32 2020
[2m[36m(pid=144544)[0m , filename = '/tmp/thalvari/4065561/automl_save_08g7s_84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7ab60faf70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=144544)[0m Exception in thread Thread-1:
[2m[36m(pid=144544)[0m Traceback (most recent call last):
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=144544)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=144544)[0m     param_dset[:] = val
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=144544)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=144544)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=144544)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=144544)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:32 2020
[2m[36m(pid=144544)[0m , filename = '/tmp/thalvari/4065561/automl_save_08g7s_84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7ab5eb1ff8, total write size = 542104, bytes this sub-write = 542104, bytes actually written = 18446744073709551615, offset = 765952)
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m Traceback (most recent call last):
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=144544)[0m     self._entrypoint()
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=144544)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=144544)[0m     output = train_func(config, reporter)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=144544)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=144544)[0m     config=config)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=144544)[0m     model.save(model_path, config_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=144544)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=144544)[0m     self.model.save(model_path)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=144544)[0m     signatures)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=144544)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=144544)[0m     f.close()
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=144544)[0m     h5i.dec_ref(id_)
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=144544)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=144544)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:32 2020
[2m[36m(pid=144544)[0m , filename = '/tmp/thalvari/4065561/automl_save_08g7s_84/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f7ab60faf70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146616)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146616)[0m Instructions for updating:
[2m[36m(pid=146616)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146616)[0m LSTM is selected.
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m Traceback (most recent call last):
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=144544)[0m     self.run()
[2m[36m(pid=144544)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=144544)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=144544)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=144544)[0m 
[2m[36m(pid=146615)[0m LSTM is selected.
[2m[36m(pid=146615)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146615)[0m Instructions for updating:
[2m[36m(pid=146615)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146616)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146616)[0m Instructions for updating:
[2m[36m(pid=146616)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146615)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146615)[0m Instructions for updating:
[2m[36m(pid=146615)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:33,202	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=144544, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:33,205	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_72_batch_size_log=6.1457,bayes_feature_DAY(timestamp)=0.62164,bayes_feature_HOUR(timestamp)=0.44418,bayes_feature_IS_AWAKE(timestamp)=0.56496,bayes_feature_IS_BUSY_HOURS(timestamp)=0.6562,bayes_feature_IS_WEEKEND(timestamp)=0.32952,bayes_feature_MONTH(timestamp)=0.64414,bayes_feature_WEEKDAY(timestamp)=0.5235,dropout_1=0.47649,dropout_2=0.23285,epochs=5,lr=0.0092651,lstm_1_units_float=8.1384,lstm_2_units_float=124.8,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=144544)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=144544)[0m 
[2m[36m(pid=144544)[0m Stack (most recent call first):
[2m[36m(pid=146616)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146616)[0m 2020-11-20 11:45:33.797660: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146616)[0m 2020-11-20 11:45:33.806970: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146616)[0m 2020-11-20 11:45:33.811252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f08790ea220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146616)[0m 2020-11-20 11:45:33.811301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146615)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146615)[0m 2020-11-20 11:45:33.930742: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146615)[0m 2020-11-20 11:45:33.941145: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146615)[0m 2020-11-20 11:45:33.945033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f988d0d0fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146615)[0m 2020-11-20 11:45:33.945069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146616)[0m 2020-11-20 11:45:37,027	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146616)[0m Traceback (most recent call last):
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146616)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146616)[0m     param_dset[:] = val
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146616)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146616)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146616)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146616)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146616)[0m , filename = '/tmp/thalvari/4065561/automl_save_64qssbkr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f087a7d0938, total write size = 820664, bytes this sub-write = 820664, bytes actually written = 18446744073709551615, offset = 466944)
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m Traceback (most recent call last):
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146616)[0m     self._entrypoint()
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146616)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146616)[0m     output = train_func(config, reporter)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146616)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146616)[0m     config=config)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146616)[0m     model.save(model_path, config_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146616)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146616)[0m     self.model.save(model_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146616)[0m     signatures)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146616)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146616)[0m     f.close()
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146616)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146616)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146616)[0m , filename = '/tmp/thalvari/4065561/automl_save_64qssbkr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f087950fe50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146616)[0m Exception in thread Thread-1:
[2m[36m(pid=146616)[0m Traceback (most recent call last):
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146616)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146616)[0m     param_dset[:] = val
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146616)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146616)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146616)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146616)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146616)[0m , filename = '/tmp/thalvari/4065561/automl_save_64qssbkr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f087a7d0938, total write size = 820664, bytes this sub-write = 820664, bytes actually written = 18446744073709551615, offset = 466944)
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m Traceback (most recent call last):
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146616)[0m     self._entrypoint()
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146616)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146616)[0m     output = train_func(config, reporter)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146616)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146616)[0m     config=config)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146616)[0m     model.save(model_path, config_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146616)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146616)[0m     self.model.save(model_path)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146616)[0m     signatures)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146616)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146616)[0m     f.close()
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146616)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146616)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146616)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146616)[0m , filename = '/tmp/thalvari/4065561/automl_save_64qssbkr/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f087950fe50, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m Traceback (most recent call last):
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146616)[0m     self.run()
[2m[36m(pid=146616)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146616)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146616)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146490)[0m 2020-11-20 11:45:37,046	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146490)[0m Traceback (most recent call last):
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146490)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146490)[0m     param_dset[:] = val
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146490)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146490)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146490)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146490)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146490)[0m , filename = '/tmp/thalvari/4065561/automl_save_av3ymk6c/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efcc69cefe8, total write size = 558440, bytes this sub-write = 558440, bytes actually written = 18446744073709551615, offset = 737280)
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m Traceback (most recent call last):
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146490)[0m     self._entrypoint()
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146490)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146490)[0m     output = train_func(config, reporter)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146490)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146490)[0m     config=config)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146490)[0m     model.save(model_path, config_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146490)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146490)[0m     self.model.save(model_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146490)[0m     signatures)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146490)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146490)[0m     f.close()
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146490)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146490)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146490)[0m , filename = '/tmp/thalvari/4065561/automl_save_av3ymk6c/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efcc66f3870, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146490)[0m Exception in thread Thread-1:
[2m[36m(pid=146490)[0m Traceback (most recent call last):
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146490)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146490)[0m     param_dset[:] = val
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146490)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146490)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146490)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146490)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146490)[0m , filename = '/tmp/thalvari/4065561/automl_save_av3ymk6c/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efcc69cefe8, total write size = 558440, bytes this sub-write = 558440, bytes actually written = 18446744073709551615, offset = 737280)
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m Traceback (most recent call last):
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146490)[0m     self._entrypoint()
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146490)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146490)[0m     output = train_func(config, reporter)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146490)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146490)[0m     config=config)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146490)[0m     model.save(model_path, config_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146490)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146490)[0m     self.model.save(model_path)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146490)[0m     signatures)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146490)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146490)[0m     f.close()
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146490)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146490)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146490)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146490)[0m , filename = '/tmp/thalvari/4065561/automl_save_av3ymk6c/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7efcc66f3870, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m Traceback (most recent call last):
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146490)[0m     self.run()
[2m[36m(pid=146490)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146490)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146490)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146615)[0m 2020-11-20 11:45:37,096	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146615)[0m Traceback (most recent call last):
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146615)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146615)[0m     param_dset[:] = val
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146615)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146615)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146615)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146615)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146615)[0m , filename = '/tmp/thalvari/4065561/automl_save_sss0rm_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f988e3dd678, total write size = 566680, bytes this sub-write = 566680, bytes actually written = 18446744073709551615, offset = 741376)
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m Traceback (most recent call last):
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146615)[0m     self._entrypoint()
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146615)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146615)[0m     output = train_func(config, reporter)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146615)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146615)[0m     config=config)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146615)[0m     model.save(model_path, config_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146615)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146615)[0m     self.model.save(model_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146615)[0m     signatures)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146615)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146615)[0m     f.close()
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146615)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146615)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146615)[0m , filename = '/tmp/thalvari/4065561/automl_save_sss0rm_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f988dee7730, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146615)[0m Exception in thread Thread-1:
[2m[36m(pid=146615)[0m Traceback (most recent call last):
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146615)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146615)[0m     param_dset[:] = val
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146615)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146615)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146615)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146615)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146615)[0m , filename = '/tmp/thalvari/4065561/automl_save_sss0rm_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f988e3dd678, total write size = 566680, bytes this sub-write = 566680, bytes actually written = 18446744073709551615, offset = 741376)
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m Traceback (most recent call last):
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146615)[0m     self._entrypoint()
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146615)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146615)[0m     output = train_func(config, reporter)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146615)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146615)[0m     config=config)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146615)[0m     model.save(model_path, config_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146615)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146615)[0m     self.model.save(model_path)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146615)[0m     signatures)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146615)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146615)[0m     f.close()
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146615)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146615)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146615)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146615)[0m , filename = '/tmp/thalvari/4065561/automl_save_sss0rm_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f988dee7730, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m Traceback (most recent call last):
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146615)[0m     self.run()
[2m[36m(pid=146615)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146615)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146615)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146626)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146626)[0m   agg_primitives: ['count']
[2m[36m(pid=146626)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146626)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 81 ({'TERMINATED': 22, 'ERROR': 49, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 43 not shown
 - train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWAKE(timestamp)=0.47949,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59739,bayes_feature_IS_WEEKEND(timestamp)=0.59274,bayes_feature_MONTH(timestamp)=0.66045,bayes_feature_WEEKDAY(timestamp)=0.46461,dropout_1=0.33974,dropout_2=0.28978,epochs=5,lr=0.0082858,lstm_1_units_float=8.289,lstm_2_units_float=126.82,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_70_batch_size_log=9.9518,bayes_feature_DAY(timestamp)=0.82523,bayes_feature_HOUR(timestamp)=0.6977,bayes_feature_IS_AWA_2020-11-20_11-45-17hl13d1kx/error_2020-11-20_11-45-28.txt
 - train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AWAKE(timestamp)=0.34367,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34334,bayes_feature_IS_WEEKEND(timestamp)=0.88485,bayes_feature_MONTH(timestamp)=0.82678,bayes_feature_WEEKDAY(timestamp)=0.72573,dropout_1=0.4421,dropout_2=0.31291,epochs=5,lr=0.0016994,lstm_1_units_float=8.286,lstm_2_units_float=123.28,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_71_batch_size_log=6.9688,bayes_feature_DAY(timestamp)=0.30714,bayes_feature_HOUR(timestamp)=0.99989,bayes_feature_IS_AW_2020-11-20_11-45-20plryjp_4/error_2020-11-20_11-45-31.txt
 - train_func_72_batch_size_log=6.1457,bayes_feature_DAY(timestamp)=0.62164,bayes_feature_HOUR(timestamp)=0.44418,bayes_feature_IS_AWAKE(timestamp)=0.56496,bayes_feature_IS_BUSY_HOURS(timestamp)=0.6562,bayes_feature_IS_WEEKEND(timestamp)=0.32952,bayes_feature_MONTH(timestamp)=0.64414,bayes_feature_WEEKDAY(timestamp)=0.5235,dropout_1=0.47649,dropout_2=0.23285,epochs=5,lr=0.0092651,lstm_1_units_float=8.1384,lstm_2_units_float=124.8,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_72_batch_size_log=6.1457,bayes_feature_DAY(timestamp)=0.62164,bayes_feature_HOUR(timestamp)=0.44418,bayes_feature_IS_AW_2020-11-20_11-45-21x_hzxbez/error_2020-11-20_11-45-33.txt
RUNNING trials:
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	RUNNING, [4 CPUs, 0 GPUs], [pid=144545], 19 s, 4 iter
 - train_func_73_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.71989,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.20016,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_74_batch_size_log=5.5261,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87693,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.34703,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=127.64,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_79_batch_size_log=6.4476,bayes_feature_DAY(timestamp)=0.35409,bayes_feature_HOUR(timestamp)=0.47132,bayes_feature_IS_AWAKE(timestamp)=0.99912,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59259,bayes_feature_IS_WEEKEND(timestamp)=0.75495,bayes_feature_MONTH(timestamp)=0.50101,bayes_feature_WEEKDAY(timestamp)=0.50292,dropout_1=0.27959,dropout_2=0.32477,epochs=5,lr=0.0093141,lstm_1_units_float=8.1193,lstm_2_units_float=120.54,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.1565,bayes_feature_DAY(timestamp)=0.32028,bayes_feature_HOUR(timestamp)=0.33162,bayes_feature_IS_AWAKE(timestamp)=0.34719,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.88836,bayes_feature_WEEKDAY(timestamp)=0.94116,dropout_1=0.2,dropout_2=0.49177,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=123.18,past_seq_len=2:	RUNNING
 - train_func_81_batch_size_log=7.9063,bayes_feature_DAY(timestamp)=0.47796,bayes_feature_HOUR(timestamp)=0.78806,bayes_feature_IS_AWAKE(timestamp)=0.69734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.41185,bayes_feature_IS_WEEKEND(timestamp)=0.82982,bayes_feature_MONTH(timestamp)=0.89016,bayes_feature_WEEKDAY(timestamp)=0.99021,dropout_1=0.47295,dropout_2=0.22686,epochs=5,lr=0.0055894,lstm_1_units_float=8.1674,lstm_2_units_float=121.64,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 16 not shown
 - train_func_54_batch_size_log=5.5596,bayes_feature_DAY(timestamp)=0.30664,bayes_feature_HOUR(timestamp)=0.63713,bayes_feature_IS_AWAKE(timestamp)=0.89269,bayes_feature_IS_BUSY_HOURS(timestamp)=0.4405,bayes_feature_IS_WEEKEND(timestamp)=0.49913,bayes_feature_MONTH(timestamp)=0.53605,bayes_feature_WEEKDAY(timestamp)=0.69008,dropout_1=0.47195,dropout_2=0.25788,epochs=5,lr=0.0020281,lstm_1_units_float=108.53,lstm_2_units_float=10.372,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141500], 30 s, 5 iter
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=146626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146626)[0m Instructions for updating:
[2m[36m(pid=146626)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146626)[0m LSTM is selected.
[2m[36m(pid=146489)[0m 2020-11-20 11:45:37,665	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146489)[0m Traceback (most recent call last):
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146489)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146489)[0m     param_dset[:] = val
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146489)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146489)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146489)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146489)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146489)[0m , filename = '/tmp/thalvari/4065561/automl_save_qxbipilg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f47429b5bc8, total write size = 612072, bytes this sub-write = 612072, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m Traceback (most recent call last):
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146489)[0m     self._entrypoint()
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146489)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146489)[0m     output = train_func(config, reporter)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146489)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146489)[0m     config=config)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146489)[0m     model.save(model_path, config_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146489)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146489)[0m     self.model.save(model_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146489)[0m     signatures)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146489)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146489)[0m     f.close()
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146489)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146489)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146489)[0m , filename = '/tmp/thalvari/4065561/automl_save_qxbipilg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4742796230, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146489)[0m Exception in thread Thread-1:
[2m[36m(pid=146489)[0m Traceback (most recent call last):
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146489)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146489)[0m     param_dset[:] = val
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146489)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146489)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146489)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146489)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146489)[0m , filename = '/tmp/thalvari/4065561/automl_save_qxbipilg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f47429b5bc8, total write size = 612072, bytes this sub-write = 612072, bytes actually written = 18446744073709551615, offset = 733184)
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m Traceback (most recent call last):
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146489)[0m     self._entrypoint()
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146489)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146489)[0m     output = train_func(config, reporter)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146489)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146489)[0m     config=config)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146489)[0m     model.save(model_path, config_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146489)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146489)[0m     self.model.save(model_path)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146489)[0m     signatures)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146489)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146489)[0m     f.close()
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146489)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146489)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146489)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:37 2020
[2m[36m(pid=146489)[0m , filename = '/tmp/thalvari/4065561/automl_save_qxbipilg/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4742796230, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m Traceback (most recent call last):
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146489)[0m     self.run()
[2m[36m(pid=146489)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146489)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146489)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146617)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146617)[0m   agg_primitives: ['count']
[2m[36m(pid=146617)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146617)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146626)[0m Instructions for updating:
[2m[36m(pid=146626)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:38,205	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146616, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:38,207	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_77_batch_size_log=9.2682,bayes_feature_DAY(timestamp)=0.5553,bayes_feature_HOUR(timestamp)=0.75266,bayes_feature_IS_AWAKE(timestamp)=0.87437,bayes_feature_IS_BUSY_HOURS(timestamp)=0.63206,bayes_feature_IS_WEEKEND(timestamp)=0.87921,bayes_feature_MONTH(timestamp)=0.38305,bayes_feature_WEEKDAY(timestamp)=0.3115,dropout_1=0.4448,dropout_2=0.30068,epochs=5,lr=0.0062949,lstm_1_units_float=9.0407,lstm_2_units_float=122.61,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146616)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146616)[0m 
[2m[36m(pid=146616)[0m Stack (most recent call first):
[2m[36m(pid=146617)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146617)[0m Instructions for updating:
[2m[36m(pid=146617)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146617)[0m LSTM is selected.
[2m[36m(pid=146614)[0m 2020-11-20 11:45:38,778	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146614)[0m Traceback (most recent call last):
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146614)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146614)[0m     param_dset[:] = val
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146614)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146614)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146614)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146614)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:38 2020
[2m[36m(pid=146614)[0m , filename = '/tmp/thalvari/4065561/automl_save_1evgihzx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd60e9def28, total write size = 632728, bytes this sub-write = 632728, bytes actually written = 18446744073709551615, offset = 724992)
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m Traceback (most recent call last):
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146614)[0m     self._entrypoint()
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146614)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146614)[0m     output = train_func(config, reporter)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146614)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146614)[0m     config=config)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146614)[0m     model.save(model_path, config_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146614)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146614)[0m     self.model.save(model_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146614)[0m     signatures)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146614)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146614)[0m     f.close()
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146614)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146614)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:38 2020
[2m[36m(pid=146614)[0m , filename = '/tmp/thalvari/4065561/automl_save_1evgihzx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd60e8e3fd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146614)[0m Exception in thread Thread-1:
[2m[36m(pid=146614)[0m Traceback (most recent call last):
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146614)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146614)[0m     param_dset[:] = val
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146614)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146614)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146614)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146614)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:38 2020
[2m[36m(pid=146614)[0m , filename = '/tmp/thalvari/4065561/automl_save_1evgihzx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd60e9def28, total write size = 632728, bytes this sub-write = 632728, bytes actually written = 18446744073709551615, offset = 724992)
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m Traceback (most recent call last):
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146614)[0m     self._entrypoint()
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146614)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146614)[0m     output = train_func(config, reporter)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146614)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146614)[0m     config=config)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146614)[0m     model.save(model_path, config_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146614)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146614)[0m     self.model.save(model_path)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146614)[0m     signatures)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146614)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146614)[0m     f.close()
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146614)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146614)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146614)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:38 2020
[2m[36m(pid=146614)[0m , filename = '/tmp/thalvari/4065561/automl_save_1evgihzx/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fd60e8e3fd0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m Traceback (most recent call last):
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146614)[0m     self.run()
[2m[36m(pid=146614)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146614)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146614)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146614)[0m 
2020-11-20 11:45:39,019	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146490, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:39,021	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_75_batch_size_log=5.9057,bayes_feature_DAY(timestamp)=0.76037,bayes_feature_HOUR(timestamp)=0.58205,bayes_feature_IS_AWAKE(timestamp)=0.31517,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79659,bayes_feature_IS_WEEKEND(timestamp)=0.30667,bayes_feature_MONTH(timestamp)=0.99752,bayes_feature_WEEKDAY(timestamp)=0.84306,dropout_1=0.33453,dropout_2=0.23942,epochs=5,lr=0.003121,lstm_1_units_float=8.1982,lstm_2_units_float=123.99,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146617)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146617)[0m Instructions for updating:
[2m[36m(pid=146617)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146490)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146490)[0m 
[2m[36m(pid=146490)[0m Stack (most recent call first):
[2m[36m(pid=146626)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146626)[0m 2020-11-20 11:45:39.304106: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146626)[0m 2020-11-20 11:45:39.312458: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146626)[0m 2020-11-20 11:45:39.314607: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f48310ea080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146626)[0m 2020-11-20 11:45:39.314639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146491)[0m 2020-11-20 11:45:39,708	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146491)[0m Traceback (most recent call last):
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146491)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146491)[0m     param_dset[:] = val
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146491)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146491)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146491)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146491)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:39 2020
[2m[36m(pid=146491)[0m , filename = '/tmp/thalvari/4065561/automl_save_var31gdk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37669df1c8, total write size = 640920, bytes this sub-write = 640920, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m Traceback (most recent call last):
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146491)[0m     self._entrypoint()
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146491)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146491)[0m     output = train_func(config, reporter)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146491)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146491)[0m     config=config)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146491)[0m     model.save(model_path, config_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146491)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146491)[0m     self.model.save(model_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146491)[0m     signatures)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146491)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146491)[0m     f.close()
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146491)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146491)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:39 2020
[2m[36m(pid=146491)[0m , filename = '/tmp/thalvari/4065561/automl_save_var31gdk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3765496090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146491)[0m Exception in thread Thread-1:
[2m[36m(pid=146491)[0m Traceback (most recent call last):
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146491)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146491)[0m     param_dset[:] = val
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146491)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146491)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146491)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146491)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:39 2020
[2m[36m(pid=146491)[0m , filename = '/tmp/thalvari/4065561/automl_save_var31gdk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f37669df1c8, total write size = 640920, bytes this sub-write = 640920, bytes actually written = 18446744073709551615, offset = 716800)
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m Traceback (most recent call last):
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146491)[0m     self._entrypoint()
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146491)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146491)[0m     output = train_func(config, reporter)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146491)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146491)[0m     config=config)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146491)[0m     model.save(model_path, config_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146491)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146491)[0m     self.model.save(model_path)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146491)[0m     signatures)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146491)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146491)[0m     f.close()
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146491)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146491)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146491)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:39 2020
[2m[36m(pid=146491)[0m , filename = '/tmp/thalvari/4065561/automl_save_var31gdk/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3765496090, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m Traceback (most recent call last):
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146491)[0m     self.run()
[2m[36m(pid=146491)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146491)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146491)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146491)[0m 
2020-11-20 11:45:39,892	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146489, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:39,895	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_74_batch_size_log=5.5261,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=1.0,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87693,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.34703,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=127.64,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146489)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146489)[0m 
[2m[36m(pid=146489)[0m Stack (most recent call first):
[2m[36m(pid=146617)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146617)[0m 2020-11-20 11:45:40.121938: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146617)[0m 2020-11-20 11:45:40.129866: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146617)[0m 2020-11-20 11:45:40.131901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f22190d1400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146617)[0m 2020-11-20 11:45:40.131928: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146628)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146628)[0m   agg_primitives: ['count']
[2m[36m(pid=146628)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146628)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:45:40,703	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146614, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:40,706	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_76_batch_size_log=5.2465,bayes_feature_DAY(timestamp)=0.93288,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.35146,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.88211,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146628)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146628)[0m Instructions for updating:
[2m[36m(pid=146628)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146628)[0m LSTM is selected.
[2m[36m(pid=146614)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146614)[0m 
[2m[36m(pid=146614)[0m Stack (most recent call first):
[2m[36m(pid=146619)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146619)[0m   agg_primitives: ['count']
[2m[36m(pid=146619)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146619)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146619)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146619)[0m Instructions for updating:
[2m[36m(pid=146619)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146619)[0m LSTM is selected.
[2m[36m(pid=146628)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146628)[0m Instructions for updating:
[2m[36m(pid=146628)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:41,612	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146491, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:41,615	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_73_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.71989,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.20016,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146619)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146619)[0m Instructions for updating:
[2m[36m(pid=146619)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146491)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146491)[0m 
[2m[36m(pid=146491)[0m Stack (most recent call first):
[2m[36m(pid=146621)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146621)[0m   agg_primitives: ['count']
[2m[36m(pid=146621)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146621)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146628)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146628)[0m 2020-11-20 11:45:42.394482: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146628)[0m 2020-11-20 11:45:42.403531: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146628)[0m 2020-11-20 11:45:42.406314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0a50e9900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146628)[0m 2020-11-20 11:45:42.406347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.6/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 87 ({'TERMINATED': 23, 'ERROR': 54, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 48 not shown
 - train_func_75_batch_size_log=5.9057,bayes_feature_DAY(timestamp)=0.76037,bayes_feature_HOUR(timestamp)=0.58205,bayes_feature_IS_AWAKE(timestamp)=0.31517,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79659,bayes_feature_IS_WEEKEND(timestamp)=0.30667,bayes_feature_MONTH(timestamp)=0.99752,bayes_feature_WEEKDAY(timestamp)=0.84306,dropout_1=0.33453,dropout_2=0.23942,epochs=5,lr=0.003121,lstm_1_units_float=8.1982,lstm_2_units_float=123.99,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_75_batch_size_log=5.9057,bayes_feature_DAY(timestamp)=0.76037,bayes_feature_HOUR(timestamp)=0.58205,bayes_feature_IS_AW_2020-11-20_11-45-24pf5gzu5o/error_2020-11-20_11-45-39.txt
 - train_func_76_batch_size_log=5.2465,bayes_feature_DAY(timestamp)=0.93288,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.35146,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.88211,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_76_batch_size_log=5.2465,bayes_feature_DAY(timestamp)=0.93288,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(_2020-11-20_11-45-25ld34rjwr/error_2020-11-20_11-45-40.txt
 - train_func_77_batch_size_log=9.2682,bayes_feature_DAY(timestamp)=0.5553,bayes_feature_HOUR(timestamp)=0.75266,bayes_feature_IS_AWAKE(timestamp)=0.87437,bayes_feature_IS_BUSY_HOURS(timestamp)=0.63206,bayes_feature_IS_WEEKEND(timestamp)=0.87921,bayes_feature_MONTH(timestamp)=0.38305,bayes_feature_WEEKDAY(timestamp)=0.3115,dropout_1=0.4448,dropout_2=0.30068,epochs=5,lr=0.0062949,lstm_1_units_float=9.0407,lstm_2_units_float=122.61,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_77_batch_size_log=9.2682,bayes_feature_DAY(timestamp)=0.5553,bayes_feature_HOUR(timestamp)=0.75266,bayes_feature_IS_AWA_2020-11-20_11-45-28316ic1r_/error_2020-11-20_11-45-38.txt
RUNNING trials:
 - train_func_78_batch_size_log=8.9535,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.73088,bayes_feature_IS_AWAKE(timestamp)=0.34201,bayes_feature_IS_BUSY_HOURS(timestamp)=0.7469,bayes_feature_IS_WEEKEND(timestamp)=0.97158,bayes_feature_MONTH(timestamp)=0.34303,bayes_feature_WEEKDAY(timestamp)=0.30025,dropout_1=0.20887,dropout_2=0.2038,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=124.87,past_seq_len=2:	RUNNING
 - train_func_79_batch_size_log=6.4476,bayes_feature_DAY(timestamp)=0.35409,bayes_feature_HOUR(timestamp)=0.47132,bayes_feature_IS_AWAKE(timestamp)=0.99912,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59259,bayes_feature_IS_WEEKEND(timestamp)=0.75495,bayes_feature_MONTH(timestamp)=0.50101,bayes_feature_WEEKDAY(timestamp)=0.50292,dropout_1=0.27959,dropout_2=0.32477,epochs=5,lr=0.0093141,lstm_1_units_float=8.1193,lstm_2_units_float=120.54,past_seq_len=2:	RUNNING
 - train_func_80_batch_size_log=5.1565,bayes_feature_DAY(timestamp)=0.32028,bayes_feature_HOUR(timestamp)=0.33162,bayes_feature_IS_AWAKE(timestamp)=0.34719,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.88836,bayes_feature_WEEKDAY(timestamp)=0.94116,dropout_1=0.2,dropout_2=0.49177,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=123.18,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_85_batch_size_log=5.5976,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.42421,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.29,past_seq_len=2:	RUNNING
 - train_func_86_batch_size_log=7.0736,bayes_feature_DAY(timestamp)=0.64458,bayes_feature_HOUR(timestamp)=0.48578,bayes_feature_IS_AWAKE(timestamp)=0.46811,bayes_feature_IS_BUSY_HOURS(timestamp)=0.825,bayes_feature_IS_WEEKEND(timestamp)=0.96393,bayes_feature_MONTH(timestamp)=0.63487,bayes_feature_WEEKDAY(timestamp)=0.43586,dropout_1=0.42094,dropout_2=0.30982,epochs=5,lr=0.002893,lstm_1_units_float=8.073,lstm_2_units_float=120.57,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=6.183,bayes_feature_DAY(timestamp)=0.89071,bayes_feature_HOUR(timestamp)=0.8331,bayes_feature_IS_AWAKE(timestamp)=0.72754,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60982,bayes_feature_IS_WEEKEND(timestamp)=0.39564,bayes_feature_MONTH(timestamp)=0.34845,bayes_feature_WEEKDAY(timestamp)=0.80308,dropout_1=0.46305,dropout_2=0.43255,epochs=5,lr=0.0097357,lstm_1_units_float=8.2413,lstm_2_units_float=121.27,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

2020-11-20 11:45:42,572	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146615, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:42,575	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_78_batch_size_log=8.9535,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.73088,bayes_feature_IS_AWAKE(timestamp)=0.34201,bayes_feature_IS_BUSY_HOURS(timestamp)=0.7469,bayes_feature_IS_WEEKEND(timestamp)=0.97158,bayes_feature_MONTH(timestamp)=0.34303,bayes_feature_WEEKDAY(timestamp)=0.30025,dropout_1=0.20887,dropout_2=0.2038,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=124.87,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146621)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146621)[0m Instructions for updating:
[2m[36m(pid=146621)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146621)[0m LSTM is selected.
[2m[36m(pid=146615)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146615)[0m 
[2m[36m(pid=146615)[0m Stack (most recent call first):
[2m[36m(pid=146619)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146619)[0m 2020-11-20 11:45:42.838938: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146619)[0m 2020-11-20 11:45:42.848859: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146619)[0m 2020-11-20 11:45:42.851091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8da90e99c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146619)[0m 2020-11-20 11:45:42.851126: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146624)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146624)[0m   agg_primitives: ['count']
[2m[36m(pid=146624)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146624)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146621)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146621)[0m Instructions for updating:
[2m[36m(pid=146621)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146624)[0m LSTM is selected.
[2m[36m(pid=146624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146624)[0m Instructions for updating:
[2m[36m(pid=146624)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146626)[0m 2020-11-20 11:45:43,841	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146626)[0m Traceback (most recent call last):
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146626)[0m     param_dset[:] = val
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146626)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:43 2020
[2m[36m(pid=146626)[0m , filename = '/tmp/thalvari/4065561/automl_save_37ehbljx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f48321ba6c8, total write size = 550296, bytes this sub-write = 550296, bytes actually written = 18446744073709551615, offset = 708608)
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m Traceback (most recent call last):
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146626)[0m     self._entrypoint()
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146626)[0m     output = train_func(config, reporter)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146626)[0m     config=config)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146626)[0m     model.save(model_path, config_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146626)[0m     self.model.save(model_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146626)[0m     signatures)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146626)[0m     f.close()
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146626)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:43 2020
[2m[36m(pid=146626)[0m , filename = '/tmp/thalvari/4065561/automl_save_37ehbljx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f483253ff70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146626)[0m Exception in thread Thread-1:
[2m[36m(pid=146626)[0m Traceback (most recent call last):
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146626)[0m     param_dset[:] = val
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146626)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:43 2020
[2m[36m(pid=146626)[0m , filename = '/tmp/thalvari/4065561/automl_save_37ehbljx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f48321ba6c8, total write size = 550296, bytes this sub-write = 550296, bytes actually written = 18446744073709551615, offset = 708608)
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m Traceback (most recent call last):
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146626)[0m     self._entrypoint()
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146626)[0m     output = train_func(config, reporter)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146626)[0m     config=config)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146626)[0m     model.save(model_path, config_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146626)[0m     self.model.save(model_path)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146626)[0m     signatures)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146626)[0m     f.close()
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146626)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:43 2020
[2m[36m(pid=146626)[0m , filename = '/tmp/thalvari/4065561/automl_save_37ehbljx/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f483253ff70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m Traceback (most recent call last):
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146626)[0m     self.run()
[2m[36m(pid=146626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146626)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146626)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146624)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146624)[0m Instructions for updating:
[2m[36m(pid=146624)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146621)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146621)[0m 2020-11-20 11:45:44.227713: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146621)[0m 2020-11-20 11:45:44.239081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146621)[0m 2020-11-20 11:45:44.241406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eee4d101fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146621)[0m 2020-11-20 11:45:44.241433: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146629)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146629)[0m   agg_primitives: ['count']
[2m[36m(pid=146629)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146629)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=149476)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=149476)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146629)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146629)[0m Instructions for updating:
[2m[36m(pid=146629)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146629)[0m LSTM is selected.
[2m[36m(pid=146613)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146613)[0m   agg_primitives: ['count']
[2m[36m(pid=146613)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146613)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146624)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146624)[0m 2020-11-20 11:45:44.962950: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146624)[0m 2020-11-20 11:45:44.970713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146624)[0m 2020-11-20 11:45:44.974316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fad510e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146624)[0m 2020-11-20 11:45:44.974353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:45:45,039	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146626, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:45,045	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_79_batch_size_log=6.4476,bayes_feature_DAY(timestamp)=0.35409,bayes_feature_HOUR(timestamp)=0.47132,bayes_feature_IS_AWAKE(timestamp)=0.99912,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59259,bayes_feature_IS_WEEKEND(timestamp)=0.75495,bayes_feature_MONTH(timestamp)=0.50101,bayes_feature_WEEKDAY(timestamp)=0.50292,dropout_1=0.27959,dropout_2=0.32477,epochs=5,lr=0.0093141,lstm_1_units_float=8.1193,lstm_2_units_float=120.54,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=149520)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=149562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=149520)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=149562)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146626)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146626)[0m 
[2m[36m(pid=146626)[0m Stack (most recent call first):
[2m[36m(pid=146613)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146613)[0m Instructions for updating:
[2m[36m(pid=146613)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146613)[0m LSTM is selected.
[2m[36m(pid=146628)[0m 2020-11-20 11:45:45,459	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146628)[0m Traceback (most recent call last):
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146628)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146628)[0m     param_dset[:] = val
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146628)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146628)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146628)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146628)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146628)[0m , filename = '/tmp/thalvari/4065561/automl_save_9chk0_wy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe0a6317e98, total write size = 603496, bytes this sub-write = 603496, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m Traceback (most recent call last):
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146628)[0m     self._entrypoint()
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146628)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146628)[0m     output = train_func(config, reporter)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146628)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146628)[0m     config=config)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146628)[0m     model.save(model_path, config_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146628)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146628)[0m     self.model.save(model_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146628)[0m     signatures)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146628)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146628)[0m     f.close()
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146628)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146628)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146628)[0m , filename = '/tmp/thalvari/4065561/automl_save_9chk0_wy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe0a61e0620, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146628)[0m Exception in thread Thread-1:
[2m[36m(pid=146628)[0m Traceback (most recent call last):
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146628)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146628)[0m     param_dset[:] = val
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146628)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146628)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146628)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146628)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146628)[0m , filename = '/tmp/thalvari/4065561/automl_save_9chk0_wy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe0a6317e98, total write size = 603496, bytes this sub-write = 603496, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m Traceback (most recent call last):
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146628)[0m     self._entrypoint()
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146628)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146628)[0m     output = train_func(config, reporter)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146628)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146628)[0m     config=config)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146628)[0m     model.save(model_path, config_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146628)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146628)[0m     self.model.save(model_path)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146628)[0m     signatures)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146628)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146628)[0m     f.close()
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146628)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146628)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146628)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146628)[0m , filename = '/tmp/thalvari/4065561/automl_save_9chk0_wy/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe0a61e0620, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m Traceback (most recent call last):
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146628)[0m     self.run()
[2m[36m(pid=146628)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146628)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146628)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146629)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146629)[0m Instructions for updating:
[2m[36m(pid=146629)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146619)[0m 2020-11-20 11:45:45,632	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146619)[0m Traceback (most recent call last):
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146619)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146619)[0m     param_dset[:] = val
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146619)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146619)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146619)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146619)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146619)[0m , filename = '/tmp/thalvari/4065561/automl_save_n_fwv60x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8daa9bda48, total write size = 603496, bytes this sub-write = 603496, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m Traceback (most recent call last):
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146619)[0m     self._entrypoint()
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146619)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146619)[0m     output = train_func(config, reporter)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146619)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146619)[0m     config=config)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146619)[0m     model.save(model_path, config_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146619)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146619)[0m     self.model.save(model_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146619)[0m     signatures)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146619)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146619)[0m     f.close()
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146619)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146619)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146619)[0m , filename = '/tmp/thalvari/4065561/automl_save_n_fwv60x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8da9664a10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146619)[0m Exception in thread Thread-1:
[2m[36m(pid=146619)[0m Traceback (most recent call last):
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146619)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146619)[0m     param_dset[:] = val
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146619)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146619)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146619)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146619)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146619)[0m , filename = '/tmp/thalvari/4065561/automl_save_n_fwv60x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8daa9bda48, total write size = 603496, bytes this sub-write = 603496, bytes actually written = 18446744073709551615, offset = 667648)
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m Traceback (most recent call last):
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146619)[0m     self._entrypoint()
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146619)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146619)[0m     output = train_func(config, reporter)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146619)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146619)[0m     config=config)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146619)[0m     model.save(model_path, config_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146619)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146619)[0m     self.model.save(model_path)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146619)[0m     signatures)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146619)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146619)[0m     f.close()
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146619)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146619)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146619)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:45 2020
[2m[36m(pid=146619)[0m , filename = '/tmp/thalvari/4065561/automl_save_n_fwv60x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8da9664a10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m Traceback (most recent call last):
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146619)[0m     self.run()
[2m[36m(pid=146619)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146619)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146619)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146613)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146613)[0m Instructions for updating:
[2m[36m(pid=146613)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146625)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=146625)[0m   agg_primitives: ['count']
[2m[36m(pid=146625)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=146625)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:45:46,556	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146628, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:46,559	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_81_batch_size_log=7.9063,bayes_feature_DAY(timestamp)=0.47796,bayes_feature_HOUR(timestamp)=0.78806,bayes_feature_IS_AWAKE(timestamp)=0.69734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.41185,bayes_feature_IS_WEEKEND(timestamp)=0.82982,bayes_feature_MONTH(timestamp)=0.89016,bayes_feature_WEEKDAY(timestamp)=0.99021,dropout_1=0.47295,dropout_2=0.22686,epochs=5,lr=0.0055894,lstm_1_units_float=8.1674,lstm_2_units_float=121.64,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146629)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146629)[0m 2020-11-20 11:45:46.621266: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146629)[0m 2020-11-20 11:45:46.664927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146629)[0m 2020-11-20 11:45:46.669202: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f24bd089400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146629)[0m 2020-11-20 11:45:46.669227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146628)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146628)[0m 
[2m[36m(pid=146628)[0m Stack (most recent call first):
[2m[36m(pid=146625)[0m LSTM is selected.
[2m[36m(pid=146625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=146625)[0m Instructions for updating:
[2m[36m(pid=146625)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=146613)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146613)[0m 2020-11-20 11:45:46.990704: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146613)[0m 2020-11-20 11:45:47.001063: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146613)[0m 2020-11-20 11:45:47.004798: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f13750d16c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146613)[0m 2020-11-20 11:45:47.004839: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:45:47,234	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146619, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:47,239	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_82_batch_size_log=9.047,bayes_feature_DAY(timestamp)=0.43343,bayes_feature_HOUR(timestamp)=0.88231,bayes_feature_IS_AWAKE(timestamp)=0.95473,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69723,bayes_feature_IS_WEEKEND(timestamp)=0.45888,bayes_feature_MONTH(timestamp)=0.51061,bayes_feature_WEEKDAY(timestamp)=0.6605,dropout_1=0.41826,dropout_2=0.34047,epochs=5,lr=0.0080811,lstm_1_units_float=8.2536,lstm_2_units_float=121.61,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146619)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146619)[0m 
[2m[36m(pid=146619)[0m Stack (most recent call first):
[2m[36m(pid=146625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=146625)[0m Instructions for updating:
[2m[36m(pid=146625)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=146621)[0m 2020-11-20 11:45:47,655	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146621)[0m Traceback (most recent call last):
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146621)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146621)[0m     param_dset[:] = val
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146621)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146621)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146621)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146621)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146621)[0m , filename = '/tmp/thalvari/4065561/automl_save_j90yy19n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee4ea15ad8, total write size = 607640, bytes this sub-write = 607640, bytes actually written = 18446744073709551615, offset = 651264)
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m Traceback (most recent call last):
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146621)[0m     self._entrypoint()
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146621)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146621)[0m     output = train_func(config, reporter)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146621)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146621)[0m     config=config)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146621)[0m     model.save(model_path, config_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146621)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146621)[0m     self.model.save(model_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146621)[0m     signatures)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146621)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146621)[0m     f.close()
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146621)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146621)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146621)[0m , filename = '/tmp/thalvari/4065561/automl_save_j90yy19n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee4e94ac30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146621)[0m Exception in thread Thread-1:
[2m[36m(pid=146621)[0m Traceback (most recent call last):
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146621)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146621)[0m     param_dset[:] = val
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146621)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146621)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146621)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146621)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146621)[0m , filename = '/tmp/thalvari/4065561/automl_save_j90yy19n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee4ea15ad8, total write size = 607640, bytes this sub-write = 607640, bytes actually written = 18446744073709551615, offset = 651264)
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m Traceback (most recent call last):
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146621)[0m     self._entrypoint()
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146621)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146621)[0m     output = train_func(config, reporter)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146621)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146621)[0m     config=config)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146621)[0m     model.save(model_path, config_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146621)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146621)[0m     self.model.save(model_path)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146621)[0m     signatures)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146621)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146621)[0m     f.close()
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146621)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146621)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146621)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146621)[0m , filename = '/tmp/thalvari/4065561/automl_save_j90yy19n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7eee4e94ac30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m Traceback (most recent call last):
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146621)[0m     self.run()
[2m[36m(pid=146621)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146621)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146621)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146617)[0m 2020-11-20 11:45:47,881	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146617)[0m Traceback (most recent call last):
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146617)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146617)[0m     param_dset[:] = val
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146617)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146617)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146617)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146617)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146617)[0m , filename = '/tmp/thalvari/4065561/automl_save_0z1zl862/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f221a9a1748, total write size = 644456, bytes this sub-write = 644456, bytes actually written = 18446744073709551615, offset = 651264)
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m Traceback (most recent call last):
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146617)[0m     self._entrypoint()
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146617)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146617)[0m     output = train_func(config, reporter)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146617)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146617)[0m     config=config)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146617)[0m     model.save(model_path, config_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146617)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146617)[0m     self.model.save(model_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146617)[0m     signatures)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146617)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146617)[0m     f.close()
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146617)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146617)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146617)[0m , filename = '/tmp/thalvari/4065561/automl_save_0z1zl862/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2219f38270, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146617)[0m Exception in thread Thread-1:
[2m[36m(pid=146617)[0m Traceback (most recent call last):
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146617)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146617)[0m     param_dset[:] = val
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146617)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146617)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146617)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146617)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146617)[0m , filename = '/tmp/thalvari/4065561/automl_save_0z1zl862/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f221a9a1748, total write size = 644456, bytes this sub-write = 644456, bytes actually written = 18446744073709551615, offset = 651264)
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m Traceback (most recent call last):
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146617)[0m     self._entrypoint()
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146617)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146617)[0m     output = train_func(config, reporter)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146617)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146617)[0m     config=config)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146617)[0m     model.save(model_path, config_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146617)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146617)[0m     self.model.save(model_path)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146617)[0m     signatures)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146617)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146617)[0m     f.close()
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146617)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146617)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146617)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:47 2020
[2m[36m(pid=146617)[0m , filename = '/tmp/thalvari/4065561/automl_save_0z1zl862/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2219f38270, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m Traceback (most recent call last):
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146617)[0m     self.run()
[2m[36m(pid=146617)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146617)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146617)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146617)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 91 ({'TERMINATED': 23, 'ERROR': 58, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 52 not shown
 - train_func_79_batch_size_log=6.4476,bayes_feature_DAY(timestamp)=0.35409,bayes_feature_HOUR(timestamp)=0.47132,bayes_feature_IS_AWAKE(timestamp)=0.99912,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59259,bayes_feature_IS_WEEKEND(timestamp)=0.75495,bayes_feature_MONTH(timestamp)=0.50101,bayes_feature_WEEKDAY(timestamp)=0.50292,dropout_1=0.27959,dropout_2=0.32477,epochs=5,lr=0.0093141,lstm_1_units_float=8.1193,lstm_2_units_float=120.54,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_79_batch_size_log=6.4476,bayes_feature_DAY(timestamp)=0.35409,bayes_feature_HOUR(timestamp)=0.47132,bayes_feature_IS_AW_2020-11-20_11-45-32trv12ll0/error_2020-11-20_11-45-45.txt
 - train_func_81_batch_size_log=7.9063,bayes_feature_DAY(timestamp)=0.47796,bayes_feature_HOUR(timestamp)=0.78806,bayes_feature_IS_AWAKE(timestamp)=0.69734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.41185,bayes_feature_IS_WEEKEND(timestamp)=0.82982,bayes_feature_MONTH(timestamp)=0.89016,bayes_feature_WEEKDAY(timestamp)=0.99021,dropout_1=0.47295,dropout_2=0.22686,epochs=5,lr=0.0055894,lstm_1_units_float=8.1674,lstm_2_units_float=121.64,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_81_batch_size_log=7.9063,bayes_feature_DAY(timestamp)=0.47796,bayes_feature_HOUR(timestamp)=0.78806,bayes_feature_IS_AW_2020-11-20_11-45-37i32ttae5/error_2020-11-20_11-45-46.txt
 - train_func_82_batch_size_log=9.047,bayes_feature_DAY(timestamp)=0.43343,bayes_feature_HOUR(timestamp)=0.88231,bayes_feature_IS_AWAKE(timestamp)=0.95473,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69723,bayes_feature_IS_WEEKEND(timestamp)=0.45888,bayes_feature_MONTH(timestamp)=0.51061,bayes_feature_WEEKDAY(timestamp)=0.6605,dropout_1=0.41826,dropout_2=0.34047,epochs=5,lr=0.0080811,lstm_1_units_float=8.2536,lstm_2_units_float=121.61,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_82_batch_size_log=9.047,bayes_feature_DAY(timestamp)=0.43343,bayes_feature_HOUR(timestamp)=0.88231,bayes_feature_IS_AWA_2020-11-20_11-45-38ol5639hy/error_2020-11-20_11-45-47.txt
RUNNING trials:
 - train_func_80_batch_size_log=5.1565,bayes_feature_DAY(timestamp)=0.32028,bayes_feature_HOUR(timestamp)=0.33162,bayes_feature_IS_AWAKE(timestamp)=0.34719,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.88836,bayes_feature_WEEKDAY(timestamp)=0.94116,dropout_1=0.2,dropout_2=0.49177,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=123.18,past_seq_len=2:	RUNNING
 - train_func_83_batch_size_log=8.3604,bayes_feature_DAY(timestamp)=0.46428,bayes_feature_HOUR(timestamp)=0.98037,bayes_feature_IS_AWAKE(timestamp)=0.60197,bayes_feature_IS_BUSY_HOURS(timestamp)=0.94598,bayes_feature_IS_WEEKEND(timestamp)=0.55455,bayes_feature_MONTH(timestamp)=0.5878,bayes_feature_WEEKDAY(timestamp)=0.59082,dropout_1=0.3871,dropout_2=0.20521,epochs=5,lr=0.0016872,lstm_1_units_float=8.289,lstm_2_units_float=120.41,past_seq_len=2:	RUNNING
 - train_func_84_batch_size_log=7.4406,bayes_feature_DAY(timestamp)=0.45163,bayes_feature_HOUR(timestamp)=0.72245,bayes_feature_IS_AWAKE(timestamp)=0.60863,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34487,bayes_feature_IS_WEEKEND(timestamp)=0.93305,bayes_feature_MONTH(timestamp)=0.85336,bayes_feature_WEEKDAY(timestamp)=0.84714,dropout_1=0.44433,dropout_2=0.42566,epochs=5,lr=0.0029853,lstm_1_units_float=8.0568,lstm_2_units_float=122.63,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_89_batch_size_log=5.765,bayes_feature_DAY(timestamp)=0.86298,bayes_feature_HOUR(timestamp)=0.70328,bayes_feature_IS_AWAKE(timestamp)=0.65694,bayes_feature_IS_BUSY_HOURS(timestamp)=0.58587,bayes_feature_IS_WEEKEND(timestamp)=0.97612,bayes_feature_MONTH(timestamp)=0.74815,bayes_feature_WEEKDAY(timestamp)=0.77001,dropout_1=0.42945,dropout_2=0.2,epochs=5,lr=0.004444,lstm_1_units_float=8.0,lstm_2_units_float=120.93,past_seq_len=2:	RUNNING
 - train_func_90_batch_size_log=7.6026,bayes_feature_DAY(timestamp)=0.46665,bayes_feature_HOUR(timestamp)=0.50019,bayes_feature_IS_AWAKE(timestamp)=0.89553,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48233,bayes_feature_IS_WEEKEND(timestamp)=0.78779,bayes_feature_MONTH(timestamp)=0.37531,bayes_feature_WEEKDAY(timestamp)=0.76388,dropout_1=0.39771,dropout_2=0.45127,epochs=5,lr=0.0024007,lstm_1_units_float=8.4014,lstm_2_units_float=120.84,past_seq_len=2:	RUNNING
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.30235,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84954,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.30126,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.31578,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=146625)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=146625)[0m 2020-11-20 11:45:48.544454: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=146625)[0m 2020-11-20 11:45:48.553076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=146625)[0m 2020-11-20 11:45:48.556789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1e890ea230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=146625)[0m 2020-11-20 11:45:48.556817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146624)[0m 2020-11-20 11:45:48,643	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146624)[0m Traceback (most recent call last):
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146624)[0m     param_dset[:] = val
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146624)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:48 2020
[2m[36m(pid=146624)[0m , filename = '/tmp/thalvari/4065561/automl_save_b3ba69s_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad5235da08, total write size = 640344, bytes this sub-write = 640344, bytes actually written = 18446744073709551615, offset = 643072)
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m Traceback (most recent call last):
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146624)[0m     self._entrypoint()
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146624)[0m     output = train_func(config, reporter)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146624)[0m     config=config)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146624)[0m     model.save(model_path, config_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146624)[0m     self.model.save(model_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146624)[0m     signatures)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146624)[0m     f.close()
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146624)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:48 2020
[2m[36m(pid=146624)[0m , filename = '/tmp/thalvari/4065561/automl_save_b3ba69s_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad51911cb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146624)[0m Exception in thread Thread-1:
[2m[36m(pid=146624)[0m Traceback (most recent call last):
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146624)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146624)[0m     param_dset[:] = val
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146624)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146624)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146624)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146624)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:48 2020
[2m[36m(pid=146624)[0m , filename = '/tmp/thalvari/4065561/automl_save_b3ba69s_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad5235da08, total write size = 640344, bytes this sub-write = 640344, bytes actually written = 18446744073709551615, offset = 643072)
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m Traceback (most recent call last):
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146624)[0m     self._entrypoint()
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146624)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146624)[0m     output = train_func(config, reporter)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146624)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146624)[0m     config=config)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146624)[0m     model.save(model_path, config_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146624)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146624)[0m     self.model.save(model_path)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146624)[0m     signatures)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146624)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146624)[0m     f.close()
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146624)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146624)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146624)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:48 2020
[2m[36m(pid=146624)[0m , filename = '/tmp/thalvari/4065561/automl_save_b3ba69s_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fad51911cb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m Traceback (most recent call last):
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146624)[0m     self.run()
[2m[36m(pid=146624)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146624)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146624)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146624)[0m 
2020-11-20 11:45:48,805	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146621, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:48,808	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_83_batch_size_log=8.3604,bayes_feature_DAY(timestamp)=0.46428,bayes_feature_HOUR(timestamp)=0.98037,bayes_feature_IS_AWAKE(timestamp)=0.60197,bayes_feature_IS_BUSY_HOURS(timestamp)=0.94598,bayes_feature_IS_WEEKEND(timestamp)=0.55455,bayes_feature_MONTH(timestamp)=0.5878,bayes_feature_WEEKDAY(timestamp)=0.59082,dropout_1=0.3871,dropout_2=0.20521,epochs=5,lr=0.0016872,lstm_1_units_float=8.289,lstm_2_units_float=120.41,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146621)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146621)[0m 
[2m[36m(pid=146621)[0m Stack (most recent call first):
[2m[36m(pid=150249)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150249)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2020-11-20 11:45:49,683	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146617, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:49,687	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_80_batch_size_log=5.1565,bayes_feature_DAY(timestamp)=0.32028,bayes_feature_HOUR(timestamp)=0.33162,bayes_feature_IS_AWAKE(timestamp)=0.34719,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.88836,bayes_feature_WEEKDAY(timestamp)=0.94116,dropout_1=0.2,dropout_2=0.49177,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=123.18,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=149476)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=149476)[0m   agg_primitives: ['count']
[2m[36m(pid=149476)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=149476)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=149520)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=149520)[0m   agg_primitives: ['count']
[2m[36m(pid=149520)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=149520)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=146617)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146617)[0m 
[2m[36m(pid=146617)[0m Stack (most recent call first):
[2m[36m(pid=150415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150416)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150417)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150537)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150415)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150535)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150535)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150416)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150417)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150537)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=149476)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=149476)[0m Instructions for updating:
[2m[36m(pid=149476)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=149476)[0m LSTM is selected.
[2m[36m(pid=149520)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=149520)[0m Instructions for updating:
[2m[36m(pid=149520)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=149520)[0m LSTM is selected.
2020-11-20 11:45:50,705	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146624, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:50,709	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_84_batch_size_log=7.4406,bayes_feature_DAY(timestamp)=0.45163,bayes_feature_HOUR(timestamp)=0.72245,bayes_feature_IS_AWAKE(timestamp)=0.60863,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34487,bayes_feature_IS_WEEKEND(timestamp)=0.93305,bayes_feature_MONTH(timestamp)=0.85336,bayes_feature_WEEKDAY(timestamp)=0.84714,dropout_1=0.44433,dropout_2=0.42566,epochs=5,lr=0.0029853,lstm_1_units_float=8.0568,lstm_2_units_float=122.63,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146624)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146624)[0m 
[2m[36m(pid=146624)[0m Stack (most recent call first):
[2m[36m(pid=149562)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=149562)[0m   agg_primitives: ['count']
[2m[36m(pid=149562)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=149562)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=149476)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=149476)[0m Instructions for updating:
[2m[36m(pid=149476)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=149520)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=149520)[0m Instructions for updating:
[2m[36m(pid=149520)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=150626)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150634)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150630)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150625)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150627)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=146613)[0m 2020-11-20 11:45:51,503	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146613)[0m Traceback (most recent call last):
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146613)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146613)[0m     param_dset[:] = val
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146613)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146613)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146613)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146613)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:51 2020
[2m[36m(pid=146613)[0m , filename = '/tmp/thalvari/4065561/automl_save_emp_194y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1376274c28, total write size = 714136, bytes this sub-write = 714136, bytes actually written = 18446744073709551615, offset = 544768)
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m Traceback (most recent call last):
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146613)[0m     self._entrypoint()
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146613)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146613)[0m     output = train_func(config, reporter)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146613)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146613)[0m     config=config)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146613)[0m     model.save(model_path, config_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146613)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146613)[0m     self.model.save(model_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146613)[0m     signatures)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146613)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146613)[0m     f.close()
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146613)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146613)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:51 2020
[2m[36m(pid=146613)[0m , filename = '/tmp/thalvari/4065561/automl_save_emp_194y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1376a1f720, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146613)[0m Exception in thread Thread-1:
[2m[36m(pid=146613)[0m Traceback (most recent call last):
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146613)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146613)[0m     param_dset[:] = val
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146613)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146613)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146613)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146613)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:51 2020
[2m[36m(pid=146613)[0m , filename = '/tmp/thalvari/4065561/automl_save_emp_194y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1376274c28, total write size = 714136, bytes this sub-write = 714136, bytes actually written = 18446744073709551615, offset = 544768)
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m Traceback (most recent call last):
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146613)[0m     self._entrypoint()
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146613)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146613)[0m     output = train_func(config, reporter)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146613)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146613)[0m     config=config)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146613)[0m     model.save(model_path, config_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146613)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146613)[0m     self.model.save(model_path)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146613)[0m     signatures)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146613)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146613)[0m     f.close()
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146613)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146613)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146613)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:51 2020
[2m[36m(pid=146613)[0m , filename = '/tmp/thalvari/4065561/automl_save_emp_194y/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f1376a1f720, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=149562)[0m Instructions for updating:
[2m[36m(pid=149562)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=149562)[0m LSTM is selected.
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m Traceback (most recent call last):
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146613)[0m     self.run()
[2m[36m(pid=146613)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146613)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146613)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146613)[0m 
[2m[36m(pid=149476)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=149476)[0m 2020-11-20 11:45:51.992193: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=149476)[0m 2020-11-20 11:45:52.000716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=149476)[0m 2020-11-20 11:45:52.004133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6d010e9fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=149476)[0m 2020-11-20 11:45:52.004182: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=149520)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=149520)[0m 2020-11-20 11:45:52.204203: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=149520)[0m 2020-11-20 11:45:52.212386: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=149520)[0m 2020-11-20 11:45:52.214854: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7c1119fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=149520)[0m 2020-11-20 11:45:52.214881: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=149562)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=149562)[0m Instructions for updating:
[2m[36m(pid=149562)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:52,566	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146613, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:52,569	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_86_batch_size_log=7.0736,bayes_feature_DAY(timestamp)=0.64458,bayes_feature_HOUR(timestamp)=0.48578,bayes_feature_IS_AWAKE(timestamp)=0.46811,bayes_feature_IS_BUSY_HOURS(timestamp)=0.825,bayes_feature_IS_WEEKEND(timestamp)=0.96393,bayes_feature_MONTH(timestamp)=0.63487,bayes_feature_WEEKDAY(timestamp)=0.43586,dropout_1=0.42094,dropout_2=0.30982,epochs=5,lr=0.002893,lstm_1_units_float=8.073,lstm_2_units_float=120.57,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146613)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146613)[0m 
[2m[36m(pid=146613)[0m Stack (most recent call first):
[2m[36m(pid=149562)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=149562)[0m 2020-11-20 11:45:53.276263: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.7/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 95 ({'TERMINATED': 23, 'ERROR': 62, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 56 not shown
 - train_func_83_batch_size_log=8.3604,bayes_feature_DAY(timestamp)=0.46428,bayes_feature_HOUR(timestamp)=0.98037,bayes_feature_IS_AWAKE(timestamp)=0.60197,bayes_feature_IS_BUSY_HOURS(timestamp)=0.94598,bayes_feature_IS_WEEKEND(timestamp)=0.55455,bayes_feature_MONTH(timestamp)=0.5878,bayes_feature_WEEKDAY(timestamp)=0.59082,dropout_1=0.3871,dropout_2=0.20521,epochs=5,lr=0.0016872,lstm_1_units_float=8.289,lstm_2_units_float=120.41,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_83_batch_size_log=8.3604,bayes_feature_DAY(timestamp)=0.46428,bayes_feature_HOUR(timestamp)=0.98037,bayes_feature_IS_AW_2020-11-20_11-45-38_8ls61qz/error_2020-11-20_11-45-48.txt
 - train_func_84_batch_size_log=7.4406,bayes_feature_DAY(timestamp)=0.45163,bayes_feature_HOUR(timestamp)=0.72245,bayes_feature_IS_AWAKE(timestamp)=0.60863,bayes_feature_IS_BUSY_HOURS(timestamp)=0.34487,bayes_feature_IS_WEEKEND(timestamp)=0.93305,bayes_feature_MONTH(timestamp)=0.85336,bayes_feature_WEEKDAY(timestamp)=0.84714,dropout_1=0.44433,dropout_2=0.42566,epochs=5,lr=0.0029853,lstm_1_units_float=8.0568,lstm_2_units_float=122.63,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_84_batch_size_log=7.4406,bayes_feature_DAY(timestamp)=0.45163,bayes_feature_HOUR(timestamp)=0.72245,bayes_feature_IS_AW_2020-11-20_11-45-39zwlm0huc/error_2020-11-20_11-45-50.txt
 - train_func_86_batch_size_log=7.0736,bayes_feature_DAY(timestamp)=0.64458,bayes_feature_HOUR(timestamp)=0.48578,bayes_feature_IS_AWAKE(timestamp)=0.46811,bayes_feature_IS_BUSY_HOURS(timestamp)=0.825,bayes_feature_IS_WEEKEND(timestamp)=0.96393,bayes_feature_MONTH(timestamp)=0.63487,bayes_feature_WEEKDAY(timestamp)=0.43586,dropout_1=0.42094,dropout_2=0.30982,epochs=5,lr=0.002893,lstm_1_units_float=8.073,lstm_2_units_float=120.57,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_86_batch_size_log=7.0736,bayes_feature_DAY(timestamp)=0.64458,bayes_feature_HOUR(timestamp)=0.48578,bayes_feature_IS_AW_2020-11-20_11-45-41opklkeyq/error_2020-11-20_11-45-52.txt
RUNNING trials:
 - train_func_85_batch_size_log=5.5976,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.42421,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.29,past_seq_len=2:	RUNNING
 - train_func_87_batch_size_log=6.183,bayes_feature_DAY(timestamp)=0.89071,bayes_feature_HOUR(timestamp)=0.8331,bayes_feature_IS_AWAKE(timestamp)=0.72754,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60982,bayes_feature_IS_WEEKEND(timestamp)=0.39564,bayes_feature_MONTH(timestamp)=0.34845,bayes_feature_WEEKDAY(timestamp)=0.80308,dropout_1=0.46305,dropout_2=0.43255,epochs=5,lr=0.0097357,lstm_1_units_float=8.2413,lstm_2_units_float=121.27,past_seq_len=2:	RUNNING
 - train_func_88_batch_size_log=9.617,bayes_feature_DAY(timestamp)=0.86066,bayes_feature_HOUR(timestamp)=0.79906,bayes_feature_IS_AWAKE(timestamp)=0.46926,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59719,bayes_feature_IS_WEEKEND(timestamp)=0.8648,bayes_feature_MONTH(timestamp)=0.41983,bayes_feature_WEEKDAY(timestamp)=0.58533,dropout_1=0.24854,dropout_2=0.45933,epochs=5,lr=0.0028035,lstm_1_units_float=8.0724,lstm_2_units_float=120.92,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_93_batch_size_log=8.6123,bayes_feature_DAY(timestamp)=0.41858,bayes_feature_HOUR(timestamp)=0.90959,bayes_feature_IS_AWAKE(timestamp)=0.37565,bayes_feature_IS_BUSY_HOURS(timestamp)=0.32132,bayes_feature_IS_WEEKEND(timestamp)=0.45869,bayes_feature_MONTH(timestamp)=0.64144,bayes_feature_WEEKDAY(timestamp)=0.71347,dropout_1=0.34547,dropout_2=0.49937,epochs=5,lr=0.0021835,lstm_1_units_float=8.2807,lstm_2_units_float=118.02,past_seq_len=2:	RUNNING
 - train_func_94_batch_size_log=8.9367,bayes_feature_DAY(timestamp)=0.58151,bayes_feature_HOUR(timestamp)=0.40448,bayes_feature_IS_AWAKE(timestamp)=0.65561,bayes_feature_IS_BUSY_HOURS(timestamp)=0.62828,bayes_feature_IS_WEEKEND(timestamp)=0.68182,bayes_feature_MONTH(timestamp)=0.61924,bayes_feature_WEEKDAY(timestamp)=0.7675,dropout_1=0.28472,dropout_2=0.48119,epochs=5,lr=0.0030739,lstm_1_units_float=8.2713,lstm_2_units_float=119.44,past_seq_len=2:	RUNNING
 - train_func_95_batch_size_log=5.4872,bayes_feature_DAY(timestamp)=0.69302,bayes_feature_HOUR(timestamp)=0.47378,bayes_feature_IS_AWAKE(timestamp)=0.61835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.57416,bayes_feature_IS_WEEKEND(timestamp)=0.90439,bayes_feature_MONTH(timestamp)=0.93161,bayes_feature_WEEKDAY(timestamp)=0.49617,dropout_1=0.45942,dropout_2=0.34544,epochs=5,lr=0.00519,lstm_1_units_float=8.1454,lstm_2_units_float=119.88,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=146629)[0m 2020-11-20 11:45:53,309	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146629)[0m Traceback (most recent call last):
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146629)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146629)[0m     param_dset[:] = val
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146629)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146629)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146629)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146629)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:53 2020
[2m[36m(pid=146629)[0m , filename = '/tmp/thalvari/4065561/automl_save_nhxh7gfn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24be7c42d8, total write size = 734568, bytes this sub-write = 734568, bytes actually written = 18446744073709551615, offset = 536576)
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m Traceback (most recent call last):
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146629)[0m     self._entrypoint()
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146629)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146629)[0m     output = train_func(config, reporter)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146629)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146629)[0m     config=config)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146629)[0m     model.save(model_path, config_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146629)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146629)[0m     self.model.save(model_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146629)[0m     signatures)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146629)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146629)[0m     f.close()
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146629)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146629)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:53 2020
[2m[36m(pid=146629)[0m , filename = '/tmp/thalvari/4065561/automl_save_nhxh7gfn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24be38def0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146629)[0m Exception in thread Thread-1:
[2m[36m(pid=146629)[0m Traceback (most recent call last):
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146629)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146629)[0m     param_dset[:] = val
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146629)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146629)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146629)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146629)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:53 2020
[2m[36m(pid=146629)[0m , filename = '/tmp/thalvari/4065561/automl_save_nhxh7gfn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24be7c42d8, total write size = 734568, bytes this sub-write = 734568, bytes actually written = 18446744073709551615, offset = 536576)
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m Traceback (most recent call last):
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146629)[0m     self._entrypoint()
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146629)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146629)[0m     output = train_func(config, reporter)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146629)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146629)[0m     config=config)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146629)[0m     model.save(model_path, config_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146629)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146629)[0m     self.model.save(model_path)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146629)[0m     signatures)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146629)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146629)[0m     f.close()
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146629)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146629)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146629)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:53 2020
[2m[36m(pid=146629)[0m , filename = '/tmp/thalvari/4065561/automl_save_nhxh7gfn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f24be38def0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149562)[0m 2020-11-20 11:45:53.284511: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=149562)[0m 2020-11-20 11:45:53.286613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f07f90d1a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=149562)[0m 2020-11-20 11:45:53.286650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m Traceback (most recent call last):
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146629)[0m     self.run()
[2m[36m(pid=146629)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146629)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146629)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146625)[0m 2020-11-20 11:45:54,163	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=146625)[0m Traceback (most recent call last):
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146625)[0m     param_dset[:] = val
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146625)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=146625)[0m , filename = '/tmp/thalvari/4065561/automl_save_b35mr1d5/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1e8a98fab8, total write size = 742760, bytes this sub-write = 742760, bytes actually written = 18446744073709551615, offset = 528384)
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m Traceback (most recent call last):
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146625)[0m     self._entrypoint()
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146625)[0m     output = train_func(config, reporter)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146625)[0m     config=config)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146625)[0m     model.save(model_path, config_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146625)[0m     self.model.save(model_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146625)[0m     signatures)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146625)[0m     f.close()
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146625)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=146625)[0m , filename = '/tmp/thalvari/4065561/automl_save_b35mr1d5/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1e8a208590, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146625)[0m Exception in thread Thread-1:
[2m[36m(pid=146625)[0m Traceback (most recent call last):
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=146625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=146625)[0m     param_dset[:] = val
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=146625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=146625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=146625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=146625)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=146625)[0m , filename = '/tmp/thalvari/4065561/automl_save_b35mr1d5/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1e8a98fab8, total write size = 742760, bytes this sub-write = 742760, bytes actually written = 18446744073709551615, offset = 528384)
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m Traceback (most recent call last):
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=146625)[0m     self._entrypoint()
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=146625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=146625)[0m     output = train_func(config, reporter)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=146625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=146625)[0m     config=config)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=146625)[0m     model.save(model_path, config_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=146625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=146625)[0m     self.model.save(model_path)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=146625)[0m     signatures)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=146625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=146625)[0m     f.close()
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=146625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=146625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=146625)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=146625)[0m , filename = '/tmp/thalvari/4065561/automl_save_b35mr1d5/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f1e8a208590, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m Traceback (most recent call last):
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=146625)[0m     self.run()
[2m[36m(pid=146625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=146625)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=146625)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=146625)[0m 
2020-11-20 11:45:54,416	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146629, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:54,419	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_85_batch_size_log=5.5976,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.3,bayes_feature_IS_WEEKEND(timestamp)=0.42421,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.29,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146629)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146629)[0m 
[2m[36m(pid=146629)[0m Stack (most recent call first):
[2m[36m(pid=150535)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150535)[0m   agg_primitives: ['count']
[2m[36m(pid=150535)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150535)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150249)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150249)[0m   agg_primitives: ['count']
[2m[36m(pid=150249)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150249)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150417)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150417)[0m   agg_primitives: ['count']
[2m[36m(pid=150417)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150417)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=149476)[0m 2020-11-20 11:45:54,777	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=149476)[0m Traceback (most recent call last):
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149476)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149476)[0m     param_dset[:] = val
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149476)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149476)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149476)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149476)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=149476)[0m , filename = '/tmp/thalvari/4065561/automl_save_x3o4cigi/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f6d02990cc8, total write size = 738712, bytes this sub-write = 738712, bytes actually written = 18446744073709551615, offset = 520192)
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m Traceback (most recent call last):
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149476)[0m     self._entrypoint()
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149476)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149476)[0m     output = train_func(config, reporter)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149476)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149476)[0m     config=config)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149476)[0m     model.save(model_path, config_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149476)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149476)[0m     self.model.save(model_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149476)[0m     signatures)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149476)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149476)[0m     f.close()
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149476)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149476)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=149476)[0m , filename = '/tmp/thalvari/4065561/automl_save_x3o4cigi/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f6d0188cae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149476)[0m Exception in thread Thread-1:
[2m[36m(pid=149476)[0m Traceback (most recent call last):
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149476)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149476)[0m     param_dset[:] = val
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149476)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149476)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149476)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149476)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=149476)[0m , filename = '/tmp/thalvari/4065561/automl_save_x3o4cigi/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f6d02990cc8, total write size = 738712, bytes this sub-write = 738712, bytes actually written = 18446744073709551615, offset = 520192)
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m Traceback (most recent call last):
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149476)[0m     self._entrypoint()
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149476)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149476)[0m     output = train_func(config, reporter)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149476)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149476)[0m     config=config)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149476)[0m     model.save(model_path, config_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149476)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149476)[0m     self.model.save(model_path)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149476)[0m     signatures)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149476)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149476)[0m     f.close()
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149476)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149476)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149476)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:54 2020
[2m[36m(pid=149476)[0m , filename = '/tmp/thalvari/4065561/automl_save_x3o4cigi/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f6d0188cae0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m Traceback (most recent call last):
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=149476)[0m     self.run()
[2m[36m(pid=149476)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=149476)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=149476)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=149476)[0m 
[2m[36m(pid=150535)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150535)[0m Instructions for updating:
[2m[36m(pid=150535)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150535)[0m LSTM is selected.
[2m[36m(pid=150249)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150249)[0m Instructions for updating:
[2m[36m(pid=150249)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150249)[0m LSTM is selected.
[2m[36m(pid=150417)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150417)[0m Instructions for updating:
[2m[36m(pid=150417)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150417)[0m LSTM is selected.
2020-11-20 11:45:55,351	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=146625, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:55,355	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_87_batch_size_log=6.183,bayes_feature_DAY(timestamp)=0.89071,bayes_feature_HOUR(timestamp)=0.8331,bayes_feature_IS_AWAKE(timestamp)=0.72754,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60982,bayes_feature_IS_WEEKEND(timestamp)=0.39564,bayes_feature_MONTH(timestamp)=0.34845,bayes_feature_WEEKDAY(timestamp)=0.80308,dropout_1=0.46305,dropout_2=0.43255,epochs=5,lr=0.0097357,lstm_1_units_float=8.2413,lstm_2_units_float=121.27,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=146625)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=146625)[0m 
[2m[36m(pid=146625)[0m Stack (most recent call first):
[2m[36m(pid=150535)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150535)[0m Instructions for updating:
[2m[36m(pid=150535)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150625)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150625)[0m   agg_primitives: ['count']
[2m[36m(pid=150625)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150625)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150417)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150417)[0m Instructions for updating:
[2m[36m(pid=150417)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150249)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150249)[0m Instructions for updating:
[2m[36m(pid=150249)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:45:56,036	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=149476, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:56,039	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_88_batch_size_log=9.617,bayes_feature_DAY(timestamp)=0.86066,bayes_feature_HOUR(timestamp)=0.79906,bayes_feature_IS_AWAKE(timestamp)=0.46926,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59719,bayes_feature_IS_WEEKEND(timestamp)=0.8648,bayes_feature_MONTH(timestamp)=0.41983,bayes_feature_WEEKDAY(timestamp)=0.58533,dropout_1=0.24854,dropout_2=0.45933,epochs=5,lr=0.0028035,lstm_1_units_float=8.0724,lstm_2_units_float=120.92,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=149476)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=149476)[0m 
[2m[36m(pid=149476)[0m Stack (most recent call first):
[2m[36m(pid=150625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150625)[0m Instructions for updating:
[2m[36m(pid=150625)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150625)[0m LSTM is selected.
[2m[36m(pid=150627)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150627)[0m   agg_primitives: ['count']
[2m[36m(pid=150627)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150627)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=149562)[0m 2020-11-20 11:45:56,755	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=149562)[0m Traceback (most recent call last):
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149562)[0m     param_dset[:] = val
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149562)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:56 2020
[2m[36m(pid=149562)[0m , filename = '/tmp/thalvari/4065561/automl_save_8kx8yv8n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07fa3a16a8, total write size = 746904, bytes this sub-write = 746904, bytes actually written = 18446744073709551615, offset = 512000)
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m Traceback (most recent call last):
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149562)[0m     self._entrypoint()
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149562)[0m     output = train_func(config, reporter)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149562)[0m     config=config)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149562)[0m     model.save(model_path, config_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149562)[0m     self.model.save(model_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149562)[0m     signatures)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149562)[0m     f.close()
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149562)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:56 2020
[2m[36m(pid=149562)[0m , filename = '/tmp/thalvari/4065561/automl_save_8kx8yv8n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f9af1350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149562)[0m Exception in thread Thread-1:
[2m[36m(pid=149562)[0m Traceback (most recent call last):
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149562)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149562)[0m     param_dset[:] = val
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149562)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149562)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149562)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149562)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:56 2020
[2m[36m(pid=149562)[0m , filename = '/tmp/thalvari/4065561/automl_save_8kx8yv8n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07fa3a16a8, total write size = 746904, bytes this sub-write = 746904, bytes actually written = 18446744073709551615, offset = 512000)
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m Traceback (most recent call last):
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149562)[0m     self._entrypoint()
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149562)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149562)[0m     output = train_func(config, reporter)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149562)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149562)[0m     config=config)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149562)[0m     model.save(model_path, config_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149562)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149562)[0m     self.model.save(model_path)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149562)[0m     signatures)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149562)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149562)[0m     f.close()
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149562)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149562)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149562)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:56 2020
[2m[36m(pid=149562)[0m , filename = '/tmp/thalvari/4065561/automl_save_8kx8yv8n/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f07f9af1350, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150417)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150417)[0m 2020-11-20 11:45:56.755539: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150417)[0m 2020-11-20 11:45:56.763476: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150417)[0m 2020-11-20 11:45:56.765820: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3bed119fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150417)[0m 2020-11-20 11:45:56.765861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m Traceback (most recent call last):
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=149562)[0m     self.run()
[2m[36m(pid=149562)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=149562)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=149562)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=149562)[0m 
[2m[36m(pid=150535)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150535)[0m 2020-11-20 11:45:56.807573: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150535)[0m 2020-11-20 11:45:56.815352: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150535)[0m 2020-11-20 11:45:56.817734: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f13590b9230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150535)[0m 2020-11-20 11:45:56.817768: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150625)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150625)[0m Instructions for updating:
[2m[36m(pid=150625)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150249)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150627)[0m Instructions for updating:
[2m[36m(pid=150627)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150627)[0m LSTM is selected.
[2m[36m(pid=150249)[0m 2020-11-20 11:45:56.916925: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150249)[0m 2020-11-20 11:45:56.924446: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150249)[0m 2020-11-20 11:45:56.926411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae150d1900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150249)[0m 2020-11-20 11:45:56.926445: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150627)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150627)[0m Instructions for updating:
[2m[36m(pid=150627)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150625)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150625)[0m 2020-11-20 11:45:57.803108: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150625)[0m 2020-11-20 11:45:57.810730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150625)[0m 2020-11-20 11:45:57.813002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4b75101ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150625)[0m 2020-11-20 11:45:57.813033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=149520)[0m 2020-11-20 11:45:57,843	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=149520)[0m Traceback (most recent call last):
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149520)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149520)[0m     param_dset[:] = val
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149520)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149520)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149520)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149520)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:57 2020
[2m[36m(pid=149520)[0m , filename = '/tmp/thalvari/4065561/automl_save_hlf41aik/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7c29c16e8, total write size = 755288, bytes this sub-write = 755288, bytes actually written = 18446744073709551615, offset = 503808)
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m Traceback (most recent call last):
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149520)[0m     self._entrypoint()
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149520)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149520)[0m     output = train_func(config, reporter)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149520)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149520)[0m     config=config)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149520)[0m     model.save(model_path, config_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149520)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149520)[0m     self.model.save(model_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149520)[0m     signatures)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149520)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149520)[0m     f.close()
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149520)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149520)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:57 2020
[2m[36m(pid=149520)[0m , filename = '/tmp/thalvari/4065561/automl_save_hlf41aik/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7c26d7b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149520)[0m Exception in thread Thread-1:
[2m[36m(pid=149520)[0m Traceback (most recent call last):
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=149520)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=149520)[0m     param_dset[:] = val
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=149520)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=149520)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=149520)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=149520)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:57 2020
[2m[36m(pid=149520)[0m , filename = '/tmp/thalvari/4065561/automl_save_hlf41aik/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7c29c16e8, total write size = 755288, bytes this sub-write = 755288, bytes actually written = 18446744073709551615, offset = 503808)
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m Traceback (most recent call last):
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=149520)[0m     self._entrypoint()
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=149520)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=149520)[0m     output = train_func(config, reporter)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=149520)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=149520)[0m     config=config)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=149520)[0m     model.save(model_path, config_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=149520)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=149520)[0m     self.model.save(model_path)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=149520)[0m     signatures)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=149520)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=149520)[0m     f.close()
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=149520)[0m     h5i.dec_ref(id_)
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=149520)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=149520)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:57 2020
[2m[36m(pid=149520)[0m , filename = '/tmp/thalvari/4065561/automl_save_hlf41aik/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7c26d7b90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m Traceback (most recent call last):
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=149520)[0m     self.run()
[2m[36m(pid=149520)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=149520)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=149520)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=149520)[0m 
2020-11-20 11:45:57,933	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=149562, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:57,935	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_90_batch_size_log=7.6026,bayes_feature_DAY(timestamp)=0.46665,bayes_feature_HOUR(timestamp)=0.50019,bayes_feature_IS_AWAKE(timestamp)=0.89553,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48233,bayes_feature_IS_WEEKEND(timestamp)=0.78779,bayes_feature_MONTH(timestamp)=0.37531,bayes_feature_WEEKDAY(timestamp)=0.76388,dropout_1=0.39771,dropout_2=0.45127,epochs=5,lr=0.0024007,lstm_1_units_float=8.4014,lstm_2_units_float=120.84,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=149562)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=149562)[0m 
[2m[36m(pid=149562)[0m Stack (most recent call first):
[2m[36m(pid=150626)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150626)[0m   agg_primitives: ['count']
[2m[36m(pid=150626)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150626)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150627)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150627)[0m 2020-11-20 11:45:58.471281: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150627)[0m 2020-11-20 11:45:58.482321: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150627)[0m 2020-11-20 11:45:58.485698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83e90e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150627)[0m 2020-11-20 11:45:58.485743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150634)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150634)[0m   agg_primitives: ['count']
[2m[36m(pid=150634)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150634)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150626)[0m LSTM is selected.
[2m[36m(pid=150626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150626)[0m Instructions for updating:
[2m[36m(pid=150626)[0m If using Keras pass *_constraint arguments to layers.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 99 ({'TERMINATED': 23, 'ERROR': 66, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 60 not shown
 - train_func_87_batch_size_log=6.183,bayes_feature_DAY(timestamp)=0.89071,bayes_feature_HOUR(timestamp)=0.8331,bayes_feature_IS_AWAKE(timestamp)=0.72754,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60982,bayes_feature_IS_WEEKEND(timestamp)=0.39564,bayes_feature_MONTH(timestamp)=0.34845,bayes_feature_WEEKDAY(timestamp)=0.80308,dropout_1=0.46305,dropout_2=0.43255,epochs=5,lr=0.0097357,lstm_1_units_float=8.2413,lstm_2_units_float=121.27,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_87_batch_size_log=6.183,bayes_feature_DAY(timestamp)=0.89071,bayes_feature_HOUR(timestamp)=0.8331,bayes_feature_IS_AWAK_2020-11-20_11-45-4212ctruwv/error_2020-11-20_11-45-55.txt
 - train_func_88_batch_size_log=9.617,bayes_feature_DAY(timestamp)=0.86066,bayes_feature_HOUR(timestamp)=0.79906,bayes_feature_IS_AWAKE(timestamp)=0.46926,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59719,bayes_feature_IS_WEEKEND(timestamp)=0.8648,bayes_feature_MONTH(timestamp)=0.41983,bayes_feature_WEEKDAY(timestamp)=0.58533,dropout_1=0.24854,dropout_2=0.45933,epochs=5,lr=0.0028035,lstm_1_units_float=8.0724,lstm_2_units_float=120.92,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_88_batch_size_log=9.617,bayes_feature_DAY(timestamp)=0.86066,bayes_feature_HOUR(timestamp)=0.79906,bayes_feature_IS_AWA_2020-11-20_11-45-43sm42vpzh/error_2020-11-20_11-45-56.txt
 - train_func_90_batch_size_log=7.6026,bayes_feature_DAY(timestamp)=0.46665,bayes_feature_HOUR(timestamp)=0.50019,bayes_feature_IS_AWAKE(timestamp)=0.89553,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48233,bayes_feature_IS_WEEKEND(timestamp)=0.78779,bayes_feature_MONTH(timestamp)=0.37531,bayes_feature_WEEKDAY(timestamp)=0.76388,dropout_1=0.39771,dropout_2=0.45127,epochs=5,lr=0.0024007,lstm_1_units_float=8.4014,lstm_2_units_float=120.84,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_90_batch_size_log=7.6026,bayes_feature_DAY(timestamp)=0.46665,bayes_feature_HOUR(timestamp)=0.50019,bayes_feature_IS_AW_2020-11-20_11-45-47gopxis35/error_2020-11-20_11-45-57.txt
RUNNING trials:
 - train_func_89_batch_size_log=5.765,bayes_feature_DAY(timestamp)=0.86298,bayes_feature_HOUR(timestamp)=0.70328,bayes_feature_IS_AWAKE(timestamp)=0.65694,bayes_feature_IS_BUSY_HOURS(timestamp)=0.58587,bayes_feature_IS_WEEKEND(timestamp)=0.97612,bayes_feature_MONTH(timestamp)=0.74815,bayes_feature_WEEKDAY(timestamp)=0.77001,dropout_1=0.42945,dropout_2=0.2,epochs=5,lr=0.004444,lstm_1_units_float=8.0,lstm_2_units_float=120.93,past_seq_len=2:	RUNNING
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.30235,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84954,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.30126,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.31578,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2:	RUNNING
 - train_func_92_batch_size_log=9.5573,bayes_feature_DAY(timestamp)=0.8552,bayes_feature_HOUR(timestamp)=0.84065,bayes_feature_IS_AWAKE(timestamp)=0.94087,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72365,bayes_feature_IS_WEEKEND(timestamp)=0.82862,bayes_feature_MONTH(timestamp)=0.56067,bayes_feature_WEEKDAY(timestamp)=0.67841,dropout_1=0.32244,dropout_2=0.24144,epochs=5,lr=0.0036379,lstm_1_units_float=8.1709,lstm_2_units_float=120.86,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_97_batch_size_log=6.1153,bayes_feature_DAY(timestamp)=0.88211,bayes_feature_HOUR(timestamp)=0.73007,bayes_feature_IS_AWAKE(timestamp)=0.466,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9663,bayes_feature_IS_WEEKEND(timestamp)=0.3759,bayes_feature_MONTH(timestamp)=0.42043,bayes_feature_WEEKDAY(timestamp)=0.43609,dropout_1=0.41607,dropout_2=0.42798,epochs=5,lr=0.0045934,lstm_1_units_float=8.1006,lstm_2_units_float=120.31,past_seq_len=2:	RUNNING
 - train_func_98_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_99_batch_size_log=9.6423,bayes_feature_DAY(timestamp)=0.39001,bayes_feature_HOUR(timestamp)=0.77117,bayes_feature_IS_AWAKE(timestamp)=0.95917,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48848,bayes_feature_IS_WEEKEND(timestamp)=0.83858,bayes_feature_MONTH(timestamp)=0.96779,bayes_feature_WEEKDAY(timestamp)=0.40396,dropout_1=0.323,dropout_2=0.31653,epochs=5,lr=0.0042258,lstm_1_units_float=8.1864,lstm_2_units_float=123.79,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

2020-11-20 11:45:59,038	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=149520, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:45:59,041	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_89_batch_size_log=5.765,bayes_feature_DAY(timestamp)=0.86298,bayes_feature_HOUR(timestamp)=0.70328,bayes_feature_IS_AWAKE(timestamp)=0.65694,bayes_feature_IS_BUSY_HOURS(timestamp)=0.58587,bayes_feature_IS_WEEKEND(timestamp)=0.97612,bayes_feature_MONTH(timestamp)=0.74815,bayes_feature_WEEKDAY(timestamp)=0.77001,dropout_1=0.42945,dropout_2=0.2,epochs=5,lr=0.004444,lstm_1_units_float=8.0,lstm_2_units_float=120.93,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=149520)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=149520)[0m 
[2m[36m(pid=149520)[0m Stack (most recent call first):
[2m[36m(pid=150634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150634)[0m Instructions for updating:
[2m[36m(pid=150634)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150634)[0m LSTM is selected.
[2m[36m(pid=150626)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150626)[0m Instructions for updating:
[2m[36m(pid=150626)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150630)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150630)[0m   agg_primitives: ['count']
[2m[36m(pid=150630)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150630)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150417)[0m 2020-11-20 11:45:59,631	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150417)[0m Traceback (most recent call last):
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150417)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150417)[0m     param_dset[:] = val
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150417)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150417)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150417)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150417)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150417)[0m , filename = '/tmp/thalvari/4065561/automl_save_tblb4gy9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3bee9b7098, total write size = 771672, bytes this sub-write = 771672, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m Traceback (most recent call last):
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150417)[0m     self._entrypoint()
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150417)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150417)[0m     output = train_func(config, reporter)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150417)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150417)[0m     config=config)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150417)[0m     model.save(model_path, config_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150417)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150417)[0m     self.model.save(model_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150417)[0m     signatures)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150417)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150417)[0m     f.close()
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150417)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150417)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150417)[0m , filename = '/tmp/thalvari/4065561/automl_save_tblb4gy9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3bedead370, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150417)[0m Exception in thread Thread-1:
[2m[36m(pid=150417)[0m Traceback (most recent call last):
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150417)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150417)[0m     param_dset[:] = val
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150417)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150417)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150417)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150417)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150417)[0m , filename = '/tmp/thalvari/4065561/automl_save_tblb4gy9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3bee9b7098, total write size = 771672, bytes this sub-write = 771672, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m Traceback (most recent call last):
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150417)[0m     self._entrypoint()
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150417)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150417)[0m     output = train_func(config, reporter)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150417)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150417)[0m     config=config)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150417)[0m     model.save(model_path, config_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150417)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150417)[0m     self.model.save(model_path)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150417)[0m     signatures)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150417)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150417)[0m     f.close()
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150417)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150417)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150417)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150417)[0m , filename = '/tmp/thalvari/4065561/automl_save_tblb4gy9/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3bedead370, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m Traceback (most recent call last):
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150417)[0m     self.run()
[2m[36m(pid=150417)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150417)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150417)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150535)[0m 2020-11-20 11:45:59,775	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150535)[0m Traceback (most recent call last):
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150535)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150535)[0m     param_dset[:] = val
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150535)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150535)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150535)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150535)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150535)[0m , filename = '/tmp/thalvari/4065561/automl_save_q6m5xdeh/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f135a99f088, total write size = 747096, bytes this sub-write = 747096, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m Traceback (most recent call last):
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150535)[0m     self._entrypoint()
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150535)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150535)[0m     output = train_func(config, reporter)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150535)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150535)[0m     config=config)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150535)[0m     model.save(model_path, config_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150535)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150535)[0m     self.model.save(model_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150535)[0m     signatures)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150535)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150535)[0m     f.close()
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150535)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150535)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150535)[0m , filename = '/tmp/thalvari/4065561/automl_save_q6m5xdeh/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f135a681310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150535)[0m Exception in thread Thread-1:
[2m[36m(pid=150535)[0m Traceback (most recent call last):
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150535)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150535)[0m     param_dset[:] = val
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150535)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150535)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150535)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150535)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150535)[0m , filename = '/tmp/thalvari/4065561/automl_save_q6m5xdeh/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f135a99f088, total write size = 747096, bytes this sub-write = 747096, bytes actually written = 18446744073709551615, offset = 487424)
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m Traceback (most recent call last):
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150535)[0m     self._entrypoint()
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150535)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150535)[0m     output = train_func(config, reporter)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150535)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150535)[0m     config=config)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150535)[0m     model.save(model_path, config_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150535)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150535)[0m     self.model.save(model_path)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150535)[0m     signatures)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150535)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150535)[0m     f.close()
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150535)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150535)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150535)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:45:59 2020
[2m[36m(pid=150535)[0m , filename = '/tmp/thalvari/4065561/automl_save_q6m5xdeh/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f135a681310, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m Traceback (most recent call last):
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150535)[0m     self.run()
[2m[36m(pid=150535)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150535)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150535)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150634)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150634)[0m Instructions for updating:
[2m[36m(pid=150634)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150630)[0m Instructions for updating:
[2m[36m(pid=150630)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150630)[0m LSTM is selected.
[2m[36m(pid=150626)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150626)[0m 2020-11-20 11:46:00.379692: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150626)[0m 2020-11-20 11:46:00.387623: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150626)[0m 2020-11-20 11:46:00.390239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f05a51196c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150626)[0m 2020-11-20 11:46:00.390289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150630)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150630)[0m Instructions for updating:
[2m[36m(pid=150630)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150625)[0m 2020-11-20 11:46:00,625	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150625)[0m Traceback (most recent call last):
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150625)[0m     param_dset[:] = val
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150625)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:00 2020
[2m[36m(pid=150625)[0m , filename = '/tmp/thalvari/4065561/automl_save_zaki9x9e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b76346dd8, total write size = 767464, bytes this sub-write = 767464, bytes actually written = 18446744073709551615, offset = 479232)
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m Traceback (most recent call last):
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150625)[0m     self._entrypoint()
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150625)[0m     output = train_func(config, reporter)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150625)[0m     config=config)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150625)[0m     model.save(model_path, config_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150625)[0m     self.model.save(model_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150625)[0m     signatures)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150625)[0m     f.close()
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150625)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:00 2020
[2m[36m(pid=150625)[0m , filename = '/tmp/thalvari/4065561/automl_save_zaki9x9e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b760f3220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150625)[0m Exception in thread Thread-1:
[2m[36m(pid=150625)[0m Traceback (most recent call last):
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150625)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150625)[0m     param_dset[:] = val
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150625)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150625)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150625)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150625)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:00 2020
[2m[36m(pid=150625)[0m , filename = '/tmp/thalvari/4065561/automl_save_zaki9x9e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b76346dd8, total write size = 767464, bytes this sub-write = 767464, bytes actually written = 18446744073709551615, offset = 479232)
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m Traceback (most recent call last):
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150625)[0m     self._entrypoint()
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150625)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150625)[0m     output = train_func(config, reporter)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150625)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150625)[0m     config=config)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150625)[0m     model.save(model_path, config_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150625)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150625)[0m     self.model.save(model_path)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150625)[0m     signatures)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150625)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150625)[0m     f.close()
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150625)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150625)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150625)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:00 2020
[2m[36m(pid=150625)[0m , filename = '/tmp/thalvari/4065561/automl_save_zaki9x9e/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b760f3220, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m Traceback (most recent call last):
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150625)[0m     self.run()
[2m[36m(pid=150625)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150625)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150625)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150625)[0m 
2020-11-20 11:46:00,700	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150417, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:00,703	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_92_batch_size_log=9.5573,bayes_feature_DAY(timestamp)=0.8552,bayes_feature_HOUR(timestamp)=0.84065,bayes_feature_IS_AWAKE(timestamp)=0.94087,bayes_feature_IS_BUSY_HOURS(timestamp)=0.72365,bayes_feature_IS_WEEKEND(timestamp)=0.82862,bayes_feature_MONTH(timestamp)=0.56067,bayes_feature_WEEKDAY(timestamp)=0.67841,dropout_1=0.32244,dropout_2=0.24144,epochs=5,lr=0.0036379,lstm_1_units_float=8.1709,lstm_2_units_float=120.86,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150417)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150417)[0m 
[2m[36m(pid=150417)[0m Stack (most recent call first):
[2m[36m(pid=150634)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150634)[0m 2020-11-20 11:46:00.839060: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150634)[0m 2020-11-20 11:46:00.914726: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150634)[0m 2020-11-20 11:46:00.919458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb1610b8fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150634)[0m 2020-11-20 11:46:00.919483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:46:01,435	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150535, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:01,437	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_93_batch_size_log=8.6123,bayes_feature_DAY(timestamp)=0.41858,bayes_feature_HOUR(timestamp)=0.90959,bayes_feature_IS_AWAKE(timestamp)=0.37565,bayes_feature_IS_BUSY_HOURS(timestamp)=0.32132,bayes_feature_IS_WEEKEND(timestamp)=0.45869,bayes_feature_MONTH(timestamp)=0.64144,bayes_feature_WEEKDAY(timestamp)=0.71347,dropout_1=0.34547,dropout_2=0.49937,epochs=5,lr=0.0021835,lstm_1_units_float=8.2807,lstm_2_units_float=118.02,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150630)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150630)[0m 2020-11-20 11:46:01.496996: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150630)[0m 2020-11-20 11:46:01.517004: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150630)[0m 2020-11-20 11:46:01.520149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f618d0d2220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150630)[0m 2020-11-20 11:46:01.520171: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150535)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150535)[0m 
[2m[36m(pid=150535)[0m Stack (most recent call first):
2020-11-20 11:46:02,284	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150625, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:02,287	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_94_batch_size_log=8.9367,bayes_feature_DAY(timestamp)=0.58151,bayes_feature_HOUR(timestamp)=0.40448,bayes_feature_IS_AWAKE(timestamp)=0.65561,bayes_feature_IS_BUSY_HOURS(timestamp)=0.62828,bayes_feature_IS_WEEKEND(timestamp)=0.68182,bayes_feature_MONTH(timestamp)=0.61924,bayes_feature_WEEKDAY(timestamp)=0.7675,dropout_1=0.28472,dropout_2=0.48119,epochs=5,lr=0.0030739,lstm_1_units_float=8.2713,lstm_2_units_float=119.44,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150625)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150625)[0m 
[2m[36m(pid=150625)[0m Stack (most recent call first):
[2m[36m(pid=150537)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150537)[0m   agg_primitives: ['count']
[2m[36m(pid=150537)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150537)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150415)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150415)[0m   agg_primitives: ['count']
[2m[36m(pid=150415)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150415)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150537)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150537)[0m Instructions for updating:
[2m[36m(pid=150537)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150537)[0m LSTM is selected.
[2m[36m(pid=150415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150415)[0m Instructions for updating:
[2m[36m(pid=150415)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150415)[0m LSTM is selected.
[2m[36m(pid=152747)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152748)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152747)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152746)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152746)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152748)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150537)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150537)[0m Instructions for updating:
[2m[36m(pid=150537)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150415)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150415)[0m Instructions for updating:
[2m[36m(pid=150415)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152872)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152872)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150626)[0m 2020-11-20 11:46:04,312	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150626)[0m Traceback (most recent call last):
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150626)[0m     param_dset[:] = val
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150626)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150626)[0m , filename = '/tmp/thalvari/4065561/automl_save_88yatn1s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f05a6265238, total write size = 835112, bytes this sub-write = 835112, bytes actually written = 18446744073709551615, offset = 438272)
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m Traceback (most recent call last):
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150626)[0m     self._entrypoint()
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150626)[0m     output = train_func(config, reporter)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150626)[0m     config=config)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150626)[0m     model.save(model_path, config_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150626)[0m     self.model.save(model_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150626)[0m     signatures)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150626)[0m     f.close()
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150626)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150626)[0m , filename = '/tmp/thalvari/4065561/automl_save_88yatn1s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f05a548dc90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150626)[0m Exception in thread Thread-1:
[2m[36m(pid=150626)[0m Traceback (most recent call last):
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150626)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150626)[0m     param_dset[:] = val
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150626)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150626)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150626)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150626)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150626)[0m , filename = '/tmp/thalvari/4065561/automl_save_88yatn1s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f05a6265238, total write size = 835112, bytes this sub-write = 835112, bytes actually written = 18446744073709551615, offset = 438272)
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m Traceback (most recent call last):
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150626)[0m     self._entrypoint()
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150626)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150626)[0m     output = train_func(config, reporter)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150626)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150626)[0m     config=config)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150626)[0m     model.save(model_path, config_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150626)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150626)[0m     self.model.save(model_path)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150626)[0m     signatures)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150626)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150626)[0m     f.close()
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150626)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150626)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150626)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150626)[0m , filename = '/tmp/thalvari/4065561/automl_save_88yatn1s/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f05a548dc90, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m Traceback (most recent call last):
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150626)[0m     self.run()
[2m[36m(pid=150626)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150626)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150626)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150626)[0m 
[2m[36m(pid=152926)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152924)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152924)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152927)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152927)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152928)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152928)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152930)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152921)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152921)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152929)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=152929)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152926)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=150630)[0m 2020-11-20 11:46:04,636	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150630)[0m Traceback (most recent call last):
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150630)[0m     param_dset[:] = val
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150630)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150630)[0m , filename = '/tmp/thalvari/4065561/automl_save_t9dp1n19/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618e769e38, total write size = 984984, bytes this sub-write = 984984, bytes actually written = 18446744073709551615, offset = 372736)
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m Traceback (most recent call last):
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150630)[0m     self._entrypoint()
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150630)[0m     output = train_func(config, reporter)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150630)[0m     config=config)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150630)[0m     model.save(model_path, config_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150630)[0m     self.model.save(model_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150630)[0m     signatures)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150630)[0m     f.close()
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150630)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150630)[0m , filename = '/tmp/thalvari/4065561/automl_save_t9dp1n19/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618e3a5fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150630)[0m Exception in thread Thread-1:
[2m[36m(pid=150630)[0m Traceback (most recent call last):
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150630)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150630)[0m     param_dset[:] = val
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150630)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150630)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150630)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150630)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150630)[0m , filename = '/tmp/thalvari/4065561/automl_save_t9dp1n19/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618e769e38, total write size = 984984, bytes this sub-write = 984984, bytes actually written = 18446744073709551615, offset = 372736)
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m Traceback (most recent call last):
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150630)[0m     self._entrypoint()
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150630)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150630)[0m     output = train_func(config, reporter)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150630)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150630)[0m     config=config)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150630)[0m     model.save(model_path, config_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150630)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150630)[0m     self.model.save(model_path)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150630)[0m     signatures)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150630)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150630)[0m     f.close()
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150630)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150630)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150630)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:04 2020
[2m[36m(pid=150630)[0m , filename = '/tmp/thalvari/4065561/automl_save_t9dp1n19/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f618e3a5fe0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m Traceback (most recent call last):
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150630)[0m     self.run()
[2m[36m(pid=150630)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150630)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150630)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150537)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150537)[0m 2020-11-20 11:46:04.980807: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150537)[0m 2020-11-20 11:46:04.990338: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150537)[0m 2020-11-20 11:46:04.993966: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f48010d1620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150537)[0m 2020-11-20 11:46:04.993999: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150415)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150415)[0m 2020-11-20 11:46:05.043993: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150415)[0m 2020-11-20 11:46:05.052495: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150415)[0m 2020-11-20 11:46:05.059896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f63710d0fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150415)[0m 2020-11-20 11:46:05.059927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:46:05,335	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150626, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:05,339	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_96_batch_size_log=7.5559,bayes_feature_DAY(timestamp)=0.96753,bayes_feature_HOUR(timestamp)=0.99971,bayes_feature_IS_AWAKE(timestamp)=0.99527,bayes_feature_IS_BUSY_HOURS(timestamp)=0.99957,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.99518,bayes_feature_WEEKDAY(timestamp)=0.59198,dropout_1=0.42484,dropout_2=0.42603,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.34,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 36/40 CPUs, 0/0 GPUs
Memory usage on this node: 16.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 103 ({'TERMINATED': 23, 'ERROR': 71, 'RUNNING': 9})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 65 not shown
 - train_func_93_batch_size_log=8.6123,bayes_feature_DAY(timestamp)=0.41858,bayes_feature_HOUR(timestamp)=0.90959,bayes_feature_IS_AWAKE(timestamp)=0.37565,bayes_feature_IS_BUSY_HOURS(timestamp)=0.32132,bayes_feature_IS_WEEKEND(timestamp)=0.45869,bayes_feature_MONTH(timestamp)=0.64144,bayes_feature_WEEKDAY(timestamp)=0.71347,dropout_1=0.34547,dropout_2=0.49937,epochs=5,lr=0.0021835,lstm_1_units_float=8.2807,lstm_2_units_float=118.02,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_93_batch_size_log=8.6123,bayes_feature_DAY(timestamp)=0.41858,bayes_feature_HOUR(timestamp)=0.90959,bayes_feature_IS_AW_2020-11-20_11-45-50xy7mot84/error_2020-11-20_11-46-01.txt
 - train_func_94_batch_size_log=8.9367,bayes_feature_DAY(timestamp)=0.58151,bayes_feature_HOUR(timestamp)=0.40448,bayes_feature_IS_AWAKE(timestamp)=0.65561,bayes_feature_IS_BUSY_HOURS(timestamp)=0.62828,bayes_feature_IS_WEEKEND(timestamp)=0.68182,bayes_feature_MONTH(timestamp)=0.61924,bayes_feature_WEEKDAY(timestamp)=0.7675,dropout_1=0.28472,dropout_2=0.48119,epochs=5,lr=0.0030739,lstm_1_units_float=8.2713,lstm_2_units_float=119.44,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_94_batch_size_log=8.9367,bayes_feature_DAY(timestamp)=0.58151,bayes_feature_HOUR(timestamp)=0.40448,bayes_feature_IS_AW_2020-11-20_11-45-51ve1mthp7/error_2020-11-20_11-46-02.txt
 - train_func_96_batch_size_log=7.5559,bayes_feature_DAY(timestamp)=0.96753,bayes_feature_HOUR(timestamp)=0.99971,bayes_feature_IS_AWAKE(timestamp)=0.99527,bayes_feature_IS_BUSY_HOURS(timestamp)=0.99957,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.99518,bayes_feature_WEEKDAY(timestamp)=0.59198,dropout_1=0.42484,dropout_2=0.42603,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.34,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_96_batch_size_log=7.5559,bayes_feature_DAY(timestamp)=0.96753,bayes_feature_HOUR(timestamp)=0.99971,bayes_feature_IS_AW_2020-11-20_11-45-55w0_85c5z/error_2020-11-20_11-46-05.txt
RUNNING trials:
 - train_func_91_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.30235,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84954,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.30126,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.31578,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2:	RUNNING
 - train_func_95_batch_size_log=5.4872,bayes_feature_DAY(timestamp)=0.69302,bayes_feature_HOUR(timestamp)=0.47378,bayes_feature_IS_AWAKE(timestamp)=0.61835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.57416,bayes_feature_IS_WEEKEND(timestamp)=0.90439,bayes_feature_MONTH(timestamp)=0.93161,bayes_feature_WEEKDAY(timestamp)=0.49617,dropout_1=0.45942,dropout_2=0.34544,epochs=5,lr=0.00519,lstm_1_units_float=8.1454,lstm_2_units_float=119.88,past_seq_len=2:	RUNNING
 - train_func_97_batch_size_log=6.1153,bayes_feature_DAY(timestamp)=0.88211,bayes_feature_HOUR(timestamp)=0.73007,bayes_feature_IS_AWAKE(timestamp)=0.466,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9663,bayes_feature_IS_WEEKEND(timestamp)=0.3759,bayes_feature_MONTH(timestamp)=0.42043,bayes_feature_WEEKDAY(timestamp)=0.43609,dropout_1=0.41607,dropout_2=0.42798,epochs=5,lr=0.0045934,lstm_1_units_float=8.1006,lstm_2_units_float=120.31,past_seq_len=2:	RUNNING
  ... 3 not shown
 - train_func_101_batch_size_log=9.2359,bayes_feature_DAY(timestamp)=0.90099,bayes_feature_HOUR(timestamp)=0.3015,bayes_feature_IS_AWAKE(timestamp)=0.6465,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8231,bayes_feature_IS_WEEKEND(timestamp)=0.64903,bayes_feature_MONTH(timestamp)=0.47482,bayes_feature_WEEKDAY(timestamp)=0.42722,dropout_1=0.31961,dropout_2=0.34164,epochs=5,lr=0.0018487,lstm_1_units_float=8.0989,lstm_2_units_float=123.16,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.99816,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.30192,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.20186,dropout_2=0.2,epochs=5,lr=0.0086871,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
 - train_func_103_batch_size_log=9.8313,bayes_feature_DAY(timestamp)=0.43257,bayes_feature_HOUR(timestamp)=0.63509,bayes_feature_IS_AWAKE(timestamp)=0.5805,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79566,bayes_feature_IS_WEEKEND(timestamp)=0.91825,bayes_feature_MONTH(timestamp)=0.91193,bayes_feature_WEEKDAY(timestamp)=0.98979,dropout_1=0.30615,dropout_2=0.47493,epochs=5,lr=0.0097841,lstm_1_units_float=8.2628,lstm_2_units_float=124.0,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=150626)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150626)[0m 
[2m[36m(pid=150626)[0m Stack (most recent call first):
[2m[36m(pid=150249)[0m 2020-11-20 11:46:05,951	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150249)[0m Traceback (most recent call last):
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150249)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150249)[0m     param_dset[:] = val
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150249)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150249)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150249)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150249)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150249)[0m , filename = '/tmp/thalvari/4065561/automl_save_5n7d3f8u/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fae16656988, total write size = 169880, bytes this sub-write = 169880, bytes actually written = 18446744073709551615, offset = 94208)
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m Traceback (most recent call last):
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150249)[0m     self._entrypoint()
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150249)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150249)[0m     output = train_func(config, reporter)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150249)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150249)[0m     config=config)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150249)[0m     model.save(model_path, config_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150249)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150249)[0m     self.model.save(model_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150249)[0m     signatures)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150249)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150249)[0m     f.close()
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150249)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150249)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150249)[0m , filename = '/tmp/thalvari/4065561/automl_save_5n7d3f8u/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fae163d3770, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150249)[0m Exception in thread Thread-1:
[2m[36m(pid=150249)[0m Traceback (most recent call last):
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150249)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150249)[0m     param_dset[:] = val
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150249)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150249)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150249)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150249)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150249)[0m , filename = '/tmp/thalvari/4065561/automl_save_5n7d3f8u/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fae16656988, total write size = 169880, bytes this sub-write = 169880, bytes actually written = 18446744073709551615, offset = 94208)
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m Traceback (most recent call last):
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150249)[0m     self._entrypoint()
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150249)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150249)[0m     output = train_func(config, reporter)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150249)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150249)[0m     config=config)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150249)[0m     model.save(model_path, config_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150249)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150249)[0m     self.model.save(model_path)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150249)[0m     signatures)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150249)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150249)[0m     f.close()
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150249)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150249)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150249)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150249)[0m , filename = '/tmp/thalvari/4065561/automl_save_5n7d3f8u/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7fae163d3770, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150627)[0m 2020-11-20 11:46:05,953	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150627)[0m Traceback (most recent call last):
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150627)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150627)[0m     param_dset[:] = val
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150627)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150627)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150627)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150627)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150627)[0m , filename = '/tmp/thalvari/4065561/automl_save_fsnji4md/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83ea79bd18, total write size = 890344, bytes this sub-write = 890344, bytes actually written = 18446744073709551615, offset = 356352)
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m Traceback (most recent call last):
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150627)[0m     self._entrypoint()
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150627)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150627)[0m     output = train_func(config, reporter)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150627)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150627)[0m     config=config)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150627)[0m     model.save(model_path, config_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150627)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150627)[0m     self.model.save(model_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150627)[0m     signatures)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150627)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150627)[0m     f.close()
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150627)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150627)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150627)[0m , filename = '/tmp/thalvari/4065561/automl_save_fsnji4md/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83ea56a840, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150627)[0m Exception in thread Thread-1:
[2m[36m(pid=150627)[0m Traceback (most recent call last):
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150627)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150627)[0m     param_dset[:] = val
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150627)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150627)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150627)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150627)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150627)[0m , filename = '/tmp/thalvari/4065561/automl_save_fsnji4md/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83ea79bd18, total write size = 890344, bytes this sub-write = 890344, bytes actually written = 18446744073709551615, offset = 356352)
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m Traceback (most recent call last):
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150627)[0m     self._entrypoint()
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150627)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150627)[0m     output = train_func(config, reporter)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150627)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150627)[0m     config=config)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150627)[0m     model.save(model_path, config_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150627)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150627)[0m     self.model.save(model_path)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150627)[0m     signatures)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150627)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150627)[0m     f.close()
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150627)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150627)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150627)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:05 2020
[2m[36m(pid=150627)[0m , filename = '/tmp/thalvari/4065561/automl_save_fsnji4md/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83ea56a840, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m Traceback (most recent call last):
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150249)[0m     self.run()
[2m[36m(pid=150249)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150249)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150249)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m Traceback (most recent call last):
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150627)[0m     self.run()
[2m[36m(pid=150627)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150627)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150627)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150416)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=150416)[0m   agg_primitives: ['count']
[2m[36m(pid=150416)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=150416)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150634)[0m 2020-11-20 11:46:06,179	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150634)[0m Traceback (most recent call last):
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150634)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150634)[0m     param_dset[:] = val
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150634)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:06 2020
[2m[36m(pid=150634)[0m , filename = '/tmp/thalvari/4065561/automl_save_kqk7ooza/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb16293c058, total write size = 910744, bytes this sub-write = 910744, bytes actually written = 18446744073709551615, offset = 348160)
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m Traceback (most recent call last):
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150634)[0m     self._entrypoint()
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150634)[0m     output = train_func(config, reporter)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150634)[0m     config=config)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150634)[0m     model.save(model_path, config_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150634)[0m     self.model.save(model_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150634)[0m     signatures)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150634)[0m     f.close()
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150634)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:06 2020
[2m[36m(pid=150634)[0m , filename = '/tmp/thalvari/4065561/automl_save_kqk7ooza/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb16210c690, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150634)[0m Exception in thread Thread-1:
[2m[36m(pid=150634)[0m Traceback (most recent call last):
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150634)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150634)[0m     param_dset[:] = val
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150634)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150634)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150634)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150634)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:06 2020
[2m[36m(pid=150634)[0m , filename = '/tmp/thalvari/4065561/automl_save_kqk7ooza/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb16293c058, total write size = 910744, bytes this sub-write = 910744, bytes actually written = 18446744073709551615, offset = 348160)
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m Traceback (most recent call last):
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150634)[0m     self._entrypoint()
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150634)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150634)[0m     output = train_func(config, reporter)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150634)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150634)[0m     config=config)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150634)[0m     model.save(model_path, config_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150634)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150634)[0m     self.model.save(model_path)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150634)[0m     signatures)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150634)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150634)[0m     f.close()
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150634)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150634)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150634)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:06 2020
[2m[36m(pid=150634)[0m , filename = '/tmp/thalvari/4065561/automl_save_kqk7ooza/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb16210c690, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m Traceback (most recent call last):
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150634)[0m     self.run()
[2m[36m(pid=150634)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150634)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150634)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150634)[0m 
2020-11-20 11:46:06,387	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150630, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:06,389	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_98_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150630)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150630)[0m 
[2m[36m(pid=150630)[0m Stack (most recent call first):
[2m[36m(pid=150416)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=150416)[0m Instructions for updating:
[2m[36m(pid=150416)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=150416)[0m LSTM is selected.
2020-11-20 11:46:07,232	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150249, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:07,235	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_91_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.30235,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84954,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.30126,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.5,dropout_2=0.31578,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150416)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=150416)[0m Instructions for updating:
[2m[36m(pid=150416)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150249)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150249)[0m 
[2m[36m(pid=150249)[0m Stack (most recent call first):
[2m[36m(pid=150537)[0m 2020-11-20 11:46:07,624	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150537)[0m Traceback (most recent call last):
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150537)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150537)[0m     param_dset[:] = val
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150537)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150537)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150537)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150537)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:07 2020
[2m[36m(pid=150537)[0m , filename = '/tmp/thalvari/4065561/automl_save_hnpo3ofn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4802729b38, total write size = 955752, bytes this sub-write = 955752, bytes actually written = 18446744073709551615, offset = 339968)
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m Traceback (most recent call last):
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150537)[0m     self._entrypoint()
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150537)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150537)[0m     output = train_func(config, reporter)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150537)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150537)[0m     config=config)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150537)[0m     model.save(model_path, config_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150537)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150537)[0m     self.model.save(model_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150537)[0m     signatures)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150537)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150537)[0m     f.close()
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150537)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150537)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:07 2020
[2m[36m(pid=150537)[0m , filename = '/tmp/thalvari/4065561/automl_save_hnpo3ofn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f480144d4d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150537)[0m Exception in thread Thread-1:
[2m[36m(pid=150537)[0m Traceback (most recent call last):
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150537)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150537)[0m     param_dset[:] = val
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150537)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150537)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150537)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150537)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:07 2020
[2m[36m(pid=150537)[0m , filename = '/tmp/thalvari/4065561/automl_save_hnpo3ofn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4802729b38, total write size = 955752, bytes this sub-write = 955752, bytes actually written = 18446744073709551615, offset = 339968)
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m Traceback (most recent call last):
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150537)[0m     self._entrypoint()
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150537)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150537)[0m     output = train_func(config, reporter)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150537)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150537)[0m     config=config)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150537)[0m     model.save(model_path, config_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150537)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150537)[0m     self.model.save(model_path)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150537)[0m     signatures)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150537)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150537)[0m     f.close()
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150537)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150537)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150537)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:07 2020
[2m[36m(pid=150537)[0m , filename = '/tmp/thalvari/4065561/automl_save_hnpo3ofn/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f480144d4d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m Traceback (most recent call last):
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150537)[0m     self.run()
[2m[36m(pid=150537)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150537)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150537)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150537)[0m 
2020-11-20 11:46:08,024	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150634, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:08,026	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_97_batch_size_log=6.1153,bayes_feature_DAY(timestamp)=0.88211,bayes_feature_HOUR(timestamp)=0.73007,bayes_feature_IS_AWAKE(timestamp)=0.466,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9663,bayes_feature_IS_WEEKEND(timestamp)=0.3759,bayes_feature_MONTH(timestamp)=0.42043,bayes_feature_WEEKDAY(timestamp)=0.43609,dropout_1=0.41607,dropout_2=0.42798,epochs=5,lr=0.0045934,lstm_1_units_float=8.1006,lstm_2_units_float=120.31,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150416)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=150416)[0m 2020-11-20 11:46:08.225604: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=150416)[0m 2020-11-20 11:46:08.235577: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=150634)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150634)[0m 
[2m[36m(pid=150634)[0m Stack (most recent call first):
[2m[36m(pid=150416)[0m 2020-11-20 11:46:08.238839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4f290d1ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=150416)[0m 2020-11-20 11:46:08.238873: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:46:08,765	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150627, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:08,768	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_95_batch_size_log=5.4872,bayes_feature_DAY(timestamp)=0.69302,bayes_feature_HOUR(timestamp)=0.47378,bayes_feature_IS_AWAKE(timestamp)=0.61835,bayes_feature_IS_BUSY_HOURS(timestamp)=0.57416,bayes_feature_IS_WEEKEND(timestamp)=0.90439,bayes_feature_MONTH(timestamp)=0.93161,bayes_feature_WEEKDAY(timestamp)=0.49617,dropout_1=0.45942,dropout_2=0.34544,epochs=5,lr=0.00519,lstm_1_units_float=8.1454,lstm_2_units_float=119.88,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152924)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152924)[0m   agg_primitives: ['count']
[2m[36m(pid=152924)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152924)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152747)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152747)[0m   agg_primitives: ['count']
[2m[36m(pid=152747)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152747)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152748)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152748)[0m   agg_primitives: ['count']
[2m[36m(pid=152748)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152748)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=150627)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150627)[0m 
[2m[36m(pid=150627)[0m Stack (most recent call first):
[2m[36m(pid=152748)[0m LSTM is selected.
[2m[36m(pid=152747)[0m LSTM is selected.
[2m[36m(pid=152748)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152748)[0m Instructions for updating:
[2m[36m(pid=152748)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152924)[0m LSTM is selected.
[2m[36m(pid=152747)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152747)[0m Instructions for updating:
[2m[36m(pid=152747)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152924)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152924)[0m Instructions for updating:
[2m[36m(pid=152924)[0m If using Keras pass *_constraint arguments to layers.
2020-11-20 11:46:09,703	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150537, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:09,706	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_99_batch_size_log=9.6423,bayes_feature_DAY(timestamp)=0.39001,bayes_feature_HOUR(timestamp)=0.77117,bayes_feature_IS_AWAKE(timestamp)=0.95917,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48848,bayes_feature_IS_WEEKEND(timestamp)=0.83858,bayes_feature_MONTH(timestamp)=0.96779,bayes_feature_WEEKDAY(timestamp)=0.40396,dropout_1=0.323,dropout_2=0.31653,epochs=5,lr=0.0042258,lstm_1_units_float=8.1864,lstm_2_units_float=123.79,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152747)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152747)[0m Instructions for updating:
[2m[36m(pid=152747)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152748)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152748)[0m Instructions for updating:
[2m[36m(pid=152748)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=150537)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150537)[0m 
[2m[36m(pid=150537)[0m Stack (most recent call first):
[2m[36m(pid=150415)[0m 2020-11-20 11:46:09,906	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150415)[0m Traceback (most recent call last):
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150415)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150415)[0m     param_dset[:] = val
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150415)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150415)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150415)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150415)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:09 2020
[2m[36m(pid=150415)[0m , filename = '/tmp/thalvari/4065561/automl_save_qjvb97eo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6372993d48, total write size = 914920, bytes this sub-write = 914920, bytes actually written = 18446744073709551615, offset = 331776)
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m Traceback (most recent call last):
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150415)[0m     self._entrypoint()
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150415)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150415)[0m     output = train_func(config, reporter)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150415)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150415)[0m     config=config)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150415)[0m     model.save(model_path, config_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150415)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150415)[0m     self.model.save(model_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150415)[0m     signatures)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150415)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150415)[0m     f.close()
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150415)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150415)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:09 2020
[2m[36m(pid=150415)[0m , filename = '/tmp/thalvari/4065561/automl_save_qjvb97eo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63718fbc10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150415)[0m Exception in thread Thread-1:
[2m[36m(pid=150415)[0m Traceback (most recent call last):
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150415)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150415)[0m     param_dset[:] = val
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150415)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150415)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150415)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150415)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:09 2020
[2m[36m(pid=150415)[0m , filename = '/tmp/thalvari/4065561/automl_save_qjvb97eo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6372993d48, total write size = 914920, bytes this sub-write = 914920, bytes actually written = 18446744073709551615, offset = 331776)
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m Traceback (most recent call last):
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150415)[0m     self._entrypoint()
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150415)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150415)[0m     output = train_func(config, reporter)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150415)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150415)[0m     config=config)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150415)[0m     model.save(model_path, config_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150415)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150415)[0m     self.model.save(model_path)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150415)[0m     signatures)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150415)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150415)[0m     f.close()
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150415)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150415)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150415)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:09 2020
[2m[36m(pid=150415)[0m , filename = '/tmp/thalvari/4065561/automl_save_qjvb97eo/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f63718fbc10, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m Traceback (most recent call last):
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150415)[0m     self.run()
[2m[36m(pid=150415)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150415)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150415)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150415)[0m 
[2m[36m(pid=152924)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152924)[0m Instructions for updating:
[2m[36m(pid=152924)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152927)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152927)[0m   agg_primitives: ['count']
[2m[36m(pid=152927)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152927)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.5/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 109 ({'TERMINATED': 23, 'ERROR': 76, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 70 not shown
 - train_func_97_batch_size_log=6.1153,bayes_feature_DAY(timestamp)=0.88211,bayes_feature_HOUR(timestamp)=0.73007,bayes_feature_IS_AWAKE(timestamp)=0.466,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9663,bayes_feature_IS_WEEKEND(timestamp)=0.3759,bayes_feature_MONTH(timestamp)=0.42043,bayes_feature_WEEKDAY(timestamp)=0.43609,dropout_1=0.41607,dropout_2=0.42798,epochs=5,lr=0.0045934,lstm_1_units_float=8.1006,lstm_2_units_float=120.31,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_97_batch_size_log=6.1153,bayes_feature_DAY(timestamp)=0.88211,bayes_feature_HOUR(timestamp)=0.73007,bayes_feature_IS_AW_2020-11-20_11-45-55bqetc31s/error_2020-11-20_11-46-08.txt
 - train_func_98_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_98_batch_size_log=10.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-45-56kodh0yy7/error_2020-11-20_11-46-06.txt
 - train_func_99_batch_size_log=9.6423,bayes_feature_DAY(timestamp)=0.39001,bayes_feature_HOUR(timestamp)=0.77117,bayes_feature_IS_AWAKE(timestamp)=0.95917,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48848,bayes_feature_IS_WEEKEND(timestamp)=0.83858,bayes_feature_MONTH(timestamp)=0.96779,bayes_feature_WEEKDAY(timestamp)=0.40396,dropout_1=0.323,dropout_2=0.31653,epochs=5,lr=0.0042258,lstm_1_units_float=8.1864,lstm_2_units_float=123.79,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_99_batch_size_log=9.6423,bayes_feature_DAY(timestamp)=0.39001,bayes_feature_HOUR(timestamp)=0.77117,bayes_feature_IS_AW_2020-11-20_11-45-58ci2j57wi/error_2020-11-20_11-46-09.txt
RUNNING trials:
 - train_func_100_batch_size_log=6.2992,bayes_feature_DAY(timestamp)=0.65685,bayes_feature_HOUR(timestamp)=0.38003,bayes_feature_IS_AWAKE(timestamp)=0.31224,bayes_feature_IS_BUSY_HOURS(timestamp)=0.76175,bayes_feature_IS_WEEKEND(timestamp)=0.34248,bayes_feature_MONTH(timestamp)=0.69206,bayes_feature_WEEKDAY(timestamp)=0.86709,dropout_1=0.46662,dropout_2=0.40712,epochs=5,lr=0.0089941,lstm_1_units_float=8.1331,lstm_2_units_float=119.75,past_seq_len=2:	RUNNING
 - train_func_101_batch_size_log=9.2359,bayes_feature_DAY(timestamp)=0.90099,bayes_feature_HOUR(timestamp)=0.3015,bayes_feature_IS_AWAKE(timestamp)=0.6465,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8231,bayes_feature_IS_WEEKEND(timestamp)=0.64903,bayes_feature_MONTH(timestamp)=0.47482,bayes_feature_WEEKDAY(timestamp)=0.42722,dropout_1=0.31961,dropout_2=0.34164,epochs=5,lr=0.0018487,lstm_1_units_float=8.0989,lstm_2_units_float=123.16,past_seq_len=2:	RUNNING
 - train_func_102_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.99816,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.30192,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.20186,dropout_2=0.2,epochs=5,lr=0.0086871,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_107_batch_size_log=9.5396,bayes_feature_DAY(timestamp)=0.90594,bayes_feature_HOUR(timestamp)=0.43449,bayes_feature_IS_AWAKE(timestamp)=0.91096,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84496,bayes_feature_IS_WEEKEND(timestamp)=0.88876,bayes_feature_MONTH(timestamp)=0.50841,bayes_feature_WEEKDAY(timestamp)=0.8685,dropout_1=0.23012,dropout_2=0.42597,epochs=5,lr=0.007817,lstm_1_units_float=8.5216,lstm_2_units_float=122.9,past_seq_len=2:	RUNNING
 - train_func_108_batch_size_log=6.8687,bayes_feature_DAY(timestamp)=0.9997,bayes_feature_HOUR(timestamp)=0.99953,bayes_feature_IS_AWAKE(timestamp)=0.30219,bayes_feature_IS_BUSY_HOURS(timestamp)=0.99983,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.77613,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.20016,dropout_2=0.20023,epochs=5,lr=0.0099432,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2:	RUNNING
 - train_func_109_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.53495,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73232,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0034242,lstm_1_units_float=8.0,lstm_2_units_float=120.83,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=152927)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152927)[0m Instructions for updating:
[2m[36m(pid=152927)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152927)[0m LSTM is selected.
[2m[36m(pid=152747)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152747)[0m 2020-11-20 11:46:10.802319: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152747)[0m 2020-11-20 11:46:10.809771: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152747)[0m 2020-11-20 11:46:10.811597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4b810d16c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152747)[0m 2020-11-20 11:46:10.811627: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=150416)[0m 2020-11-20 11:46:10,809	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=150416)[0m Traceback (most recent call last):
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150416)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150416)[0m     param_dset[:] = val
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150416)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150416)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150416)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150416)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:10 2020
[2m[36m(pid=150416)[0m , filename = '/tmp/thalvari/4065561/automl_save_zgo5u8h0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4f2a7c4e18, total write size = 972136, bytes this sub-write = 972136, bytes actually written = 18446744073709551615, offset = 323584)
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m Traceback (most recent call last):
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150416)[0m     self._entrypoint()
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150416)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150416)[0m     output = train_func(config, reporter)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150416)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150416)[0m     config=config)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150416)[0m     model.save(model_path, config_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150416)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150416)[0m     self.model.save(model_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150416)[0m     signatures)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150416)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150416)[0m     f.close()
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150416)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150416)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:10 2020
[2m[36m(pid=150416)[0m , filename = '/tmp/thalvari/4065561/automl_save_zgo5u8h0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4f29532ee0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150416)[0m Exception in thread Thread-1:
[2m[36m(pid=150416)[0m Traceback (most recent call last):
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=150416)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=150416)[0m     param_dset[:] = val
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=150416)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=150416)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=150416)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=150416)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:10 2020
[2m[36m(pid=150416)[0m , filename = '/tmp/thalvari/4065561/automl_save_zgo5u8h0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4f2a7c4e18, total write size = 972136, bytes this sub-write = 972136, bytes actually written = 18446744073709551615, offset = 323584)
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m Traceback (most recent call last):
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=150416)[0m     self._entrypoint()
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=150416)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=150416)[0m     output = train_func(config, reporter)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=150416)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=150416)[0m     config=config)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=150416)[0m     model.save(model_path, config_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=150416)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=150416)[0m     self.model.save(model_path)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=150416)[0m     signatures)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=150416)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=150416)[0m     f.close()
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=150416)[0m     h5i.dec_ref(id_)
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=150416)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=150416)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:10 2020
[2m[36m(pid=150416)[0m , filename = '/tmp/thalvari/4065561/automl_save_zgo5u8h0/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4f29532ee0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m Traceback (most recent call last):
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=150416)[0m     self.run()
[2m[36m(pid=150416)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=150416)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=150416)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=150416)[0m 
[2m[36m(pid=152748)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152748)[0m 2020-11-20 11:46:10.861963: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152748)[0m 2020-11-20 11:46:10.869690: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152748)[0m 2020-11-20 11:46:10.871775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7e9101c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152748)[0m 2020-11-20 11:46:10.871804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152924)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152924)[0m 2020-11-20 11:46:10.957922: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152924)[0m 2020-11-20 11:46:10.965354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152924)[0m 2020-11-20 11:46:10.967065: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94750e9e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152924)[0m 2020-11-20 11:46:10.967084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152928)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152928)[0m   agg_primitives: ['count']
[2m[36m(pid=152928)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152928)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:46:11,088	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150415, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:11,090	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_100_batch_size_log=6.2992,bayes_feature_DAY(timestamp)=0.65685,bayes_feature_HOUR(timestamp)=0.38003,bayes_feature_IS_AWAKE(timestamp)=0.31224,bayes_feature_IS_BUSY_HOURS(timestamp)=0.76175,bayes_feature_IS_WEEKEND(timestamp)=0.34248,bayes_feature_MONTH(timestamp)=0.69206,bayes_feature_WEEKDAY(timestamp)=0.86709,dropout_1=0.46662,dropout_2=0.40712,epochs=5,lr=0.0089941,lstm_1_units_float=8.1331,lstm_2_units_float=119.75,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150415)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150415)[0m 
[2m[36m(pid=150415)[0m Stack (most recent call first):
[2m[36m(pid=152927)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152927)[0m Instructions for updating:
[2m[36m(pid=152927)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152928)[0m LSTM is selected.
[2m[36m(pid=152928)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152928)[0m Instructions for updating:
[2m[36m(pid=152928)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152930)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152930)[0m   agg_primitives: ['count']
[2m[36m(pid=152930)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152930)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:46:11,821	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=150416, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:11,823	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_101_batch_size_log=9.2359,bayes_feature_DAY(timestamp)=0.90099,bayes_feature_HOUR(timestamp)=0.3015,bayes_feature_IS_AWAKE(timestamp)=0.6465,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8231,bayes_feature_IS_WEEKEND(timestamp)=0.64903,bayes_feature_MONTH(timestamp)=0.47482,bayes_feature_WEEKDAY(timestamp)=0.42722,dropout_1=0.31961,dropout_2=0.34164,epochs=5,lr=0.0018487,lstm_1_units_float=8.0989,lstm_2_units_float=123.16,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=150416)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=150416)[0m 
[2m[36m(pid=150416)[0m Stack (most recent call first):
[2m[36m(pid=152928)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152928)[0m Instructions for updating:
[2m[36m(pid=152928)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152930)[0m Instructions for updating:
[2m[36m(pid=152930)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152930)[0m LSTM is selected.
[2m[36m(pid=152927)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152927)[0m 2020-11-20 11:46:12.246339: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152927)[0m 2020-11-20 11:46:12.261044: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152927)[0m 2020-11-20 11:46:12.263316: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d090e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152927)[0m 2020-11-20 11:46:12.263347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152926)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152926)[0m   agg_primitives: ['count']
[2m[36m(pid=152926)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152926)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152930)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152930)[0m Instructions for updating:
[2m[36m(pid=152930)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152928)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152928)[0m 2020-11-20 11:46:12.983335: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152928)[0m 2020-11-20 11:46:12.994876: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152928)[0m 2020-11-20 11:46:12.998314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5990e9fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152928)[0m 2020-11-20 11:46:12.998351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152926)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152926)[0m Instructions for updating:
[2m[36m(pid=152926)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152926)[0m LSTM is selected.
[2m[36m(pid=152747)[0m 2020-11-20 11:46:13,331	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152747)[0m Traceback (most recent call last):
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152747)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152747)[0m     param_dset[:] = val
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152747)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152747)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152747)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152747)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152747)[0m , filename = '/tmp/thalvari/4065561/automl_save_78hqe740/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b814ec6a0, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 34712)
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m Traceback (most recent call last):
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152747)[0m     self._entrypoint()
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152747)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152747)[0m     output = train_func(config, reporter)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152747)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152747)[0m     config=config)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152747)[0m     model.save(model_path, config_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152747)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152747)[0m     self.model.save(model_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152747)[0m     signatures)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152747)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152747)[0m     f.close()
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152747)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152747)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152747)[0m , filename = '/tmp/thalvari/4065561/automl_save_78hqe740/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b81ddaee0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152747)[0m Exception in thread Thread-1:
[2m[36m(pid=152747)[0m Traceback (most recent call last):
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152747)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152747)[0m     param_dset[:] = val
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152747)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152747)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152747)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152747)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152747)[0m , filename = '/tmp/thalvari/4065561/automl_save_78hqe740/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b814ec6a0, total write size = 262144, bytes this sub-write = 262144, bytes actually written = 18446744073709551615, offset = 34712)
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m Traceback (most recent call last):
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152747)[0m     self._entrypoint()
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152747)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152747)[0m     output = train_func(config, reporter)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152747)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152747)[0m     config=config)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152747)[0m     model.save(model_path, config_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152747)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152747)[0m     self.model.save(model_path)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152747)[0m     signatures)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152747)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152747)[0m     f.close()
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152747)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152747)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152747)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152747)[0m , filename = '/tmp/thalvari/4065561/automl_save_78hqe740/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4b81ddaee0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m Traceback (most recent call last):
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152747)[0m     self.run()
[2m[36m(pid=152747)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152747)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152747)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152748)[0m 2020-11-20 11:46:13,368	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152748)[0m Traceback (most recent call last):
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152748)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152748)[0m     param_dset[:] = val
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152748)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152748)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152748)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152748)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152748)[0m , filename = '/tmp/thalvari/4065561/automl_save_60y3glad/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7ea7890b8, total write size = 1000856, bytes this sub-write = 1000856, bytes actually written = 18446744073709551615, offset = 307200)
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m Traceback (most recent call last):
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152748)[0m     self._entrypoint()
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152748)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152748)[0m     output = train_func(config, reporter)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152748)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152748)[0m     config=config)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152748)[0m     model.save(model_path, config_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152748)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152748)[0m     self.model.save(model_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152748)[0m     signatures)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152748)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152748)[0m     f.close()
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152748)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152748)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152748)[0m , filename = '/tmp/thalvari/4065561/automl_save_60y3glad/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7e97382e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152748)[0m Exception in thread Thread-1:
[2m[36m(pid=152748)[0m Traceback (most recent call last):
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152748)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152748)[0m     param_dset[:] = val
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152748)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152748)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152748)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152748)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152748)[0m , filename = '/tmp/thalvari/4065561/automl_save_60y3glad/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7ea7890b8, total write size = 1000856, bytes this sub-write = 1000856, bytes actually written = 18446744073709551615, offset = 307200)
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m Traceback (most recent call last):
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152748)[0m     self._entrypoint()
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152748)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152748)[0m     output = train_func(config, reporter)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152748)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152748)[0m     config=config)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152748)[0m     model.save(model_path, config_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152748)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152748)[0m     self.model.save(model_path)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152748)[0m     signatures)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152748)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152748)[0m     f.close()
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152748)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152748)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152748)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:13 2020
[2m[36m(pid=152748)[0m , filename = '/tmp/thalvari/4065561/automl_save_60y3glad/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fa7e97382e0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m Traceback (most recent call last):
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152748)[0m     self.run()
[2m[36m(pid=152748)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152748)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152748)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152930)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152930)[0m 2020-11-20 11:46:13.688315: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152930)[0m 2020-11-20 11:46:13.698488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152930)[0m 2020-11-20 11:46:13.700674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f53311021b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152930)[0m 2020-11-20 11:46:13.700707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152926)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152926)[0m Instructions for updating:
[2m[36m(pid=152926)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152921)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152921)[0m   agg_primitives: ['count']
[2m[36m(pid=152921)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152921)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152921)[0m LSTM is selected.
[2m[36m(pid=152921)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152921)[0m Instructions for updating:
[2m[36m(pid=152921)[0m If using Keras pass *_constraint arguments to layers.
2020-11-20 11:46:14,438	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152748, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:14,445	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_103_batch_size_log=9.8313,bayes_feature_DAY(timestamp)=0.43257,bayes_feature_HOUR(timestamp)=0.63509,bayes_feature_IS_AWAKE(timestamp)=0.5805,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79566,bayes_feature_IS_WEEKEND(timestamp)=0.91825,bayes_feature_MONTH(timestamp)=0.91193,bayes_feature_WEEKDAY(timestamp)=0.98979,dropout_1=0.30615,dropout_2=0.47493,epochs=5,lr=0.0097841,lstm_1_units_float=8.2628,lstm_2_units_float=124.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152748)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152748)[0m 
[2m[36m(pid=152748)[0m Stack (most recent call first):
[2m[36m(pid=152926)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152926)[0m 2020-11-20 11:46:14.750393: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152926)[0m 2020-11-20 11:46:14.760079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152926)[0m 2020-11-20 11:46:14.763404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f27850e9860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152926)[0m 2020-11-20 11:46:14.763438: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152921)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152921)[0m Instructions for updating:
[2m[36m(pid=152921)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152927)[0m 2020-11-20 11:46:15,138	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152927)[0m Traceback (most recent call last):
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152927)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152927)[0m     param_dset[:] = val
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152927)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152927)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152927)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152927)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152927)[0m , filename = '/tmp/thalvari/4065561/automl_save_8z4foesh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d0aa15608, total write size = 984408, bytes this sub-write = 984408, bytes actually written = 18446744073709551615, offset = 299008)
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m Traceback (most recent call last):
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152927)[0m     self._entrypoint()
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152927)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152927)[0m     output = train_func(config, reporter)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152927)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152927)[0m     config=config)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152927)[0m     model.save(model_path, config_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152927)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152927)[0m     self.model.save(model_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152927)[0m     signatures)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152927)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152927)[0m     f.close()
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152927)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152927)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152927)[0m , filename = '/tmp/thalvari/4065561/automl_save_8z4foesh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d09ddcef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152927)[0m Exception in thread Thread-1:
[2m[36m(pid=152927)[0m Traceback (most recent call last):
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152927)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152927)[0m     param_dset[:] = val
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152927)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152927)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152927)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152927)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152927)[0m , filename = '/tmp/thalvari/4065561/automl_save_8z4foesh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d0aa15608, total write size = 984408, bytes this sub-write = 984408, bytes actually written = 18446744073709551615, offset = 299008)
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m Traceback (most recent call last):
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152927)[0m     self._entrypoint()
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152927)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152927)[0m     output = train_func(config, reporter)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152927)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152927)[0m     config=config)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152927)[0m     model.save(model_path, config_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152927)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152927)[0m     self.model.save(model_path)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152927)[0m     signatures)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152927)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152927)[0m     f.close()
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152927)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152927)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152927)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152927)[0m , filename = '/tmp/thalvari/4065561/automl_save_8z4foesh/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f4d09ddcef0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m Traceback (most recent call last):
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152927)[0m     self.run()
[2m[36m(pid=152927)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152927)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152927)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152927)[0m 
2020-11-20 11:46:15,275	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152747, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:15,279	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_102_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.99816,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.30192,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.20186,dropout_2=0.2,epochs=5,lr=0.0086871,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152929)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152929)[0m   agg_primitives: ['count']
[2m[36m(pid=152929)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152929)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152747)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152747)[0m 
[2m[36m(pid=152747)[0m Stack (most recent call first):
[2m[36m(pid=152924)[0m 2020-11-20 11:46:15,819	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152924)[0m Traceback (most recent call last):
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152924)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152924)[0m     param_dset[:] = val
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152924)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152924)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152924)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152924)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152924)[0m , filename = '/tmp/thalvari/4065561/automl_save_hndlkcfi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f947695bf38, total write size = 980376, bytes this sub-write = 980376, bytes actually written = 18446744073709551615, offset = 278528)
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m Traceback (most recent call last):
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152924)[0m     self._entrypoint()
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152924)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152924)[0m     output = train_func(config, reporter)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152924)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152924)[0m     config=config)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152924)[0m     model.save(model_path, config_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152924)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152924)[0m     self.model.save(model_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152924)[0m     signatures)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152924)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152924)[0m     f.close()
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152924)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152924)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152924)[0m , filename = '/tmp/thalvari/4065561/automl_save_hndlkcfi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f94764869d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152924)[0m Exception in thread Thread-1:
[2m[36m(pid=152924)[0m Traceback (most recent call last):
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152924)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152924)[0m     param_dset[:] = val
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152924)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152924)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152924)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152924)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152924)[0m , filename = '/tmp/thalvari/4065561/automl_save_hndlkcfi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f947695bf38, total write size = 980376, bytes this sub-write = 980376, bytes actually written = 18446744073709551615, offset = 278528)
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m Traceback (most recent call last):
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152924)[0m     self._entrypoint()
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152924)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152924)[0m     output = train_func(config, reporter)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152924)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152924)[0m     config=config)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152924)[0m     model.save(model_path, config_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152924)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152924)[0m     self.model.save(model_path)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152924)[0m     signatures)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152924)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152924)[0m     f.close()
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152924)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152924)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152924)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152924)[0m , filename = '/tmp/thalvari/4065561/automl_save_hndlkcfi/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f94764869d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=152928)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd5998b5580, total write size = 6936, bytes this sub-write = 6936, bytes actually written = 18446744073709551615, offset = 24576)
[2m[36m(pid=152928)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=152928)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd5998b5580, total write size = 6936, bytes this sub-write = 6936, bytes actually written = 18446744073709551615, offset = 24576)
[2m[36m(pid=152928)[0m 2020-11-20 11:46:15,810	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152928)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152928)[0m     param_dset[:] = val
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152928)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152928)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152928)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152928)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd59a631c50, total write size = 226576, bytes this sub-write = 226576, bytes actually written = 18446744073709551615, offset = 33560)
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152928)[0m     self._entrypoint()
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152928)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152928)[0m     output = train_func(config, reporter)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152928)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152928)[0m     config=config)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152928)[0m     model.save(model_path, config_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152928)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152928)[0m     self.model.save(model_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152928)[0m     signatures)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152928)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152928)[0m     f.close()
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152928)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152928)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd59a72dd70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152928)[0m Exception in thread Thread-1:
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152928)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152928)[0m     param_dset[:] = val
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152928)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152928)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152928)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152928)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd59a631c50, total write size = 226576, bytes this sub-write = 226576, bytes actually written = 18446744073709551615, offset = 33560)
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152928)[0m     self._entrypoint()
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152928)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152928)[0m     output = train_func(config, reporter)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152928)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152928)[0m     config=config)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152928)[0m     model.save(model_path, config_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152928)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152928)[0m     self.model.save(model_path)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152928)[0m     signatures)
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152928)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152929)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152929)[0m Instructions for updating:
[2m[36m(pid=152929)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152929)[0m LSTM is selected.
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m Traceback (most recent call last):
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152924)[0m     self.run()
[2m[36m(pid=152924)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152924)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152924)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152928)[0m     f.close()
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152928)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152928)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152928)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:15 2020
[2m[36m(pid=152928)[0m , filename = '/tmp/thalvari/4065561/automl_save_d_nvtd_i/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fd59a72dd70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m Traceback (most recent call last):
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152928)[0m     self.run()
[2m[36m(pid=152928)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152928)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152928)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152921)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152921)[0m 2020-11-20 11:46:16.010812: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152921)[0m 2020-11-20 11:46:16.019210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152921)[0m 2020-11-20 11:46:16.021825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f270d0e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152921)[0m 2020-11-20 11:46:16.021862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.3/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 113 ({'TERMINATED': 23, 'ERROR': 80, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 74 not shown
 - train_func_101_batch_size_log=9.2359,bayes_feature_DAY(timestamp)=0.90099,bayes_feature_HOUR(timestamp)=0.3015,bayes_feature_IS_AWAKE(timestamp)=0.6465,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8231,bayes_feature_IS_WEEKEND(timestamp)=0.64903,bayes_feature_MONTH(timestamp)=0.47482,bayes_feature_WEEKDAY(timestamp)=0.42722,dropout_1=0.31961,dropout_2=0.34164,epochs=5,lr=0.0018487,lstm_1_units_float=8.0989,lstm_2_units_float=123.16,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_101_batch_size_log=9.2359,bayes_feature_DAY(timestamp)=0.90099,bayes_feature_HOUR(timestamp)=0.3015,bayes_feature_IS_AW_2020-11-20_11-46-01o_24zaue/error_2020-11-20_11-46-11.txt
 - train_func_102_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.99816,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.30192,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.20186,dropout_2=0.2,epochs=5,lr=0.0086871,lstm_1_units_float=8.0,lstm_2_units_float=128.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_102_batch_size_log=10.0,bayes_feature_DAY(timestamp)=0.99816,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(t_2020-11-20_11-46-02uk94t8am/error_2020-11-20_11-46-15.txt
 - train_func_103_batch_size_log=9.8313,bayes_feature_DAY(timestamp)=0.43257,bayes_feature_HOUR(timestamp)=0.63509,bayes_feature_IS_AWAKE(timestamp)=0.5805,bayes_feature_IS_BUSY_HOURS(timestamp)=0.79566,bayes_feature_IS_WEEKEND(timestamp)=0.91825,bayes_feature_MONTH(timestamp)=0.91193,bayes_feature_WEEKDAY(timestamp)=0.98979,dropout_1=0.30615,dropout_2=0.47493,epochs=5,lr=0.0097841,lstm_1_units_float=8.2628,lstm_2_units_float=124.0,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_103_batch_size_log=9.8313,bayes_feature_DAY(timestamp)=0.43257,bayes_feature_HOUR(timestamp)=0.63509,bayes_feature_IS_A_2020-11-20_11-46-03s7lwn1r6/error_2020-11-20_11-46-14.txt
RUNNING trials:
 - train_func_104_batch_size_log=6.3921,bayes_feature_DAY(timestamp)=0.53896,bayes_feature_HOUR(timestamp)=0.35076,bayes_feature_IS_AWAKE(timestamp)=0.67893,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31875,bayes_feature_IS_WEEKEND(timestamp)=0.83416,bayes_feature_MONTH(timestamp)=0.80696,bayes_feature_WEEKDAY(timestamp)=0.87824,dropout_1=0.34226,dropout_2=0.33996,epochs=5,lr=0.0080001,lstm_1_units_float=8.1095,lstm_2_units_float=120.88,past_seq_len=2:	RUNNING
 - train_func_105_batch_size_log=8.673,bayes_feature_DAY(timestamp)=0.91044,bayes_feature_HOUR(timestamp)=0.93167,bayes_feature_IS_AWAKE(timestamp)=0.39268,bayes_feature_IS_BUSY_HOURS(timestamp)=0.35829,bayes_feature_IS_WEEKEND(timestamp)=0.68284,bayes_feature_MONTH(timestamp)=0.72034,bayes_feature_WEEKDAY(timestamp)=0.60674,dropout_1=0.40806,dropout_2=0.3751,epochs=5,lr=0.0028619,lstm_1_units_float=8.0994,lstm_2_units_float=122.14,past_seq_len=2:	RUNNING
 - train_func_106_batch_size_log=8.6814,bayes_feature_DAY(timestamp)=0.4981,bayes_feature_HOUR(timestamp)=0.77899,bayes_feature_IS_AWAKE(timestamp)=0.56016,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59883,bayes_feature_IS_WEEKEND(timestamp)=0.4582,bayes_feature_MONTH(timestamp)=0.76119,bayes_feature_WEEKDAY(timestamp)=0.80949,dropout_1=0.33771,dropout_2=0.4042,epochs=5,lr=0.0076468,lstm_1_units_float=8.0963,lstm_2_units_float=119.65,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_111_batch_size_log=6.4554,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.48504,bayes_feature_IS_AWAKE(timestamp)=0.81395,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33993,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.81088,bayes_feature_WEEKDAY(timestamp)=0.86232,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0069571,lstm_1_units_float=8.0,lstm_2_units_float=121.02,past_seq_len=2:	RUNNING
 - train_func_112_batch_size_log=5.7218,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.89,past_seq_len=2:	RUNNING
 - train_func_113_batch_size_log=6.3862,bayes_feature_DAY(timestamp)=0.35366,bayes_feature_HOUR(timestamp)=0.61143,bayes_feature_IS_AWAKE(timestamp)=0.83608,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89815,bayes_feature_IS_WEEKEND(timestamp)=0.43136,bayes_feature_MONTH(timestamp)=0.78907,bayes_feature_WEEKDAY(timestamp)=0.41692,dropout_1=0.26354,dropout_2=0.47938,epochs=5,lr=0.0098638,lstm_1_units_float=8.0088,lstm_2_units_float=124.28,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

2020-11-20 11:46:16,256	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152927, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:16,259	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_105_batch_size_log=8.673,bayes_feature_DAY(timestamp)=0.91044,bayes_feature_HOUR(timestamp)=0.93167,bayes_feature_IS_AWAKE(timestamp)=0.39268,bayes_feature_IS_BUSY_HOURS(timestamp)=0.35829,bayes_feature_IS_WEEKEND(timestamp)=0.68284,bayes_feature_MONTH(timestamp)=0.72034,bayes_feature_WEEKDAY(timestamp)=0.60674,dropout_1=0.40806,dropout_2=0.3751,epochs=5,lr=0.0028619,lstm_1_units_float=8.0994,lstm_2_units_float=122.14,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152929)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152929)[0m Instructions for updating:
[2m[36m(pid=152929)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152930)[0m 2020-11-20 11:46:16,432	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152930)[0m Traceback (most recent call last):
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152930)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152930)[0m     param_dset[:] = val
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152930)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:16 2020
[2m[36m(pid=152930)[0m , filename = '/tmp/thalvari/4065561/automl_save_abtgb6pp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5332148a58, total write size = 1752, bytes this sub-write = 1752, bytes actually written = 18446744073709551615, offset = 270336)
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m Traceback (most recent call last):
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152930)[0m     self._entrypoint()
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152930)[0m     output = train_func(config, reporter)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152930)[0m     config=config)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152930)[0m     model.save(model_path, config_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152930)[0m     self.model.save(model_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152930)[0m     signatures)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152930)[0m     f.close()
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152930)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:16 2020
[2m[36m(pid=152930)[0m , filename = '/tmp/thalvari/4065561/automl_save_abtgb6pp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f53323a2bb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152930)[0m Exception in thread Thread-1:
[2m[36m(pid=152930)[0m Traceback (most recent call last):
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152930)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152930)[0m     param_dset[:] = val
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152930)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152930)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152930)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152930)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:16 2020
[2m[36m(pid=152930)[0m , filename = '/tmp/thalvari/4065561/automl_save_abtgb6pp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f5332148a58, total write size = 1752, bytes this sub-write = 1752, bytes actually written = 18446744073709551615, offset = 270336)
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m Traceback (most recent call last):
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152930)[0m     self._entrypoint()
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152930)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152930)[0m     output = train_func(config, reporter)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152930)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152930)[0m     config=config)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152930)[0m     model.save(model_path, config_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152930)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152930)[0m     self.model.save(model_path)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152930)[0m     signatures)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152930)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152930)[0m     f.close()
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152930)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152930)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152930)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:16 2020
[2m[36m(pid=152930)[0m , filename = '/tmp/thalvari/4065561/automl_save_abtgb6pp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f53323a2bb0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m Traceback (most recent call last):
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152930)[0m     self.run()
[2m[36m(pid=152930)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152930)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152930)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152927)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152927)[0m 
[2m[36m(pid=152927)[0m Stack (most recent call first):
[2m[36m(pid=152872)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152872)[0m   agg_primitives: ['count']
[2m[36m(pid=152872)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152872)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:46:16,977	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152928, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:16,983	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_106_batch_size_log=8.6814,bayes_feature_DAY(timestamp)=0.4981,bayes_feature_HOUR(timestamp)=0.77899,bayes_feature_IS_AWAKE(timestamp)=0.56016,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59883,bayes_feature_IS_WEEKEND(timestamp)=0.4582,bayes_feature_MONTH(timestamp)=0.76119,bayes_feature_WEEKDAY(timestamp)=0.80949,dropout_1=0.33771,dropout_2=0.4042,epochs=5,lr=0.0076468,lstm_1_units_float=8.0963,lstm_2_units_float=119.65,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152872)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152872)[0m Instructions for updating:
[2m[36m(pid=152872)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152872)[0m LSTM is selected.
[2m[36m(pid=155126)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155128)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155128)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155208)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155126)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155208)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155209)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155210)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155210)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155209)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152929)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152929)[0m 2020-11-20 11:46:17.481139: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152929)[0m 2020-11-20 11:46:17.489186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152929)[0m 2020-11-20 11:46:17.491110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd41119fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152929)[0m 2020-11-20 11:46:17.491131: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152928)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152928)[0m 
[2m[36m(pid=152928)[0m Stack (most recent call first):
[2m[36m(pid=152872)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152872)[0m Instructions for updating:
[2m[36m(pid=152872)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155376)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155377)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155377)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155335)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155335)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155334)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155334)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155379)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155376)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2020-11-20 11:46:18,153	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152924, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

[2m[36m(pid=155379)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155424)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155424)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
2020-11-20 11:46:18,158	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_104_batch_size_log=6.3921,bayes_feature_DAY(timestamp)=0.53896,bayes_feature_HOUR(timestamp)=0.35076,bayes_feature_IS_AWAKE(timestamp)=0.67893,bayes_feature_IS_BUSY_HOURS(timestamp)=0.31875,bayes_feature_IS_WEEKEND(timestamp)=0.83416,bayes_feature_MONTH(timestamp)=0.80696,bayes_feature_WEEKDAY(timestamp)=0.87824,dropout_1=0.34226,dropout_2=0.33996,epochs=5,lr=0.0080001,lstm_1_units_float=8.1095,lstm_2_units_float=120.88,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155422)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155380)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155380)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155423)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155423)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155427)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155427)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=155378)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/bigdl/share/conf/spark-bigdl.conf to sys.path
[2m[36m(pid=155378)[0m Prepending /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/share/conf/spark-analytics-zoo.conf to sys.path
[2m[36m(pid=152924)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152924)[0m 
[2m[36m(pid=152924)[0m Stack (most recent call first):
[2m[36m(pid=152872)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152872)[0m 2020-11-20 11:46:18.845065: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152872)[0m 2020-11-20 11:46:18.854723: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152872)[0m 2020-11-20 11:46:18.857715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe1590e9c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152872)[0m 2020-11-20 11:46:18.857749: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=152926)[0m 2020-11-20 11:46:19,291	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152926)[0m Traceback (most recent call last):
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152926)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152926)[0m     param_dset[:] = val
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152926)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152926)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152926)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152926)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:19 2020
[2m[36m(pid=152926)[0m , filename = '/tmp/thalvari/4065561/automl_save_ndij6ga6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f278667ada8, total write size = 133016, bytes this sub-write = 133016, bytes actually written = 18446744073709551615, offset = 131072)
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m Traceback (most recent call last):
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152926)[0m     self._entrypoint()
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152926)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152926)[0m     output = train_func(config, reporter)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152926)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152926)[0m     config=config)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152926)[0m     model.save(model_path, config_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152926)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152926)[0m     self.model.save(model_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152926)[0m     signatures)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152926)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152926)[0m     f.close()
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152926)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152926)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:19 2020
[2m[36m(pid=152926)[0m , filename = '/tmp/thalvari/4065561/automl_save_ndij6ga6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2786939580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152926)[0m Exception in thread Thread-1:
[2m[36m(pid=152926)[0m Traceback (most recent call last):
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152926)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152926)[0m     param_dset[:] = val
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152926)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152926)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152926)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152926)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:19 2020
[2m[36m(pid=152926)[0m , filename = '/tmp/thalvari/4065561/automl_save_ndij6ga6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f278667ada8, total write size = 133016, bytes this sub-write = 133016, bytes actually written = 18446744073709551615, offset = 131072)
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m Traceback (most recent call last):
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152926)[0m     self._entrypoint()
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152926)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152926)[0m     output = train_func(config, reporter)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152926)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152926)[0m     config=config)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152926)[0m     model.save(model_path, config_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152926)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152926)[0m     self.model.save(model_path)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152926)[0m     signatures)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152926)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152926)[0m     f.close()
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152926)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152926)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152926)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:19 2020
[2m[36m(pid=152926)[0m , filename = '/tmp/thalvari/4065561/automl_save_ndij6ga6/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f2786939580, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m Traceback (most recent call last):
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152926)[0m     self.run()
[2m[36m(pid=152926)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152926)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152926)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152926)[0m 
2020-11-20 11:46:19,444	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152930, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:19,448	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_107_batch_size_log=9.5396,bayes_feature_DAY(timestamp)=0.90594,bayes_feature_HOUR(timestamp)=0.43449,bayes_feature_IS_AWAKE(timestamp)=0.91096,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84496,bayes_feature_IS_WEEKEND(timestamp)=0.88876,bayes_feature_MONTH(timestamp)=0.50841,bayes_feature_WEEKDAY(timestamp)=0.8685,dropout_1=0.23012,dropout_2=0.42597,epochs=5,lr=0.007817,lstm_1_units_float=8.5216,lstm_2_units_float=122.9,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152930)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152930)[0m 
[2m[36m(pid=152930)[0m Stack (most recent call first):
[2m[36m(pid=152746)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=152746)[0m   agg_primitives: ['count']
[2m[36m(pid=152746)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=152746)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152746)[0m LSTM is selected.
2020-11-20 11:46:20,354	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152926, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:20,356	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_108_batch_size_log=6.8687,bayes_feature_DAY(timestamp)=0.9997,bayes_feature_HOUR(timestamp)=0.99953,bayes_feature_IS_AWAKE(timestamp)=0.30219,bayes_feature_IS_BUSY_HOURS(timestamp)=0.99983,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.77613,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.20016,dropout_2=0.20023,epochs=5,lr=0.0099432,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152746)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=152746)[0m Instructions for updating:
[2m[36m(pid=152746)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152926)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152926)[0m 
[2m[36m(pid=152926)[0m Stack (most recent call first):
[2m[36m(pid=152746)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=152746)[0m Instructions for updating:
[2m[36m(pid=152746)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.9/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 118 ({'TERMINATED': 23, 'ERROR': 85, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 79 not shown
 - train_func_106_batch_size_log=8.6814,bayes_feature_DAY(timestamp)=0.4981,bayes_feature_HOUR(timestamp)=0.77899,bayes_feature_IS_AWAKE(timestamp)=0.56016,bayes_feature_IS_BUSY_HOURS(timestamp)=0.59883,bayes_feature_IS_WEEKEND(timestamp)=0.4582,bayes_feature_MONTH(timestamp)=0.76119,bayes_feature_WEEKDAY(timestamp)=0.80949,dropout_1=0.33771,dropout_2=0.4042,epochs=5,lr=0.0076468,lstm_1_units_float=8.0963,lstm_2_units_float=119.65,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_106_batch_size_log=8.6814,bayes_feature_DAY(timestamp)=0.4981,bayes_feature_HOUR(timestamp)=0.77899,bayes_feature_IS_AW_2020-11-20_11-46-07tsaa39v4/error_2020-11-20_11-46-16.txt
 - train_func_107_batch_size_log=9.5396,bayes_feature_DAY(timestamp)=0.90594,bayes_feature_HOUR(timestamp)=0.43449,bayes_feature_IS_AWAKE(timestamp)=0.91096,bayes_feature_IS_BUSY_HOURS(timestamp)=0.84496,bayes_feature_IS_WEEKEND(timestamp)=0.88876,bayes_feature_MONTH(timestamp)=0.50841,bayes_feature_WEEKDAY(timestamp)=0.8685,dropout_1=0.23012,dropout_2=0.42597,epochs=5,lr=0.007817,lstm_1_units_float=8.5216,lstm_2_units_float=122.9,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_107_batch_size_log=9.5396,bayes_feature_DAY(timestamp)=0.90594,bayes_feature_HOUR(timestamp)=0.43449,bayes_feature_IS_A_2020-11-20_11-46-080nhubn00/error_2020-11-20_11-46-19.txt
 - train_func_108_batch_size_log=6.8687,bayes_feature_DAY(timestamp)=0.9997,bayes_feature_HOUR(timestamp)=0.99953,bayes_feature_IS_AWAKE(timestamp)=0.30219,bayes_feature_IS_BUSY_HOURS(timestamp)=0.99983,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.77613,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.20016,dropout_2=0.20023,epochs=5,lr=0.0099432,lstm_1_units_float=8.0,lstm_2_units_float=120.99,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_108_batch_size_log=6.8687,bayes_feature_DAY(timestamp)=0.9997,bayes_feature_HOUR(timestamp)=0.99953,bayes_feature_IS_AW_2020-11-20_11-46-09io_odrbk/error_2020-11-20_11-46-20.txt
RUNNING trials:
 - train_func_109_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.53495,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73232,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0034242,lstm_1_units_float=8.0,lstm_2_units_float=120.83,past_seq_len=2:	RUNNING
 - train_func_110_batch_size_log=6.2234,bayes_feature_DAY(timestamp)=0.55722,bayes_feature_HOUR(timestamp)=0.97075,bayes_feature_IS_AWAKE(timestamp)=0.86734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.54784,bayes_feature_IS_WEEKEND(timestamp)=0.53487,bayes_feature_MONTH(timestamp)=0.60563,bayes_feature_WEEKDAY(timestamp)=0.54984,dropout_1=0.20101,dropout_2=0.41189,epochs=5,lr=0.0097562,lstm_1_units_float=8.2416,lstm_2_units_float=114.98,past_seq_len=2:	RUNNING
 - train_func_111_batch_size_log=6.4554,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.48504,bayes_feature_IS_AWAKE(timestamp)=0.81395,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33993,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.81088,bayes_feature_WEEKDAY(timestamp)=0.86232,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0069571,lstm_1_units_float=8.0,lstm_2_units_float=121.02,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_116_batch_size_log=6.1771,bayes_feature_DAY(timestamp)=0.36337,bayes_feature_HOUR(timestamp)=0.55245,bayes_feature_IS_AWAKE(timestamp)=0.62175,bayes_feature_IS_BUSY_HOURS(timestamp)=0.76026,bayes_feature_IS_WEEKEND(timestamp)=0.56925,bayes_feature_MONTH(timestamp)=0.38828,bayes_feature_WEEKDAY(timestamp)=0.48745,dropout_1=0.4931,dropout_2=0.30574,epochs=5,lr=0.003756,lstm_1_units_float=8.1889,lstm_2_units_float=118.84,past_seq_len=2:	RUNNING
 - train_func_117_batch_size_log=9.3485,bayes_feature_DAY(timestamp)=0.68586,bayes_feature_HOUR(timestamp)=0.95321,bayes_feature_IS_AWAKE(timestamp)=0.37666,bayes_feature_IS_BUSY_HOURS(timestamp)=0.61885,bayes_feature_IS_WEEKEND(timestamp)=0.92561,bayes_feature_MONTH(timestamp)=0.34297,bayes_feature_WEEKDAY(timestamp)=0.55958,dropout_1=0.23845,dropout_2=0.48219,epochs=5,lr=0.0073628,lstm_1_units_float=8.0601,lstm_2_units_float=125.49,past_seq_len=2:	RUNNING
 - train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_AWAKE(timestamp)=0.67257,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70846,bayes_feature_IS_WEEKEND(timestamp)=0.43838,bayes_feature_MONTH(timestamp)=0.53994,bayes_feature_WEEKDAY(timestamp)=0.7792,dropout_1=0.34067,dropout_2=0.26248,epochs=5,lr=0.0083338,lstm_1_units_float=8.6338,lstm_2_units_float=119.23,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=152746)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=152746)[0m 2020-11-20 11:46:21.896606: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=152746)[0m 2020-11-20 11:46:21.905938: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=152746)[0m 2020-11-20 11:46:21.910296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f641d0a0c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=152746)[0m 2020-11-20 11:46:21.910347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155126)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155126)[0m   agg_primitives: ['count']
[2m[36m(pid=155126)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155126)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155128)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155128)[0m   agg_primitives: ['count']
[2m[36m(pid=155128)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155128)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155424)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155424)[0m   agg_primitives: ['count']
[2m[36m(pid=155424)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155424)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155422)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155422)[0m   agg_primitives: ['count']
[2m[36m(pid=155422)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155422)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155424)[0m LSTM is selected.
[2m[36m(pid=155422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155422)[0m Instructions for updating:
[2m[36m(pid=155422)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155422)[0m LSTM is selected.
[2m[36m(pid=155126)[0m LSTM is selected.
[2m[36m(pid=155128)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155128)[0m Instructions for updating:
[2m[36m(pid=155128)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155128)[0m LSTM is selected.
[2m[36m(pid=155424)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155424)[0m Instructions for updating:
[2m[36m(pid=155424)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155126)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155126)[0m Instructions for updating:
[2m[36m(pid=155126)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=152929)[0m 2020-11-20 11:46:23,076	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152929)[0m Traceback (most recent call last):
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152929)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152929)[0m     param_dset[:] = val
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152929)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152929)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152929)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152929)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152929)[0m , filename = '/tmp/thalvari/4065561/automl_save_pnmxnur_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd426cd588, total write size = 124312, bytes this sub-write = 124312, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m Traceback (most recent call last):
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152929)[0m     self._entrypoint()
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152929)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152929)[0m     output = train_func(config, reporter)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152929)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152929)[0m     config=config)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152929)[0m     model.save(model_path, config_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152929)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152929)[0m     self.model.save(model_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152929)[0m     signatures)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152929)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152929)[0m     f.close()
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152929)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152929)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152929)[0m , filename = '/tmp/thalvari/4065561/automl_save_pnmxnur_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd42280de0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152929)[0m Exception in thread Thread-1:
[2m[36m(pid=152929)[0m Traceback (most recent call last):
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152929)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152929)[0m     param_dset[:] = val
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152929)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152929)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152929)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152929)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152929)[0m , filename = '/tmp/thalvari/4065561/automl_save_pnmxnur_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd426cd588, total write size = 124312, bytes this sub-write = 124312, bytes actually written = 18446744073709551615, offset = 118784)
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m Traceback (most recent call last):
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152929)[0m     self._entrypoint()
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152929)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152929)[0m     output = train_func(config, reporter)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152929)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152929)[0m     config=config)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152929)[0m     model.save(model_path, config_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152929)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152929)[0m     self.model.save(model_path)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152929)[0m     signatures)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152929)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152929)[0m     f.close()
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152929)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152929)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152929)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152929)[0m , filename = '/tmp/thalvari/4065561/automl_save_pnmxnur_/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fdd42280de0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m Traceback (most recent call last):
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152929)[0m     self.run()
[2m[36m(pid=152929)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152929)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152929)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152929)[0m 
[2m[36m(pid=155380)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155380)[0m   agg_primitives: ['count']
[2m[36m(pid=155380)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155380)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155126)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155126)[0m Instructions for updating:
[2m[36m(pid=155126)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155128)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155128)[0m Instructions for updating:
[2m[36m(pid=155128)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155422)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155422)[0m Instructions for updating:
[2m[36m(pid=155422)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155424)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155424)[0m Instructions for updating:
[2m[36m(pid=155424)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=152872)[0m 2020-11-20 11:46:23,739	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152872)[0m Traceback (most recent call last):
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152872)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152872)[0m     param_dset[:] = val
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152872)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152872)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152872)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152872)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152872)[0m , filename = '/tmp/thalvari/4065561/automl_save_ma5cbhqu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe15a6637b8, total write size = 157480, bytes this sub-write = 157480, bytes actually written = 18446744073709551615, offset = 110592)
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m Traceback (most recent call last):
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152872)[0m     self._entrypoint()
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152872)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152872)[0m     output = train_func(config, reporter)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152872)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152872)[0m     config=config)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152872)[0m     model.save(model_path, config_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152872)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152872)[0m     self.model.save(model_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152872)[0m     signatures)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152872)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152872)[0m     f.close()
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152872)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152872)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152872)[0m , filename = '/tmp/thalvari/4065561/automl_save_ma5cbhqu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe159924020, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152872)[0m Exception in thread Thread-1:
[2m[36m(pid=152872)[0m Traceback (most recent call last):
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152872)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152872)[0m     param_dset[:] = val
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152872)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152872)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152872)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152872)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152872)[0m , filename = '/tmp/thalvari/4065561/automl_save_ma5cbhqu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe15a6637b8, total write size = 157480, bytes this sub-write = 157480, bytes actually written = 18446744073709551615, offset = 110592)
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m Traceback (most recent call last):
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152872)[0m     self._entrypoint()
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152872)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152872)[0m     output = train_func(config, reporter)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152872)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152872)[0m     config=config)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152872)[0m     model.save(model_path, config_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152872)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152872)[0m     self.model.save(model_path)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152872)[0m     signatures)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152872)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152872)[0m     f.close()
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152872)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152872)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152872)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:23 2020
[2m[36m(pid=152872)[0m , filename = '/tmp/thalvari/4065561/automl_save_ma5cbhqu/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fe159924020, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m Traceback (most recent call last):
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152872)[0m     self.run()
[2m[36m(pid=152872)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152872)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152872)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152872)[0m 
[2m[36m(pid=155380)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155380)[0m Instructions for updating:
[2m[36m(pid=155380)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155380)[0m LSTM is selected.
2020-11-20 11:46:24,115	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152929, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:24,118	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_110_batch_size_log=6.2234,bayes_feature_DAY(timestamp)=0.55722,bayes_feature_HOUR(timestamp)=0.97075,bayes_feature_IS_AWAKE(timestamp)=0.86734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.54784,bayes_feature_IS_WEEKEND(timestamp)=0.53487,bayes_feature_MONTH(timestamp)=0.60563,bayes_feature_WEEKDAY(timestamp)=0.54984,dropout_1=0.20101,dropout_2=0.41189,epochs=5,lr=0.0097562,lstm_1_units_float=8.2416,lstm_2_units_float=114.98,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155423)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155423)[0m   agg_primitives: ['count']
[2m[36m(pid=155423)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155423)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=152929)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152929)[0m 
[2m[36m(pid=152929)[0m Stack (most recent call first):
[2m[36m(pid=155128)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155128)[0m 2020-11-20 11:46:24.423752: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155128)[0m 2020-11-20 11:46:24.431987: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155128)[0m 2020-11-20 11:46:24.434404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7ba10d1300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155128)[0m 2020-11-20 11:46:24.434436: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155126)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155126)[0m 2020-11-20 11:46:24.443801: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155126)[0m 2020-11-20 11:46:24.452097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155126)[0m 2020-11-20 11:46:24.454480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f43310b8c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155126)[0m 2020-11-20 11:46:24.454502: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155424)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155424)[0m 2020-11-20 11:46:24.479051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155424)[0m 2020-11-20 11:46:24.487465: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155424)[0m 2020-11-20 11:46:24.489879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f58a10b8ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155424)[0m 2020-11-20 11:46:24.489904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155422)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155422)[0m 2020-11-20 11:46:24.451089: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155422)[0m 2020-11-20 11:46:24.459203: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155422)[0m 2020-11-20 11:46:24.461640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7effc90d1c40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155422)[0m 2020-11-20 11:46:24.461673: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155380)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155380)[0m Instructions for updating:
[2m[36m(pid=155380)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155423)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155423)[0m Instructions for updating:
[2m[36m(pid=155423)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155423)[0m LSTM is selected.
[2m[36m(pid=152921)[0m 2020-11-20 11:46:24,712	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152921)[0m Traceback (most recent call last):
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152921)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152921)[0m     param_dset[:] = val
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152921)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152921)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152921)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152921)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:24 2020
[2m[36m(pid=152921)[0m , filename = '/tmp/thalvari/4065561/automl_save_uczl15d8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f270d575248, total write size = 161688, bytes this sub-write = 161688, bytes actually written = 18446744073709551615, offset = 102400)
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m Traceback (most recent call last):
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152921)[0m     self._entrypoint()
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152921)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152921)[0m     output = train_func(config, reporter)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152921)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152921)[0m     config=config)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152921)[0m     model.save(model_path, config_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152921)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152921)[0m     self.model.save(model_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152921)[0m     signatures)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152921)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152921)[0m     f.close()
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152921)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152921)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:24 2020
[2m[36m(pid=152921)[0m , filename = '/tmp/thalvari/4065561/automl_save_uczl15d8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f270e2c1e20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152921)[0m Exception in thread Thread-1:
[2m[36m(pid=152921)[0m Traceback (most recent call last):
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152921)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152921)[0m     param_dset[:] = val
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152921)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152921)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152921)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152921)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:24 2020
[2m[36m(pid=152921)[0m , filename = '/tmp/thalvari/4065561/automl_save_uczl15d8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f270d575248, total write size = 161688, bytes this sub-write = 161688, bytes actually written = 18446744073709551615, offset = 102400)
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m Traceback (most recent call last):
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152921)[0m     self._entrypoint()
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152921)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152921)[0m     output = train_func(config, reporter)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152921)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152921)[0m     config=config)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152921)[0m     model.save(model_path, config_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152921)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152921)[0m     self.model.save(model_path)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152921)[0m     signatures)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152921)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152921)[0m     f.close()
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152921)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152921)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152921)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:24 2020
[2m[36m(pid=152921)[0m , filename = '/tmp/thalvari/4065561/automl_save_uczl15d8/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f270e2c1e20, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m Traceback (most recent call last):
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152921)[0m     self.run()
[2m[36m(pid=152921)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152921)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152921)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152921)[0m 
2020-11-20 11:46:24,900	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152872, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:24,902	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_111_batch_size_log=6.4554,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.48504,bayes_feature_IS_AWAKE(timestamp)=0.81395,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33993,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.81088,bayes_feature_WEEKDAY(timestamp)=0.86232,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0069571,lstm_1_units_float=8.0,lstm_2_units_float=121.02,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152872)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152872)[0m 
[2m[36m(pid=152872)[0m Stack (most recent call first):
[2m[36m(pid=155423)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155423)[0m Instructions for updating:
[2m[36m(pid=155423)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155380)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155380)[0m 2020-11-20 11:46:25.570422: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155380)[0m 2020-11-20 11:46:25.578508: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155380)[0m 2020-11-20 11:46:25.581054: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f60090e9900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155380)[0m 2020-11-20 11:46:25.581080: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:46:25,859	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152921, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:25,863	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_109_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.53495,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73232,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0034242,lstm_1_units_float=8.0,lstm_2_units_float=120.83,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=152921)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152921)[0m 
[2m[36m(pid=152921)[0m Stack (most recent call first):
[2m[36m(pid=155423)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155423)[0m 2020-11-20 11:46:26.352975: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155423)[0m 2020-11-20 11:46:26.363215: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155423)[0m 2020-11-20 11:46:26.367902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbc50e96c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155423)[0m 2020-11-20 11:46:26.367941: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 15.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 121 ({'TERMINATED': 23, 'ERROR': 88, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 82 not shown
 - train_func_109_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.53495,bayes_feature_IS_BUSY_HOURS(timestamp)=0.73232,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.3,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0034242,lstm_1_units_float=8.0,lstm_2_units_float=120.83,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_109_batch_size_log=5.0,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timest_2020-11-20_11-46-103wciqkvk/error_2020-11-20_11-46-25.txt
 - train_func_110_batch_size_log=6.2234,bayes_feature_DAY(timestamp)=0.55722,bayes_feature_HOUR(timestamp)=0.97075,bayes_feature_IS_AWAKE(timestamp)=0.86734,bayes_feature_IS_BUSY_HOURS(timestamp)=0.54784,bayes_feature_IS_WEEKEND(timestamp)=0.53487,bayes_feature_MONTH(timestamp)=0.60563,bayes_feature_WEEKDAY(timestamp)=0.54984,dropout_1=0.20101,dropout_2=0.41189,epochs=5,lr=0.0097562,lstm_1_units_float=8.2416,lstm_2_units_float=114.98,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_110_batch_size_log=6.2234,bayes_feature_DAY(timestamp)=0.55722,bayes_feature_HOUR(timestamp)=0.97075,bayes_feature_IS_A_2020-11-20_11-46-11qqouxpya/error_2020-11-20_11-46-24.txt
 - train_func_111_batch_size_log=6.4554,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.48504,bayes_feature_IS_AWAKE(timestamp)=0.81395,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33993,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.81088,bayes_feature_WEEKDAY(timestamp)=0.86232,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0069571,lstm_1_units_float=8.0,lstm_2_units_float=121.02,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_111_batch_size_log=6.4554,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.48504,bayes_feature_IS_AWAKE_2020-11-20_11-46-12oeb79s5v/error_2020-11-20_11-46-24.txt
RUNNING trials:
 - train_func_112_batch_size_log=5.7218,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.89,past_seq_len=2:	RUNNING
 - train_func_113_batch_size_log=6.3862,bayes_feature_DAY(timestamp)=0.35366,bayes_feature_HOUR(timestamp)=0.61143,bayes_feature_IS_AWAKE(timestamp)=0.83608,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89815,bayes_feature_IS_WEEKEND(timestamp)=0.43136,bayes_feature_MONTH(timestamp)=0.78907,bayes_feature_WEEKDAY(timestamp)=0.41692,dropout_1=0.26354,dropout_2=0.47938,epochs=5,lr=0.0098638,lstm_1_units_float=8.0088,lstm_2_units_float=124.28,past_seq_len=2:	RUNNING
 - train_func_114_batch_size_log=5.3171,bayes_feature_DAY(timestamp)=0.35406,bayes_feature_HOUR(timestamp)=0.41616,bayes_feature_IS_AWAKE(timestamp)=0.38727,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9188,bayes_feature_IS_WEEKEND(timestamp)=0.5558,bayes_feature_MONTH(timestamp)=0.81142,bayes_feature_WEEKDAY(timestamp)=0.39401,dropout_1=0.44015,dropout_2=0.28644,epochs=5,lr=0.0049033,lstm_1_units_float=8.0574,lstm_2_units_float=122.43,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_119_batch_size_log=6.1162,bayes_feature_DAY(timestamp)=0.36467,bayes_feature_HOUR(timestamp)=0.80344,bayes_feature_IS_AWAKE(timestamp)=0.80376,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48999,bayes_feature_IS_WEEKEND(timestamp)=0.82115,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.20447,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.06,past_seq_len=2:	RUNNING
 - train_func_120_batch_size_log=6.9814,bayes_feature_DAY(timestamp)=0.55431,bayes_feature_HOUR(timestamp)=0.92283,bayes_feature_IS_AWAKE(timestamp)=0.78882,bayes_feature_IS_BUSY_HOURS(timestamp)=0.88287,bayes_feature_IS_WEEKEND(timestamp)=0.82778,bayes_feature_MONTH(timestamp)=0.57771,bayes_feature_WEEKDAY(timestamp)=0.67736,dropout_1=0.27974,dropout_2=0.31606,epochs=5,lr=0.0047302,lstm_1_units_float=8.3059,lstm_2_units_float=119.87,past_seq_len=2:	RUNNING
 - train_func_121_batch_size_log=6.0091,bayes_feature_DAY(timestamp)=0.51723,bayes_feature_HOUR(timestamp)=0.72144,bayes_feature_IS_AWAKE(timestamp)=0.34021,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87806,bayes_feature_IS_WEEKEND(timestamp)=0.80011,bayes_feature_MONTH(timestamp)=0.69489,bayes_feature_WEEKDAY(timestamp)=0.50848,dropout_1=0.22293,dropout_2=0.46117,epochs=5,lr=0.0012092,lstm_1_units_float=8.1824,lstm_2_units_float=121.47,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=152746)[0m 2020-11-20 11:46:28,158	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=152746)[0m Traceback (most recent call last):
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152746)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152746)[0m     param_dset[:] = val
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152746)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152746)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152746)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152746)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=152746)[0m , filename = '/tmp/thalvari/4065561/automl_save_ifwq6o8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f641e898658, total write size = 169880, bytes this sub-write = 169880, bytes actually written = 18446744073709551615, offset = 94208)
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m Traceback (most recent call last):
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152746)[0m     self._entrypoint()
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152746)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152746)[0m     output = train_func(config, reporter)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152746)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152746)[0m     config=config)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152746)[0m     model.save(model_path, config_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152746)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152746)[0m     self.model.save(model_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152746)[0m     signatures)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152746)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152746)[0m     f.close()
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152746)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152746)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=152746)[0m , filename = '/tmp/thalvari/4065561/automl_save_ifwq6o8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f641e636480, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152746)[0m Exception in thread Thread-1:
[2m[36m(pid=152746)[0m Traceback (most recent call last):
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=152746)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=152746)[0m     param_dset[:] = val
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=152746)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=152746)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=152746)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=152746)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=152746)[0m , filename = '/tmp/thalvari/4065561/automl_save_ifwq6o8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f641e898658, total write size = 169880, bytes this sub-write = 169880, bytes actually written = 18446744073709551615, offset = 94208)
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m Traceback (most recent call last):
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=152746)[0m     self._entrypoint()
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=152746)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=152746)[0m     output = train_func(config, reporter)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=152746)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=152746)[0m     config=config)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=152746)[0m     model.save(model_path, config_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=152746)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=152746)[0m     self.model.save(model_path)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=152746)[0m     signatures)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=152746)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=152746)[0m     f.close()
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=152746)[0m     h5i.dec_ref(id_)
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=152746)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=152746)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=152746)[0m , filename = '/tmp/thalvari/4065561/automl_save_ifwq6o8x/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f641e636480, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m Traceback (most recent call last):
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=152746)[0m     self.run()
[2m[36m(pid=152746)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=152746)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=152746)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=152746)[0m 
[2m[36m(pid=155380)[0m 2020-11-20 11:46:28,464	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155380)[0m Traceback (most recent call last):
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155380)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155380)[0m     param_dset[:] = val
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155380)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155380)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155380)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155380)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=155380)[0m , filename = '/tmp/thalvari/4065561/automl_save_ecd09hbv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f600a64ae38, total write size = 198312, bytes this sub-write = 198312, bytes actually written = 18446744073709551615, offset = 86016)
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m Traceback (most recent call last):
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155380)[0m     self._entrypoint()
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155380)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155380)[0m     output = train_func(config, reporter)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155380)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155380)[0m     config=config)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155380)[0m     model.save(model_path, config_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155380)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155380)[0m     self.model.save(model_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155380)[0m     signatures)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155380)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155380)[0m     f.close()
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155380)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155380)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=155380)[0m , filename = '/tmp/thalvari/4065561/automl_save_ecd09hbv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6009cf33c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155380)[0m Exception in thread Thread-1:
[2m[36m(pid=155380)[0m Traceback (most recent call last):
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155380)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155380)[0m     param_dset[:] = val
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155380)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155380)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155380)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155380)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=155380)[0m , filename = '/tmp/thalvari/4065561/automl_save_ecd09hbv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f600a64ae38, total write size = 198312, bytes this sub-write = 198312, bytes actually written = 18446744073709551615, offset = 86016)
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m Traceback (most recent call last):
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155380)[0m     self._entrypoint()
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155380)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155380)[0m     output = train_func(config, reporter)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155380)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155380)[0m     config=config)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155380)[0m     model.save(model_path, config_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155380)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155380)[0m     self.model.save(model_path)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155380)[0m     signatures)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155380)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155380)[0m     f.close()
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155380)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155380)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155380)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:28 2020
[2m[36m(pid=155380)[0m , filename = '/tmp/thalvari/4065561/automl_save_ecd09hbv/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f6009cf33c0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m Traceback (most recent call last):
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155380)[0m     self.run()
[2m[36m(pid=155380)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155380)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155380)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155427)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155427)[0m   agg_primitives: ['count']
[2m[36m(pid=155427)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155427)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155379)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155379)[0m   agg_primitives: ['count']
[2m[36m(pid=155379)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155379)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:46:29,246	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=152746, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:29,251	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_112_batch_size_log=5.7218,bayes_feature_DAY(timestamp)=0.3,bayes_feature_HOUR(timestamp)=0.3,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=0.3,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=0.3,dropout_1=0.2,dropout_2=0.5,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=120.89,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155128)[0m 2020-11-20 11:46:29,247	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155128)[0m Traceback (most recent call last):
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155128)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155128)[0m     param_dset[:] = val
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155128)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155128)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155128)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155128)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155128)[0m , filename = '/tmp/thalvari/4065561/automl_save_lkccg9kt/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7ba24e7328, total write size = 202392, bytes this sub-write = 202392, bytes actually written = 18446744073709551615, offset = 77824)
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m Traceback (most recent call last):
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155128)[0m     self._entrypoint()
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155128)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155128)[0m     output = train_func(config, reporter)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155128)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155128)[0m     config=config)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155128)[0m     model.save(model_path, config_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155128)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155128)[0m     self.model.save(model_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155128)[0m     signatures)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155128)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155128)[0m     f.close()
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155128)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155128)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155128)[0m , filename = '/tmp/thalvari/4065561/automl_save_lkccg9kt/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7ba2561c80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155128)[0m Exception in thread Thread-1:
[2m[36m(pid=155128)[0m Traceback (most recent call last):
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155128)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155128)[0m     param_dset[:] = val
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155128)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155128)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155128)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155128)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155128)[0m , filename = '/tmp/thalvari/4065561/automl_save_lkccg9kt/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7ba24e7328, total write size = 202392, bytes this sub-write = 202392, bytes actually written = 18446744073709551615, offset = 77824)
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m Traceback (most recent call last):
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155128)[0m     self._entrypoint()
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155128)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155128)[0m     output = train_func(config, reporter)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155128)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155128)[0m     config=config)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155128)[0m     model.save(model_path, config_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155128)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155128)[0m     self.model.save(model_path)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155128)[0m     signatures)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155128)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155128)[0m     f.close()
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155128)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155128)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155128)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155128)[0m , filename = '/tmp/thalvari/4065561/automl_save_lkccg9kt/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f7ba2561c80, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m Traceback (most recent call last):
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155128)[0m     self.run()
[2m[36m(pid=155128)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155128)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155128)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155379)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155379)[0m Instructions for updating:
[2m[36m(pid=155379)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155379)[0m LSTM is selected.
[2m[36m(pid=152746)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=152746)[0m 
[2m[36m(pid=152746)[0m Stack (most recent call first):
[2m[36m(pid=155427)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155427)[0m Instructions for updating:
[2m[36m(pid=155427)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155427)[0m LSTM is selected.
[2m[36m(pid=155423)[0m 2020-11-20 11:46:29,587	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155423)[0m Traceback (most recent call last):
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155423)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155423)[0m     param_dset[:] = val
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155423)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155423)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155423)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155423)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155423)[0m , filename = '/tmp/thalvari/4065561/automl_save_715860wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc5e20f38, total write size = 190504, bytes this sub-write = 190504, bytes actually written = 18446744073709551615, offset = 69632)
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m Traceback (most recent call last):
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155423)[0m     self._entrypoint()
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155423)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155423)[0m     output = train_func(config, reporter)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155423)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155423)[0m     config=config)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155423)[0m     model.save(model_path, config_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155423)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155423)[0m     self.model.save(model_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155423)[0m     signatures)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155423)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155423)[0m     f.close()
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155423)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155423)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155423)[0m , filename = '/tmp/thalvari/4065561/automl_save_715860wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc5eb56d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155423)[0m Exception in thread Thread-1:
[2m[36m(pid=155423)[0m Traceback (most recent call last):
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155423)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155423)[0m     param_dset[:] = val
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155423)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155423)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155423)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155423)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155423)[0m , filename = '/tmp/thalvari/4065561/automl_save_715860wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc5e20f38, total write size = 190504, bytes this sub-write = 190504, bytes actually written = 18446744073709551615, offset = 69632)
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m Traceback (most recent call last):
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155423)[0m     self._entrypoint()
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155423)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155423)[0m     output = train_func(config, reporter)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155423)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155423)[0m     config=config)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155423)[0m     model.save(model_path, config_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155423)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155423)[0m     self.model.save(model_path)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155423)[0m     signatures)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155423)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155423)[0m     f.close()
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155423)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155423)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155423)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155423)[0m , filename = '/tmp/thalvari/4065561/automl_save_715860wa/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fcbc5eb56d0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m Traceback (most recent call last):
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155423)[0m     self.run()
[2m[36m(pid=155423)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155423)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155423)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155379)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155379)[0m Instructions for updating:
[2m[36m(pid=155379)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155422)[0m 2020-11-20 11:46:29,950	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155422)[0m Traceback (most recent call last):
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155422)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155422)[0m     param_dset[:] = val
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155422)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155422)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155422)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155422)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155422)[0m , filename = '/tmp/thalvari/4065561/automl_save_m33l2ks7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7effca5d6f78, total write size = 194776, bytes this sub-write = 194776, bytes actually written = 18446744073709551615, offset = 61440)
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m Traceback (most recent call last):
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155422)[0m     self._entrypoint()
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155422)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155422)[0m     output = train_func(config, reporter)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155422)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155422)[0m     config=config)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155422)[0m     model.save(model_path, config_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155422)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155422)[0m     self.model.save(model_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155422)[0m     signatures)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155422)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155422)[0m     f.close()
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155422)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155422)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155422)[0m , filename = '/tmp/thalvari/4065561/automl_save_m33l2ks7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7effc9df9ed0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155422)[0m Exception in thread Thread-1:
[2m[36m(pid=155422)[0m Traceback (most recent call last):
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155422)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155422)[0m     param_dset[:] = val
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155422)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155422)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155422)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155422)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155422)[0m , filename = '/tmp/thalvari/4065561/automl_save_m33l2ks7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7effca5d6f78, total write size = 194776, bytes this sub-write = 194776, bytes actually written = 18446744073709551615, offset = 61440)
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m Traceback (most recent call last):
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155422)[0m     self._entrypoint()
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155422)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155422)[0m     output = train_func(config, reporter)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155422)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155422)[0m     config=config)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155422)[0m     model.save(model_path, config_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155422)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155422)[0m     self.model.save(model_path)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155422)[0m     signatures)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155422)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155422)[0m     f.close()
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155422)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155422)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155422)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:29 2020
[2m[36m(pid=155422)[0m , filename = '/tmp/thalvari/4065561/automl_save_m33l2ks7/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7effc9df9ed0, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155427)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155427)[0m Instructions for updating:
[2m[36m(pid=155427)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m Traceback (most recent call last):
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155422)[0m     self.run()
[2m[36m(pid=155422)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155422)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155422)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155422)[0m 
2020-11-20 11:46:30,095	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155380, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:30,097	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_117_batch_size_log=9.3485,bayes_feature_DAY(timestamp)=0.68586,bayes_feature_HOUR(timestamp)=0.95321,bayes_feature_IS_AWAKE(timestamp)=0.37666,bayes_feature_IS_BUSY_HOURS(timestamp)=0.61885,bayes_feature_IS_WEEKEND(timestamp)=0.92561,bayes_feature_MONTH(timestamp)=0.34297,bayes_feature_WEEKDAY(timestamp)=0.55958,dropout_1=0.23845,dropout_2=0.48219,epochs=5,lr=0.0073628,lstm_1_units_float=8.0601,lstm_2_units_float=125.49,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155380)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155380)[0m 
[2m[36m(pid=155380)[0m Stack (most recent call first):
[2m[36m(pid=155376)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155376)[0m   agg_primitives: ['count']
[2m[36m(pid=155376)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155376)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155424)[0m 2020-11-20 11:46:30,335	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155424)[0m Traceback (most recent call last):
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155424)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155424)[0m     param_dset[:] = val
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155424)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155424)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155424)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155424)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:30 2020
[2m[36m(pid=155424)[0m , filename = '/tmp/thalvari/4065561/automl_save_btih28gd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f58a14bef68, total write size = 206888, bytes this sub-write = 206888, bytes actually written = 18446744073709551615, offset = 53248)
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m Traceback (most recent call last):
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155424)[0m     self._entrypoint()
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155424)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155424)[0m     output = train_func(config, reporter)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155424)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155424)[0m     config=config)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155424)[0m     model.save(model_path, config_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155424)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155424)[0m     self.model.save(model_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155424)[0m     signatures)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155424)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155424)[0m     f.close()
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155424)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155424)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:30 2020
[2m[36m(pid=155424)[0m , filename = '/tmp/thalvari/4065561/automl_save_btih28gd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f58a1857900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155424)[0m Exception in thread Thread-1:
[2m[36m(pid=155424)[0m Traceback (most recent call last):
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155424)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155424)[0m     param_dset[:] = val
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155424)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155424)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155424)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155424)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:30 2020
[2m[36m(pid=155424)[0m , filename = '/tmp/thalvari/4065561/automl_save_btih28gd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f58a14bef68, total write size = 206888, bytes this sub-write = 206888, bytes actually written = 18446744073709551615, offset = 53248)
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m Traceback (most recent call last):
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155424)[0m     self._entrypoint()
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155424)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155424)[0m     output = train_func(config, reporter)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155424)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155424)[0m     config=config)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155424)[0m     model.save(model_path, config_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155424)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155424)[0m     self.model.save(model_path)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155424)[0m     signatures)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155424)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155424)[0m     f.close()
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155424)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155424)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155424)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:30 2020
[2m[36m(pid=155424)[0m , filename = '/tmp/thalvari/4065561/automl_save_btih28gd/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f58a1857900, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m Traceback (most recent call last):
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155424)[0m     self.run()
[2m[36m(pid=155424)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155424)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155424)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155424)[0m 
2020-11-20 11:46:30,836	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155423, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:30,838	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_AWAKE(timestamp)=0.67257,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70846,bayes_feature_IS_WEEKEND(timestamp)=0.43838,bayes_feature_MONTH(timestamp)=0.53994,bayes_feature_WEEKDAY(timestamp)=0.7792,dropout_1=0.34067,dropout_2=0.26248,epochs=5,lr=0.0083338,lstm_1_units_float=8.6338,lstm_2_units_float=119.23,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155376)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155376)[0m Instructions for updating:
[2m[36m(pid=155376)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155376)[0m LSTM is selected.
[2m[36m(pid=155423)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155423)[0m 
[2m[36m(pid=155423)[0m Stack (most recent call first):
[2m[36m(pid=155427)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155427)[0m 2020-11-20 11:46:30.907425: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155427)[0m 2020-11-20 11:46:30.945159: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155427)[0m 2020-11-20 11:46:30.949603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83510ea400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155427)[0m 2020-11-20 11:46:30.949638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155379)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155379)[0m 2020-11-20 11:46:30.989818: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155379)[0m 2020-11-20 11:46:30.997954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155379)[0m 2020-11-20 11:46:31.003732: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3445119860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155379)[0m 2020-11-20 11:46:31.003760: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155376)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155376)[0m Instructions for updating:
[2m[36m(pid=155376)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-11-20 11:46:31,522	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155424, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:31,524	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_115_batch_size_log=5.7981,bayes_feature_DAY(timestamp)=0.89475,bayes_feature_HOUR(timestamp)=0.31196,bayes_feature_IS_AWAKE(timestamp)=0.46474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33964,bayes_feature_IS_WEEKEND(timestamp)=0.50463,bayes_feature_MONTH(timestamp)=0.94533,bayes_feature_WEEKDAY(timestamp)=0.38906,dropout_1=0.33586,dropout_2=0.36592,epochs=5,lr=0.0075648,lstm_1_units_float=8.532,lstm_2_units_float=119.18,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155424)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155424)[0m 
[2m[36m(pid=155424)[0m Stack (most recent call first):
[2m[36m(pid=155126)[0m 2020-11-20 11:46:31,767	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155126)[0m Traceback (most recent call last):
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155126)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155126)[0m     param_dset[:] = val
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155126)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155126)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155126)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155126)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:31 2020
[2m[36m(pid=155126)[0m , filename = '/tmp/thalvari/4065561/automl_save_5hzw6sk2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f433150ce88, total write size = 227032, bytes this sub-write = 227032, bytes actually written = 18446744073709551615, offset = 45056)
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m Traceback (most recent call last):
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155126)[0m     self._entrypoint()
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155126)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155126)[0m     output = train_func(config, reporter)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155126)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155126)[0m     config=config)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155126)[0m     model.save(model_path, config_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155126)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155126)[0m     self.model.save(model_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155126)[0m     signatures)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155126)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155126)[0m     f.close()
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155126)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155126)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:31 2020
[2m[36m(pid=155126)[0m , filename = '/tmp/thalvari/4065561/automl_save_5hzw6sk2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f43325dcb30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155126)[0m Exception in thread Thread-1:
[2m[36m(pid=155126)[0m Traceback (most recent call last):
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155126)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155126)[0m     param_dset[:] = val
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155126)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155126)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155126)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155126)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:31 2020
[2m[36m(pid=155126)[0m , filename = '/tmp/thalvari/4065561/automl_save_5hzw6sk2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f433150ce88, total write size = 227032, bytes this sub-write = 227032, bytes actually written = 18446744073709551615, offset = 45056)
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m Traceback (most recent call last):
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155126)[0m     self._entrypoint()
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155126)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155126)[0m     output = train_func(config, reporter)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155126)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155126)[0m     config=config)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155126)[0m     model.save(model_path, config_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155126)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155126)[0m     self.model.save(model_path)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155126)[0m     signatures)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155126)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155126)[0m     f.close()
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155126)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155126)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155126)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:31 2020
[2m[36m(pid=155126)[0m , filename = '/tmp/thalvari/4065561/automl_save_5hzw6sk2/weights_tune.h5', file descriptor = 21, errno = 28, error message = 'No space left on device', buf = 0x7f43325dcb30, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m Traceback (most recent call last):
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155126)[0m     self.run()
[2m[36m(pid=155126)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155126)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155126)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155126)[0m 
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.8/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 125 ({'TERMINATED': 23, 'ERROR': 92, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 86 not shown
 - train_func_115_batch_size_log=5.7981,bayes_feature_DAY(timestamp)=0.89475,bayes_feature_HOUR(timestamp)=0.31196,bayes_feature_IS_AWAKE(timestamp)=0.46474,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33964,bayes_feature_IS_WEEKEND(timestamp)=0.50463,bayes_feature_MONTH(timestamp)=0.94533,bayes_feature_WEEKDAY(timestamp)=0.38906,dropout_1=0.33586,dropout_2=0.36592,epochs=5,lr=0.0075648,lstm_1_units_float=8.532,lstm_2_units_float=119.18,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_115_batch_size_log=5.7981,bayes_feature_DAY(timestamp)=0.89475,bayes_feature_HOUR(timestamp)=0.31196,bayes_feature_IS_A_2020-11-20_11-46-1878m1p4ba/error_2020-11-20_11-46-31.txt
 - train_func_117_batch_size_log=9.3485,bayes_feature_DAY(timestamp)=0.68586,bayes_feature_HOUR(timestamp)=0.95321,bayes_feature_IS_AWAKE(timestamp)=0.37666,bayes_feature_IS_BUSY_HOURS(timestamp)=0.61885,bayes_feature_IS_WEEKEND(timestamp)=0.92561,bayes_feature_MONTH(timestamp)=0.34297,bayes_feature_WEEKDAY(timestamp)=0.55958,dropout_1=0.23845,dropout_2=0.48219,epochs=5,lr=0.0073628,lstm_1_units_float=8.0601,lstm_2_units_float=125.49,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_117_batch_size_log=9.3485,bayes_feature_DAY(timestamp)=0.68586,bayes_feature_HOUR(timestamp)=0.95321,bayes_feature_IS_A_2020-11-20_11-46-20zsh15l83/error_2020-11-20_11-46-30.txt
 - train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_AWAKE(timestamp)=0.67257,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70846,bayes_feature_IS_WEEKEND(timestamp)=0.43838,bayes_feature_MONTH(timestamp)=0.53994,bayes_feature_WEEKDAY(timestamp)=0.7792,dropout_1=0.34067,dropout_2=0.26248,epochs=5,lr=0.0083338,lstm_1_units_float=8.6338,lstm_2_units_float=119.23,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_A_2020-11-20_11-46-21lf8kpo5t/error_2020-11-20_11-46-30.txt
RUNNING trials:
 - train_func_113_batch_size_log=6.3862,bayes_feature_DAY(timestamp)=0.35366,bayes_feature_HOUR(timestamp)=0.61143,bayes_feature_IS_AWAKE(timestamp)=0.83608,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89815,bayes_feature_IS_WEEKEND(timestamp)=0.43136,bayes_feature_MONTH(timestamp)=0.78907,bayes_feature_WEEKDAY(timestamp)=0.41692,dropout_1=0.26354,dropout_2=0.47938,epochs=5,lr=0.0098638,lstm_1_units_float=8.0088,lstm_2_units_float=124.28,past_seq_len=2:	RUNNING
 - train_func_114_batch_size_log=5.3171,bayes_feature_DAY(timestamp)=0.35406,bayes_feature_HOUR(timestamp)=0.41616,bayes_feature_IS_AWAKE(timestamp)=0.38727,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9188,bayes_feature_IS_WEEKEND(timestamp)=0.5558,bayes_feature_MONTH(timestamp)=0.81142,bayes_feature_WEEKDAY(timestamp)=0.39401,dropout_1=0.44015,dropout_2=0.28644,epochs=5,lr=0.0049033,lstm_1_units_float=8.0574,lstm_2_units_float=122.43,past_seq_len=2:	RUNNING
 - train_func_116_batch_size_log=6.1771,bayes_feature_DAY(timestamp)=0.36337,bayes_feature_HOUR(timestamp)=0.55245,bayes_feature_IS_AWAKE(timestamp)=0.62175,bayes_feature_IS_BUSY_HOURS(timestamp)=0.76026,bayes_feature_IS_WEEKEND(timestamp)=0.56925,bayes_feature_MONTH(timestamp)=0.38828,bayes_feature_WEEKDAY(timestamp)=0.48745,dropout_1=0.4931,dropout_2=0.30574,epochs=5,lr=0.003756,lstm_1_units_float=8.1889,lstm_2_units_float=118.84,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_123_batch_size_log=5.9685,bayes_feature_DAY(timestamp)=0.98879,bayes_feature_HOUR(timestamp)=0.9388,bayes_feature_IS_AWAKE(timestamp)=0.70386,bayes_feature_IS_BUSY_HOURS(timestamp)=0.97974,bayes_feature_IS_WEEKEND(timestamp)=0.65915,bayes_feature_MONTH(timestamp)=0.4873,bayes_feature_WEEKDAY(timestamp)=0.75869,dropout_1=0.27407,dropout_2=0.42677,epochs=5,lr=0.009126,lstm_1_units_float=8.1112,lstm_2_units_float=119.6,past_seq_len=2:	RUNNING
 - train_func_124_batch_size_log=5.7897,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.95776,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.69952,bayes_feature_WEEKDAY(timestamp)=0.4877,dropout_1=0.32815,dropout_2=0.26446,epochs=5,lr=0.0096913,lstm_1_units_float=8.0,lstm_2_units_float=120.87,past_seq_len=2:	RUNNING
 - train_func_125_batch_size_log=7.3661,bayes_feature_DAY(timestamp)=0.65898,bayes_feature_HOUR(timestamp)=0.97837,bayes_feature_IS_AWAKE(timestamp)=0.62581,bayes_feature_IS_BUSY_HOURS(timestamp)=0.38274,bayes_feature_IS_WEEKEND(timestamp)=0.77375,bayes_feature_MONTH(timestamp)=0.78078,bayes_feature_WEEKDAY(timestamp)=0.88022,dropout_1=0.43373,dropout_2=0.35505,epochs=5,lr=0.0054844,lstm_1_units_float=8.076,lstm_2_units_float=118.14,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

2020-11-20 11:46:32,273	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155422, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:32,276	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_116_batch_size_log=6.1771,bayes_feature_DAY(timestamp)=0.36337,bayes_feature_HOUR(timestamp)=0.55245,bayes_feature_IS_AWAKE(timestamp)=0.62175,bayes_feature_IS_BUSY_HOURS(timestamp)=0.76026,bayes_feature_IS_WEEKEND(timestamp)=0.56925,bayes_feature_MONTH(timestamp)=0.38828,bayes_feature_WEEKDAY(timestamp)=0.48745,dropout_1=0.4931,dropout_2=0.30574,epochs=5,lr=0.003756,lstm_1_units_float=8.1889,lstm_2_units_float=118.84,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155422)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155422)[0m 
[2m[36m(pid=155422)[0m Stack (most recent call first):
[2m[36m(pid=155376)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155376)[0m 2020-11-20 11:46:32.412512: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155376)[0m 2020-11-20 11:46:32.425755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155376)[0m 2020-11-20 11:46:32.429763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6b11025a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155376)[0m 2020-11-20 11:46:32.429792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-20 11:46:33,146	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155126, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:33,149	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_114_batch_size_log=5.3171,bayes_feature_DAY(timestamp)=0.35406,bayes_feature_HOUR(timestamp)=0.41616,bayes_feature_IS_AWAKE(timestamp)=0.38727,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9188,bayes_feature_IS_WEEKEND(timestamp)=0.5558,bayes_feature_MONTH(timestamp)=0.81142,bayes_feature_WEEKDAY(timestamp)=0.39401,dropout_1=0.44015,dropout_2=0.28644,epochs=5,lr=0.0049033,lstm_1_units_float=8.0574,lstm_2_units_float=122.43,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155126)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155126)[0m 
[2m[36m(pid=155126)[0m Stack (most recent call first):
[2m[36m(pid=155377)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155377)[0m   agg_primitives: ['count']
[2m[36m(pid=155377)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155377)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155335)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155335)[0m   agg_primitives: ['count']
[2m[36m(pid=155335)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155335)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155377)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155377)[0m Instructions for updating:
[2m[36m(pid=155377)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155377)[0m LSTM is selected.
[2m[36m(pid=155335)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155335)[0m Instructions for updating:
[2m[36m(pid=155335)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155335)[0m LSTM is selected.
2020-11-20 11:46:33,911	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155128, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:33,916	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_113_batch_size_log=6.3862,bayes_feature_DAY(timestamp)=0.35366,bayes_feature_HOUR(timestamp)=0.61143,bayes_feature_IS_AWAKE(timestamp)=0.83608,bayes_feature_IS_BUSY_HOURS(timestamp)=0.89815,bayes_feature_IS_WEEKEND(timestamp)=0.43136,bayes_feature_MONTH(timestamp)=0.78907,bayes_feature_WEEKDAY(timestamp)=0.41692,dropout_1=0.26354,dropout_2=0.47938,epochs=5,lr=0.0098638,lstm_1_units_float=8.0088,lstm_2_units_float=124.28,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155128)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155128)[0m 
[2m[36m(pid=155128)[0m Stack (most recent call first):
[2m[36m(pid=155377)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155377)[0m Instructions for updating:
[2m[36m(pid=155377)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155335)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155335)[0m Instructions for updating:
[2m[36m(pid=155335)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155334)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155334)[0m   agg_primitives: ['count']
[2m[36m(pid=155334)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155334)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155379)[0m 2020-11-20 11:46:34,875	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155379)[0m Traceback (most recent call last):
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155379)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155379)[0m     param_dset[:] = val
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155379)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155379)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155379)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155379)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:34 2020
[2m[36m(pid=155379)[0m , filename = '/tmp/thalvari/4065561/automl_save_6k2__474/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f344633d9c8, total write size = 225512, bytes this sub-write = 225512, bytes actually written = 18446744073709551615, offset = 36864)
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m Traceback (most recent call last):
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155379)[0m     self._entrypoint()
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155379)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155379)[0m     output = train_func(config, reporter)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155379)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155379)[0m     config=config)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155379)[0m     model.save(model_path, config_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155379)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155379)[0m     self.model.save(model_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155379)[0m     signatures)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155379)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155379)[0m     f.close()
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155379)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155379)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:34 2020
[2m[36m(pid=155379)[0m , filename = '/tmp/thalvari/4065561/automl_save_6k2__474/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3445939720, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155379)[0m Exception in thread Thread-1:
[2m[36m(pid=155379)[0m Traceback (most recent call last):
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155379)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155379)[0m     param_dset[:] = val
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155379)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155379)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155379)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155379)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:34 2020
[2m[36m(pid=155379)[0m , filename = '/tmp/thalvari/4065561/automl_save_6k2__474/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f344633d9c8, total write size = 225512, bytes this sub-write = 225512, bytes actually written = 18446744073709551615, offset = 36864)
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m Traceback (most recent call last):
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155379)[0m     self._entrypoint()
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155379)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155379)[0m     output = train_func(config, reporter)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155379)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155379)[0m     config=config)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155379)[0m     model.save(model_path, config_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155379)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155379)[0m     self.model.save(model_path)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155379)[0m     signatures)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155379)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155379)[0m     f.close()
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155379)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155379)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155379)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:34 2020
[2m[36m(pid=155379)[0m , filename = '/tmp/thalvari/4065561/automl_save_6k2__474/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f3445939720, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m Traceback (most recent call last):
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155379)[0m     self.run()
[2m[36m(pid=155379)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155379)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155379)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155334)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155334)[0m Instructions for updating:
[2m[36m(pid=155334)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155334)[0m LSTM is selected.
[2m[36m(pid=155377)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155377)[0m 2020-11-20 11:46:35.420120: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155377)[0m 2020-11-20 11:46:35.429010: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155377)[0m 2020-11-20 11:46:35.431430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efe350b96c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155377)[0m 2020-11-20 11:46:35.431456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155335)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155335)[0m 2020-11-20 11:46:35.496936: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155335)[0m 2020-11-20 11:46:35.504528: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155335)[0m 2020-11-20 11:46:35.506340: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd75101a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155335)[0m 2020-11-20 11:46:35.506367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155210)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155210)[0m   agg_primitives: ['count']
[2m[36m(pid=155210)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155210)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155334)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155334)[0m Instructions for updating:
[2m[36m(pid=155334)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=155427)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83522fba80, total write size = 3096, bytes this sub-write = 3096, bytes actually written = 18446744073709551615, offset = 28672)
[2m[36m(pid=155427)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=155427)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f83522fba80, total write size = 3096, bytes this sub-write = 3096, bytes actually written = 18446744073709551615, offset = 28672)
[2m[36m(pid=155427)[0m 2020-11-20 11:46:35,813	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155427)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155427)[0m     param_dset[:] = val
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155427)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155427)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155427)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155427)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8351d9a450, total write size = 234256, bytes this sub-write = 234256, bytes actually written = 18446744073709551615, offset = 33816)
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155427)[0m     self._entrypoint()
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155427)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155427)[0m     output = train_func(config, reporter)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155427)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155427)[0m     config=config)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155427)[0m     model.save(model_path, config_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155427)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155427)[0m     self.model.save(model_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155427)[0m     signatures)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155427)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155427)[0m     f.close()
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155427)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155427)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8351923e40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155427)[0m Exception in thread Thread-1:
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155427)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155427)[0m     param_dset[:] = val
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155427)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155427)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155427)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155427)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8351d9a450, total write size = 234256, bytes this sub-write = 234256, bytes actually written = 18446744073709551615, offset = 33816)
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155427)[0m     self._entrypoint()
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155427)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155427)[0m     output = train_func(config, reporter)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155427)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155427)[0m     config=config)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155427)[0m     model.save(model_path, config_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155427)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155427)[0m     self.model.save(model_path)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155427)[0m     signatures)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155427)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155427)[0m     f.close()
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155427)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155427)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155427)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:35 2020
[2m[36m(pid=155427)[0m , filename = '/tmp/thalvari/4065561/automl_save_tzzkjtqp/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7f8351923e40, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m Traceback (most recent call last):
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155427)[0m     self.run()
[2m[36m(pid=155427)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155427)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155427)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155427)[0m 
2020-11-20 11:46:35,956	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155379, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:35,959	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_120_batch_size_log=6.9814,bayes_feature_DAY(timestamp)=0.55431,bayes_feature_HOUR(timestamp)=0.92283,bayes_feature_IS_AWAKE(timestamp)=0.78882,bayes_feature_IS_BUSY_HOURS(timestamp)=0.88287,bayes_feature_IS_WEEKEND(timestamp)=0.82778,bayes_feature_MONTH(timestamp)=0.57771,bayes_feature_WEEKDAY(timestamp)=0.67736,dropout_1=0.27974,dropout_2=0.31606,epochs=5,lr=0.0047302,lstm_1_units_float=8.3059,lstm_2_units_float=119.87,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155210)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155210)[0m Instructions for updating:
[2m[36m(pid=155210)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155210)[0m LSTM is selected.
[2m[36m(pid=155379)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155379)[0m 
[2m[36m(pid=155379)[0m Stack (most recent call first):
[2m[36m(pid=155378)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155378)[0m   agg_primitives: ['count']
[2m[36m(pid=155378)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155378)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155210)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155210)[0m Instructions for updating:
[2m[36m(pid=155210)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155378)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155378)[0m Instructions for updating:
[2m[36m(pid=155378)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155378)[0m LSTM is selected.
[2m[36m(pid=155334)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155334)[0m 2020-11-20 11:46:36.794219: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155334)[0m 2020-11-20 11:46:36.802129: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155334)[0m 2020-11-20 11:46:36.805016: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f43d1102220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155334)[0m 2020-11-20 11:46:36.805050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155209)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155209)[0m   agg_primitives: ['count']
[2m[36m(pid=155209)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155209)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
2020-11-20 11:46:36,966	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155427, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:36,969	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_119_batch_size_log=6.1162,bayes_feature_DAY(timestamp)=0.36467,bayes_feature_HOUR(timestamp)=0.80344,bayes_feature_IS_AWAKE(timestamp)=0.80376,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48999,bayes_feature_IS_WEEKEND(timestamp)=0.82115,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.20447,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.06,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155427)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155427)[0m 
[2m[36m(pid=155427)[0m Stack (most recent call first):
[2m[36m(pid=155209)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155209)[0m Instructions for updating:
[2m[36m(pid=155209)[0m If using Keras pass *_constraint arguments to layers.
[2m[36m(pid=155209)[0m LSTM is selected.
[2m[36m(pid=155378)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155378)[0m Instructions for updating:
[2m[36m(pid=155378)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=155376)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b18cbae0, total write size = 15384, bytes this sub-write = 15384, bytes actually written = 18446744073709551615, offset = 16384)
[2m[36m(pid=155376)[0m Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 193, in h5py._objects.ObjectID.__dealloc__
[2m[36m(pid=155376)[0m RuntimeError: Can't decrement id ref count (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b18cbae0, total write size = 15384, bytes this sub-write = 15384, bytes actually written = 18446744073709551615, offset = 16384)
[2m[36m(pid=155376)[0m 2020-11-20 11:46:37,645	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155376)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155376)[0m     param_dset[:] = val
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155376)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155376)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155376)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155376)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b27a6c40, total write size = 234256, bytes this sub-write = 234256, bytes actually written = 18446744073709551615, offset = 33816)
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155376)[0m     self._entrypoint()
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155376)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155376)[0m     output = train_func(config, reporter)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155376)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155376)[0m     config=config)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155376)[0m     model.save(model_path, config_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155376)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155376)[0m     self.model.save(model_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155376)[0m     signatures)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155376)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155376)[0m     f.close()
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155376)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155376)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b13e8e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155376)[0m Exception in thread Thread-1:
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 103, in save_model_to_hdf5
[2m[36m(pid=155376)[0m     save_weights_to_hdf5_group(model_weights_group, model_layers)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 630, in save_weights_to_hdf5_group
[2m[36m(pid=155376)[0m     param_dset[:] = val
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/dataset.py", line 708, in __setitem__
[2m[36m(pid=155376)[0m     self.id.write(mspace, fspace, val, mtype, dxpl=self._dxpl)
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/h5d.pyx", line 222, in h5py.h5d.DatasetID.write
[2m[36m(pid=155376)[0m   File "h5py/_proxy.pyx", line 132, in h5py._proxy.dset_rw
[2m[36m(pid=155376)[0m   File "h5py/_proxy.pyx", line 93, in h5py._proxy.H5PY_H5Dwrite
[2m[36m(pid=155376)[0m OSError: Can't write data (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b27a6c40, total write size = 234256, bytes this sub-write = 234256, bytes actually written = 18446744073709551615, offset = 33816)
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155376)[0m     self._entrypoint()
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155376)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155376)[0m     output = train_func(config, reporter)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155376)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155376)[0m     config=config)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 120, in save
[2m[36m(pid=155376)[0m     model.save(model_path, config_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/time_sequence.py", line 122, in save
[2m[36m(pid=155376)[0m     self.model.save(model_path, config_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/model/VanillaLSTM.py", line 163, in save
[2m[36m(pid=155376)[0m     self.model.save(model_path)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1171, in save
[2m[36m(pid=155376)[0m     signatures)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 109, in save_model
[2m[36m(pid=155376)[0m     model, filepath, overwrite, include_optimizer)
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 114, in save_model_to_hdf5
[2m[36m(pid=155376)[0m     f.close()
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/h5py/_hl/files.py", line 443, in close
[2m[36m(pid=155376)[0m     h5i.dec_ref(id_)
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
[2m[36m(pid=155376)[0m   File "h5py/h5i.pyx", line 150, in h5py.h5i.dec_ref
[2m[36m(pid=155376)[0m RuntimeError: Problems closing file (file write failed: time = Fri Nov 20 11:46:37 2020
[2m[36m(pid=155376)[0m , filename = '/tmp/thalvari/4065561/automl_save_2e58leul/weights_tune.h5', file descriptor = 20, errno = 28, error message = 'No space left on device', buf = 0x7fb6b13e8e70, total write size = 2048, bytes this sub-write = 2048, bytes actually written = 18446744073709551615, offset = 4096)
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m Traceback (most recent call last):
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/threading.py", line 916, in _bootstrap_inner
[2m[36m(pid=155376)[0m     self.run()
[2m[36m(pid=155376)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 104, in run
[2m[36m(pid=155376)[0m     err_tb = err_tb.format_exc()
[2m[36m(pid=155376)[0m AttributeError: 'traceback' object has no attribute 'format_exc'
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155210)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155210)[0m 2020-11-20 11:46:37.770990: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155210)[0m 2020-11-20 11:46:37.780213: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155210)[0m 2020-11-20 11:46:37.783043: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f78911016c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155210)[0m 2020-11-20 11:46:37.783077: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155209)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155209)[0m Instructions for updating:
[2m[36m(pid=155209)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.4/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 130 ({'TERMINATED': 23, 'ERROR': 97, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 91 not shown
 - train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_AWAKE(timestamp)=0.67257,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70846,bayes_feature_IS_WEEKEND(timestamp)=0.43838,bayes_feature_MONTH(timestamp)=0.53994,bayes_feature_WEEKDAY(timestamp)=0.7792,dropout_1=0.34067,dropout_2=0.26248,epochs=5,lr=0.0083338,lstm_1_units_float=8.6338,lstm_2_units_float=119.23,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_118_batch_size_log=8.6749,bayes_feature_DAY(timestamp)=0.35145,bayes_feature_HOUR(timestamp)=0.81169,bayes_feature_IS_A_2020-11-20_11-46-21lf8kpo5t/error_2020-11-20_11-46-30.txt
 - train_func_119_batch_size_log=6.1162,bayes_feature_DAY(timestamp)=0.36467,bayes_feature_HOUR(timestamp)=0.80344,bayes_feature_IS_AWAKE(timestamp)=0.80376,bayes_feature_IS_BUSY_HOURS(timestamp)=0.48999,bayes_feature_IS_WEEKEND(timestamp)=0.82115,bayes_feature_MONTH(timestamp)=1.0,bayes_feature_WEEKDAY(timestamp)=1.0,dropout_1=0.2,dropout_2=0.20447,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.06,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_119_batch_size_log=6.1162,bayes_feature_DAY(timestamp)=0.36467,bayes_feature_HOUR(timestamp)=0.80344,bayes_feature_IS_A_2020-11-20_11-46-24hlzoznby/error_2020-11-20_11-46-36.txt
 - train_func_120_batch_size_log=6.9814,bayes_feature_DAY(timestamp)=0.55431,bayes_feature_HOUR(timestamp)=0.92283,bayes_feature_IS_AWAKE(timestamp)=0.78882,bayes_feature_IS_BUSY_HOURS(timestamp)=0.88287,bayes_feature_IS_WEEKEND(timestamp)=0.82778,bayes_feature_MONTH(timestamp)=0.57771,bayes_feature_WEEKDAY(timestamp)=0.67736,dropout_1=0.27974,dropout_2=0.31606,epochs=5,lr=0.0047302,lstm_1_units_float=8.3059,lstm_2_units_float=119.87,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_120_batch_size_log=6.9814,bayes_feature_DAY(timestamp)=0.55431,bayes_feature_HOUR(timestamp)=0.92283,bayes_feature_IS_A_2020-11-20_11-46-25ztcd1rwn/error_2020-11-20_11-46-35.txt
RUNNING trials:
 - train_func_121_batch_size_log=6.0091,bayes_feature_DAY(timestamp)=0.51723,bayes_feature_HOUR(timestamp)=0.72144,bayes_feature_IS_AWAKE(timestamp)=0.34021,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87806,bayes_feature_IS_WEEKEND(timestamp)=0.80011,bayes_feature_MONTH(timestamp)=0.69489,bayes_feature_WEEKDAY(timestamp)=0.50848,dropout_1=0.22293,dropout_2=0.46117,epochs=5,lr=0.0012092,lstm_1_units_float=8.1824,lstm_2_units_float=121.47,past_seq_len=2:	RUNNING
 - train_func_122_batch_size_log=6.2226,bayes_feature_DAY(timestamp)=0.85238,bayes_feature_HOUR(timestamp)=0.72378,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71759,bayes_feature_IS_WEEKEND(timestamp)=0.47707,bayes_feature_MONTH(timestamp)=0.30331,bayes_feature_WEEKDAY(timestamp)=0.30078,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.007113,lstm_1_units_float=8.0,lstm_2_units_float=120.98,past_seq_len=2:	RUNNING
 - train_func_123_batch_size_log=5.9685,bayes_feature_DAY(timestamp)=0.98879,bayes_feature_HOUR(timestamp)=0.9388,bayes_feature_IS_AWAKE(timestamp)=0.70386,bayes_feature_IS_BUSY_HOURS(timestamp)=0.97974,bayes_feature_IS_WEEKEND(timestamp)=0.65915,bayes_feature_MONTH(timestamp)=0.4873,bayes_feature_WEEKDAY(timestamp)=0.75869,dropout_1=0.27407,dropout_2=0.42677,epochs=5,lr=0.009126,lstm_1_units_float=8.1112,lstm_2_units_float=119.6,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_128_batch_size_log=7.1229,bayes_feature_DAY(timestamp)=0.89454,bayes_feature_HOUR(timestamp)=0.44692,bayes_feature_IS_AWAKE(timestamp)=0.78208,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33226,bayes_feature_IS_WEEKEND(timestamp)=0.57867,bayes_feature_MONTH(timestamp)=0.61192,bayes_feature_WEEKDAY(timestamp)=0.83239,dropout_1=0.22622,dropout_2=0.26643,epochs=5,lr=0.0069093,lstm_1_units_float=8.0325,lstm_2_units_float=118.72,past_seq_len=2:	RUNNING
 - train_func_129_batch_size_log=6.3992,bayes_feature_DAY(timestamp)=0.88551,bayes_feature_HOUR(timestamp)=0.91299,bayes_feature_IS_AWAKE(timestamp)=0.46738,bayes_feature_IS_BUSY_HOURS(timestamp)=0.97611,bayes_feature_IS_WEEKEND(timestamp)=0.97469,bayes_feature_MONTH(timestamp)=0.32709,bayes_feature_WEEKDAY(timestamp)=0.40487,dropout_1=0.20125,dropout_2=0.374,epochs=5,lr=0.0064661,lstm_1_units_float=8.0,lstm_2_units_float=120.95,past_seq_len=2:	RUNNING
 - train_func_130_batch_size_log=8.2066,bayes_feature_DAY(timestamp)=0.38726,bayes_feature_HOUR(timestamp)=0.94214,bayes_feature_IS_AWAKE(timestamp)=0.58346,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69551,bayes_feature_IS_WEEKEND(timestamp)=0.81565,bayes_feature_MONTH(timestamp)=0.56338,bayes_feature_WEEKDAY(timestamp)=0.67104,dropout_1=0.2,dropout_2=0.31083,epochs=5,lr=0.01,lstm_1_units_float=8.0,lstm_2_units_float=121.56,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

[2m[36m(pid=155208)[0m /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/featuretools/synthesis/dfs.py:313: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:
[2m[36m(pid=155208)[0m   agg_primitives: ['count']
[2m[36m(pid=155208)[0m This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible variable types for the primitive were found in the data.
[2m[36m(pid=155208)[0m   warnings.warn(warning_msg, UnusedPrimitiveWarning)
[2m[36m(pid=155378)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155378)[0m 2020-11-20 11:46:38.484989: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155378)[0m 2020-11-20 11:46:38.494282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155378)[0m 2020-11-20 11:46:38.496791: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f43150e9ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155378)[0m 2020-11-20 11:46:38.496825: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155208)[0m LSTM is selected.
[2m[36m(pid=155208)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
[2m[36m(pid=155208)[0m Instructions for updating:
[2m[36m(pid=155208)[0m If using Keras pass *_constraint arguments to layers.
2020-11-20 11:46:38,778	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155376, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:38,782	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_121_batch_size_log=6.0091,bayes_feature_DAY(timestamp)=0.51723,bayes_feature_HOUR(timestamp)=0.72144,bayes_feature_IS_AWAKE(timestamp)=0.34021,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87806,bayes_feature_IS_WEEKEND(timestamp)=0.80011,bayes_feature_MONTH(timestamp)=0.69489,bayes_feature_WEEKDAY(timestamp)=0.50848,dropout_1=0.22293,dropout_2=0.46117,epochs=5,lr=0.0012092,lstm_1_units_float=8.1824,lstm_2_units_float=121.47,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155209)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155209)[0m 2020-11-20 11:46:39.120962: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155209)[0m 2020-11-20 11:46:39.130735: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155209)[0m 2020-11-20 11:46:39.134916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3215101ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155209)[0m 2020-11-20 11:46:39.134964: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155376)[0m Fatal Python error: Segmentation fault
[2m[36m(pid=155376)[0m 
[2m[36m(pid=155376)[0m Stack (most recent call first):
[2m[36m(pid=155208)[0m WARNING:tensorflow:From /projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
[2m[36m(pid=155208)[0m Instructions for updating:
[2m[36m(pid=155208)[0m Use tf.where in 2.0, which has the same broadcast rule as np.where
[2m[36m(pid=155377)[0m 2020-11-20 11:46:40,378	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155377)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155377)[0m 
[2m[36m(pid=155377)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155377)[0m 
[2m[36m(pid=155377)[0m Traceback (most recent call last):
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155377)[0m     self._entrypoint()
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155377)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155377)[0m     output = train_func(config, reporter)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155377)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155377)[0m     config=config)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155377)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155377)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155377)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155377)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155377)[0m Exception in thread Thread-1:
[2m[36m(pid=155377)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155377)[0m 
[2m[36m(pid=155377)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155377)[0m 
[2m[36m(pid=155377)[0m Traceback (most recent call last):
[2m[36m(pid=155377)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=155208)[0m WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.
[2m[36m(pid=155208)[0m 2020-11-20 11:46:40.458605: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
[2m[36m(pid=155208)[0m 2020-11-20 11:46:40.466930: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
[2m[36m(pid=155208)[0m 2020-11-20 11:46:40.470284: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7eff450e9fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[2m[36m(pid=155208)[0m 2020-11-20 11:46:40.470322: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2m[36m(pid=155335)[0m 2020-11-20 11:46:40,769	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155335)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155335)[0m 
[2m[36m(pid=155335)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155335)[0m 
[2m[36m(pid=155335)[0m Traceback (most recent call last):
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155335)[0m     self._entrypoint()
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155335)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155335)[0m     output = train_func(config, reporter)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155335)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155335)[0m     config=config)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155335)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155335)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155335)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155335)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155335)[0m Exception in thread Thread-1:
[2m[36m(pid=155335)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155335)[0m 
[2m[36m(pid=155335)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155335)[0m 
[2m[36m(pid=155335)[0m Traceback (most recent call last):
[2m[36m(pid=155335)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=155210)[0m 2020-11-20 11:46:41,046	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155210)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155210)[0m 
[2m[36m(pid=155210)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155210)[0m 
[2m[36m(pid=155210)[0m Traceback (most recent call last):
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155210)[0m     self._entrypoint()
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155210)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155210)[0m     output = train_func(config, reporter)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155210)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155210)[0m     config=config)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155210)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155210)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155210)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155210)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155210)[0m Exception in thread Thread-1:
[2m[36m(pid=155210)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155210)[0m 
[2m[36m(pid=155210)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155210)[0m 
[2m[36m(pid=155210)[0m Traceback (most recent call last):
[2m[36m(pid=155210)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
2020-11-20 11:46:41,565	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155377, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:41,569	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_122_batch_size_log=6.2226,bayes_feature_DAY(timestamp)=0.85238,bayes_feature_HOUR(timestamp)=0.72378,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71759,bayes_feature_IS_WEEKEND(timestamp)=0.47707,bayes_feature_MONTH(timestamp)=0.30331,bayes_feature_WEEKDAY(timestamp)=0.30078,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.007113,lstm_1_units_float=8.0,lstm_2_units_float=120.98,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155334)[0m 2020-11-20 11:46:42,360	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155334)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155334)[0m 
[2m[36m(pid=155334)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155334)[0m 
[2m[36m(pid=155334)[0m Traceback (most recent call last):
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155334)[0m     self._entrypoint()
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155334)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155334)[0m     output = train_func(config, reporter)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155334)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155334)[0m     config=config)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155334)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155334)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155334)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155334)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155334)[0m Exception in thread Thread-1:
[2m[36m(pid=155334)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155334)[0m 
[2m[36m(pid=155334)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155334)[0m 
[2m[36m(pid=155334)[0m Traceback (most recent call last):
[2m[36m(pid=155334)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
2020-11-20 11:46:42,734	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155210, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:42,737	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_125_batch_size_log=7.3661,bayes_feature_DAY(timestamp)=0.65898,bayes_feature_HOUR(timestamp)=0.97837,bayes_feature_IS_AWAKE(timestamp)=0.62581,bayes_feature_IS_BUSY_HOURS(timestamp)=0.38274,bayes_feature_IS_WEEKEND(timestamp)=0.77375,bayes_feature_MONTH(timestamp)=0.78078,bayes_feature_WEEKDAY(timestamp)=0.88022,dropout_1=0.43373,dropout_2=0.35505,epochs=5,lr=0.0054844,lstm_1_units_float=8.076,lstm_2_units_float=118.14,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155378)[0m 2020-11-20 11:46:43,395	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155378)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155378)[0m 
[2m[36m(pid=155378)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155378)[0m 
[2m[36m(pid=155378)[0m Traceback (most recent call last):
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155378)[0m     self._entrypoint()
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155378)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155378)[0m     output = train_func(config, reporter)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155378)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155378)[0m     config=config)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155378)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155378)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155378)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155378)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155378)[0m Exception in thread Thread-1:
[2m[36m(pid=155378)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155378)[0m 
[2m[36m(pid=155378)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155378)[0m 
[2m[36m(pid=155378)[0m Traceback (most recent call last):
[2m[36m(pid=155378)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 40/40 CPUs, 0/0 GPUs
Memory usage on this node: 14.0/200.9 GB
Result logdir: /scratch/project_2003107/ray_results_9otbxs6t/automl
Number of trials: 133 ({'TERMINATED': 23, 'ERROR': 100, 'RUNNING': 10})
ERROR trials:
 - train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWAKE(timestamp)=0.59211,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69108,bayes_feature_IS_WEEKEND(timestamp)=0.39827,bayes_feature_MONTH(timestamp)=0.43867,bayes_feature_WEEKDAY(timestamp)=0.86052,dropout_1=0.49048,dropout_2=0.29403,epochs=5,lr=0.0072309,lstm_1_units_float=113.17,lstm_2_units_float=115.35,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_2_batch_size_log=9.3906,bayes_feature_DAY(timestamp)=0.31917,bayes_feature_HOUR(timestamp)=0.76933,bayes_feature_IS_AWA_2020-11-20_11-43-096eget5nu/error_2020-11-20_11-43-22.txt
 - train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAKE(timestamp)=0.49631,bayes_feature_IS_BUSY_HOURS(timestamp)=0.8525,bayes_feature_IS_WEEKEND(timestamp)=0.37226,bayes_feature_MONTH(timestamp)=0.61353,bayes_feature_WEEKDAY(timestamp)=0.93602,dropout_1=0.28808,dropout_2=0.28633,epochs=5,lr=0.0021703,lstm_1_units_float=10.324,lstm_2_units_float=89.46,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_4_batch_size_log=8.7507,bayes_feature_DAY(timestamp)=0.9922,bayes_feature_HOUR(timestamp)=0.82372,bayes_feature_IS_AWAK_2020-11-20_11-43-09o35vj994/error_2020-11-20_11-43-22.txt
 - train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWAKE(timestamp)=0.5857,bayes_feature_IS_BUSY_HOURS(timestamp)=0.46592,bayes_feature_IS_WEEKEND(timestamp)=0.93237,bayes_feature_MONTH(timestamp)=0.70158,bayes_feature_WEEKDAY(timestamp)=0.30201,dropout_1=0.38514,dropout_2=0.29799,epochs=5,lr=0.0057435,lstm_1_units_float=114.31,lstm_2_units_float=50.872,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_8_batch_size_log=9.7474,bayes_feature_DAY(timestamp)=0.61494,bayes_feature_HOUR(timestamp)=0.70487,bayes_feature_IS_AWA_2020-11-20_11-43-09jahxncfd/error_2020-11-20_11-43-24.txt, [4 CPUs, 0 GPUs], [pid=130909], 6 s, 2 iter
  ... 94 not shown
 - train_func_121_batch_size_log=6.0091,bayes_feature_DAY(timestamp)=0.51723,bayes_feature_HOUR(timestamp)=0.72144,bayes_feature_IS_AWAKE(timestamp)=0.34021,bayes_feature_IS_BUSY_HOURS(timestamp)=0.87806,bayes_feature_IS_WEEKEND(timestamp)=0.80011,bayes_feature_MONTH(timestamp)=0.69489,bayes_feature_WEEKDAY(timestamp)=0.50848,dropout_1=0.22293,dropout_2=0.46117,epochs=5,lr=0.0012092,lstm_1_units_float=8.1824,lstm_2_units_float=121.47,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_121_batch_size_log=6.0091,bayes_feature_DAY(timestamp)=0.51723,bayes_feature_HOUR(timestamp)=0.72144,bayes_feature_IS_A_2020-11-20_11-46-26oln9ngn_/error_2020-11-20_11-46-38.txt
 - train_func_122_batch_size_log=6.2226,bayes_feature_DAY(timestamp)=0.85238,bayes_feature_HOUR(timestamp)=0.72378,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=0.71759,bayes_feature_IS_WEEKEND(timestamp)=0.47707,bayes_feature_MONTH(timestamp)=0.30331,bayes_feature_WEEKDAY(timestamp)=0.30078,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.007113,lstm_1_units_float=8.0,lstm_2_units_float=120.98,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_122_batch_size_log=6.2226,bayes_feature_DAY(timestamp)=0.85238,bayes_feature_HOUR(timestamp)=0.72378,bayes_feature_IS_A_2020-11-20_11-46-30zl6aaatt/error_2020-11-20_11-46-41.txt
 - train_func_125_batch_size_log=7.3661,bayes_feature_DAY(timestamp)=0.65898,bayes_feature_HOUR(timestamp)=0.97837,bayes_feature_IS_AWAKE(timestamp)=0.62581,bayes_feature_IS_BUSY_HOURS(timestamp)=0.38274,bayes_feature_IS_WEEKEND(timestamp)=0.77375,bayes_feature_MONTH(timestamp)=0.78078,bayes_feature_WEEKDAY(timestamp)=0.88022,dropout_1=0.43373,dropout_2=0.35505,epochs=5,lr=0.0054844,lstm_1_units_float=8.076,lstm_2_units_float=118.14,past_seq_len=2:	ERROR, 1 failures: /scratch/project_2003107/ray_results_9otbxs6t/automl/train_func_125_batch_size_log=7.3661,bayes_feature_DAY(timestamp)=0.65898,bayes_feature_HOUR(timestamp)=0.97837,bayes_feature_IS_A_2020-11-20_11-46-32zvev0726/error_2020-11-20_11-46-42.txt
RUNNING trials:
 - train_func_123_batch_size_log=5.9685,bayes_feature_DAY(timestamp)=0.98879,bayes_feature_HOUR(timestamp)=0.9388,bayes_feature_IS_AWAKE(timestamp)=0.70386,bayes_feature_IS_BUSY_HOURS(timestamp)=0.97974,bayes_feature_IS_WEEKEND(timestamp)=0.65915,bayes_feature_MONTH(timestamp)=0.4873,bayes_feature_WEEKDAY(timestamp)=0.75869,dropout_1=0.27407,dropout_2=0.42677,epochs=5,lr=0.009126,lstm_1_units_float=8.1112,lstm_2_units_float=119.6,past_seq_len=2:	RUNNING
 - train_func_124_batch_size_log=5.7897,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.95776,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.69952,bayes_feature_WEEKDAY(timestamp)=0.4877,dropout_1=0.32815,dropout_2=0.26446,epochs=5,lr=0.0096913,lstm_1_units_float=8.0,lstm_2_units_float=120.87,past_seq_len=2:	RUNNING
 - train_func_126_batch_size_log=6.2849,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.74208,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.5174,bayes_feature_WEEKDAY(timestamp)=0.36547,dropout_1=0.39033,dropout_2=0.48056,epochs=5,lr=0.0099959,lstm_1_units_float=8.0,lstm_2_units_float=120.88,past_seq_len=2:	RUNNING
  ... 4 not shown
 - train_func_131_batch_size_log=9.9041,bayes_feature_DAY(timestamp)=0.77307,bayes_feature_HOUR(timestamp)=0.39938,bayes_feature_IS_AWAKE(timestamp)=0.71015,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40871,bayes_feature_IS_WEEKEND(timestamp)=0.6067,bayes_feature_MONTH(timestamp)=0.81824,bayes_feature_WEEKDAY(timestamp)=0.64978,dropout_1=0.46315,dropout_2=0.33068,epochs=5,lr=0.0054349,lstm_1_units_float=8.259,lstm_2_units_float=121.72,past_seq_len=2:	RUNNING
 - train_func_132_batch_size_log=5.0295,bayes_feature_DAY(timestamp)=0.6184,bayes_feature_HOUR(timestamp)=0.72454,bayes_feature_IS_AWAKE(timestamp)=0.50378,bayes_feature_IS_BUSY_HOURS(timestamp)=0.69008,bayes_feature_IS_WEEKEND(timestamp)=0.32328,bayes_feature_MONTH(timestamp)=0.65766,bayes_feature_WEEKDAY(timestamp)=0.6197,dropout_1=0.44108,dropout_2=0.32666,epochs=5,lr=0.0010812,lstm_1_units_float=8.6624,lstm_2_units_float=120.57,past_seq_len=2:	RUNNING
 - train_func_133_batch_size_log=7.0543,bayes_feature_DAY(timestamp)=0.73839,bayes_feature_HOUR(timestamp)=0.81387,bayes_feature_IS_AWAKE(timestamp)=0.80112,bayes_feature_IS_BUSY_HOURS(timestamp)=0.37407,bayes_feature_IS_WEEKEND(timestamp)=0.61412,bayes_feature_MONTH(timestamp)=0.31433,bayes_feature_WEEKDAY(timestamp)=0.3342,dropout_1=0.22869,dropout_2=0.33432,epochs=5,lr=0.0045296,lstm_1_units_float=8.242,lstm_2_units_float=119.88,past_seq_len=2:	RUNNING
TERMINATED trials:
 - train_func_1_batch_size_log=7.0851,bayes_feature_DAY(timestamp)=0.80423,bayes_feature_HOUR(timestamp)=0.30008,bayes_feature_IS_AWAKE(timestamp)=0.51163,bayes_feature_IS_BUSY_HOURS(timestamp)=0.40273,bayes_feature_IS_WEEKEND(timestamp)=0.36464,bayes_feature_MONTH(timestamp)=0.43038,bayes_feature_WEEKDAY(timestamp)=0.54189,dropout_1=0.31903,dropout_2=0.36165,epochs=5,lr=0.0047728,lstm_1_units_float=90.226,lstm_2_units_float=32.534,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130902], 16 s, 5 iter
 - train_func_3_batch_size_log=5.4252,bayes_feature_DAY(timestamp)=0.32734,bayes_feature_HOUR(timestamp)=0.41888,bayes_feature_IS_AWAKE(timestamp)=0.9147,bayes_feature_IS_BUSY_HOURS(timestamp)=0.36884,bayes_feature_IS_WEEKEND(timestamp)=0.59478,bayes_feature_MONTH(timestamp)=0.97052,bayes_feature_WEEKDAY(timestamp)=0.67322,dropout_1=0.40756,dropout_2=0.29465,epochs=5,lr=0.0071785,lstm_1_units_float=108.16,lstm_2_units_float=10.195,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130903], 36 s, 5 iter
 - train_func_5_batch_size_log=6.0581,bayes_feature_DAY(timestamp)=0.48588,bayes_feature_HOUR(timestamp)=0.6441,bayes_feature_IS_AWAKE(timestamp)=0.33735,bayes_feature_IS_BUSY_HOURS(timestamp)=0.70188,bayes_feature_IS_WEEKEND(timestamp)=0.40271,bayes_feature_MONTH(timestamp)=0.71251,bayes_feature_WEEKDAY(timestamp)=0.78983,dropout_1=0.2307,dropout_2=0.32422,epochs=5,lr=0.0072496,lstm_1_units_float=57.702,lstm_2_units_float=13.994,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=130900], 25 s, 5 iter
  ... 17 not shown
 - train_func_59_batch_size_log=7.3039,bayes_feature_DAY(timestamp)=0.65521,bayes_feature_HOUR(timestamp)=0.8118,bayes_feature_IS_AWAKE(timestamp)=0.53032,bayes_feature_IS_BUSY_HOURS(timestamp)=0.86479,bayes_feature_IS_WEEKEND(timestamp)=0.99221,bayes_feature_MONTH(timestamp)=0.57101,bayes_feature_WEEKDAY(timestamp)=0.48889,dropout_1=0.48928,dropout_2=0.37239,epochs=5,lr=0.0047639,lstm_1_units_float=27.407,lstm_2_units_float=54.577,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=141884], 14 s, 5 iter
 - train_func_64_batch_size_log=5.8229,bayes_feature_DAY(timestamp)=0.52048,bayes_feature_HOUR(timestamp)=0.72534,bayes_feature_IS_AWAKE(timestamp)=0.39143,bayes_feature_IS_BUSY_HOURS(timestamp)=0.9676,bayes_feature_IS_WEEKEND(timestamp)=0.68775,bayes_feature_MONTH(timestamp)=0.86909,bayes_feature_WEEKDAY(timestamp)=0.42184,dropout_1=0.21472,dropout_2=0.44212,epochs=5,lr=0.0091701,lstm_1_units_float=57.572,lstm_2_units_float=13.972,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144545], 23 s, 5 iter
 - train_func_67_batch_size_log=6.0842,bayes_feature_DAY(timestamp)=0.45777,bayes_feature_HOUR(timestamp)=0.65626,bayes_feature_IS_AWAKE(timestamp)=0.71124,bayes_feature_IS_BUSY_HOURS(timestamp)=0.60474,bayes_feature_IS_WEEKEND(timestamp)=0.82386,bayes_feature_MONTH(timestamp)=0.9055,bayes_feature_WEEKDAY(timestamp)=0.81593,dropout_1=0.49159,dropout_2=0.34859,epochs=5,lr=0.0049451,lstm_1_units_float=57.773,lstm_2_units_float=14.337,past_seq_len=2:	TERMINATED, [4 CPUs, 0 GPUs], [pid=144758], 22 s, 5 iter

2020-11-20 11:46:43,934	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155335, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:43,937	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_123_batch_size_log=5.9685,bayes_feature_DAY(timestamp)=0.98879,bayes_feature_HOUR(timestamp)=0.9388,bayes_feature_IS_AWAKE(timestamp)=0.70386,bayes_feature_IS_BUSY_HOURS(timestamp)=0.97974,bayes_feature_IS_WEEKEND(timestamp)=0.65915,bayes_feature_MONTH(timestamp)=0.4873,bayes_feature_WEEKDAY(timestamp)=0.75869,dropout_1=0.27407,dropout_2=0.42677,epochs=5,lr=0.009126,lstm_1_units_float=8.1112,lstm_2_units_float=119.6,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[2m[36m(pid=155209)[0m 2020-11-20 11:46:44,297	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155209)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155209)[0m 
[2m[36m(pid=155209)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155209)[0m 
[2m[36m(pid=155209)[0m Traceback (most recent call last):
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155209)[0m     self._entrypoint()
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155209)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155209)[0m     output = train_func(config, reporter)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155209)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155209)[0m     config=config)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155209)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155209)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155209)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155209)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155209)[0m Exception in thread Thread-1:
[2m[36m(pid=155209)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155209)[0m 
[2m[36m(pid=155209)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155209)[0m 
[2m[36m(pid=155209)[0m Traceback (most recent call last):
[2m[36m(pid=155209)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
[2m[36m(pid=155208)[0m 2020-11-20 11:46:44,421	ERROR function_runner.py:98 -- Runner Thread raised error.
[2m[36m(pid=155208)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155208)[0m 
[2m[36m(pid=155208)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155208)[0m 
[2m[36m(pid=155208)[0m Traceback (most recent call last):
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 92, in run
[2m[36m(pid=155208)[0m     self._entrypoint()
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 143, in entrypoint
[2m[36m(pid=155208)[0m     return self._trainable_func(config, self._status_reporter)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 262, in _trainable_func
[2m[36m(pid=155208)[0m     output = train_func(config, reporter)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/search/RayTuneSearchEngine.py", line 340, in train_func
[2m[36m(pid=155208)[0m     save_zip(ckpt_name, trial_ft, trial_model, config)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 135, in save_zip
[2m[36m(pid=155208)[0m     config=config)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 118, in save
[2m[36m(pid=155208)[0m     feature_transformers.save(config_path, replace=True)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/feature/time_sequence.py", line 295, in save
[2m[36m(pid=155208)[0m     save_config(file_path, data_to_save, replace=replace)
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/zoo/automl/common/util.py", line 103, in save_config
[2m[36m(pid=155208)[0m     json.dump(config, output_file, cls=NumpyEncoder)
[2m[36m(pid=155208)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155208)[0m Exception in thread Thread-1:
[2m[36m(pid=155208)[0m OSError: [Errno 28] No space left on device
[2m[36m(pid=155208)[0m 
[2m[36m(pid=155208)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=155208)[0m 
[2m[36m(pid=155208)[0m Traceback (most recent call last):
[2m[36m(pid=155208)[0m   File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/fu
2020-11-20 11:46:44,922	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155378, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:44,924	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_126_batch_size_log=6.2849,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=0.74208,bayes_feature_IS_AWAKE(timestamp)=0.3,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.5174,bayes_feature_WEEKDAY(timestamp)=0.36547,dropout_1=0.39033,dropout_2=0.48056,epochs=5,lr=0.0099959,lstm_1_units_float=8.0,lstm_2_units_float=120.88,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 11:46:45,682	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155209, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:45,684	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_127_batch_size_log=6.2863,bayes_feature_DAY(timestamp)=0.7377,bayes_feature_HOUR(timestamp)=0.69838,bayes_feature_IS_AWAKE(timestamp)=0.8304,bayes_feature_IS_BUSY_HOURS(timestamp)=0.66506,bayes_feature_IS_WEEKEND(timestamp)=0.47482,bayes_feature_MONTH(timestamp)=0.76623,bayes_feature_WEEKDAY(timestamp)=0.66854,dropout_1=0.2,dropout_2=0.2,epochs=5,lr=0.0059005,lstm_1_units_float=8.0,lstm_2_units_float=120.98,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 11:46:46,455	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155208, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:46,457	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_128_batch_size_log=7.1229,bayes_feature_DAY(timestamp)=0.89454,bayes_feature_HOUR(timestamp)=0.44692,bayes_feature_IS_AWAKE(timestamp)=0.78208,bayes_feature_IS_BUSY_HOURS(timestamp)=0.33226,bayes_feature_IS_WEEKEND(timestamp)=0.57867,bayes_feature_MONTH(timestamp)=0.61192,bayes_feature_WEEKDAY(timestamp)=0.83239,dropout_1=0.22622,dropout_2=0.26643,epochs=5,lr=0.0069093,lstm_1_units_float=8.0325,lstm_2_units_float=118.72,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-20 11:46:47,227	ERROR trial_runner.py:490 -- Error processing event.
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 439, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=155334, host=r04c25.bullx)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/trainable.py", line 150, in train
    result = self._train()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/tune/function_runner.py", line 205, in _train
    ("Wrapped function ran until completion without reporting "
ray.tune.error.TuneError: Wrapped function ran until completion without reporting results or raising an exception.

2020-11-20 11:46:47,229	INFO ray_trial_executor.py:187 -- Destroying actor for trial train_func_124_batch_size_log=5.7897,bayes_feature_DAY(timestamp)=1.0,bayes_feature_HOUR(timestamp)=1.0,bayes_feature_IS_AWAKE(timestamp)=0.95776,bayes_feature_IS_BUSY_HOURS(timestamp)=1.0,bayes_feature_IS_WEEKEND(timestamp)=1.0,bayes_feature_MONTH(timestamp)=0.69952,bayes_feature_WEEKDAY(timestamp)=0.4877,dropout_1=0.32815,dropout_2=0.26446,epochs=5,lr=0.0096913,lstm_1_units_float=8.0,lstm_2_units_float=120.87,past_seq_len=2. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2020-11-21 01:35:10,486	ERROR worker.py:1672 -- The reporter on node r04c25.bullx failed with the following error:
Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/224263/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 176, in run
    self.perform_iteration()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 165, in perform_iteration
    stats = self.get_all_stats()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 156, in get_all_stats
    "workers": self.get_workers(),
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in get_workers
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 131, in <listcomp>
    ]) for x in psutil.process_iter() if running_worker(x.name())
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/__init__.py", line 634, in name
    name = self._proc.name()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1610, in name
    name = self._parse_stat_file()['name']
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=224263, name='ntpdate')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 218, in <module>
    reporter.run()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/site-packages/ray/reporter.py", line 178, in run
    traceback.print_exc()
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 163, in print_exc
    print_exception(*sys.exc_info(), limit=limit, file=file, chain=chain)
  File "/projappl/project_2003107/anaconda3/envs/analytics-zoo/lib/python3.6/traceback.py", line 105, in print_exception
    print(line, file=file, end="")
OSError: [Errno 28] No space left on device

