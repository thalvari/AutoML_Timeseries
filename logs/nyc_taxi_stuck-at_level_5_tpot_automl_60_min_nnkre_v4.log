30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   7%|▋         | 7/100 [00:59<13:07,  8.46s/pipeline]Optimization Progress:  87%|████████▋ | 87/100 [01:03<01:17,  5.94s/pipeline]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 100/100 [01:05<00:00,  5.94s/pipeline]Optimization Progress: 100%|██████████| 100/100 [01:05<00:00,  4.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [01:05<00:00,  4.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [01:05<00:00,  4.18s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 100/100 [01:06<00:00,  4.18s/pipeline]Optimization Progress:  50%|█████     | 101/200 [01:09<07:16,  4.41s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  50%|█████     | 101/200 [01:09<07:16,  4.41s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [01:21<07:43,  4.78s/pipeline]Optimization Progress:  92%|█████████▏| 183/200 [01:26<00:57,  3.36s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-215867056.7991621	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [01:29<00:00,  3.36s/pipeline]Optimization Progress: 100%|██████████| 200/200 [01:29<00:00,  2.41s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [01:30<00:00,  2.41s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [01:30<00:00,  2.41s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [01:32<00:00,  2.41s/pipeline]Optimization Progress:  67%|██████▋   | 202/300 [01:33<03:42,  2.27s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  67%|██████▋   | 202/300 [01:33<03:42,  2.27s/pipeline]Optimization Progress:  68%|██████▊   | 204/300 [04:28<44:35, 27.87s/pipeline]Optimization Progress:  95%|█████████▍| 284/300 [04:48<05:13, 19.58s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-215867056.7991621	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [04:50<00:00, 19.58s/pipeline]Optimization Progress: 100%|██████████| 300/300 [04:50<00:00, 13.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [04:50<00:00, 13.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [04:51<00:00, 13.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [04:51<00:00, 13.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 300/300 [04:52<00:00, 13.74s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 300/300 [04:56<00:00, 13.74s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [04:57<16:42, 10.33s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  76%|███████▌  | 303/400 [04:57<16:42, 10.33s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  76%|███████▌  | 304/400 [04:57<16:31, 10.33s/pipeline]Optimization Progress:  76%|███████▋  | 306/400 [05:55<20:28, 13.07s/pipeline]Optimization Progress:  96%|█████████▋| 386/400 [06:01<02:08,  9.17s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-215867056.7991621	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [06:02<00:00,  9.17s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [06:04<00:00,  9.17s/pipeline]Optimization Progress: 100%|██████████| 400/400 [06:04<00:00,  6.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 400/400 [06:04<00:00,  6.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [06:05<00:00,  6.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 400/400 [06:05<00:00,  6.46s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 400/400 [06:10<00:00,  6.46s/pipeline]Optimization Progress:  80%|████████  | 402/500 [06:10<08:54,  5.45s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 402/500 [06:10<08:54,  5.45s/pipeline]Optimization Progress:  81%|████████  | 404/500 [06:37<12:37,  7.89s/pipeline]Optimization Progress:  97%|█████████▋| 484/500 [06:43<01:28,  5.54s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-215867056.7991621	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-211373288.11255607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=16), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [06:44<00:00,  5.54s/pipeline]Optimization Progress: 100%|██████████| 500/500 [06:44<00:00,  3.91s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [06:46<00:00,  3.91s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [06:48<00:00,  3.91s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [06:48<00:00,  3.91s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [06:50<05:50,  3.58s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▎ | 502/600 [06:50<05:50,  3.58s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  84%|████████▍ | 503/600 [06:50<05:47,  3.58s/pipeline]Optimization Progress:  84%|████████▍ | 505/600 [07:05<06:25,  4.06s/pipeline]Optimization Progress:  98%|█████████▊| 585/600 [07:12<00:42,  2.87s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-211878358.53598464	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-211373288.11255607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=16), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [07:14<00:00,  2.87s/pipeline]Optimization Progress: 100%|██████████| 600/600 [07:14<00:00,  2.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 600/600 [07:15<00:00,  2.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [07:16<00:00,  2.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 600/600 [07:18<00:00,  2.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [07:18<00:00,  2.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [07:18<00:00,  2.04s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [08:40<23:31, 14.40s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  86%|████████▌ | 602/700 [08:40<23:31, 14.40s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [08:49<18:15, 11.41s/pipeline]Optimization Progress:  98%|█████████▊| 684/700 [08:54<02:08,  8.01s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-211878358.53598464	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-211373288.11255607	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=16), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [08:54<00:00,  8.01s/pipeline]Optimization Progress: 100%|██████████| 700/700 [08:54<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [08:55<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [08:55<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [08:55<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [08:57<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 700/700 [09:01<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [09:04<00:00,  5.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 700/700 [09:04<00:00,  5.61s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 702/800 [09:04<09:09,  5.61s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [09:04<07:59,  4.94s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  88%|████████▊ | 703/800 [09:04<07:59,  4.94s/pipeline]Optimization Progress:  88%|████████▊ | 705/800 [09:33<12:14,  7.74s/pipeline]Optimization Progress:  98%|█████████▊| 785/800 [09:39<01:21,  5.44s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-206937347.00929993	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [09:46<00:00,  5.44s/pipeline]Optimization Progress: 100%|██████████| 800/800 [09:46<00:00,  3.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 800/800 [09:48<00:00,  3.96s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [09:48<04:48,  2.97s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [09:58<07:42,  4.82s/pipeline]Optimization Progress:  98%|█████████▊| 884/900 [10:03<00:54,  3.39s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-206937347.00929993	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-204709604.5125	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [10:03<00:00,  3.39s/pipeline]Optimization Progress: 100%|██████████| 900/900 [10:03<00:00,  2.38s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [10:03<00:00,  2.38s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [10:08<00:00,  2.38s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [10:10<00:00,  2.38s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 900/900 [10:11<00:00,  2.38s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [10:13<00:00,  2.38s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 901/1000 [10:14<03:55,  2.38s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [10:20<03:53,  2.38s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [10:32<07:24,  4.58s/pipeline]Optimization Progress:  98%|█████████▊| 983/1000 [10:37<00:54,  3.23s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-206937347.00929993	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-204709604.5125	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [10:38<00:00,  3.23s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [10:38<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [10:44<00:00,  2.28s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [10:47<04:53,  2.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1002/1100 [10:47<04:53,  2.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1003/1100 [10:47<04:50,  2.99s/pipeline]Optimization Progress:  91%|█████████▏| 1005/1100 [11:15<07:41,  4.86s/pipeline]Optimization Progress:  99%|█████████▊| 1085/1100 [11:21<00:51,  3.42s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-206937347.00929993	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-203745806.00408426	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.55, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=1.0), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [11:26<00:00,  3.42s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [11:26<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [11:29<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [11:29<00:00,  2.50s/pipeline]Optimization Progress:  92%|█████████▏| 1101/1200 [11:37<08:30,  5.15s/pipeline]Optimization Progress:  98%|█████████▊| 1181/1200 [11:40<01:08,  3.62s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-206937347.00929993	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-2	-203745806.00408426	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.55, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=1.0), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [11:45<00:00,  3.62s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [11:45<00:00,  2.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [11:46<00:00,  2.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1200/1200 [11:46<00:00,  2.60s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [11:48<00:00,  2.60s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [11:50<04:13,  2.59s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [12:10<12:42,  7.86s/pipeline]Optimization Progress:  99%|█████████▊| 1283/1300 [12:17<01:33,  5.53s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-206429609.5652018	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=19, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-203745806.00408426	GradientBoostingRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.55, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=1.0), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.45, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [12:17<00:00,  5.53s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [12:17<00:00,  3.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [12:18<00:00,  3.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 1300/1300 [12:21<00:00,  3.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [12:21<00:00,  3.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1300/1300 [12:25<00:00,  3.87s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [12:30<06:23,  3.87s/pipeline]Optimization Progress:  93%|█████████▎| 1302/1400 [12:53<13:17,  8.14s/pipeline]Optimization Progress:  99%|█████████▊| 1382/1400 [13:10<01:43,  5.76s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-205389753.458596	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-203559202.69559938	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-5	-198115177.30261627	GradientBoostingRegressor(ExtraTreesRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [13:13<00:00,  5.76s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [13:13<00:00,  4.08s/pipeline]Optimization Progress:  94%|█████████▎| 1403/1500 [13:20<05:41,  3.52s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▎| 1403/1500 [13:20<05:41,  3.52s/pipeline]Optimization Progress:  94%|█████████▎| 1405/1500 [13:40<08:37,  5.45s/pipeline]Optimization Progress:  99%|█████████▉| 1485/1500 [13:43<00:57,  3.83s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-205389753.458596	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-203559202.69559938	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-203484446.9209247	GradientBoostingRegressor(DecisionTreeRegressor(VarianceThreshold(input_matrix, VarianceThreshold__threshold=0.005), DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-5	-198115177.30261627	GradientBoostingRegressor(ExtraTreesRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [13:44<00:00,  3.83s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [13:44<00:00,  2.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [13:46<00:00,  2.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [13:46<00:00,  2.70s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [13:51<00:00,  2.70s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [13:52<06:58,  4.23s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [14:26<21:53, 13.41s/pipeline]Optimization Progress:  99%|█████████▉| 1582/1600 [14:31<02:49,  9.40s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-205389753.458596	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)
-2	-203559202.69559938	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-203484446.9209247	GradientBoostingRegressor(DecisionTreeRegressor(VarianceThreshold(input_matrix, VarianceThreshold__threshold=0.005), DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-5	-198115177.30261627	GradientBoostingRegressor(ExtraTreesRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.45, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=18, ExtraTreesRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [14:33<00:00,  9.40s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [14:33<00:00,  6.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [14:35<00:00,  6.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [14:40<00:00,  6.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [14:40<00:00,  6.62s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [14:40<11:01,  6.68s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [14:48<11:45,  7.20s/pipeline]Optimization Progress:  99%|█████████▉| 1682/1700 [14:54<01:31,  5.06s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-203650575.3093614	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-203559202.69559938	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=2, DecisionTreeRegressor__min_samples_leaf=12, DecisionTreeRegressor__min_samples_split=6), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8500000000000001)
-3	-203402295.56939608	GradientBoostingRegressor(DecisionTreeRegressor(SelectFromModel(input_matrix, SelectFromModel__ExtraTreesRegressor__max_features=0.2, SelectFromModel__ExtraTreesRegressor__n_estimators=100, SelectFromModel__threshold=0.5), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=15, DecisionTreeRegressor__min_samples_split=17), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-4	-197558271.875	GradientBoostingRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)Optimization Progress: 100%|██████████| 1700/1700 [15:03<00:00,  3.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1700/1800 [15:03<06:10,  3.70s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1701/1800 [15:03<06:06,  3.70s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [15:21<06:59,  4.33s/pipeline]Optimization Progress:  99%|█████████▉| 1783/1800 [15:25<00:51,  3.05s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-202908959.12027872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-197558271.875	GradientBoostingRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 1800/1800 [15:27<00:00,  3.05s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [15:27<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [15:28<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [15:28<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [15:29<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [15:30<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [15:32<00:00,  2.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [15:32<00:00,  2.17s/pipeline]Optimization Progress:  95%|█████████▍| 1801/1900 [15:34<05:50,  3.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1801/1900 [15:34<05:50,  3.55s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [15:39<05:18,  3.28s/pipeline]Optimization Progress:  99%|█████████▉| 1883/1900 [15:45<00:39,  2.32s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-202908959.12027872	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-202560204.17933768	GradientBoostingRegressor(DecisionTreeRegressor(VarianceThreshold(input_matrix, VarianceThreshold__threshold=0.01), DecisionTreeRegressor__max_depth=3, DecisionTreeRegressor__min_samples_leaf=15, DecisionTreeRegressor__min_samples_split=17), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=15, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)
-4	-197558271.875	GradientBoostingRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [15:51<00:00,  2.32s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [15:51<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [15:53<00:00,  1.72s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [15:54<03:46,  2.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1901/2000 [15:54<03:46,  2.29s/pipeline]Optimization Progress:  95%|█████████▌| 1903/2000 [16:02<04:27,  2.76s/pipeline]Optimization Progress:  99%|█████████▉| 1983/2000 [16:05<00:32,  1.94s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-201924050.7292969	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-197558271.875	GradientBoostingRegressor(RobustScaler(FastICA(LinearSVR(input_matrix, LinearSVR__C=0.001, LinearSVR__dual=False, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), FastICA__tol=0.9)), GradientBoostingRegressor__alpha=0.95, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 2000/2000 [16:05<00:00,  1.94s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [16:05<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [16:09<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [16:11<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [16:12<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [16:12<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 2000/2000 [16:13<00:00,  1.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [16:13<00:00,  1.37s/pipeline]Optimization Progress:  95%|█████████▌| 2000/2100 [16:20<02:17,  1.37s/pipeline]Optimization Progress:  95%|█████████▌| 2001/2100 [16:33<15:26,  9.35s/pipeline]Optimization Progress:  99%|█████████▉| 2081/2100 [16:37<02:04,  6.56s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-201924050.7292969	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:38<00:00,  6.56s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [16:38<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2100/2100 [16:40<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 2100/2100 [16:40<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:41<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 2100/2100 [16:43<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [16:43<00:00,  4.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:43<00:00,  4.62s/pipeline]Optimization Progress:  96%|█████████▌| 2102/2200 [16:46<07:06,  4.35s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [17:13<18:02, 11.16s/pipeline]Optimization Progress:  99%|█████████▉| 2183/2200 [17:16<02:13,  7.83s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:16<00:00,  7.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:18<00:00,  7.83s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [17:18<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2200/2200 [17:18<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 2200/2200 [17:20<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:21<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [17:22<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [17:24<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2200/2200 [17:24<00:00,  5.52s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:25<00:00,  5.52s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [17:25<09:50,  5.97s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [18:16<31:51, 19.50s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [18:22<04:06, 13.68s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [18:22<00:00, 13.68s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [18:22<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [18:23<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [18:26<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [18:26<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [18:26<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [18:27<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [18:32<00:00,  9.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [18:32<00:00,  9.58s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [18:39<14:54,  9.13s/pipeline]Optimization Progress:  99%|█████████▉| 2382/2400 [18:56<01:56,  6.46s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [19:01<00:00,  6.46s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [19:01<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [19:01<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:01<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:01<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:02<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:03<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2400/2400 [19:03<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:04<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [19:04<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [19:05<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:05<00:00,  4.59s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [19:07<00:00,  4.59s/pipeline]Optimization Progress:  96%|█████████▌| 2403/2500 [19:07<06:13,  3.85s/pipeline]Optimization Progress:  96%|█████████▌| 2404/2500 [19:14<07:46,  4.85s/pipeline]Optimization Progress:  99%|█████████▉| 2484/2500 [19:17<00:54,  3.41s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-200628512.13791758	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [19:18<00:00,  3.41s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [19:18<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2500/2500 [19:18<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [19:19<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [19:21<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 2500/2500 [19:21<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [19:22<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [19:22<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [19:25<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2500/2500 [19:25<00:00,  2.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 2500/2500 [19:28<00:00,  2.39s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [19:30<03:56,  2.39s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [19:51<10:50,  6.63s/pipeline]Optimization Progress:  99%|█████████▉| 2582/2600 [19:55<01:23,  4.66s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-200628512.13791758	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [19:56<00:00,  4.66s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [19:56<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [19:57<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [19:57<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [19:57<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2600/2600 [19:57<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [19:58<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 2600/2600 [19:58<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [19:58<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [19:59<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2600/2600 [19:59<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [20:02<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [20:02<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [20:02<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [20:03<00:00,  3.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [20:03<00:00,  3.28s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [20:05<04:46,  2.99s/pipeline]Optimization Progress:  96%|█████████▋| 2605/2700 [20:11<06:21,  4.02s/pipeline]Optimization Progress:  99%|█████████▉| 2685/2700 [20:17<00:42,  2.84s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-200845141.9947607	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=4, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-2	-200743902.79326084	GradientBoostingRegressor(PCA(input_matrix, PCA__iterated_power=9, PCA__svd_solver=randomized), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-3	-200628512.13791758	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2700/2700 [20:18<00:00,  2.84s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [20:18<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [20:22<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [20:23<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [20:23<00:00,  1.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.01000.
Optimization Progress: 100%|██████████| 2700/2700 [20:26<00:00,  1.99s/pipeline]Optimization Progress:  96%|█████████▋| 2701/2800 [20:30<03:17,  1.99s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [20:47<09:26,  5.78s/pipeline]Optimization Progress:  99%|█████████▉| 2782/2800 [20:50<01:13,  4.06s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [20:51<00:00,  4.06s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [20:51<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [20:52<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [20:52<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [20:52<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [20:52<00:00,  2.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2800/2800 [20:58<00:00,  2.86s/pipeline]Optimization Progress:  97%|█████████▋| 2801/2900 [20:59<07:17,  4.41s/pipeline]Optimization Progress:  97%|█████████▋| 2802/2900 [21:10<10:15,  6.29s/pipeline]Optimization Progress:  99%|█████████▉| 2882/2900 [21:14<01:19,  4.41s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [21:17<00:00,  4.41s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [21:17<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [21:17<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2900/2900 [21:20<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [21:22<00:00,  3.14s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [21:22<04:20,  2.69s/pipeline]Optimization Progress:  97%|█████████▋| 2904/3000 [22:07<24:32, 15.34s/pipeline]Optimization Progress:  99%|█████████▉| 2984/3000 [22:09<02:51, 10.75s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [22:13<00:00, 10.75s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [22:13<00:00,  7.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 3000/3000 [22:13<00:00,  7.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [22:13<00:00,  7.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [22:15<00:00,  7.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [22:15<00:00,  7.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [22:17<00:00,  7.58s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [22:18<11:32,  7.00s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [22:45<21:16, 13.03s/pipeline]Optimization Progress:  99%|█████████▉| 3082/3100 [22:53<02:44,  9.15s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [22:53<00:00,  9.15s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [22:53<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [22:57<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 3100/3100 [22:57<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [22:58<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [22:58<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 3100/3100 [22:58<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [22:59<00:00,  6.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.
Optimization Progress: 100%|██████████| 3100/3100 [22:59<00:00,  6.41s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [23:05<09:09,  5.66s/pipeline]Optimization Progress:  99%|█████████▉| 3181/3200 [23:08<01:15,  3.98s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [23:10<00:00,  3.98s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [23:10<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [23:11<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [23:13<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [23:14<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [23:14<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 3200/3200 [23:14<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [23:16<00:00,  2.81s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [23:18<07:09,  4.34s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [23:28<10:11,  6.24s/pipeline]Optimization Progress:  99%|█████████▉| 3282/3300 [23:34<01:18,  4.39s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:35<00:00,  4.39s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [23:35<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:35<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:37<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:40<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:40<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:40<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [23:41<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [23:41<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [23:41<00:00,  3.09s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [23:42<05:26,  3.33s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3302/3400 [23:42<05:26,  3.33s/pipeline]Optimization Progress:  97%|█████████▋| 3304/3400 [23:49<05:17,  3.31s/pipeline]Optimization Progress: 100%|█████████▉| 3384/3400 [23:53<00:37,  2.33s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=4 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=5 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:53<00:00,  2.33s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [08:56:36] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f1960f23dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f1961034669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f1961041f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f1961028cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f1960f15f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f0f6ed109dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f0f6ed10067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f0f6ed2827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f0f6ed28cb4]

.
Optimization Progress: 100%|██████████| 3400/3400 [23:54<00:00,  2.33s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [23:54<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:57<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:57<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:58<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [23:59<00:00,  1.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 3400/3400 [24:00<00:00,  1.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3401/3500 [24:02<02:43,  1.65s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [24:02<04:02,  2.47s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [26:55<1:26:33, 53.55s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [27:01<10:37, 37.50s/pipeline]  
Generation 34 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 3500/3500 [27:04<00:00, 37.50s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [27:04<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:04<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [27:04<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:07<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:07<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3500/3500 [27:07<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:08<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:08<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:08<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:09<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:09<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:09<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3500/3500 [27:09<00:00, 26.30s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [27:11<00:00, 26.30s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3500/3600 [27:12<43:50, 26.30s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [27:12<34:36, 20.97s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [27:12<34:36, 20.97s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [32:13<1:36:44, 59.84s/pipeline]                                                                                  Skipped pipeline #3540 due to time out. Continuing to the next pipeline.
Optimization Progress:  98%|█████████▊| 3540/3600 [32:13<59:50, 59.84s/pipeline]/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
Optimization Progress: 100%|█████████▉| 3584/3600 [32:19<11:10, 41.91s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 3601pipeline [32:23, 41.91s/pipeline]Optimization Progress: 3601pipeline [32:23, 29.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 3601pipeline [32:23, 29.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3601pipeline [32:25, 29.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3601pipeline [32:26, 29.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [32:27, 29.40s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3601pipeline [32:27, 29.40s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [32:29<36:30, 22.35s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [36:44<2:29:07, 92.24s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [36:56<18:18, 64.61s/pipeline]  
Generation 36 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-4	-195000534.91065648	GradientBoostingRegressor(PolynomialFeatures(SGDRegressor(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.01, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), SGDRegressor__alpha=0.01, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=False, SGDRegressor__l1_ratio=0.25, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=100.0), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.8)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [36:57, 64.61s/pipeline]Optimization Progress: 3701pipeline [36:57, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [37:00, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3701pipeline [37:00, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3701pipeline [37:01, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [37:03, 45.24s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [37:05, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [37:05, 45.24s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3701pipeline [37:06, 45.24s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [37:10<1:14:38, 45.24s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [37:12<59:18, 36.32s/pipeline]  Optimization Progress: 100%|█████████▉| 3782/3800 [37:16<07:37, 25.43s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [37:18, 25.43s/pipeline]Optimization Progress: 3801pipeline [37:18, 17.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [37:18, 17.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3801pipeline [37:20, 17.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [37:21, 17.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 3801pipeline [37:25, 17.83s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3801pipeline [37:25, 17.83s/pipeline]Optimization Progress:  97%|█████████▋| 3802/3900 [37:26<24:20, 14.90s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [37:35<21:26, 13.26s/pipeline]Optimization Progress: 100%|█████████▉| 3883/3900 [37:39<02:38,  9.30s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [37:42,  9.30s/pipeline]Optimization Progress: 3901pipeline [37:42,  6.56s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3901pipeline [37:43,  6.56s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=1 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 3901pipeline [37:43,  6.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [37:44,  6.56s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 3901pipeline [37:45,  6.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [37:45,  6.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 3901pipeline [37:45,  6.56s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 3901pipeline [37:47,  6.56s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [37:48<08:44,  5.41s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [38:05<14:35,  9.12s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [38:11<01:42,  6.41s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4001pipeline [38:11,  6.41s/pipeline]Optimization Progress: 4001pipeline [38:11,  4.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [38:16,  4.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [38:19,  4.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4001pipeline [38:19,  4.49s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4001pipeline [38:19,  4.49s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [38:30<07:24,  4.49s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [38:34<16:19, 10.00s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [38:40<02:06,  7.02s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4101pipeline [38:43,  7.02s/pipeline]Optimization Progress: 4101pipeline [38:43,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:47,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:47,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:47,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4101pipeline [38:47,  4.96s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4101pipeline [38:49,  4.96s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4101pipeline [38:51,  4.96s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [38:53<07:54,  4.89s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4103/4200 [38:53<07:54,  4.89s/pipeline]Optimization Progress:  98%|█████████▊| 4105/4200 [39:01<07:24,  4.68s/pipeline]Optimization Progress: 100%|█████████▉| 4185/4200 [39:10<00:49,  3.31s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 4201pipeline [39:11,  3.31s/pipeline]Optimization Progress: 4201pipeline [39:11,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [39:11,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [39:11,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4201pipeline [39:11,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [39:11,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [39:13,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4201pipeline [39:13,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 4201pipeline [39:13,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 4201pipeline [39:13,  2.34s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4201pipeline [39:14,  2.34s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [39:18<06:16,  3.85s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [39:23<06:55,  4.28s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [39:26<00:51,  3.01s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [39:31,  3.01s/pipeline]Optimization Progress: 4301pipeline [39:31,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4301pipeline [39:32,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4301pipeline [39:34,  2.18s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 4301pipeline [39:35,  2.18s/pipeline]Optimization Progress:  98%|█████████▊| 4303/4400 [39:36<03:44,  2.32s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4303/4400 [39:36<03:44,  2.32s/pipeline]Optimization Progress:  98%|█████████▊| 4305/4400 [40:28<14:53,  9.40s/pipeline]Optimization Progress: 100%|█████████▉| 4385/4400 [40:36<01:39,  6.61s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-189177409.55223876	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=10, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [40:37,  6.61s/pipeline]Optimization Progress: 4401pipeline [40:37,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 4401pipeline [40:38,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [40:38,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [40:38,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [40:39,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4401pipeline [40:40,  4.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4401pipeline [40:43,  4.64s/pipeline]Optimization Progress:  98%|█████████▊| 4403/4500 [40:44<07:01,  4.35s/pipeline]Optimization Progress:  98%|█████████▊| 4404/4500 [40:51<08:20,  5.21s/pipeline]Optimization Progress: 100%|█████████▉| 4484/4500 [40:55<00:58,  3.66s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4501pipeline [40:56,  3.66s/pipeline]Optimization Progress: 4501pipeline [40:56,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 4501pipeline [40:58,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 4501pipeline [40:59,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [41:00,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [41:02,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [41:02,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4501pipeline [41:02,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [41:03,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 4501pipeline [41:03,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4501pipeline [41:04,  2.57s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4501pipeline [41:04,  2.57s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [41:04<04:15,  2.66s/pipeline]Optimization Progress:  98%|█████████▊| 4504/4600 [41:20<04:15,  2.66s/pipeline]Optimization Progress:  98%|█████████▊| 4505/4600 [45:40<2:13:48, 84.51s/pipeline]Optimization Progress: 100%|█████████▉| 4585/4600 [45:42<14:47, 59.17s/pipeline]  
Generation 45 - Current Pareto front scores:
-1	-199377261.38303298	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.8, GradientBoostingRegressor__min_samples_leaf=6, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [45:43, 59.17s/pipeline]Optimization Progress: 4601pipeline [45:43, 41.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [45:44, 41.44s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [45:45, 41.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4601pipeline [45:46, 41.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4601pipeline [45:48, 41.44s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 4601pipeline [45:50, 41.44s/pipeline]                                                            Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [45:51<1:07:41, 41.44s/pipeline]Optimization Progress:  98%|█████████▊| 4603/4700 [45:51<48:46, 30.17s/pipeline]                                                                                  Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [45:51<48:46, 30.17s/pipeline]Optimization Progress:  98%|█████████▊| 4605/4700 [46:12<38:19, 24.21s/pipeline]Optimization Progress: 100%|█████████▉| 4685/4700 [46:17<04:14, 16.96s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [46:17, 16.96s/pipeline]Optimization Progress: 4701pipeline [46:17, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4701pipeline [46:17, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [46:19, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 4701pipeline [46:19, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [46:21, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4701pipeline [46:24, 11.88s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4701pipeline [46:24, 11.88s/pipeline]Optimization Progress:  98%|█████████▊| 4701/4800 [46:30<19:36, 11.88s/pipeline]Optimization Progress:  98%|█████████▊| 4702/4800 [51:01<2:32:34, 93.41s/pipeline]Optimization Progress: 100%|█████████▉| 4782/4800 [51:05<19:37, 65.40s/pipeline]  
Generation 47 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [51:06, 65.40s/pipeline]Optimization Progress: 4801pipeline [51:06, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 4801pipeline [51:07, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [51:10, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [51:11, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [51:13, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4801pipeline [51:13, 45.80s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4801pipeline [51:14, 45.80s/pipeline]Optimization Progress:  98%|█████████▊| 4802/4900 [51:14<56:20, 34.49s/pipeline]Optimization Progress:  98%|█████████▊| 4803/4900 [51:27<45:02, 27.86s/pipeline]Optimization Progress: 100%|█████████▉| 4883/4900 [51:30<05:31, 19.52s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [51:34, 19.52s/pipeline]Optimization Progress: 4901pipeline [51:34, 13.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [51:34, 13.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 4901pipeline [51:34, 13.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [51:34, 13.73s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 4901pipeline [51:36, 13.73s/pipeline]Optimization Progress:  98%|█████████▊| 4905/5000 [51:39<15:49,  9.99s/pipeline]Optimization Progress:  98%|█████████▊| 4906/5000 [51:46<13:58,  8.92s/pipeline]Optimization Progress: 100%|█████████▉| 4986/5000 [51:54<01:27,  6.27s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5001pipeline [51:54,  6.27s/pipeline]Optimization Progress: 5001pipeline [51:54,  4.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5001pipeline [52:00,  4.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [52:00,  4.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [52:00,  4.41s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5001pipeline [52:03,  4.41s/pipeline]                                                            Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 5001/5100 [52:03<07:16,  4.41s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [52:03<09:22,  5.74s/pipeline]Optimization Progress:  98%|█████████▊| 5003/5100 [52:33<20:54, 12.93s/pipeline]Optimization Progress: 100%|█████████▉| 5083/5100 [52:36<02:34,  9.06s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 5101pipeline [52:38,  9.06s/pipeline]Optimization Progress: 5101pipeline [52:38,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5101pipeline [52:40,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [52:40,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 5101pipeline [52:41,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [52:41,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [52:42,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [52:42,  6.37s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5101pipeline [52:49,  6.37s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [52:50<13:11,  8.07s/pipeline]Optimization Progress:  98%|█████████▊| 5103/5200 [57:27<2:23:30, 88.77s/pipeline]Optimization Progress: 100%|█████████▉| 5183/5200 [57:30<17:36, 62.15s/pipeline]  
Generation 51 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [57:30, 62.15s/pipeline]Optimization Progress: 5201pipeline [57:30, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [57:30, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [57:30, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5201pipeline [57:31, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 5201pipeline [57:32, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [57:37, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5201pipeline [57:37, 43.51s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5201pipeline [57:39, 43.51s/pipeline]Optimization Progress:  98%|█████████▊| 5204/5300 [57:45<51:00, 31.88s/pipeline]Optimization Progress: 100%|█████████▉| 5282/5300 [57:48<06:41, 22.33s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:30:31] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f1960f23dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f1961034669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f1961041f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f1961028cbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f1960f15f35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f0f6ed109dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f0f6ed10067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f0f6ed2827e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f0f6ed28cb4]

.
Optimization Progress: 5301pipeline [57:49, 22.33s/pipeline]Optimization Progress: 5301pipeline [57:49, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 5301pipeline [57:50, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5301pipeline [57:51, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [57:51, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [57:52, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 5301pipeline [57:53, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 5301pipeline [57:53, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [57:54, 15.64s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5301pipeline [57:56, 15.64s/pipeline]Optimization Progress:  98%|█████████▊| 5301/5400 [58:00<25:48, 15.64s/pipeline]Optimization Progress:  98%|█████████▊| 5302/5400 [58:08<27:26, 16.81s/pipeline]Optimization Progress: 100%|█████████▉| 5382/5400 [58:14<03:32, 11.79s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 5401pipeline [58:15, 11.79s/pipeline]Optimization Progress: 5401pipeline [58:15,  8.26s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 5401pipeline [58:16,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [58:18,  8.26s/pipeline]                                                            _pre_test decorator: _mate_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 5401pipeline [58:18,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [58:19,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5401pipeline [58:21,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 5401pipeline [58:22,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [58:22,  8.26s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5401pipeline [58:23,  8.26s/pipeline]Optimization Progress:  98%|█████████▊| 5403/5500 [58:23<11:16,  6.98s/pipeline]Optimization Progress:  98%|█████████▊| 5404/5500 [58:32<12:21,  7.73s/pipeline]Optimization Progress: 100%|█████████▉| 5484/5500 [58:38<01:26,  5.43s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-182240677.5238372	GradientBoostingRegressor(SGDRegressor(SelectFwe(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SelectFwe__alpha=0.004), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-5	-181563993.8993426	GradientBoostingRegressor(RobustScaler(SGDRegressor(PolynomialFeatures(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5501pipeline [58:40,  5.43s/pipeline]Optimization Progress: 5501pipeline [58:40,  3.85s/pipeline]Optimization Progress:  98%|█████████▊| 5503/5600 [58:47<06:03,  3.74s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 5503/5600 [58:47<06:03,  3.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5504/5600 [58:47<05:59,  3.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5505/5600 [58:47<05:55,  3.74s/pipeline]Optimization Progress:  98%|█████████▊| 5507/5600 [58:59<05:22,  3.47s/pipeline]Optimization Progress: 100%|█████████▉| 5587/5600 [59:02<00:31,  2.44s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-182240677.5238372	GradientBoostingRegressor(SGDRegressor(SelectFwe(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SelectFwe__alpha=0.004), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-5	-181563993.8993426	GradientBoostingRegressor(RobustScaler(SGDRegressor(PolynomialFeatures(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 5601pipeline [59:04,  2.44s/pipeline]Optimization Progress: 5601pipeline [59:04,  1.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 5601pipeline [59:06,  1.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 5601pipeline [59:06,  1.75s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5601pipeline [59:09,  1.75s/pipeline]Optimization Progress:  98%|█████████▊| 5602/5700 [59:19<09:35,  5.88s/pipeline]Optimization Progress: 100%|█████████▉| 5682/5700 [59:22<01:14,  4.12s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-198821408.73982558	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-2	-197364229.1334302	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.55, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=9, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-3	-185908464.57095137	GradientBoostingRegressor(SGDRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-4	-182240677.5238372	GradientBoostingRegressor(SGDRegressor(SelectFwe(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=8, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), SelectFwe__alpha=0.004), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-5	-181563993.8993426	GradientBoostingRegressor(RobustScaler(SGDRegressor(PolynomialFeatures(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=squared_loss, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=11, GradientBoostingRegressor__min_samples_split=11, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [59:24,  4.12s/pipeline]Optimization Progress: 5701pipeline [59:24,  2.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 5701pipeline [59:26,  2.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [59:28,  2.91s/pipeline]                                                            _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 5701pipeline [59:28,  2.91s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [1:04:12<2:24:41, 88.59s/pipeline]                                                                                    
Optimization Progress: 100%|█████████▉| 5781/5800 [1:04:12<28:03, 88.59s/pipeline]                                                                                  64.33 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 5781/5800 [1:04:12<28:03, 88.59s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 5781/5800 [1:04:12<28:03, 88.59s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 5781/5800 [1:04:12<28:03, 88.59s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=DecisionTreeRegressor(max_depth=9,
                                                  min_samples_leaf=3,
                                                  min_samples_split=3))
1. PolynomialFeatures(include_bias=False)
2. StackingEstimator(estimator=SGDRegressor(alpha=0.001, eta0=0.1, l1_ratio=0.75,
                                         penalty='elasticnet', power_t=0.0))
3. RobustScaler()
4. GradientBoostingRegressor(learning_rate=0.5, loss='quantile', max_depth=2,
                          max_features=0.6000000000000001, min_samples_leaf=11,
                          min_samples_split=11, subsample=0.3)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
