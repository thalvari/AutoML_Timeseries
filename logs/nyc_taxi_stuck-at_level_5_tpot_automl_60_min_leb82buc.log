30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  11%|█         | 11/100 [00:08<01:05,  1.36pipeline/s]Optimization Progress:  91%|█████████ | 91/100 [00:12<00:04,  1.88pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  1.88pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:15<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:17<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:19<00:00,  2.61pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:19<00:00,  2.61pipeline/s]Optimization Progress:  51%|█████     | 102/200 [00:19<01:57,  1.20s/pipeline]Optimization Progress:  52%|█████▏    | 103/200 [00:36<09:50,  6.08s/pipeline]Optimization Progress:  92%|█████████▏| 183/200 [00:42<01:12,  4.28s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-215033305.6841731	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:42<00:00,  4.28s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 200/200 [00:44<00:00,  4.28s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:44<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:46<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 200/200 [00:47<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:47<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:49<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 200/200 [00:51<00:00,  3.04s/pipeline]Optimization Progress:  67%|██████▋   | 201/300 [00:59<10:45,  6.52s/pipeline]Optimization Progress:  94%|█████████▎| 281/300 [01:05<01:27,  4.58s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-215033305.6841731	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 300/300 [01:06<00:00,  4.58s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:06<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 300/300 [01:07<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 300/300 [01:12<00:00,  3.22s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:12<00:00,  3.22s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  75%|███████▌  | 300/400 [01:15<05:22,  3.22s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [01:15<08:09,  4.94s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  75%|███████▌  | 301/400 [01:15<08:09,  4.94s/pipeline]Optimization Progress:  76%|███████▌  | 303/400 [02:12<19:22, 11.98s/pipeline]Optimization Progress:  96%|█████████▌| 383/400 [02:14<02:22,  8.40s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-213622876.06239042	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:15<00:00,  8.40s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:15<00:00,  5.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [02:20<00:00,  5.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:24<00:00,  5.88s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:25<00:00,  5.88s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  80%|████████  | 401/500 [02:25<09:42,  5.88s/pipeline]Optimization Progress:  80%|████████  | 402/500 [02:30<09:36,  5.88s/pipeline]Optimization Progress:  81%|████████  | 403/500 [02:34<09:47,  6.06s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [02:39<01:12,  4.26s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-212038024.46406084	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-210340380.40052614	GradientBoostingRegressor(MinMaxScaler(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:45<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 500/500 [02:45<00:00,  3.08s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:46<00:00,  3.08s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:46<00:00,  3.08s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 500/500 [02:46<00:00,  3.08s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [02:47<04:41,  2.84s/pipeline]Optimization Progress:  84%|████████▎ | 502/600 [02:58<08:47,  5.39s/pipeline]Optimization Progress:  97%|█████████▋| 582/600 [03:03<01:08,  3.79s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-212038024.46406084	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-3	-210340380.40052614	GradientBoostingRegressor(MinMaxScaler(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 600/600 [03:04<00:00,  3.79s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:04<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:05<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:06<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:09<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:11<00:00,  2.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 600/600 [03:12<00:00,  2.67s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  86%|████████▌ | 600/700 [03:12<04:26,  2.67s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [03:12<07:13,  4.38s/pipeline]Optimization Progress:  86%|████████▌ | 602/700 [03:45<21:04, 12.90s/pipeline]Optimization Progress:  97%|█████████▋| 682/700 [03:48<02:42,  9.04s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-212038024.46406084	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.7000000000000001)
-2	-211000266.4373773	GradientBoostingRegressor(RobustScaler(input_matrix), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)
-3	-210340380.40052614	GradientBoostingRegressor(MinMaxScaler(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=True, LinearSVR__epsilon=0.0001, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001)), GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 700/700 [03:50<00:00,  9.04s/pipeline]Optimization Progress: 100%|██████████| 700/700 [03:50<00:00,  6.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [03:52<00:00,  6.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [03:55<00:00,  6.36s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [03:56<10:14,  6.21s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [04:19<18:35, 11.39s/pipeline]Optimization Progress:  98%|█████████▊| 782/800 [04:25<02:23,  7.99s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-210003782.28597352	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-210003570.39114594	GradientBoostingRegressor(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.5, AdaBoostRegressor__loss=linear, AdaBoostRegressor__n_estimators=100), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-3	-209157353.5474936	XGBRegressor(XGBRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.1)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  7.99s/pipeline]Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [04:30<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [04:31<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:31<00:00,  5.67s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [04:34<00:00,  5.67s/pipeline]Optimization Progress:  89%|████████▉ | 801/900 [04:35<08:56,  5.42s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 801/900 [04:35<08:56,  5.42s/pipeline]Optimization Progress:  89%|████████▉ | 803/900 [04:42<07:50,  4.86s/pipeline]Optimization Progress:  98%|█████████▊| 883/900 [04:56<00:58,  3.45s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-210003782.28597352	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-209320199.23352462	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-209157353.5474936	XGBRegressor(XGBRegressor(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=ls, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.5, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=1.0), XGBRegressor__learning_rate=0.5, XGBRegressor__max_depth=3, XGBRegressor__min_child_weight=12, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.05), XGBRegressor__learning_rate=1.0, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=16, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.1)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 900/900 [04:57<00:00,  3.45s/pipeline]Optimization Progress: 100%|██████████| 900/900 [04:57<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 900/900 [04:58<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 900/900 [05:03<00:00,  2.43s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [05:05<00:00,  2.43s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 901/1000 [05:05<04:00,  2.43s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [05:05<04:41,  2.87s/pipeline]                                                                               Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  90%|█████████ | 902/1000 [05:05<04:41,  2.87s/pipeline]Optimization Progress:  90%|█████████ | 904/1000 [05:57<15:49,  9.89s/pipeline]Optimization Progress:  98%|█████████▊| 984/1000 [06:01<01:51,  6.94s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-210003782.28597352	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-203924265.67189655	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:02<00:00,  6.94s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [06:02<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [06:02<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 1000/1000 [06:03<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:03<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [06:04<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:05<00:00,  4.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [06:07<00:00,  4.87s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [06:20<08:01,  4.87s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [06:47<16:36, 10.17s/pipeline]Optimization Progress:  98%|█████████▊| 1082/1100 [06:54<02:08,  7.14s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-210003782.28597352	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.99, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=13, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.45)
-2	-203924265.67189655	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-198340553.53565437	GradientBoostingRegressor(RobustScaler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=18, DecisionTreeRegressor__min_samples_split=16)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [06:54<00:00,  7.14s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [06:54<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [06:57<00:00,  5.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [06:59<00:00,  5.01s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [07:03<06:38,  4.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  92%|█████████▏| 1104/1200 [07:03<06:38,  4.15s/pipeline]Optimization Progress:  92%|█████████▏| 1106/1200 [08:10<20:18, 12.96s/pipeline]Optimization Progress:  99%|█████████▉| 1186/1200 [08:14<02:07,  9.09s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-204830240.21586755	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-2	-203924265.67189655	GradientBoostingRegressor(StandardScaler(input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-198340553.53565437	GradientBoostingRegressor(RobustScaler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=18, DecisionTreeRegressor__min_samples_split=16)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [08:16<00:00,  9.09s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [08:16<00:00,  6.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [08:18<00:00,  6.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [08:20<00:00,  6.40s/pipeline]Optimization Progress:  92%|█████████▏| 1201/1300 [08:23<11:02,  6.70s/pipeline]Optimization Progress:  92%|█████████▏| 1202/1300 [09:29<40:00, 24.49s/pipeline]Optimization Progress:  99%|█████████▊| 1282/1300 [11:17<05:15, 17.55s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-199288662.83063638	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.1, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-198340553.53565437	GradientBoostingRegressor(RobustScaler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=18, DecisionTreeRegressor__min_samples_split=16)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.15000000000000002)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 1300/1300 [11:19<00:00, 17.55s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [11:19<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [11:20<00:00, 12.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [11:22<00:00, 12.32s/pipeline]Optimization Progress:  93%|█████████▎| 1302/1400 [11:26<15:42,  9.62s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [11:33<14:27,  8.94s/pipeline]Optimization Progress:  99%|█████████▉| 1383/1400 [11:37<01:46,  6.27s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-198163676.91662905	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [11:40<00:00,  6.27s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [11:40<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [11:43<00:00,  4.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1400/1400 [11:44<00:00,  4.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1400/1500 [11:47<07:23,  4.44s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [11:47<08:39,  5.25s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [11:54<09:14,  5.66s/pipeline]Optimization Progress:  99%|█████████▉| 1482/1500 [11:58<01:11,  3.98s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-198163676.91662905	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [11:59<00:00,  3.98s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [11:59<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:03<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 1500/1500 [12:03<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 1500/1500 [12:04<00:00,  2.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1500/1500 [12:05<00:00,  2.81s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [12:08<05:14,  3.21s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [12:27<13:02,  8.06s/pipeline]Optimization Progress:  99%|█████████▉| 1583/1600 [12:31<01:36,  5.66s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-198163676.91662905	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [12:32<00:00,  5.66s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [12:32<00:00,  3.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [12:34<00:00,  3.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 1600/1600 [12:37<00:00,  3.99s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [12:41<06:34,  4.03s/pipeline]Optimization Progress:  94%|█████████▍| 1603/1700 [13:33<29:53, 18.49s/pipeline]Optimization Progress:  99%|█████████▉| 1683/1700 [13:39<03:40, 12.96s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-198163676.91662905	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1700/1700 [13:41<00:00, 12.96s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [13:41<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [13:43<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1700/1700 [13:44<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 1700/1700 [13:44<00:00,  9.11s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 1700/1700 [13:47<00:00,  9.11s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [14:22<30:37, 18.56s/pipeline]Optimization Progress:  99%|█████████▉| 1781/1800 [14:25<04:07, 13.01s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-198163676.91662905	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=18, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [14:30<00:00, 13.01s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [14:30<00:00,  9.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:32<00:00,  9.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1800/1800 [14:32<00:00,  9.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:32<00:00,  9.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:32<00:00,  9.18s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [14:33<11:16,  6.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1802/1900 [14:33<11:16,  6.90s/pipeline]Optimization Progress:  95%|█████████▍| 1804/1900 [15:23<19:50, 12.40s/pipeline]Optimization Progress:  99%|█████████▉| 1884/1900 [15:25<02:19,  8.69s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-197703543.0726043	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:26<00:00,  8.69s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [15:26<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:26<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1900/1900 [15:26<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:28<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:29<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:29<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 1900/1900 [15:32<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:32<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:32<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:33<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [15:33<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1900/1900 [15:33<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1900/1900 [15:33<00:00,  6.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 1900/1900 [15:33<00:00,  6.10s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [15:40<10:03,  6.10s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [15:40<10:19,  6.32s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [15:44<01:19,  4.44s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-197703543.0726043	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [15:46<00:00,  4.44s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [15:46<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2000/2000 [15:49<00:00,  3.13s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [15:49<00:00,  3.13s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [15:53<04:20,  2.72s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [16:38<24:25, 15.43s/pipeline]Optimization Progress:  99%|█████████▉| 2085/2100 [16:42<02:42, 10.82s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-197703543.0726043	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2100/2100 [16:44<00:00, 10.82s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [16:44<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [16:44<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:46<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:46<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2100/2100 [16:46<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2100/2100 [16:47<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:47<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:47<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:47<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:47<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 2100/2100 [16:48<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:50<00:00,  7.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [16:50<00:00,  7.62s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [16:59<16:30, 10.01s/pipeline]Optimization Progress:  99%|█████████▉| 2181/2200 [17:02<02:13,  7.01s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-196579316.23621517	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.6000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-196531298.62656388	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.55)
-4	-195976987.73319897	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:02<00:00,  7.01s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [17:02<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2200/2200 [17:03<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2200/2200 [17:04<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2200/2200 [17:04<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:06<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [17:08<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [17:08<00:00,  4.91s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 2200/2200 [17:10<00:00,  4.91s/pipeline]Optimization Progress:  96%|█████████▌| 2204/2300 [17:15<07:01,  4.39s/pipeline]Optimization Progress:  99%|█████████▉| 2282/2300 [17:18<00:55,  3.08s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:18<00:00,  3.08s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [17:18<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:19<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [17:20<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [17:21<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:23<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:24<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:24<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:26<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [17:26<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [17:27<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [17:27<00:00,  2.16s/pipeline]Optimization Progress:  96%|█████████▌| 2300/2400 [17:30<03:36,  2.16s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [17:55<20:26, 12.39s/pipeline]Optimization Progress:  99%|█████████▉| 2381/2400 [17:58<02:45,  8.69s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [17:59<00:00,  8.69s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [17:59<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [17:59<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [17:59<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [18:00<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [18:01<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [18:02<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2400/2400 [18:02<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [18:03<00:00,  6.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [18:03<00:00,  6.09s/pipeline]Optimization Progress:  96%|█████████▌| 2400/2500 [18:10<10:09,  6.09s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [18:13<14:12,  8.61s/pipeline]Optimization Progress:  99%|█████████▉| 2481/2500 [18:16<01:54,  6.04s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:16<00:00,  6.04s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [18:16<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2500/2500 [18:17<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 2500/2500 [18:17<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 2500/2500 [18:17<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [18:20<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [18:20<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:20<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:21<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:21<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:21<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:21<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2500/2500 [18:22<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2500/2500 [18:22<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:22<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:23<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:23<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:23<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 2500/2500 [18:23<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:24<00:00,  4.23s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [18:24<00:00,  4.23s/pipeline]Optimization Progress:  96%|█████████▌| 2502/2600 [18:30<06:54,  4.23s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [18:31<07:04,  4.38s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [18:34<00:52,  3.08s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:34<00:00,  3.08s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [18:34<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:34<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:34<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:37<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:37<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [18:38<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:39<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 2600/2600 [18:39<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:39<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:39<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:40<00:00,  2.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [18:41<00:00,  2.16s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2601/2700 [18:42<03:34,  2.16s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [18:42<04:16,  2.62s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [18:48<04:21,  2.72s/pipeline]Optimization Progress:  99%|█████████▉| 2683/2700 [18:55<00:32,  1.93s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.93s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:55<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:56<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [18:57<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 2700/2700 [18:58<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:58<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:59<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [18:59<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [18:59<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 2700/2700 [19:01<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [19:02<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [19:02<00:00,  1.36s/pipeline]Optimization Progress:  96%|█████████▋| 2701/2800 [19:10<02:14,  1.36s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [19:24<08:35,  5.26s/pipeline]Optimization Progress:  99%|█████████▉| 2782/2800 [19:28<01:06,  3.70s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:29<00:00,  3.70s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [19:29<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:29<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:30<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:30<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 2800/2800 [19:31<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:31<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:31<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:31<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.
Optimization Progress: 100%|██████████| 2800/2800 [19:32<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [19:32<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:32<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:33<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:35<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [19:36<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 2800/2800 [19:37<00:00,  2.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [19:37<00:00,  2.61s/pipeline]Optimization Progress:  97%|█████████▋| 2801/2900 [19:43<09:51,  5.97s/pipeline]Optimization Progress:  99%|█████████▉| 2881/2900 [19:47<01:19,  4.20s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:48<00:00,  4.20s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [19:48<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 2900/2900 [19:48<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 2900/2900 [19:49<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:49<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:49<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:49<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [19:49<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:50<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:50<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:50<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:55<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:55<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:55<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:56<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:56<00:00,  2.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [19:56<00:00,  2.96s/pipeline]Optimization Progress:  97%|█████████▋| 2902/3000 [19:56<05:16,  3.23s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [20:24<17:25, 10.78s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [20:29<02:08,  7.56s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [20:29<00:00,  7.56s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [20:29<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [20:30<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3000/3000 [20:30<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [20:31<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [20:34<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [20:35<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [20:35<00:00,  5.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [20:35<00:00,  5.31s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [20:37<09:54,  6.01s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [20:46<11:28,  7.03s/pipeline]Optimization Progress:  99%|█████████▉| 3082/3100 [21:00<01:29,  4.97s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [21:01<00:00,  4.97s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [21:01<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3100/3100 [21:03<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [21:05<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [21:05<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [21:05<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3100/3100 [21:06<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3100/3100 [21:06<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3100/3100 [21:08<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 3100/3100 [21:08<00:00,  3.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3100/3100 [21:08<00:00,  3.49s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [21:09<05:45,  3.49s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [21:09<05:53,  3.61s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [21:29<13:56,  8.63s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [21:43<01:43,  6.09s/pipeline]
Generation 31 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:43<00:00,  6.09s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [21:43<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:43<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3200/3200 [21:44<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [21:44<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:44<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:44<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:45<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:45<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3200/3200 [21:47<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:47<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 3200/3200 [21:49<00:00,  4.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [21:53<00:00,  4.27s/pipeline]Optimization Progress:  97%|█████████▋| 3200/3300 [22:00<07:07,  4.27s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [22:02<14:16,  8.65s/pipeline]Optimization Progress:  99%|█████████▉| 3281/3300 [22:08<01:55,  6.07s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [22:08<00:00,  6.07s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [22:08<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [22:10<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [22:11<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [22:12<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [22:12<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 3300/3300 [22:12<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3300/3300 [22:13<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [22:18<00:00,  4.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [22:18<00:00,  4.26s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [22:19<07:32,  4.62s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [22:26<08:45,  5.41s/pipeline]Optimization Progress: 100%|█████████▉| 3383/3400 [22:30<01:04,  3.80s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3400/3400 [22:31<00:00,  3.80s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [22:31<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [22:36<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [22:36<00:00,  2.68s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 3400/3400 [22:38<00:00,  2.68s/pipeline]Optimization Progress:  97%|█████████▋| 3402/3500 [22:42<05:34,  3.41s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [22:50<07:58,  4.93s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [22:53<00:58,  3.46s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [22:54<00:00,  3.46s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [22:54<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [22:56<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [22:57<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [22:59<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [23:01<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [23:02<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3500/3500 [23:02<00:00,  2.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3500/3500 [23:02<00:00,  2.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3500/3600 [23:05<04:04,  2.44s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [23:05<07:54,  4.79s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [23:12<09:05,  5.56s/pipeline]Optimization Progress: 100%|█████████▉| 3582/3600 [23:37<01:11,  3.99s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [23:38<00:00,  3.99s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [23:38<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 3600/3600 [23:38<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:38<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:38<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:40<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:40<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:40<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:40<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:41<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3600/3600 [23:41<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3600/3600 [23:42<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3600/3600 [23:42<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [23:44<00:00,  2.80s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3600/3600 [23:44<00:00,  2.80s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [23:47<07:59,  4.84s/pipeline]Optimization Progress:  97%|█████████▋| 3602/3700 [23:53<08:30,  5.21s/pipeline]Optimization Progress: 100%|█████████▉| 3682/3700 [23:57<01:05,  3.66s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [23:58<00:00,  3.66s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [23:58<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [23:59<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 3700/3700 [24:00<00:00,  2.58s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3700/3700 [24:09<00:00,  2.58s/pipeline]Optimization Progress:  97%|█████████▋| 3700/3800 [24:10<04:17,  2.58s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [24:14<11:05,  6.72s/pipeline]Optimization Progress: 100%|█████████▉| 3781/3800 [24:19<01:29,  4.72s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:19<00:00,  4.72s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [24:19<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 3800/3800 [24:19<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:20<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 3800/3800 [24:23<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:24<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [24:25<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [24:26<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3800/3800 [24:28<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 3800/3800 [24:28<00:00,  3.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 3800/3800 [24:28<00:00,  3.31s/pipeline]Optimization Progress:  98%|█████████▊| 3803/3900 [24:29<05:24,  3.35s/pipeline]Optimization Progress:  98%|█████████▊| 3804/3900 [24:39<08:06,  5.07s/pipeline]Optimization Progress: 100%|█████████▉| 3884/3900 [24:45<00:57,  3.57s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [24:45<00:00,  3.57s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [24:45<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [24:47<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [24:47<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 3900/3900 [24:55<00:00,  2.51s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 3901/4000 [24:56<04:08,  2.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3902/4000 [24:56<04:05,  2.51s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [25:00<04:03,  2.51s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [25:04<05:03,  3.17s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [25:12<00:35,  2.24s/pipeline]
Generation 39 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [25:15<00:00,  2.24s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [25:15<00:00,  1.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [25:16<00:00,  1.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [25:18<00:00,  1.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [25:21<00:00,  1.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [25:23<00:00,  1.64s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [25:24<03:56,  2.41s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4002/4100 [25:24<03:56,  2.41s/pipeline]Optimization Progress:  98%|█████████▊| 4004/4100 [25:38<06:04,  3.80s/pipeline]Optimization Progress: 100%|█████████▉| 4084/4100 [25:52<00:43,  2.71s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:54<00:00,  2.71s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [25:54<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [25:55<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4100/4100 [25:56<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [25:56<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4100/4100 [25:57<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [26:00<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [26:00<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [26:00<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [26:00<00:00,  1.93s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [26:03<00:00,  1.93s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [26:12<11:18,  6.86s/pipeline]Optimization Progress: 100%|█████████▉| 4181/4200 [26:20<01:31,  4.83s/pipeline]
Generation 41 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [26:21<00:00,  4.83s/pipeline]Optimization Progress: 100%|██████████| 4200/4200 [26:21<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [26:22<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 4200/4200 [26:25<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [26:27<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 4200/4200 [26:28<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4200/4200 [26:29<00:00,  3.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [26:30<00:00,  3.39s/pipeline]Optimization Progress:  98%|█████████▊| 4202/4300 [26:32<06:38,  4.06s/pipeline]Optimization Progress:  98%|█████████▊| 4203/4300 [26:39<07:59,  4.94s/pipeline]Optimization Progress: 100%|█████████▉| 4283/4300 [26:42<00:59,  3.47s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [26:47<00:00,  3.47s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [26:47<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [26:48<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [26:48<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [26:48<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 4300/4300 [26:49<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4300/4300 [26:49<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [26:50<00:00,  2.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [26:53<00:00,  2.51s/pipeline]Optimization Progress:  98%|█████████▊| 4302/4400 [26:54<04:44,  2.90s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4302/4400 [26:54<04:44,  2.90s/pipeline]Optimization Progress:  98%|█████████▊| 4304/4400 [27:04<05:38,  3.52s/pipeline]Optimization Progress: 100%|█████████▉| 4384/4400 [27:09<00:39,  2.48s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [27:09<00:00,  2.48s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [27:09<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 4400/4400 [27:09<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [27:12<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [27:12<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [27:14<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [27:17<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4400/4400 [27:18<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4400/4400 [27:19<00:00,  1.74s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [27:20<00:00,  1.74s/pipeline]Optimization Progress:  98%|█████████▊| 4401/4500 [27:31<13:01,  7.89s/pipeline]Optimization Progress: 100%|█████████▉| 4481/4500 [27:44<01:45,  5.57s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 4500/4500 [27:46<00:00,  5.57s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [27:46<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:50<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:50<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [27:50<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [27:51<00:00,  3.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [27:57<00:00,  3.92s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4500/4600 [27:59<06:32,  3.92s/pipeline]Optimization Progress:  98%|█████████▊| 4501/4600 [27:59<11:14,  6.81s/pipeline]Optimization Progress:  98%|█████████▊| 4502/4600 [28:40<27:51, 17.05s/pipeline]Optimization Progress: 100%|█████████▉| 4582/4600 [28:44<03:35, 11.95s/pipeline]
Generation 45 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 4600/4600 [28:47<00:00, 11.95s/pipeline]Optimization Progress: 100%|██████████| 4600/4600 [28:47<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [28:49<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4600/4600 [28:49<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [28:50<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [28:51<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 4600/4600 [28:52<00:00,  8.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4600/4600 [28:53<00:00,  8.41s/pipeline]Optimization Progress:  98%|█████████▊| 4601/4700 [28:55<14:02,  8.51s/pipeline]Optimization Progress:  98%|█████████▊| 4602/4700 [29:04<13:54,  8.51s/pipeline]Optimization Progress: 100%|█████████▉| 4682/4700 [29:10<01:47,  5.98s/pipeline]
Generation 46 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 4700/4700 [29:13<00:00,  5.98s/pipeline]Optimization Progress: 100%|██████████| 4700/4700 [29:13<00:00,  4.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [29:14<00:00,  4.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [29:16<00:00,  4.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4700/4700 [29:16<00:00,  4.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4700/4700 [29:17<00:00,  4.24s/pipeline]Optimization Progress:  98%|█████████▊| 4701/4800 [29:44<20:14, 12.27s/pipeline]Optimization Progress: 100%|█████████▉| 4781/4800 [29:50<02:43,  8.61s/pipeline]
Generation 47 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4800/4800 [29:54<00:00,  8.61s/pipeline]Optimization Progress: 100%|██████████| 4800/4800 [29:54<00:00,  6.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4800/4800 [29:58<00:00,  6.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 4800/4800 [29:59<00:00,  6.08s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 4800/4800 [29:59<00:00,  6.08s/pipeline]Optimization Progress:  98%|█████████▊| 4803/4900 [30:03<08:25,  5.21s/pipeline]Optimization Progress:  98%|█████████▊| 4804/4900 [30:11<09:38,  6.03s/pipeline]Optimization Progress: 100%|█████████▉| 4884/4900 [30:18<01:07,  4.24s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [30:25<00:00,  4.24s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [30:25<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by RobustScaler..
Optimization Progress: 100%|██████████| 4900/4900 [30:25<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [30:25<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 4900/4900 [30:25<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [30:26<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [30:26<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [30:27<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4900/4900 [30:29<00:00,  3.10s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4900/4900 [30:30<00:00,  3.10s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [31:33<37:23, 22.66s/pipeline]Optimization Progress: 100%|█████████▉| 4981/5000 [31:38<05:01, 15.88s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [31:38<00:00, 15.88s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [31:38<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [31:43<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [31:47<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5000/5000 [31:47<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [31:47<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [31:49<00:00, 11.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [31:50<00:00, 11.12s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [31:50<00:00, 11.12s/pipeline]Optimization Progress:  98%|█████████▊| 5002/5100 [31:55<16:42, 10.23s/pipeline]Optimization Progress:  98%|█████████▊| 5003/5100 [32:06<17:07, 10.59s/pipeline]Optimization Progress: 100%|█████████▉| 5083/5100 [33:08<02:09,  7.65s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [33:10<00:00,  7.65s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [33:10<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [33:13<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [33:15<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [33:15<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 5100/5100 [33:16<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 5100/5100 [33:16<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 5100/5100 [33:19<00:00,  5.38s/pipeline]Optimization Progress:  98%|█████████▊| 5101/5200 [33:21<11:35,  7.03s/pipeline]Optimization Progress:  98%|█████████▊| 5102/5200 [33:29<11:57,  7.32s/pipeline]Optimization Progress: 100%|█████████▉| 5182/5200 [33:34<01:32,  5.14s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [33:39<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [33:39<00:00,  3.68s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5200/5300 [33:47<06:08,  3.68s/pipeline]Optimization Progress:  98%|█████████▊| 5201/5300 [33:47<08:16,  5.01s/pipeline]Optimization Progress:  98%|█████████▊| 5202/5300 [33:56<10:12,  6.25s/pipeline]Optimization Progress: 100%|█████████▉| 5282/5300 [34:02<01:19,  4.39s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [34:03<00:00,  4.39s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [34:03<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [34:04<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [34:05<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [34:06<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [34:10<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 5300/5300 [34:10<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [34:10<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [34:10<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 5300/5300 [34:12<00:00,  3.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [34:13<00:00,  3.09s/pipeline]Optimization Progress:  98%|█████████▊| 5300/5400 [34:20<05:08,  3.09s/pipeline]Optimization Progress:  98%|█████████▊| 5301/5400 [34:25<14:41,  8.90s/pipeline]Optimization Progress: 100%|█████████▉| 5381/5400 [34:31<01:58,  6.26s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 5400/5400 [34:39<00:00,  6.26s/pipeline]Optimization Progress: 100%|██████████| 5400/5400 [34:39<00:00,  4.51s/pipeline]Optimization Progress:  98%|█████████▊| 5401/5500 [34:55<12:47,  7.75s/pipeline]Optimization Progress: 100%|█████████▉| 5481/5500 [35:01<01:43,  5.45s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 5500/5500 [35:05<00:00,  5.45s/pipeline]Optimization Progress: 100%|██████████| 5500/5500 [35:05<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 5500/5500 [35:11<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [35:11<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5500/5500 [35:12<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [35:13<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5500/5500 [35:14<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 5500/5500 [35:16<00:00,  3.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [35:16<00:00,  3.88s/pipeline]Optimization Progress:  98%|█████████▊| 5502/5600 [35:17<07:14,  4.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5502/5600 [35:17<07:14,  4.44s/pipeline]Optimization Progress:  98%|█████████▊| 5504/5600 [36:26<21:37, 13.51s/pipeline]Optimization Progress: 100%|█████████▉| 5584/5600 [36:31<02:31,  9.48s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [36:31<00:00,  9.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [36:32<00:00,  9.48s/pipeline]Optimization Progress: 100%|██████████| 5600/5600 [36:32<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5600/5600 [36:36<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [36:37<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [36:37<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5600/5600 [36:40<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 5600/5600 [36:40<00:00,  6.65s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 5600/5600 [36:43<00:00,  6.65s/pipeline]Optimization Progress:  98%|█████████▊| 5603/5700 [36:45<09:40,  5.99s/pipeline]Optimization Progress:  98%|█████████▊| 5604/5700 [36:55<11:41,  7.31s/pipeline]Optimization Progress: 100%|█████████▉| 5684/5700 [37:02<01:22,  5.14s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5700/5700 [37:09<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [37:09<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 5700/5700 [37:13<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [37:15<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [37:16<00:00,  3.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 5700/5700 [37:16<00:00,  3.73s/pipeline]Optimization Progress:  98%|█████████▊| 5701/5800 [37:18<08:41,  5.27s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [37:34<13:57,  8.55s/pipeline]Optimization Progress: 100%|█████████▉| 5782/5800 [37:39<01:48,  6.00s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [37:39<00:00,  6.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 5800/5800 [37:42<00:00,  6.00s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [37:42<00:00,  4.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5800/5800 [37:43<00:00,  4.25s/pipeline]Optimization Progress:  98%|█████████▊| 5801/5900 [37:54<10:50,  6.58s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 5801/5900 [37:54<10:50,  6.58s/pipeline]Optimization Progress:  98%|█████████▊| 5803/5900 [38:03<09:30,  5.89s/pipeline]Optimization Progress: 100%|█████████▉| 5883/5900 [38:08<01:10,  4.14s/pipeline]
Generation 58 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-177269106.1289584	GradientBoostingRegressor(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.5, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=18, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-4	-165257527.35342962	GradientBoostingRegressor(RidgeCV(LassoLarsCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 5900/5900 [38:13<00:00,  4.14s/pipeline]Optimization Progress: 100%|██████████| 5900/5900 [38:13<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 5900/5900 [38:17<00:00,  2.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5900/5900 [38:18<00:00,  2.99s/pipeline]Optimization Progress:  98%|█████████▊| 5901/6000 [39:27<40:11, 24.36s/pipeline]Optimization Progress: 100%|█████████▉| 5981/6000 [39:33<05:24, 17.07s/pipeline]
Generation 59 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [39:35<00:00, 17.07s/pipeline]Optimization Progress: 100%|██████████| 6000/6000 [39:35<00:00, 11.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 6000/6000 [39:36<00:00, 11.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [39:38<00:00, 11.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [39:43<00:00, 11.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [39:45<00:00, 11.99s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6000/6100 [39:46<19:58, 11.99s/pipeline]Optimization Progress:  98%|█████████▊| 6001/6100 [39:46<19:23, 11.75s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6001/6100 [39:46<19:23, 11.75s/pipeline]Optimization Progress:  98%|█████████▊| 6003/6100 [40:48<28:18, 17.51s/pipeline]Optimization Progress: 100%|█████████▉| 6083/6100 [40:53<03:28, 12.27s/pipeline]
Generation 60 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [40:55<00:00, 12.27s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [40:55<00:00,  8.64s/pipeline]Optimization Progress:  98%|█████████▊| 6102/6200 [41:06<12:23,  7.59s/pipeline]Optimization Progress:  98%|█████████▊| 6103/6200 [42:09<39:10, 24.23s/pipeline]Optimization Progress: 100%|█████████▉| 6183/6200 [42:13<04:48, 16.98s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [42:15<00:00, 16.98s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [42:15<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 6200/6200 [42:25<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [42:26<00:00, 11.92s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [42:27<00:00, 11.92s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6200/6300 [42:27<19:51, 11.92s/pipeline]Optimization Progress:  98%|█████████▊| 6201/6300 [42:27<20:02, 12.14s/pipeline]Optimization Progress:  98%|█████████▊| 6202/6300 [42:35<17:50, 10.92s/pipeline]Optimization Progress: 100%|█████████▉| 6282/6300 [42:39<02:17,  7.66s/pipeline]
Generation 62 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6300/6300 [42:41<00:00,  7.66s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [42:41<00:00,  5.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.20000.
Optimization Progress: 100%|██████████| 6300/6300 [42:44<00:00,  5.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 6300/6300 [42:45<00:00,  5.39s/pipeline]Optimization Progress:  98%|█████████▊| 6301/6400 [43:04<17:13, 10.44s/pipeline]Optimization Progress: 100%|█████████▉| 6381/6400 [43:14<02:19,  7.35s/pipeline]
Generation 63 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [43:16<00:00,  7.35s/pipeline]Optimization Progress: 100%|██████████| 6400/6400 [43:16<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [43:19<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [43:22<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [43:23<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 6400/6400 [43:23<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 6400/6400 [43:23<00:00,  5.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6400/6400 [43:28<00:00,  5.17s/pipeline]Optimization Progress:  99%|█████████▊| 6403/6500 [43:29<07:55,  4.90s/pipeline]Optimization Progress:  99%|█████████▊| 6404/6500 [43:38<09:51,  6.16s/pipeline]Optimization Progress: 100%|█████████▉| 6484/6500 [43:43<01:09,  4.33s/pipeline]
Generation 64 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 6500/6500 [43:43<00:00,  4.33s/pipeline]Optimization Progress: 100%|██████████| 6500/6500 [43:43<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 6500/6500 [43:43<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [43:45<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [43:48<00:00,  3.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [43:55<00:00,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6500/6600 [43:56<05:04,  3.04s/pipeline]Optimization Progress:  98%|█████████▊| 6501/6600 [44:00<05:01,  3.04s/pipeline]Optimization Progress:  99%|█████████▊| 6502/6600 [44:06<09:03,  5.54s/pipeline]Optimization Progress: 100%|█████████▉| 6582/6600 [44:10<01:10,  3.90s/pipeline]
Generation 65 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 6600/6600 [44:11<00:00,  3.90s/pipeline]Optimization Progress: 100%|██████████| 6600/6600 [44:11<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6600/6600 [44:13<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 6600/6600 [44:15<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6600/6600 [44:16<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [44:20<00:00,  2.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 6600/6600 [44:24<00:00,  2.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6600/6700 [44:28<04:34,  2.74s/pipeline]Optimization Progress:  99%|█████████▊| 6601/6700 [44:28<11:39,  7.06s/pipeline]Optimization Progress:  99%|█████████▊| 6602/6700 [44:41<14:25,  8.83s/pipeline]Optimization Progress: 100%|█████████▉| 6682/6700 [44:46<01:51,  6.20s/pipeline]
Generation 66 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6700/6700 [44:47<00:00,  6.20s/pipeline]Optimization Progress: 100%|██████████| 6700/6700 [44:47<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 6700/6700 [44:55<00:00,  4.36s/pipeline]Optimization Progress:  99%|█████████▊| 6701/6800 [45:01<11:53,  7.21s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6701/6800 [45:01<11:53,  7.21s/pipeline]Optimization Progress:  99%|█████████▊| 6703/6800 [46:05<23:48, 14.72s/pipeline]Optimization Progress: 100%|█████████▉| 6783/6800 [46:09<02:55, 10.32s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6800/6800 [46:11<00:00, 10.32s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [46:11<00:00,  7.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 6800/6800 [46:16<00:00,  7.26s/pipeline]Optimization Progress:  99%|█████████▊| 6801/6900 [46:33<19:00, 11.52s/pipeline]Optimization Progress: 100%|█████████▉| 6881/6900 [46:38<02:33,  8.08s/pipeline]
Generation 68 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [46:39<00:00,  8.08s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [46:39<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 6900/6900 [46:42<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6900/6900 [46:43<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [46:45<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [46:45<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [46:45<00:00,  5.67s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [46:50<00:00,  5.67s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6900/6900 [46:52<00:00,  5.67s/pipeline]Optimization Progress:  99%|█████████▊| 6901/7000 [46:53<13:39,  8.28s/pipeline]Optimization Progress:  99%|█████████▊| 6902/7000 [47:01<13:16,  8.13s/pipeline]Optimization Progress: 100%|█████████▉| 6982/7000 [47:07<01:42,  5.72s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-164117135.1631318	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7000/7000 [47:10<00:00,  5.72s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [47:10<00:00,  4.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 7000/7000 [47:10<00:00,  4.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 7000/7000 [47:17<00:00,  4.04s/pipeline]Optimization Progress:  99%|█████████▊| 7001/7100 [47:22<10:31,  6.38s/pipeline]Optimization Progress:  99%|█████████▊| 7002/7100 [47:37<14:28,  8.86s/pipeline]Optimization Progress: 100%|█████████▉| 7082/7100 [47:42<01:52,  6.22s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-160392894.47677106	GradientBoostingRegressor(XGBRegressor(ElasticNetCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.001), XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=9, XGBRegressor__min_child_weight=19, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=1.0), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.2)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 7100/7100 [47:45<00:00,  6.22s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [47:45<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 7100/7100 [47:45<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7100/7100 [47:47<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [47:52<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7100/7100 [47:53<00:00,  4.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [47:55<00:00,  4.41s/pipeline]Optimization Progress:  99%|█████████▊| 7101/7200 [49:00<41:57, 25.42s/pipeline]Optimization Progress: 100%|█████████▉| 7181/7200 [49:05<05:38, 17.82s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-157402039.82779795	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [49:07<00:00, 17.82s/pipeline]Optimization Progress: 100%|██████████| 7200/7200 [49:07<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [49:09<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [49:09<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [49:09<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7200/7200 [49:09<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 7200/7200 [49:10<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [49:14<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 7200/7200 [49:16<00:00, 12.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7200/7200 [49:16<00:00, 12.51s/pipeline]Optimization Progress:  99%|█████████▊| 7201/7300 [49:19<20:01, 12.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7201/7300 [49:19<20:01, 12.13s/pipeline]Optimization Progress:  99%|█████████▊| 7203/7300 [49:27<15:38,  9.67s/pipeline]Optimization Progress: 100%|█████████▉| 7283/7300 [49:30<01:55,  6.78s/pipeline]
Generation 72 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-152888239.3030435	GradientBoostingRegressor(RidgeCV(LassoLarsCV(SelectFwe(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), SelectFwe__alpha=0.003), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7300/7300 [49:36<00:00,  6.78s/pipeline]Optimization Progress: 100%|██████████| 7300/7300 [49:36<00:00,  4.85s/pipeline]Optimization Progress:  99%|█████████▊| 7301/7400 [49:43<09:01,  5.47s/pipeline]Optimization Progress:  99%|█████████▊| 7302/7400 [50:27<27:51, 17.05s/pipeline]Optimization Progress: 100%|█████████▉| 7382/7400 [50:42<03:35, 11.99s/pipeline]
Generation 73 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-152888239.3030435	GradientBoostingRegressor(RidgeCV(LassoLarsCV(SelectFwe(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), SelectFwe__alpha=0.003), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)Optimization Progress: 100%|██████████| 7400/7400 [50:56<00:00,  8.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7400/7500 [50:56<14:22,  8.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7401/7500 [50:56<14:13,  8.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7402/7500 [50:56<14:05,  8.62s/pipeline]Optimization Progress:  99%|█████████▊| 7404/7500 [51:57<17:01, 10.64s/pipeline]Optimization Progress: 100%|█████████▉| 7484/7500 [52:00<01:59,  7.46s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-152888239.3030435	GradientBoostingRegressor(RidgeCV(LassoLarsCV(SelectFwe(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), SelectFwe__alpha=0.003), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7500/7500 [52:02<00:00,  7.46s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [52:02<00:00,  5.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7500/7500 [52:04<00:00,  5.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 7500/7500 [52:06<00:00,  5.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 7500/7500 [52:11<00:00,  5.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7500/7500 [52:11<00:00,  5.25s/pipeline]Optimization Progress:  99%|█████████▊| 7503/7600 [52:14<07:56,  4.91s/pipeline]Optimization Progress:  99%|█████████▊| 7504/7600 [52:23<09:41,  6.05s/pipeline]Optimization Progress: 100%|█████████▉| 7584/7600 [52:29<01:08,  4.26s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-152888239.3030435	GradientBoostingRegressor(RidgeCV(LassoLarsCV(SelectFwe(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100), SelectFwe__alpha=0.003), LassoLarsCV__normalize=False)), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7600/7600 [52:30<00:00,  4.26s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [52:30<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [52:34<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7600/7600 [52:34<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 7600/7600 [52:35<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [52:35<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 7600/7600 [52:36<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7600/7600 [52:36<00:00,  3.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [52:37<00:00,  3.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7600/7700 [52:41<05:00,  3.01s/pipeline]Optimization Progress:  99%|█████████▊| 7601/7700 [52:41<08:35,  5.20s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7601/7700 [52:41<08:35,  5.20s/pipeline]Optimization Progress:  99%|█████████▊| 7603/7700 [53:44<21:16, 13.16s/pipeline]Optimization Progress: 100%|█████████▉| 7683/7700 [53:49<02:36,  9.23s/pipeline]
Generation 76 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [53:51<00:00,  9.23s/pipeline]Optimization Progress: 100%|██████████| 7700/7700 [53:51<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7700/7700 [53:53<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7700/7700 [53:53<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00050.
Optimization Progress: 100%|██████████| 7700/7700 [53:54<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [53:59<00:00,  6.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [54:03<00:00,  6.49s/pipeline]Optimization Progress:  99%|█████████▊| 7701/7800 [54:18<20:56, 12.70s/pipeline]Optimization Progress: 100%|█████████▉| 7781/7800 [54:26<02:49,  8.92s/pipeline]
Generation 77 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [54:28<00:00,  8.92s/pipeline]Optimization Progress: 100%|██████████| 7800/7800 [54:28<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7800/7800 [54:30<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7800/7800 [54:30<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [54:30<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [54:33<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00010.
Optimization Progress: 100%|██████████| 7800/7800 [54:37<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7800/7800 [54:38<00:00,  6.27s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [54:40<00:00,  6.27s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7800/7900 [54:40<10:26,  6.27s/pipeline]Optimization Progress:  99%|█████████▊| 7801/7900 [54:40<13:15,  8.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7801/7900 [54:40<13:15,  8.04s/pipeline]Optimization Progress:  99%|█████████▉| 7803/7900 [54:49<11:21,  7.02s/pipeline]Optimization Progress: 100%|█████████▉| 7883/7900 [54:54<01:23,  4.94s/pipeline]
Generation 78 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 7900/7900 [54:55<00:00,  4.94s/pipeline]Optimization Progress: 100%|██████████| 7900/7900 [54:55<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 7900/7900 [54:56<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [54:59<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [55:02<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 7900/7900 [55:02<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [55:02<00:00,  3.47s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7900/7900 [55:02<00:00,  3.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7900/8000 [55:05<05:46,  3.47s/pipeline]Optimization Progress:  99%|█████████▉| 7901/8000 [55:05<09:19,  5.65s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7901/8000 [55:06<09:19,  5.65s/pipeline]Optimization Progress:  99%|█████████▉| 7903/8000 [55:13<08:06,  5.01s/pipeline]Optimization Progress: 100%|█████████▉| 7983/8000 [55:17<00:59,  3.52s/pipeline]
Generation 79 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-162790119.9701851	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=13), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-4	-158619948.54856	GradientBoostingRegressor(ElasticNetCV(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), ElasticNetCV__l1_ratio=0.2, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 8000/8000 [55:18<00:00,  3.52s/pipeline]Optimization Progress: 100%|██████████| 8000/8000 [55:18<00:00,  2.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [55:23<00:00,  2.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8000/8000 [55:28<00:00,  2.48s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [55:28<00:00,  2.48s/pipeline]Optimization Progress: 100%|██████████| 8000/8000 [55:30<00:00,  2.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8000/8100 [55:31<04:08,  2.48s/pipeline]Optimization Progress:  99%|█████████▉| 8001/8100 [55:31<09:16,  5.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8001/8100 [55:31<09:16,  5.62s/pipeline]Optimization Progress:  99%|█████████▉| 8003/8100 [55:50<10:56,  6.77s/pipeline]Optimization Progress: 100%|█████████▉| 8083/8100 [56:04<01:21,  4.79s/pipeline]
Generation 80 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..
Optimization Progress: 100%|██████████| 8100/8100 [56:07<00:00,  4.79s/pipeline]Optimization Progress: 100%|██████████| 8100/8100 [56:07<00:00,  3.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 8100/8100 [56:10<00:00,  3.41s/pipeline]Optimization Progress:  99%|█████████▉| 8101/8200 [56:24<12:23,  7.51s/pipeline]Optimization Progress: 100%|█████████▉| 8181/8200 [56:33<01:40,  5.29s/pipeline]
Generation 81 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8200/8200 [56:34<00:00,  5.29s/pipeline]Optimization Progress: 100%|██████████| 8200/8200 [56:34<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 8200/8200 [56:40<00:00,  3.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 8200/8200 [56:43<00:00,  3.72s/pipeline]Optimization Progress:  99%|█████████▉| 8204/8300 [56:44<05:25,  3.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8204/8300 [56:44<05:25,  3.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8205/8300 [56:44<05:22,  3.40s/pipeline]Optimization Progress:  99%|█████████▉| 8207/8300 [56:51<04:47,  3.09s/pipeline]Optimization Progress: 100%|█████████▉| 8287/8300 [56:57<00:28,  2.18s/pipeline]
Generation 82 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-155823911.76522636	GradientBoostingRegressor(ElasticNetCV(CombineDFs(PCA(CombineDFs(input_matrix, DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20)), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [56:58<00:00,  2.18s/pipeline]Optimization Progress: 100%|██████████| 8300/8300 [56:58<00:00,  1.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [56:58<00:00,  1.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8300/8300 [56:58<00:00,  1.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 8300/8300 [56:58<00:00,  1.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8300/8300 [56:59<00:00,  1.55s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8300/8300 [57:03<00:00,  1.55s/pipeline]Optimization Progress:  99%|█████████▉| 8303/8400 [57:07<03:16,  2.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8303/8400 [57:07<03:16,  2.02s/pipeline]Optimization Progress:  99%|█████████▉| 8305/8400 [57:16<04:17,  2.71s/pipeline]Optimization Progress: 100%|█████████▉| 8385/8400 [57:21<00:28,  1.92s/pipeline]
Generation 83 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-155823911.76522636	GradientBoostingRegressor(ElasticNetCV(CombineDFs(PCA(CombineDFs(input_matrix, DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20)), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [57:23<00:00,  1.92s/pipeline]Optimization Progress: 100%|██████████| 8400/8400 [57:23<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [57:24<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8400/8400 [57:27<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8400/8400 [57:28<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 8400/8400 [57:31<00:00,  1.39s/pipeline]Optimization Progress:  99%|█████████▉| 8403/8500 [57:33<03:06,  1.92s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8403/8500 [57:33<03:06,  1.92s/pipeline]Optimization Progress:  99%|█████████▉| 8405/8500 [57:48<05:41,  3.59s/pipeline]Optimization Progress: 100%|█████████▉| 8485/8500 [57:56<00:38,  2.55s/pipeline]
Generation 84 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-155823911.76522636	GradientBoostingRegressor(ElasticNetCV(CombineDFs(PCA(CombineDFs(input_matrix, DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20)), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 8500/8500 [57:58<00:00,  2.55s/pipeline]Optimization Progress: 100%|██████████| 8500/8500 [57:58<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 8500/8500 [57:59<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8500/8500 [58:00<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [58:01<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8500/8500 [58:01<00:00,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8500/8600 [58:06<03:02,  1.83s/pipeline]Optimization Progress:  99%|█████████▉| 8501/8600 [58:06<05:58,  3.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8501/8600 [58:06<05:58,  3.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8502/8600 [58:06<05:54,  3.62s/pipeline]Optimization Progress:  99%|█████████▉| 8504/8600 [58:13<05:15,  3.29s/pipeline]Optimization Progress: 100%|█████████▉| 8584/8600 [58:20<00:37,  2.32s/pipeline]
Generation 85 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-157726206.39280257	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=4), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.8500000000000001, GradientBoostingRegressor__min_samples_leaf=10, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-4	-155823911.76522636	GradientBoostingRegressor(ElasticNetCV(CombineDFs(PCA(CombineDFs(input_matrix, DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20)), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.1), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8600/8600 [58:25<00:00,  2.32s/pipeline]Optimization Progress: 100%|██████████| 8600/8600 [58:25<00:00,  1.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 8600/8600 [58:26<00:00,  1.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8600/8600 [58:30<00:00,  1.73s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8600/8600 [58:30<00:00,  1.73s/pipeline]Optimization Progress:  99%|█████████▉| 8601/8700 [58:39<08:40,  5.26s/pipeline]Optimization Progress: 100%|█████████▉| 8681/8700 [58:44<01:10,  3.70s/pipeline]
Generation 86 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-152440550.4988042	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 8700/8700 [58:48<00:00,  3.70s/pipeline]Optimization Progress: 100%|██████████| 8700/8700 [58:48<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 8700/8700 [58:49<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [58:52<00:00,  2.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8700/8700 [58:53<00:00,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8700/8800 [58:55<04:26,  2.66s/pipeline]Optimization Progress:  99%|█████████▉| 8701/8800 [58:55<06:15,  3.79s/pipeline]Optimization Progress:  99%|█████████▉| 8702/8800 [59:03<08:11,  5.02s/pipeline]Optimization Progress: 100%|█████████▉| 8782/8800 [59:11<01:03,  3.54s/pipeline]
Generation 87 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-152440550.4988042	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 8800/8800 [59:12<00:00,  3.54s/pipeline]Optimization Progress: 100%|██████████| 8800/8800 [59:12<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [59:14<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8800/8800 [59:14<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8800/8800 [59:15<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 8800/8800 [59:15<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8800/8800 [59:19<00:00,  2.50s/pipeline]Optimization Progress:  99%|█████████▉| 8801/8900 [59:30<11:25,  6.92s/pipeline]Optimization Progress: 100%|█████████▉| 8881/8900 [59:36<01:32,  4.87s/pipeline]
Generation 88 - Current Pareto front scores:
-1	-193724850.33615598	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=6, GradientBoostingRegressor__max_features=0.15000000000000002, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=15, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.25)
-3	-152440550.4988042	GradientBoostingRegressor(CombineDFs(PCA(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=4, DecisionTreeRegressor__min_samples_split=20), PCA__iterated_power=7, PCA__svd_solver=randomized), input_matrix), GradientBoostingRegressor__alpha=0.75, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7500000000000001, GradientBoostingRegressor__min_samples_leaf=14, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.05)
-5	-134709020.98671362	GradientBoostingRegressor(LassoLarsCV(LassoLarsCV(RidgeCV(AdaBoostRegressor(input_matrix, AdaBoostRegressor__learning_rate=0.001, AdaBoostRegressor__loss=exponential, AdaBoostRegressor__n_estimators=100)), LassoLarsCV__normalize=False), LassoLarsCV__normalize=True), GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=1.0, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=8, GradientBoostingRegressor__max_features=0.05, GradientBoostingRegressor__min_samples_leaf=8, GradientBoostingRegressor__min_samples_split=7, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.1)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 8900/8900 [59:37<00:00,  4.87s/pipeline]Optimization Progress: 100%|██████████| 8900/8900 [59:37<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [59:38<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [59:38<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 8900/8900 [59:40<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8900/8900 [59:44<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8900/8900 [59:46<00:00,  3.42s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8900/9000 [59:48<05:41,  3.42s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8901/9000 [59:48<05:38,  3.42s/pipeline]Optimization Progress:  99%|█████████▉| 8902/9000 [59:48<06:31,  3.99s/pipeline]Optimization Progress:  99%|█████████▉| 8903/9000 [1:00:37<28:16, 17.49s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 8982/9000 [1:00:37<05:14, 17.49s/pipeline]                                                                                  60.74 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 8982/9000 [1:00:37<05:14, 17.49s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 8982/9000 [1:00:37<05:14, 17.49s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 8982/9000 [1:00:37<05:14, 17.49s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=AdaBoostRegressor(learning_rate=0.001,
                                              loss='exponential',
                                              n_estimators=100))
1. StackingEstimator(estimator=RidgeCV(alphas=array([ 0.1,  1. , 10. ])))
2. StackingEstimator(estimator=LassoLarsCV(normalize=False))
3. StackingEstimator(estimator=LassoLarsCV())
4. GradientBoostingRegressor(learning_rate=1.0, loss='quantile', max_depth=8,
                          max_features=0.05, min_samples_leaf=8,
                          min_samples_split=7, subsample=0.1)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
