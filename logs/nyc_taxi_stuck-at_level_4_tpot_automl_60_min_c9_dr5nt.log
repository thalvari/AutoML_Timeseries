30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:   5%|▌         | 5/100 [00:06<02:11,  1.39s/pipeline]Optimization Progress:  85%|████████▌ | 85/100 [00:10<00:14,  1.02pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.02pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.42pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:16<00:00,  1.42pipeline/s]Optimization Progress:  50%|█████     | 101/200 [00:16<03:25,  2.07s/pipeline]Optimization Progress:  51%|█████     | 102/200 [00:24<06:11,  3.79s/pipeline]Optimization Progress:  91%|█████████ | 182/200 [00:28<00:48,  2.67s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  2.67s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:29<00:00,  1.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:32<00:00,  1.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.87s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:35<00:00,  1.87s/pipeline]Optimization Progress:  67%|██████▋   | 200/300 [00:39<03:07,  1.87s/pipeline]Optimization Progress:  67%|██████▋   | 201/300 [00:45<10:02,  6.08s/pipeline]Optimization Progress:  94%|█████████▎| 281/300 [00:50<01:21,  4.28s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  4.28s/pipeline]Optimization Progress: 100%|██████████| 300/300 [00:53<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.
Optimization Progress: 100%|██████████| 300/300 [00:59<00:00,  3.04s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 300/300 [01:00<00:00,  3.04s/pipeline]Optimization Progress:  75%|███████▌  | 301/400 [01:02<08:04,  4.89s/pipeline]Optimization Progress:  76%|███████▌  | 302/400 [01:13<11:09,  6.84s/pipeline]Optimization Progress:  96%|█████████▌| 382/400 [02:49<01:32,  5.14s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [02:49<00:00,  5.14s/pipeline]Optimization Progress: 100%|██████████| 400/400 [02:49<00:00,  3.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.
Optimization Progress: 100%|██████████| 400/400 [02:52<00:00,  3.61s/pipeline]Optimization Progress: 100%|██████████| 400/400 [03:00<00:00,  3.61s/pipeline]Optimization Progress:  80%|████████  | 401/500 [03:02<10:39,  6.45s/pipeline]Optimization Progress:  80%|████████  | 402/500 [03:09<10:52,  6.66s/pipeline]Optimization Progress:  96%|█████████▋| 482/500 [03:17<01:24,  4.69s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:19<00:00,  4.69s/pipeline]Optimization Progress: 100%|██████████| 500/500 [03:19<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:26<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:26<00:00,  3.32s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [03:26<00:00,  3.32s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [03:44<16:00,  9.70s/pipeline]Optimization Progress:  97%|█████████▋| 581/600 [04:01<02:10,  6.85s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 600/600 [04:04<00:00,  6.85s/pipeline]Optimization Progress: 100%|██████████| 600/600 [04:04<00:00,  4.84s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 600/600 [04:09<00:00,  4.84s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 600/600 [04:11<00:00,  4.84s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 600/600 [04:12<00:00,  4.84s/pipeline]Optimization Progress:  86%|████████▌ | 601/700 [06:56<1:30:40, 54.96s/pipeline]Optimization Progress:  97%|█████████▋| 681/700 [07:00<12:11, 38.48s/pipeline]  
Generation 6 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [07:01<00:00, 38.48s/pipeline]Optimization Progress: 100%|██████████| 700/700 [07:01<00:00, 26.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [07:03<00:00, 26.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 700/700 [07:04<00:00, 26.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [07:06<00:00, 26.96s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [07:11<00:00, 26.96s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [07:13<36:54, 22.37s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  88%|████████▊ | 701/800 [07:13<36:54, 22.37s/pipeline]Optimization Progress:  88%|████████▊ | 703/800 [07:20<27:11, 16.82s/pipeline]Optimization Progress:  98%|█████████▊| 783/800 [07:25<03:20, 11.80s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:29<00:00, 11.80s/pipeline]Optimization Progress: 100%|██████████| 800/800 [07:29<00:00,  8.33s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:30<00:00,  8.33s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:30<00:00,  8.33s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:30<00:00,  8.33s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=4 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:30<00:00,  8.33s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=5 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [07:30<00:00,  8.33s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [07:37<10:17,  6.43s/pipeline]Optimization Progress:  89%|████████▉ | 805/900 [07:44<10:12,  6.44s/pipeline]Optimization Progress:  98%|█████████▊| 885/900 [07:54<01:08,  4.55s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [07:58<00:00,  4.55s/pipeline]Optimization Progress: 100%|██████████| 900/900 [07:58<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 900/900 [08:00<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [08:01<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [08:01<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 900/900 [08:02<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [08:02<00:00,  3.26s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [08:03<00:00,  3.26s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [08:06<05:44,  3.52s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [08:20<10:52,  6.72s/pipeline]Optimization Progress:  98%|█████████▊| 983/1000 [09:02<01:22,  4.86s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1000/1000 [09:02<00:00,  4.86s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [09:02<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 1000/1000 [09:03<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [09:03<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 1000/1000 [09:04<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [09:04<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1000/1000 [09:05<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X needs to contain only non-negative integers..
Optimization Progress: 100%|██████████| 1000/1000 [09:05<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [09:09<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1000/1000 [09:09<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1000/1000 [09:09<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1000/1000 [09:11<00:00,  3.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1000/1000 [09:11<00:00,  3.42s/pipeline]Optimization Progress:  91%|█████████ | 1001/1100 [09:12<08:26,  5.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  91%|█████████ | 1001/1100 [09:12<08:26,  5.12s/pipeline]Optimization Progress:  91%|█████████ | 1003/1100 [09:20<07:57,  4.93s/pipeline]Optimization Progress:  98%|█████████▊| 1083/1100 [09:26<00:58,  3.47s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 1100/1100 [09:27<00:00,  3.47s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [09:27<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [09:28<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [09:28<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [09:30<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [09:32<00:00,  2.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1100/1100 [09:34<00:00,  2.45s/pipeline]Optimization Progress:  92%|█████████▏| 1102/1200 [09:35<04:38,  2.84s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  92%|█████████▏| 1102/1200 [09:35<04:38,  2.84s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [09:43<05:04,  3.17s/pipeline]Optimization Progress:  99%|█████████▊| 1184/1200 [09:47<00:35,  2.23s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [09:47<00:00,  2.23s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [09:47<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:48<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:48<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:49<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:51<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:52<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 1200/1200 [09:54<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [09:54<00:00,  1.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [09:55<00:00,  1.57s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [09:56<02:51,  1.78s/pipeline]Optimization Progress:  93%|█████████▎| 1204/1300 [10:10<02:51,  1.78s/pipeline]Optimization Progress:  93%|█████████▎| 1205/1300 [10:25<15:30,  9.79s/pipeline]Optimization Progress:  99%|█████████▉| 1285/1300 [10:27<01:42,  6.87s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-6	-506508743.3857609	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [10:28<00:00,  6.87s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [10:28<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [10:29<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 1300/1300 [10:29<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [10:31<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [10:31<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [10:31<00:00,  4.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 1300/1300 [10:34<00:00,  4.81s/pipeline]Optimization Progress:  93%|█████████▎| 1303/1400 [10:40<07:46,  4.81s/pipeline]Optimization Progress:  93%|█████████▎| 1304/1400 [10:42<07:07,  4.46s/pipeline]Optimization Progress:  99%|█████████▉| 1384/1400 [10:44<00:50,  3.13s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-550665485.0944672	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=5, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.9, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-6	-506508743.3857609	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:46<00:00,  3.13s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [10:46<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 1400/1400 [10:47<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 1400/1400 [10:47<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:49<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:50<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 1400/1400 [10:52<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 1400/1400 [10:52<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:53<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:53<00:00,  2.22s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 1400/1400 [10:54<00:00,  2.22s/pipeline]Optimization Progress:  93%|█████████▎| 1400/1500 [11:00<03:41,  2.22s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [12:40<59:11, 35.87s/pipeline]Optimization Progress:  99%|█████████▊| 1481/1500 [12:51<07:57, 25.15s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-510873819.3079246	ExtraTreesRegressor(ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.2), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-506508743.3857609	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:52<00:00, 25.15s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [12:52<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:52<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..
Optimization Progress: 100%|██████████| 1500/1500 [12:52<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:53<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1500/1500 [12:53<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:54<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:54<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:54<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=4 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=5 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=6 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=7 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=8 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=9 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1500/1500 [12:55<00:00, 17.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [12:57<00:00, 17.61s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1501/1600 [13:01<29:03, 17.61s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [13:10<28:45, 17.61s/pipeline]Optimization Progress:  94%|█████████▍| 1503/1600 [13:56<30:20, 18.77s/pipeline]Optimization Progress:  99%|█████████▉| 1583/1600 [14:02<03:43, 13.16s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-510873819.3079246	ExtraTreesRegressor(ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.2), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-510762214.79082096	ExtraTreesRegressor(RBFSampler(GradientBoostingRegressor(RobustScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-506508743.3857609	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1600/1600 [14:05<00:00, 13.16s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [14:05<00:00,  9.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [14:12<00:00,  9.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 1600/1600 [14:12<00:00,  9.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 1600/1600 [14:12<00:00,  9.26s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 1600/1600 [14:14<00:00,  9.26s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [14:15<15:19,  9.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1601/1700 [14:15<15:19,  9.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1602/1700 [14:15<15:10,  9.29s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  94%|█████████▍| 1603/1700 [14:15<15:01,  9.29s/pipeline]Optimization Progress:  94%|█████████▍| 1605/1700 [14:44<13:50,  8.74s/pipeline]Optimization Progress:  99%|█████████▉| 1685/1700 [14:51<01:32,  6.14s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-510873819.3079246	ExtraTreesRegressor(ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.2), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-510762214.79082096	ExtraTreesRegressor(RBFSampler(GradientBoostingRegressor(RobustScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-506508743.3857609	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-503161437.98048514	ExtraTreesRegressor(RBFSampler(StandardScaler(RobustScaler(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100))), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [14:54<00:00,  6.14s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [14:54<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [14:58<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [15:00<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [15:01<00:00,  4.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1700/1700 [15:02<00:00,  4.36s/pipeline]Optimization Progress:  94%|█████████▍| 1701/1800 [15:03<09:42,  5.89s/pipeline]Optimization Progress:  95%|█████████▍| 1702/1800 [15:22<15:54,  9.74s/pipeline]Optimization Progress:  99%|█████████▉| 1782/1800 [15:36<02:03,  6.87s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-510873819.3079246	ExtraTreesRegressor(ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.2), ExtraTreesRegressor__bootstrap=True, ExtraTreesRegressor__max_features=0.9500000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=3, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-510762214.79082096	ExtraTreesRegressor(RBFSampler(GradientBoostingRegressor(RobustScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), GradientBoostingRegressor__alpha=0.85, GradientBoostingRegressor__learning_rate=0.1, GradientBoostingRegressor__loss=huber, GradientBoostingRegressor__max_depth=4, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=3, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.6500000000000001), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 1800/1800 [15:37<00:00,  6.87s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [15:37<00:00,  4.82s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [15:43<00:00,  4.82s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1800/1800 [15:43<00:00,  4.82s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.10000.
Optimization Progress: 100%|██████████| 1800/1800 [15:44<00:00,  4.82s/pipeline]Optimization Progress:  95%|█████████▍| 1803/1900 [15:46<06:59,  4.33s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1803/1900 [15:46<06:59,  4.33s/pipeline]Optimization Progress:  95%|█████████▌| 1805/1900 [18:33<44:23, 28.04s/pipeline]Optimization Progress:  99%|█████████▉| 1885/1900 [19:56<04:59, 19.94s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1900/1900 [19:57<00:00, 19.94s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [19:57<00:00, 13.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [20:02<00:00, 13.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 1900/1900 [20:02<00:00, 13.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1900/1900 [20:03<00:00, 13.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [20:03<00:00, 13.99s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1900/1900 [20:04<00:00, 13.99s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [20:05<19:46, 11.98s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1901/2000 [20:05<19:46, 11.98s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 1902/2000 [20:05<19:34, 11.98s/pipeline]Optimization Progress:  95%|█████████▌| 1904/2000 [20:12<14:36,  9.13s/pipeline]Optimization Progress:  99%|█████████▉| 1984/2000 [20:18<01:42,  6.41s/pipeline]
Generation 19 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [20:18<00:00,  6.41s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [20:18<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 2000/2000 [20:18<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2000/2000 [20:18<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [20:19<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [20:21<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 2000/2000 [20:22<00:00,  4.49s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2000/2000 [20:25<00:00,  4.49s/pipeline]Optimization Progress:  95%|█████████▌| 2004/2100 [20:27<06:09,  3.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2004/2100 [20:27<06:09,  3.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▌| 2005/2100 [20:27<06:05,  3.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2006/2100 [20:27<06:01,  3.85s/pipeline]Optimization Progress:  96%|█████████▌| 2008/2100 [20:37<05:15,  3.43s/pipeline]Optimization Progress:  99%|█████████▉| 2087/2100 [20:50<00:44,  3.43s/pipeline]Optimization Progress:  99%|█████████▉| 2088/2100 [23:36<00:36,  3.07s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 2100/2100 [23:36<00:00,  3.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2100/2100 [23:41<00:00,  3.07s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [23:41<00:00,  2.28s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [23:44<00:00,  2.28s/pipeline]Optimization Progress:  96%|█████████▌| 2104/2200 [23:44<02:55,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2104/2200 [23:44<02:55,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2105/2200 [23:44<02:53,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2106/2200 [23:44<02:51,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2107/2200 [23:44<02:50,  1.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2108/2200 [23:44<02:48,  1.83s/pipeline]Optimization Progress:  96%|█████████▌| 2110/2200 [23:56<02:47,  1.87s/pipeline]Optimization Progress: 100%|█████████▉| 2190/2200 [24:06<00:13,  1.35s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-554196308.4264463	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=5)
-2	-544971346.9877601	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [24:06<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2200/2200 [24:06<00:00,  1.35s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 2200/2200 [24:09<00:00,  1.35s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [24:09<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [24:10<00:00,  1.03s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [24:10<00:00,  1.03s/pipeline]Optimization Progress:  96%|█████████▌| 2201/2300 [24:10<01:42,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [24:10<01:42,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2202/2300 [24:10<01:41,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2203/2300 [24:10<01:40,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2204/2300 [24:10<01:39,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2205/2300 [24:10<01:38,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2206/2300 [24:10<01:37,  1.03s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2207/2300 [24:10<01:36,  1.03s/pipeline]Optimization Progress:  96%|█████████▌| 2209/2300 [24:20<01:37,  1.07s/pipeline]Optimization Progress: 100%|█████████▉| 2289/2300 [24:23<00:08,  1.31pipeline/s]
Generation 22 - Current Pareto front scores:
-1	-551883934.4602319	DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=1, DecisionTreeRegressor__min_samples_split=3)
-2	-544970905.8711219	ElasticNetCV(XGBRegressor(input_matrix, XGBRegressor__learning_rate=0.1, XGBRegressor__max_depth=6, XGBRegressor__min_child_weight=4, XGBRegressor__n_estimators=100, XGBRegressor__nthread=1, XGBRegressor__objective=reg:squarederror, XGBRegressor__subsample=0.9000000000000001), ElasticNetCV__l1_ratio=0.05, ElasticNetCV__tol=0.0001)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [24:23<00:00,  1.31pipeline/s]Optimization Progress: 100%|██████████| 2300/2300 [24:23<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [24:23<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [24:24<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2300/2300 [24:25<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [24:26<00:00,  1.81pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [24:26<00:00,  1.81pipeline/s]Optimization Progress:  96%|█████████▌| 2303/2400 [24:26<01:05,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2303/2400 [24:26<01:05,  1.48pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2304/2400 [24:26<01:04,  1.48pipeline/s]Optimization Progress:  96%|█████████▌| 2306/2400 [24:41<03:06,  1.99s/pipeline]Optimization Progress:  99%|█████████▉| 2386/2400 [24:44<00:19,  1.40s/pipeline]
Generation 23 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [24:44<00:00,  1.40s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [24:44<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [24:44<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 2400/2400 [24:44<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2400/2400 [24:45<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [24:46<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [24:46<00:00,  1.01pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 2400/2400 [24:47<00:00,  1.01pipeline/s]Optimization Progress:  96%|█████████▌| 2402/2500 [24:48<02:01,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2402/2500 [24:48<02:01,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2403/2500 [24:48<02:00,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2404/2500 [24:48<01:59,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2405/2500 [24:48<01:57,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2406/2500 [24:48<01:56,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2407/2500 [24:48<01:55,  1.24s/pipeline]Optimization Progress:  96%|█████████▋| 2409/2500 [24:54<01:41,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 2489/2500 [25:01<00:08,  1.24pipeline/s]
Generation 24 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:02<00:00,  1.24pipeline/s]Optimization Progress: 100%|██████████| 2500/2500 [25:02<00:00,  1.71pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [25:02<00:00,  1.71pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [25:02<00:00,  1.71pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:03<00:00,  1.71pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:03<00:00,  1.71pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2500/2500 [25:03<00:00,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2500/2600 [25:05<00:58,  1.71pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [25:05<00:57,  1.71pipeline/s]Optimization Progress:  96%|█████████▌| 2502/2600 [25:05<01:21,  1.20pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2502/2600 [25:05<01:21,  1.20pipeline/s]Optimization Progress:  96%|█████████▋| 2504/2600 [25:14<03:13,  2.02s/pipeline]Optimization Progress:  99%|█████████▉| 2584/2600 [25:20<00:22,  1.44s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-492738356.67830724	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [25:20<00:00,  1.44s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [25:20<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [25:20<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 2600/2600 [25:20<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:20<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:21<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:21<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [25:21<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 2600/2600 [25:21<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2600/2600 [25:21<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:22<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:22<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [25:22<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:22<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [25:22<00:00,  1.01s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [25:23<00:00,  1.01s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2601/2700 [25:23<01:40,  1.01s/pipeline]Optimization Progress:  96%|█████████▋| 2602/2700 [25:23<01:49,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2602/2700 [25:23<01:49,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2603/2700 [25:23<01:48,  1.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2604/2700 [25:23<01:47,  1.12s/pipeline]Optimization Progress:  97%|█████████▋| 2606/2700 [25:30<01:59,  1.27s/pipeline]Optimization Progress:  99%|█████████▉| 2686/2700 [25:37<00:12,  1.09pipeline/s]
Generation 26 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-492352821.0572178	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [25:38<00:00,  1.09pipeline/s]Optimization Progress: 100%|██████████| 2700/2700 [25:38<00:00,  1.53pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [25:38<00:00,  1.53pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [25:39<00:00,  1.53pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [25:39<00:00,  1.53pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [25:42<00:00,  1.53pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2701/2800 [25:42<01:04,  1.53pipeline/s]Optimization Progress:  96%|█████████▋| 2702/2800 [25:42<01:43,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▋| 2702/2800 [25:42<01:43,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2703/2800 [25:42<01:42,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2704/2800 [25:42<01:41,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2705/2800 [25:42<01:40,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2706/2800 [25:42<01:38,  1.05s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2707/2800 [25:42<01:37,  1.05s/pipeline]Optimization Progress:  97%|█████████▋| 2709/2800 [25:49<01:34,  1.04s/pipeline]Optimization Progress: 100%|█████████▉| 2789/2800 [25:51<00:08,  1.36pipeline/s]
Generation 27 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-492352821.0572178	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [25:51<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 2800/2800 [25:51<00:00,  1.36pipeline/s]Optimization Progress: 100%|██████████| 2800/2800 [25:51<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 2800/2800 [25:52<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 2800/2800 [25:52<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [25:53<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [25:53<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2800/2800 [25:54<00:00,  1.90pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [25:54<00:00,  1.90pipeline/s]Optimization Progress:  97%|█████████▋| 2804/2900 [25:55<01:06,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2804/2900 [25:55<01:06,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2805/2900 [25:55<01:05,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2806/2900 [25:55<01:04,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2807/2900 [25:55<01:04,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2808/2900 [25:56<01:03,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2809/2900 [25:56<01:02,  1.45pipeline/s]Optimization Progress:  97%|█████████▋| 2811/2900 [26:01<01:04,  1.37pipeline/s]Optimization Progress: 100%|█████████▉| 2891/2900 [26:10<00:04,  1.84pipeline/s]
Generation 28 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-492352821.0572178	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-490468225.8103337	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [26:11<00:00,  1.84pipeline/s]Optimization Progress: 100%|██████████| 2900/2900 [26:11<00:00,  2.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2900/2900 [26:11<00:00,  2.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [26:11<00:00,  2.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 2900/2900 [26:13<00:00,  2.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [26:14<00:00,  2.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [26:14<00:00,  2.45pipeline/s]Optimization Progress:  97%|█████████▋| 2902/3000 [26:16<01:39,  1.01s/pipeline]Optimization Progress:  97%|█████████▋| 2903/3000 [26:25<05:36,  3.47s/pipeline]Optimization Progress:  99%|█████████▉| 2983/3000 [26:32<00:41,  2.46s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-492352821.0572178	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-490468225.8103337	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [26:33<00:00,  2.46s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [26:33<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 3000/3000 [26:33<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [26:33<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3000/3000 [26:34<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [26:35<00:00,  1.74s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.
Optimization Progress: 100%|██████████| 3000/3000 [26:35<00:00,  1.74s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3000/3100 [26:38<02:53,  1.74s/pipeline]Optimization Progress:  97%|█████████▋| 3001/3100 [26:38<04:23,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3001/3100 [26:38<04:23,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3002/3100 [26:38<04:21,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3003/3100 [26:38<04:18,  2.67s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3004/3100 [26:38<04:15,  2.67s/pipeline]Optimization Progress:  97%|█████████▋| 3006/3100 [26:55<04:31,  2.88s/pipeline]Optimization Progress: 100%|█████████▉| 3086/3100 [27:00<00:28,  2.04s/pipeline]
Generation 30 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-492352821.0572178	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-490468225.8103337	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.
Optimization Progress: 100%|██████████| 3100/3100 [27:04<00:00,  2.04s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [27:04<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [27:04<00:00,  1.50s/pipeline]Optimization Progress:  97%|█████████▋| 3101/3200 [27:05<02:29,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [27:05<02:29,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3102/3200 [27:05<02:28,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3103/3200 [27:05<02:26,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3104/3200 [27:05<02:24,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3105/3200 [27:05<02:23,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3106/3200 [27:05<02:21,  1.51s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3107/3200 [27:05<02:20,  1.51s/pipeline]Optimization Progress:  97%|█████████▋| 3109/3200 [27:14<02:06,  1.39s/pipeline]Optimization Progress: 100%|█████████▉| 3189/3200 [27:20<00:10,  1.00pipeline/s]
Generation 31 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 3200/3200 [27:20<00:00,  1.00pipeline/s]Optimization Progress: 100%|██████████| 3200/3200 [27:20<00:00,  1.41pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 3200/3200 [27:23<00:00,  1.41pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3200/3200 [27:26<00:00,  1.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3200/3300 [27:26<01:10,  1.41pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3201/3300 [27:26<01:10,  1.41pipeline/s]Optimization Progress:  97%|█████████▋| 3202/3300 [27:26<02:11,  1.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3202/3300 [27:26<02:11,  1.34s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3203/3300 [27:26<02:10,  1.34s/pipeline]Optimization Progress:  97%|█████████▋| 3205/3300 [27:45<04:33,  2.88s/pipeline]Optimization Progress: 100%|█████████▉| 3285/3300 [27:54<00:30,  2.05s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [27:54<00:00,  2.05s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [27:54<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3300/3300 [27:55<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3300/3300 [27:56<00:00,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3302/3400 [27:59<02:20,  1.44s/pipeline]Optimization Progress:  97%|█████████▋| 3303/3400 [27:59<02:23,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3303/3400 [27:59<02:23,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3304/3400 [27:59<02:21,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3305/3400 [27:59<02:20,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3306/3400 [27:59<02:18,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3307/3400 [27:59<02:17,  1.47s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3308/3400 [27:59<02:15,  1.47s/pipeline]Optimization Progress:  97%|█████████▋| 3309/3400 [28:10<02:14,  1.47s/pipeline]Optimization Progress:  97%|█████████▋| 3310/3400 [30:30<11:14,  7.50s/pipeline]Optimization Progress: 100%|█████████▉| 3390/3400 [30:34<00:52,  5.26s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [30:34<00:00,  5.26s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [30:34<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3400/3400 [30:36<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [30:37<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3400/3400 [30:39<00:00,  3.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [30:39<00:00,  3.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3401/3500 [30:39<06:05,  3.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3402/3500 [30:39<06:01,  3.69s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [30:39<04:55,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3403/3500 [30:39<04:55,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3404/3500 [30:39<04:52,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3405/3500 [30:39<04:49,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3406/3500 [30:39<04:45,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3407/3500 [30:39<04:42,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3408/3500 [30:39<04:39,  3.04s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3409/3500 [30:39<04:36,  3.04s/pipeline]Optimization Progress:  97%|█████████▋| 3410/3500 [30:50<04:33,  3.04s/pipeline]Optimization Progress:  97%|█████████▋| 3411/3500 [30:55<04:05,  2.76s/pipeline]Optimization Progress: 100%|█████████▉| 3491/3500 [31:03<00:17,  1.96s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [31:03<00:00,  1.96s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 3500/3500 [31:05<00:00,  1.96s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [31:05<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [31:07<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [31:07<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [31:08<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [31:08<00:00,  1.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3500/3500 [31:08<00:00,  1.44s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3500/3600 [31:08<02:23,  1.44s/pipeline]Optimization Progress:  97%|█████████▋| 3501/3600 [31:08<03:00,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3501/3600 [31:08<03:00,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3502/3600 [31:08<02:58,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3503/3600 [31:08<02:56,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3504/3600 [31:08<02:54,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3505/3600 [31:08<02:52,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3506/3600 [31:08<02:51,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3507/3600 [31:08<02:49,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3508/3600 [31:08<02:47,  1.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3509/3600 [31:08<02:45,  1.82s/pipeline]Optimization Progress:  98%|█████████▊| 3511/3600 [31:17<02:17,  1.55s/pipeline]Optimization Progress: 100%|█████████▉| 3591/3600 [31:19<00:09,  1.09s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 3600/3600 [31:23<00:00,  1.09s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [31:23<00:00,  1.11pipeline/s]Optimization Progress:  97%|█████████▋| 3603/3700 [31:25<01:13,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3603/3700 [31:25<01:13,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3604/3700 [31:25<01:12,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3605/3700 [31:25<01:12,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3606/3700 [31:25<01:11,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3607/3700 [31:25<01:10,  1.32pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3608/3700 [31:25<01:09,  1.32pipeline/s]Optimization Progress:  98%|█████████▊| 3610/3700 [31:38<01:41,  1.12s/pipeline]Optimization Progress: 100%|█████████▉| 3690/3700 [31:45<00:08,  1.24pipeline/s]
Generation 36 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486763733.1977078	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 3700/3700 [31:45<00:00,  1.24pipeline/s]Optimization Progress: 100%|██████████| 3700/3700 [31:45<00:00,  1.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [31:46<00:00,  1.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [31:47<00:00,  1.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [31:47<00:00,  1.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [31:50<00:00,  1.69pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [31:51<00:00,  1.69pipeline/s]Optimization Progress:  97%|█████████▋| 3702/3800 [31:51<02:01,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3702/3800 [31:51<02:01,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3703/3800 [31:51<01:59,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3704/3800 [31:51<01:58,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3705/3800 [31:51<01:57,  1.24s/pipeline]Optimization Progress:  98%|█████████▊| 3707/3800 [32:01<02:15,  1.46s/pipeline]Optimization Progress: 100%|█████████▉| 3787/3800 [32:06<00:13,  1.04s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-486446261.20468676	ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=13, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [32:07<00:00,  1.04s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [32:07<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 3800/3800 [32:07<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3800/3800 [32:09<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [32:11<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3800/3800 [32:11<00:00,  1.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3801/3900 [32:12<01:12,  1.36pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3802/3900 [32:12<01:11,  1.36pipeline/s]Optimization Progress:  98%|█████████▊| 3803/3900 [32:12<01:42,  1.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3803/3900 [32:12<01:42,  1.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3804/3900 [32:12<01:41,  1.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3805/3900 [32:12<01:40,  1.06s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3806/3900 [32:12<01:39,  1.06s/pipeline]Optimization Progress:  98%|█████████▊| 3808/3900 [32:22<02:05,  1.37s/pipeline]Optimization Progress: 100%|█████████▉| 3888/3900 [32:38<00:12,  1.02s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [32:39<00:00,  1.02s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [32:39<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [32:40<00:00,  1.36pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [32:41<00:00,  1.36pipeline/s]Optimization Progress:  98%|█████████▊| 3904/4000 [32:41<01:04,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3904/4000 [32:41<01:04,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3905/4000 [32:41<01:03,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3906/4000 [32:41<01:02,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3907/4000 [32:41<01:02,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3908/4000 [32:41<01:01,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3909/4000 [32:41<01:00,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3910/4000 [32:41<01:00,  1.49pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 3911/4000 [32:41<00:59,  1.49pipeline/s]Optimization Progress:  98%|█████████▊| 3913/4000 [32:51<01:08,  1.27pipeline/s]Optimization Progress: 100%|█████████▉| 3993/4000 [32:58<00:04,  1.74pipeline/s]
Generation 39 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [32:58<00:00,  1.74pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [32:59<00:00,  1.74pipeline/s]Optimization Progress: 100%|██████████| 4000/4000 [32:59<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [32:59<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [33:00<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [33:02<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [33:02<00:00,  2.29pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 4000/4000 [33:02<00:00,  2.29pipeline/s]Optimization Progress:  98%|█████████▊| 4003/4100 [33:03<01:11,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4003/4100 [33:03<01:11,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4004/4100 [33:03<01:11,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4005/4100 [33:03<01:10,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4006/4100 [33:03<01:09,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4007/4100 [33:03<01:09,  1.35pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4008/4100 [33:03<01:08,  1.35pipeline/s]Optimization Progress:  98%|█████████▊| 4010/4100 [33:13<01:27,  1.03pipeline/s]Optimization Progress: 100%|█████████▉| 4090/4100 [33:16<00:06,  1.45pipeline/s]
Generation 40 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4100/4100 [33:17<00:00,  1.45pipeline/s]Optimization Progress: 100%|██████████| 4100/4100 [33:17<00:00,  2.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4100/4100 [33:17<00:00,  2.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [33:18<00:00,  2.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [33:18<00:00,  2.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4100/4100 [33:20<00:00,  2.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [33:21<00:00,  2.02pipeline/s]Optimization Progress:  98%|█████████▊| 4105/4200 [33:21<00:58,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4105/4200 [33:21<00:58,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4106/4200 [33:21<00:57,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4107/4200 [33:21<00:57,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4108/4200 [33:21<00:56,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4109/4200 [33:21<00:55,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4110/4200 [33:21<00:55,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4111/4200 [33:21<00:54,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4112/4200 [33:21<00:54,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4113/4200 [33:21<00:53,  1.63pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4114/4200 [33:21<00:52,  1.63pipeline/s]Optimization Progress:  98%|█████████▊| 4116/4200 [33:31<00:57,  1.46pipeline/s]Optimization Progress: 100%|█████████▉| 4196/4200 [33:36<00:02,  2.00pipeline/s]
Generation 41 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 4200/4200 [33:38<00:00,  2.00pipeline/s]Optimization Progress: 100%|██████████| 4200/4200 [33:38<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4200/4200 [33:39<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4200/4200 [33:39<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 4200/4200 [33:40<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [33:40<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4200/4200 [33:40<00:00,  2.08pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4200/4200 [33:40<00:00,  2.08pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4200/4300 [33:42<00:48,  2.08pipeline/s]Optimization Progress:  98%|█████████▊| 4201/4300 [33:42<02:34,  1.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4201/4300 [33:42<02:34,  1.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4202/4300 [33:42<02:32,  1.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4203/4300 [33:42<02:31,  1.56s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4204/4300 [33:42<02:29,  1.56s/pipeline]Optimization Progress:  98%|█████████▊| 4206/4300 [33:56<03:02,  1.94s/pipeline]Optimization Progress: 100%|█████████▉| 4286/4300 [34:06<00:19,  1.39s/pipeline]
Generation 42 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.39s/pipeline]Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:06<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [34:08<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:09<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4300/4300 [34:09<00:00,  1.02pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4300/4300 [34:09<00:00,  1.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4301/4400 [34:09<01:36,  1.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4302/4400 [34:09<01:35,  1.02pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4303/4400 [34:09<01:34,  1.02pipeline/s]Optimization Progress:  98%|█████████▊| 4304/4400 [34:09<01:30,  1.06pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4304/4400 [34:09<01:30,  1.06pipeline/s]Optimization Progress:  98%|█████████▊| 4307/4400 [34:19<02:31,  1.63s/pipeline]Optimization Progress: 100%|█████████▉| 4386/4400 [34:20<00:16,  1.15s/pipeline]
Generation 43 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [34:21<00:00,  1.15s/pipeline]Optimization Progress: 100%|██████████| 4400/4400 [34:21<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.
Optimization Progress: 100%|██████████| 4400/4400 [34:21<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 4400/4400 [34:22<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4400/4400 [34:22<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [34:24<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 4400/4400 [34:24<00:00,  1.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4400/4400 [34:26<00:00,  1.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4400/4500 [34:26<01:21,  1.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4401/4500 [34:26<01:20,  1.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4402/4500 [34:26<01:20,  1.22pipeline/s]Optimization Progress:  98%|█████████▊| 4404/4500 [34:34<02:27,  1.54s/pipeline]Optimization Progress: 100%|█████████▉| 4484/4500 [34:35<00:17,  1.08s/pipeline]
Generation 44 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [34:37<00:00,  1.08s/pipeline]Optimization Progress: 100%|██████████| 4500/4500 [34:37<00:00,  1.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4500/4500 [34:37<00:00,  1.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4500/4500 [34:39<00:00,  1.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4500/4500 [34:39<00:00,  1.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 4500/4500 [34:40<00:00,  1.28pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4500/4500 [34:40<00:00,  1.28pipeline/s]Optimization Progress:  98%|█████████▊| 4503/4600 [34:40<01:22,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4503/4600 [34:40<01:22,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4504/4600 [34:40<01:21,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4505/4600 [34:40<01:21,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4506/4600 [34:40<01:20,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4507/4600 [34:40<01:19,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4508/4600 [34:40<01:18,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4509/4600 [34:40<01:17,  1.17pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4510/4600 [34:40<01:16,  1.17pipeline/s]Optimization Progress:  98%|█████████▊| 4512/4600 [34:47<01:13,  1.19pipeline/s]Optimization Progress: 100%|█████████▉| 4592/4600 [34:50<00:04,  1.68pipeline/s]
Generation 45 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4600/4600 [34:50<00:00,  1.68pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4600/4600 [34:50<00:00,  1.68pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4600/4600 [34:54<00:00,  1.68pipeline/s]Optimization Progress: 100%|██████████| 4600/4600 [34:54<00:00,  1.66pipeline/s]Optimization Progress:  98%|█████████▊| 4602/4700 [34:55<00:53,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4602/4700 [34:55<00:53,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4603/4700 [34:55<00:53,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4604/4700 [34:55<00:52,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4605/4700 [34:55<00:52,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4606/4700 [34:55<00:51,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4607/4700 [34:55<00:51,  1.82pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4608/4700 [34:55<00:50,  1.82pipeline/s]Optimization Progress:  98%|█████████▊| 4610/4700 [35:05<01:07,  1.34pipeline/s]Optimization Progress: 100%|█████████▉| 4690/4700 [35:11<00:05,  1.84pipeline/s]
Generation 46 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-3	-514329168.85161006	DecisionTreeRegressor(Nystroem(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=1.0, RandomForestRegressor__min_samples_leaf=11, RandomForestRegressor__min_samples_split=6, RandomForestRegressor__n_estimators=100), Nystroem__gamma=0.45, Nystroem__kernel=additive_chi2, Nystroem__n_components=9), DecisionTreeRegressor__max_depth=4, DecisionTreeRegressor__min_samples_leaf=2, DecisionTreeRegressor__min_samples_split=12)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:17:47] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 4700/4700 [35:13<00:00,  1.84pipeline/s]Optimization Progress: 100%|██████████| 4700/4700 [35:13<00:00,  2.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 4700/4700 [35:13<00:00,  2.22pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 4700/4700 [35:14<00:00,  2.22pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4700/4800 [35:16<00:44,  2.22pipeline/s]Optimization Progress:  98%|█████████▊| 4701/4800 [35:16<02:02,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4701/4800 [35:16<02:02,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4702/4800 [35:16<02:01,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4703/4800 [35:16<02:00,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4704/4800 [35:16<01:59,  1.24s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4705/4800 [35:16<01:57,  1.24s/pipeline]Optimization Progress:  98%|█████████▊| 4707/4800 [35:26<02:07,  1.37s/pipeline]Optimization Progress: 100%|█████████▉| 4787/4800 [35:32<00:12,  1.02pipeline/s]
Generation 47 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [35:32<00:00,  1.02pipeline/s]Optimization Progress: 100%|██████████| 4800/4800 [35:32<00:00,  1.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 4800/4800 [35:32<00:00,  1.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4800/4800 [35:33<00:00,  1.45pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4800/4800 [35:36<00:00,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4800/4900 [35:36<01:09,  1.45pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4801/4900 [35:36<01:08,  1.45pipeline/s]Optimization Progress:  98%|█████████▊| 4802/4900 [35:36<01:52,  1.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4802/4900 [35:36<01:52,  1.15s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4803/4900 [35:36<01:51,  1.15s/pipeline]Optimization Progress:  98%|█████████▊| 4804/4900 [35:50<01:50,  1.15s/pipeline]Optimization Progress:  98%|█████████▊| 4805/4900 [35:54<04:06,  2.59s/pipeline]Optimization Progress: 100%|█████████▉| 4885/4900 [35:58<00:27,  1.83s/pipeline]
Generation 48 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [35:58<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 4900/4900 [35:58<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [36:00<00:00,  1.83s/pipeline]Optimization Progress: 100%|██████████| 4900/4900 [36:00<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [36:00<00:00,  1.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4900/4900 [36:03<00:00,  1.31s/pipeline]Optimization Progress:  98%|█████████▊| 4901/5000 [36:04<03:31,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 4901/5000 [36:04<03:31,  2.13s/pipeline]Optimization Progress:  98%|█████████▊| 4903/5000 [36:30<08:40,  5.37s/pipeline]Optimization Progress: 100%|█████████▉| 4983/5000 [37:44<01:08,  4.04s/pipeline]
Generation 49 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5000/5000 [37:44<00:00,  4.04s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5000/5000 [37:48<00:00,  4.04s/pipeline]Optimization Progress: 100%|██████████| 5000/5000 [37:48<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [37:49<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5000/5000 [37:50<00:00,  2.88s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5000/5000 [37:50<00:00,  2.88s/pipeline]Optimization Progress:  98%|█████████▊| 5001/5100 [37:51<04:58,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5001/5100 [37:51<04:58,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5002/5100 [37:51<04:55,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5003/5100 [37:51<04:52,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5004/5100 [37:51<04:49,  3.02s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5005/5100 [37:51<04:46,  3.02s/pipeline]Optimization Progress:  98%|█████████▊| 5007/5100 [38:17<05:16,  3.41s/pipeline]Optimization Progress: 100%|█████████▉| 5087/5100 [38:26<00:31,  2.42s/pipeline]
Generation 50 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 5100/5100 [38:27<00:00,  2.42s/pipeline]Optimization Progress: 100%|██████████| 5100/5100 [38:27<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.
Optimization Progress: 100%|██████████| 5100/5100 [38:28<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..
Optimization Progress: 100%|██████████| 5100/5100 [38:29<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [38:30<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5100/5100 [38:30<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [38:30<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [38:30<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5100/5100 [38:31<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5100/5100 [38:31<00:00,  1.72s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5100/5100 [38:32<00:00,  1.72s/pipeline]Optimization Progress:  98%|█████████▊| 5101/5200 [38:32<04:23,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5101/5200 [38:32<04:23,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5102/5200 [38:32<04:20,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5103/5200 [38:32<04:18,  2.66s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5104/5200 [38:32<04:15,  2.66s/pipeline]Optimization Progress:  98%|█████████▊| 5106/5200 [38:46<04:14,  2.71s/pipeline]Optimization Progress: 100%|█████████▉| 5186/5200 [38:56<00:27,  1.93s/pipeline]
Generation 51 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5200/5200 [38:56<00:00,  1.93s/pipeline]Optimization Progress: 100%|██████████| 5200/5200 [38:56<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 5200/5200 [38:57<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [38:57<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5200/5200 [38:59<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [39:00<00:00,  1.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 5200/5200 [39:00<00:00,  1.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5201/5300 [39:01<02:14,  1.36s/pipeline]Optimization Progress:  98%|█████████▊| 5202/5300 [39:01<02:45,  1.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5202/5300 [39:01<02:45,  1.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5203/5300 [39:01<02:43,  1.69s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5204/5300 [39:01<02:42,  1.69s/pipeline]Optimization Progress:  98%|█████████▊| 5206/5300 [39:13<03:14,  2.07s/pipeline]Optimization Progress: 100%|█████████▉| 5286/5300 [39:15<00:20,  1.46s/pipeline]
Generation 52 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 5300/5300 [39:15<00:00,  1.46s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5300/5300 [39:17<00:00,  1.46s/pipeline]Optimization Progress: 100%|██████████| 5300/5300 [39:17<00:00,  1.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5300/5300 [39:20<00:00,  1.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [39:21<00:00,  1.07s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5300/5300 [39:22<00:00,  1.07s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5300/5400 [39:22<01:46,  1.07s/pipeline]Optimization Progress:  98%|█████████▊| 5301/5400 [39:22<03:30,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5301/5400 [39:22<03:30,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5302/5400 [39:22<03:28,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5303/5400 [39:22<03:26,  2.13s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5304/5400 [39:22<03:24,  2.13s/pipeline]Optimization Progress:  98%|█████████▊| 5306/5400 [39:32<03:15,  2.08s/pipeline]Optimization Progress: 100%|█████████▉| 5386/5400 [39:36<00:20,  1.48s/pipeline]
Generation 53 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 5400/5400 [39:37<00:00,  1.48s/pipeline]Optimization Progress: 100%|██████████| 5400/5400 [39:37<00:00,  1.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [39:40<00:00,  1.05s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5400/5400 [39:40<00:00,  1.05s/pipeline]Optimization Progress:  98%|█████████▊| 5402/5500 [39:42<02:22,  1.46s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5402/5500 [39:42<02:22,  1.46s/pipeline]Optimization Progress:  98%|█████████▊| 5404/5500 [39:53<04:16,  2.67s/pipeline]Optimization Progress: 100%|█████████▉| 5484/5500 [39:57<00:30,  1.89s/pipeline]
Generation 54 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5500/5500 [39:58<00:00,  1.89s/pipeline]Optimization Progress: 100%|██████████| 5500/5500 [39:58<00:00,  1.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.
Optimization Progress: 100%|██████████| 5500/5500 [40:02<00:00,  1.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5500/5500 [40:03<00:00,  1.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5500/5500 [40:03<00:00,  1.34s/pipeline]Optimization Progress:  98%|█████████▊| 5501/5600 [40:04<04:10,  2.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5501/5600 [40:04<04:10,  2.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5502/5600 [40:04<04:08,  2.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5503/5600 [40:04<04:05,  2.53s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5504/5600 [40:04<04:03,  2.53s/pipeline]Optimization Progress:  98%|█████████▊| 5506/5600 [40:13<03:40,  2.35s/pipeline]Optimization Progress: 100%|█████████▉| 5586/5600 [40:18<00:23,  1.66s/pipeline]
Generation 55 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [40:18<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [40:18<00:00,  1.66s/pipeline]Optimization Progress: 100%|██████████| 5600/5600 [40:18<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [40:18<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [40:18<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5600/5600 [40:19<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 5600/5600 [40:21<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 5600/5600 [40:21<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5600/5600 [40:21<00:00,  1.17s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.
Optimization Progress: 100%|██████████| 5600/5600 [40:22<00:00,  1.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5601/5700 [40:23<01:55,  1.17s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5602/5700 [40:23<01:54,  1.17s/pipeline]Optimization Progress:  98%|█████████▊| 5603/5700 [40:23<02:04,  1.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5603/5700 [40:23<02:04,  1.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5604/5700 [40:23<02:03,  1.28s/pipeline]Optimization Progress:  98%|█████████▊| 5605/5700 [40:40<02:01,  1.28s/pipeline]Optimization Progress:  98%|█████████▊| 5606/5700 [40:47<05:08,  3.28s/pipeline]Optimization Progress: 100%|█████████▉| 5686/5700 [40:56<00:32,  2.33s/pipeline]
Generation 56 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 5700/5700 [40:57<00:00,  2.33s/pipeline]Optimization Progress: 100%|██████████| 5700/5700 [40:57<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.
Optimization Progress: 100%|██████████| 5700/5700 [40:57<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [40:58<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5700/5700 [40:59<00:00,  1.66s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5700/5700 [40:59<00:00,  1.66s/pipeline]Optimization Progress:  98%|█████████▊| 5702/5800 [41:01<02:47,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5702/5800 [41:01<02:47,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5703/5800 [41:01<02:45,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5704/5800 [41:01<02:44,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5705/5800 [41:01<02:42,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5706/5800 [41:01<02:40,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5707/5800 [41:01<02:38,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5708/5800 [41:01<02:37,  1.71s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5709/5800 [41:01<02:35,  1.71s/pipeline]Optimization Progress:  98%|█████████▊| 5711/5800 [41:10<02:13,  1.49s/pipeline]Optimization Progress: 100%|█████████▉| 5791/5800 [41:12<00:09,  1.06s/pipeline]
Generation 57 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 5800/5800 [41:13<00:00,  1.06s/pipeline]Optimization Progress: 100%|██████████| 5800/5800 [41:13<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 5800/5800 [41:13<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 5800/5800 [41:14<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [41:14<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [41:15<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5800/5800 [41:15<00:00,  1.34pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5800/5800 [41:16<00:00,  1.34pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5800/5900 [41:17<01:14,  1.34pipeline/s]Optimization Progress:  98%|█████████▊| 5804/5900 [41:24<02:10,  1.36s/pipeline]Optimization Progress: 100%|█████████▉| 5882/5900 [41:28<00:17,  1.03pipeline/s]
Generation 58 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [41:30<00:00,  1.03pipeline/s]Optimization Progress: 100%|██████████| 5900/5900 [41:30<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [41:30<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5900/5900 [41:30<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5900/5900 [41:30<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5900/5900 [41:31<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 5900/5900 [41:31<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 5900/5900 [41:32<00:00,  1.42pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 5900/5900 [41:32<00:00,  1.42pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5900/6000 [41:33<01:10,  1.42pipeline/s]Optimization Progress:  98%|█████████▊| 5901/6000 [41:33<02:42,  1.64s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5901/6000 [41:33<02:42,  1.64s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5902/6000 [41:33<02:40,  1.64s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5903/6000 [41:33<02:39,  1.64s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 5904/6000 [41:33<02:37,  1.64s/pipeline]Optimization Progress:  98%|█████████▊| 5906/6000 [41:40<02:25,  1.55s/pipeline]Optimization Progress: 100%|█████████▉| 5986/6000 [41:54<00:15,  1.13s/pipeline]
Generation 59 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 6000/6000 [41:55<00:00,  1.13s/pipeline]Optimization Progress: 100%|██████████| 6000/6000 [41:55<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6000/6000 [41:55<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 6000/6000 [41:55<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [41:55<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [41:56<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [41:56<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [41:56<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 6000/6000 [41:56<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.
Optimization Progress: 100%|██████████| 6000/6000 [41:57<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6000/6000 [41:57<00:00,  1.24pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6000/6000 [41:58<00:00,  1.24pipeline/s]Optimization Progress:  98%|█████████▊| 6001/6100 [41:59<02:54,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6001/6100 [41:59<02:54,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6002/6100 [41:59<02:52,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6003/6100 [41:59<02:51,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6004/6100 [41:59<02:49,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6005/6100 [41:59<02:47,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6006/6100 [41:59<02:45,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6007/6100 [41:59<02:44,  1.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6008/6100 [41:59<02:42,  1.76s/pipeline]Optimization Progress:  99%|█████████▊| 6010/6100 [42:05<02:09,  1.44s/pipeline]Optimization Progress: 100%|█████████▉| 6090/6100 [42:10<00:10,  1.03s/pipeline]
Generation 60 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6100/6100 [42:13<00:00,  1.03s/pipeline]Optimization Progress: 100%|██████████| 6100/6100 [42:13<00:00,  1.21pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.
Optimization Progress: 100%|██████████| 6100/6100 [42:14<00:00,  1.21pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6100/6100 [42:14<00:00,  1.21pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6100/6100 [42:16<00:00,  1.21pipeline/s]Optimization Progress:  98%|█████████▊| 6101/6200 [42:17<02:37,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6101/6200 [42:17<02:37,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6102/6200 [42:17<02:36,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6103/6200 [42:17<02:34,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6104/6200 [42:17<02:33,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6105/6200 [42:17<02:31,  1.60s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6106/6200 [42:17<02:29,  1.60s/pipeline]Optimization Progress:  99%|█████████▊| 6108/6200 [46:18<17:34, 11.46s/pipeline]Optimization Progress: 100%|█████████▉| 6188/6200 [46:22<01:36,  8.04s/pipeline]
Generation 61 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 6200/6200 [46:22<00:00,  8.04s/pipeline]Optimization Progress: 100%|██████████| 6200/6200 [46:22<00:00,  5.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 6200/6200 [46:23<00:00,  5.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6200/6200 [46:23<00:00,  5.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6200/6200 [46:23<00:00,  5.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6200/6200 [46:24<00:00,  5.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6201/6300 [46:28<09:17,  5.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6202/6300 [46:28<09:11,  5.63s/pipeline]Optimization Progress:  98%|█████████▊| 6203/6300 [46:28<07:15,  4.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6203/6300 [46:28<07:15,  4.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6204/6300 [46:28<07:10,  4.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6205/6300 [46:28<07:06,  4.48s/pipeline]Optimization Progress:  99%|█████████▊| 6206/6300 [46:40<07:01,  4.48s/pipeline]Optimization Progress:  99%|█████████▊| 6207/6300 [46:41<06:21,  4.11s/pipeline]Optimization Progress: 100%|█████████▉| 6287/6300 [46:46<00:37,  2.90s/pipeline]
Generation 62 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6300/6300 [46:49<00:00,  2.90s/pipeline]Optimization Progress: 100%|██████████| 6300/6300 [46:49<00:00,  2.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6300/6300 [46:50<00:00,  2.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6300/6300 [46:51<00:00,  2.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 6300/6300 [46:51<00:00,  2.09s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6300/6300 [46:53<00:00,  2.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6300/6400 [46:55<03:29,  2.09s/pipeline]Optimization Progress:  98%|█████████▊| 6301/6400 [46:55<05:05,  3.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6301/6400 [46:55<05:05,  3.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6302/6400 [46:55<05:02,  3.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6303/6400 [46:55<04:59,  3.09s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6304/6400 [46:55<04:56,  3.09s/pipeline]Optimization Progress:  99%|█████████▊| 6306/6400 [47:05<04:23,  2.81s/pipeline]Optimization Progress: 100%|█████████▉| 6386/6400 [47:11<00:27,  1.99s/pipeline]
Generation 63 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [47:11<00:00,  1.99s/pipeline]Optimization Progress: 100%|██████████| 6400/6400 [47:11<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6400/6400 [47:12<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [47:12<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6400/6400 [47:12<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [47:12<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6400/6400 [47:13<00:00,  1.39s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6400/6400 [47:14<00:00,  1.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6400/6500 [47:17<02:19,  1.39s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  98%|█████████▊| 6401/6500 [47:17<02:17,  1.39s/pipeline]Optimization Progress:  98%|█████████▊| 6402/6500 [47:30<02:16,  1.39s/pipeline]Optimization Progress:  99%|█████████▊| 6403/6500 [47:32<04:57,  3.07s/pipeline]Optimization Progress: 100%|█████████▉| 6483/6500 [47:42<00:37,  2.18s/pipeline]
Generation 64 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [47:42<00:00,  2.18s/pipeline]Optimization Progress: 100%|██████████| 6500/6500 [47:42<00:00,  1.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 6500/6500 [47:42<00:00,  1.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6500/6500 [47:44<00:00,  1.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.
Optimization Progress: 100%|██████████| 6500/6500 [47:45<00:00,  1.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6500/6500 [47:45<00:00,  1.53s/pipeline]Optimization Progress:  99%|█████████▊| 6503/6600 [47:47<02:37,  1.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6503/6600 [47:47<02:37,  1.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6504/6600 [47:47<02:35,  1.62s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6505/6600 [47:47<02:34,  1.62s/pipeline]Optimization Progress:  99%|█████████▊| 6507/6600 [47:58<02:57,  1.91s/pipeline]Optimization Progress: 100%|█████████▉| 6587/6600 [48:04<00:17,  1.36s/pipeline]
Generation 65 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6600/6600 [48:04<00:00,  1.36s/pipeline]Optimization Progress: 100%|██████████| 6600/6600 [48:04<00:00,  1.04pipeline/s]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6600/6600 [48:06<00:00,  1.04pipeline/s]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6601/6700 [48:10<01:35,  1.04pipeline/s]Optimization Progress:  99%|█████████▊| 6602/6700 [48:10<02:33,  1.57s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6602/6700 [48:10<02:33,  1.57s/pipeline]Optimization Progress:  99%|█████████▊| 6604/6700 [48:20<04:08,  2.59s/pipeline]Optimization Progress: 100%|█████████▉| 6684/6700 [48:26<00:29,  1.83s/pipeline]
Generation 66 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6700/6700 [48:26<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 6700/6700 [48:28<00:00,  1.83s/pipeline]Optimization Progress: 100%|██████████| 6700/6700 [48:28<00:00,  1.32s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 6700/6700 [48:32<00:00,  1.32s/pipeline]Optimization Progress:  99%|█████████▊| 6702/6800 [48:33<02:45,  1.69s/pipeline]Optimization Progress:  99%|█████████▊| 6703/6800 [48:51<10:57,  6.78s/pipeline]Optimization Progress: 100%|█████████▉| 6783/6800 [49:06<01:21,  4.80s/pipeline]
Generation 67 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 6800/6800 [49:07<00:00,  4.80s/pipeline]Optimization Progress: 100%|██████████| 6800/6800 [49:07<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [49:07<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.
Optimization Progress: 100%|██████████| 6800/6800 [49:09<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [49:11<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 6800/6800 [49:11<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 6800/6800 [49:12<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 6800/6800 [49:13<00:00,  3.37s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 6801/6900 [49:14<05:33,  3.37s/pipeline]Optimization Progress:  99%|█████████▊| 6802/6900 [49:14<05:46,  3.54s/pipeline]Optimization Progress:  99%|█████████▊| 6803/6900 [49:32<12:37,  7.81s/pipeline]Optimization Progress: 100%|█████████▉| 6883/6900 [49:38<01:33,  5.49s/pipeline]
Generation 68 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 6900/6900 [49:38<00:00,  5.49s/pipeline]Optimization Progress: 100%|██████████| 6900/6900 [49:38<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 6900/6900 [49:38<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 6900/6900 [49:39<00:00,  3.84s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 6900/6900 [49:45<00:00,  3.84s/pipeline]Optimization Progress:  99%|█████████▊| 6902/7000 [49:50<06:16,  3.84s/pipeline]Optimization Progress:  99%|█████████▊| 6903/7000 [50:02<08:12,  5.08s/pipeline]Optimization Progress: 100%|█████████▉| 6983/7000 [50:06<01:00,  3.57s/pipeline]
Generation 69 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-487856410.652902	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.35000000000000003, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 7000/7000 [50:06<00:00,  3.57s/pipeline]Optimization Progress: 100%|██████████| 7000/7000 [50:06<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7000/7000 [50:07<00:00,  2.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.
Optimization Progress: 100%|██████████| 7000/7000 [50:14<00:00,  2.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7003/7100 [50:15<04:02,  2.50s/pipeline]Optimization Progress:  99%|█████████▊| 7004/7100 [50:15<03:52,  2.43s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7004/7100 [50:15<03:52,  2.43s/pipeline]Optimization Progress:  99%|█████████▊| 7007/7100 [50:26<04:16,  2.76s/pipeline]Optimization Progress: 100%|█████████▉| 7086/7100 [50:40<00:27,  1.99s/pipeline]
Generation 70 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 7100/7100 [50:41<00:00,  1.99s/pipeline]Optimization Progress: 100%|██████████| 7100/7100 [50:41<00:00,  1.40s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7100/7100 [50:43<00:00,  1.40s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7101/7200 [50:50<02:18,  1.40s/pipeline]Optimization Progress:  99%|█████████▊| 7102/7200 [50:50<04:01,  2.46s/pipeline]Optimization Progress:  99%|█████████▊| 7103/7200 [52:15<43:54, 27.16s/pipeline]Optimization Progress: 100%|█████████▉| 7183/7200 [52:24<05:23, 19.05s/pipeline]
Generation 71 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7200/7200 [52:25<00:00, 19.05s/pipeline]Optimization Progress: 100%|██████████| 7200/7200 [52:25<00:00, 13.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7200/7200 [52:26<00:00, 13.34s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 7200/7200 [52:27<00:00, 13.34s/pipeline]Optimization Progress:  99%|█████████▊| 7202/7300 [52:33<17:19, 10.60s/pipeline]Optimization Progress:  99%|█████████▊| 7203/7300 [52:47<18:39, 11.55s/pipeline]Optimization Progress: 100%|█████████▉| 7283/7300 [53:09<02:18,  8.17s/pipeline]
Generation 72 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7300/7300 [53:15<00:00,  8.17s/pipeline]Optimization Progress: 100%|██████████| 7300/7300 [53:15<00:00,  5.81s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7300/7300 [53:15<00:00,  5.81s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7300/7400 [53:20<09:41,  5.81s/pipeline]Optimization Progress:  99%|█████████▊| 7301/7400 [53:20<09:06,  5.52s/pipeline]Optimization Progress:  99%|█████████▊| 7302/7400 [53:29<10:58,  6.72s/pipeline]Optimization Progress: 100%|█████████▉| 7382/7400 [53:35<01:25,  4.72s/pipeline]
Generation 73 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 7400/7400 [53:38<00:00,  4.72s/pipeline]Optimization Progress: 100%|██████████| 7400/7400 [53:38<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7400/7400 [53:38<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7400/7400 [53:39<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7400/7400 [53:41<00:00,  3.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 7400/7400 [53:43<00:00,  3.37s/pipeline]Optimization Progress:  99%|█████████▊| 7401/7500 [53:56<12:29,  7.57s/pipeline]Optimization Progress: 100%|█████████▉| 7481/7500 [54:16<01:42,  5.37s/pipeline]
Generation 74 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-498274785.5942728	ExtraTreesRegressor(FastICA(RandomForestRegressor(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.01), RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:36:50] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7500/7500 [54:16<00:00,  5.37s/pipeline]Optimization Progress: 100%|██████████| 7500/7500 [54:16<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [54:16<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.
Optimization Progress: 100%|██████████| 7500/7500 [54:19<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [54:21<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [54:21<00:00,  3.76s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7500/7500 [54:23<00:00,  3.76s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7500/7600 [54:23<06:16,  3.76s/pipeline]Optimization Progress:  99%|█████████▊| 7501/7600 [54:30<06:12,  3.76s/pipeline]Optimization Progress:  99%|█████████▊| 7502/7600 [55:52<27:45, 17.00s/pipeline]Optimization Progress: 100%|█████████▉| 7582/7600 [56:01<03:34, 11.93s/pipeline]
Generation 75 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 7600/7600 [56:02<00:00, 11.93s/pipeline]Optimization Progress: 100%|██████████| 7600/7600 [56:02<00:00,  8.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:38:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7600/7600 [56:05<00:00,  8.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 7600/7600 [56:06<00:00,  8.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7602/7700 [56:08<13:38,  8.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7603/7700 [56:08<13:30,  8.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7604/7700 [56:08<13:22,  8.36s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7605/7700 [56:08<13:13,  8.36s/pipeline]Optimization Progress:  99%|█████████▉| 7606/7700 [56:08<09:38,  6.15s/pipeline]Optimization Progress:  99%|█████████▉| 7610/7700 [56:18<07:35,  5.06s/pipeline]Optimization Progress: 100%|█████████▉| 7687/7700 [56:23<00:46,  3.56s/pipeline]Optimization Progress: 100%|█████████▉| 7688/7700 [56:23<00:30,  2.53s/pipeline]
Generation 76 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [56:23<00:00,  2.53s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [56:25<00:00,  2.53s/pipeline]Optimization Progress: 100%|██████████| 7700/7700 [56:25<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7700/7700 [56:25<00:00,  1.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7700/7700 [56:26<00:00,  1.83s/pipeline]Optimization Progress:  99%|█████████▊| 7701/7800 [56:29<03:46,  2.28s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7701/7800 [56:29<03:46,  2.28s/pipeline]Optimization Progress:  99%|█████████▉| 7703/7800 [56:46<06:53,  4.26s/pipeline]Optimization Progress: 100%|█████████▉| 7783/7800 [56:53<00:51,  3.01s/pipeline]
Generation 77 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.
Optimization Progress: 100%|██████████| 7800/7800 [56:54<00:00,  3.01s/pipeline]Optimization Progress: 100%|██████████| 7800/7800 [56:54<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:39:28] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7800/7800 [56:54<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 7800/7800 [56:55<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 7800/7800 [56:55<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 7800/7800 [56:57<00:00,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7800/7900 [56:59<03:31,  2.12s/pipeline]Optimization Progress:  99%|█████████▊| 7801/7900 [56:59<04:39,  2.82s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▊| 7801/7900 [56:59<04:39,  2.82s/pipeline]Optimization Progress:  99%|█████████▉| 7803/7900 [57:13<06:44,  4.17s/pipeline]Optimization Progress: 100%|█████████▉| 7883/7900 [57:41<00:51,  3.02s/pipeline]
Generation 78 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [57:41<00:00,  3.02s/pipeline]Optimization Progress: 100%|██████████| 7900/7900 [57:41<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [57:41<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7900/7900 [57:42<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 7900/7900 [57:42<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:16] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7900/7900 [57:42<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 7900/7900 [57:43<00:00,  2.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:18] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 7900/7900 [57:44<00:00,  2.12s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 7901/8000 [57:45<03:29,  2.12s/pipeline]Optimization Progress:  99%|█████████▉| 7902/8000 [57:45<03:21,  2.06s/pipeline]Optimization Progress:  99%|█████████▉| 7904/8000 [58:00<05:53,  3.69s/pipeline]Optimization Progress: 100%|█████████▉| 7983/8000 [58:17<00:44,  2.64s/pipeline]
Generation 79 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.
Optimization Progress: 100%|██████████| 8000/8000 [58:17<00:00,  2.64s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:51] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8000/8000 [58:17<00:00,  2.64s/pipeline]Optimization Progress: 100%|██████████| 8000/8000 [58:17<00:00,  1.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8000/8000 [58:18<00:00,  1.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 8000/8000 [58:19<00:00,  1.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8000/8000 [58:19<00:00,  1.86s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:40:55] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8000/8000 [58:21<00:00,  1.86s/pipeline]Optimization Progress:  99%|█████████▉| 8002/8100 [58:28<04:40,  2.86s/pipeline]Optimization Progress: 100%|█████████▉| 8082/8100 [58:33<00:36,  2.02s/pipeline]
Generation 80 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [58:34<00:00,  2.02s/pipeline]Optimization Progress: 100%|██████████| 8100/8100 [58:34<00:00,  1.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8100/8100 [58:35<00:00,  1.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [58:35<00:00,  1.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 8100/8100 [58:36<00:00,  1.42s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8100/8100 [58:37<00:00,  1.42s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8100/8200 [58:38<02:22,  1.42s/pipeline]Optimization Progress:  99%|█████████▉| 8101/8200 [58:50<02:21,  1.42s/pipeline]Optimization Progress:  99%|█████████▉| 8102/8200 [58:56<07:11,  4.40s/pipeline]Optimization Progress: 100%|█████████▉| 8182/8200 [59:02<00:55,  3.10s/pipeline]
Generation 81 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 8200/8200 [59:02<00:00,  3.10s/pipeline]Optimization Progress: 100%|██████████| 8200/8200 [59:02<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.
Optimization Progress: 100%|██████████| 8200/8200 [59:03<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:41:37] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8200/8200 [59:03<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [59:03<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 8200/8200 [59:05<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8200/8200 [59:05<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:41:40] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8200/8200 [59:06<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..
Optimization Progress: 100%|██████████| 8200/8200 [59:06<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 8200/8200 [59:07<00:00,  2.18s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:41:41] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8200/8200 [59:07<00:00,  2.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8201/8300 [59:07<03:35,  2.18s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8202/8300 [59:07<03:33,  2.18s/pipeline]Optimization Progress:  99%|█████████▉| 8203/8300 [59:07<03:15,  2.02s/pipeline]Optimization Progress:  99%|█████████▉| 8205/8300 [59:18<04:45,  3.01s/pipeline]Optimization Progress: 100%|█████████▉| 8284/8300 [59:22<00:33,  2.12s/pipeline]
Generation 82 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _mate_operator: num_test=0 X contains negative values..
Optimization Progress: 100%|██████████| 8300/8300 [59:23<00:00,  2.12s/pipeline]Optimization Progress: 100%|██████████| 8300/8300 [59:23<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.
Optimization Progress: 100%|██████████| 8300/8300 [59:24<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 [09:41:58] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8300/8300 [59:24<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 8300/8300 [59:24<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 8300/8300 [59:25<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8300/8300 [59:26<00:00,  1.50s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 8300/8300 [59:27<00:00,  1.50s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8300/8400 [59:27<02:30,  1.50s/pipeline]Optimization Progress:  99%|█████████▉| 8301/8400 [59:27<03:42,  2.25s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8301/8400 [59:27<03:42,  2.25s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8302/8400 [59:27<03:40,  2.25s/pipeline]Optimization Progress:  99%|█████████▉| 8304/8400 [59:42<04:50,  3.02s/pipeline]Optimization Progress: 100%|█████████▉| 8384/8400 [59:47<00:34,  2.14s/pipeline]
Generation 83 - Current Pareto front scores:
-1	-521141236.157053	SGDRegressor(input_matrix, SGDRegressor__alpha=0.0, SGDRegressor__eta0=0.01, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.0, SGDRegressor__learning_rate=constant, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.1)
-2	-509836086.0441612	DecisionTreeRegressor(RBFSampler(input_matrix, RBFSampler__gamma=1.0), DecisionTreeRegressor__max_depth=5, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=7)
-3	-505810276.99278337	ExtraTreesRegressor(FastICA(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.25, RandomForestRegressor__min_samples_leaf=14, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), FastICA__tol=0.65), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=5, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-4	-487203901.8337795	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MinMaxScaler(input_matrix), DecisionTreeRegressor__max_depth=10, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-5	-485405915.56041384	ExtraTreesRegressor(CombineDFs(input_matrix, RBFSampler(DecisionTreeRegressor(MaxAbsScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.05, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=3), RBFSampler__gamma=0.8)), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=7, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-6	-478513821.5097206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-7	-476709208.45508206	ExtraTreesRegressor(RBFSampler(DecisionTreeRegressor(MaxAbsScaler(MinMaxScaler(OneHotEncoder(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.1, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), OneHotEncoder__minimum_fraction=0.05, OneHotEncoder__sparse=False, OneHotEncoder__threshold=10))), DecisionTreeRegressor__max_depth=7, DecisionTreeRegressor__min_samples_leaf=3, DecisionTreeRegressor__min_samples_split=17), RBFSampler__gamma=0.25), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=2, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)
-8	-469664124.6109368	ExtraTreesRegressor(ExtraTreesRegressor(RBFSampler(StandardScaler(SelectFwe(RandomForestRegressor(RandomForestRegressor(RandomForestRegressor(input_matrix, RandomForestRegressor__bootstrap=True, RandomForestRegressor__max_features=0.7500000000000001, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.4, RandomForestRegressor__min_samples_leaf=17, RandomForestRegressor__min_samples_split=15, RandomForestRegressor__n_estimators=100), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.8500000000000001, RandomForestRegressor__min_samples_leaf=8, RandomForestRegressor__min_samples_split=8, RandomForestRegressor__n_estimators=100), SelectFwe__alpha=0.03)), RBFSampler__gamma=0.7000000000000001), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.6000000000000001, ExtraTreesRegressor__min_samples_leaf=13, ExtraTreesRegressor__min_samples_split=9, ExtraTreesRegressor__n_estimators=100), ExtraTreesRegressor__bootstrap=False, ExtraTreesRegressor__max_features=0.05, ExtraTreesRegressor__min_samples_leaf=17, ExtraTreesRegressor__min_samples_split=13, ExtraTreesRegressor__n_estimators=100)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 8400/8400 [59:48<00:00,  2.14s/pipeline]Optimization Progress: 100%|██████████| 8400/8400 [59:48<00:00,  1.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.
Optimization Progress: 100%|██████████| 8400/8400 [59:51<00:00,  1.51s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 [09:42:26] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7f73426f8dc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7f7342809669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7f7342816f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7f73427fdcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7f73426eaf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7f69504e59dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7f69504e5067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f69504fd27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7f69504fdcb4]

.
Optimization Progress: 100%|██████████| 8400/8400 [59:52<00:00,  1.51s/pipeline]Optimization Progress:  99%|█████████▉| 8401/8500 [59:52<03:49,  2.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8401/8500 [59:52<03:49,  2.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8402/8500 [59:52<03:47,  2.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8403/8500 [59:52<03:44,  2.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8404/8500 [59:52<03:42,  2.32s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  99%|█████████▉| 8405/8500 [59:52<03:40,  2.32s/pipeline]Optimization Progress:  99%|█████████▉| 8407/8500 [1:00:14<04:14,  2.74s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 8486/8500 [1:00:14<00:38,  2.74s/pipeline]                                                                                  60.36 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 8486/8500 [1:00:14<00:38,  2.74s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 8486/8500 [1:00:14<00:38,  2.74s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 8486/8500 [1:00:14<00:38,  2.74s/pipeline]                                                                                  Best pipeline:
0. StackingEstimator(estimator=RandomForestRegressor(max_features=0.7500000000000001,
                                                  min_samples_leaf=17,
                                                  min_samples_split=4))
1. StackingEstimator(estimator=RandomForestRegressor(bootstrap=False,
                                                  max_features=0.4,
                                                  min_samples_leaf=17,
                                                  min_samples_split=15))
2. StackingEstimator(estimator=RandomForestRegressor(bootstrap=False,
                                                  max_features=0.8500000000000001,
                                                  min_samples_leaf=8,
                                                  min_samples_split=8))
3. SelectFwe(alpha=0.03, score_func=<function f_regression at 0x7f5f28fd1170>)
4. StandardScaler()
5. RBFSampler(gamma=0.7000000000000001)
6. StackingEstimator(estimator=ExtraTreesRegressor(max_features=0.6000000000000001,
                                                min_samples_leaf=13,
                                                min_samples_split=9))
7. ExtraTreesRegressor(max_features=0.05, min_samples_leaf=17,
                    min_samples_split=13)
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
