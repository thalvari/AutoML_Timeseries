30 operators have been imported by TPOT.
Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]Optimization Progress:  14%|█▍        | 14/100 [00:08<00:50,  1.69pipeline/s]Optimization Progress:  94%|█████████▍| 94/100 [00:09<00:02,  2.40pipeline/s]                                                                             _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:09<00:00,  2.40pipeline/s]Optimization Progress: 100%|██████████| 100/100 [00:09<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:12<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 100/100 [00:13<00:00,  3.20pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 100/100 [00:14<00:00,  3.20pipeline/s]Optimization Progress:  52%|█████▏    | 103/200 [00:14<01:11,  1.36pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 103/200 [00:14<01:11,  1.36pipeline/s]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  52%|█████▏    | 104/200 [00:14<01:10,  1.36pipeline/s]Optimization Progress:  53%|█████▎    | 106/200 [00:29<03:00,  1.92s/pipeline]Optimization Progress:  93%|█████████▎| 186/200 [00:31<00:18,  1.35s/pipeline]
Generation 1 - Current Pareto front scores:
-1	-1063723141.7976282	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=12, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.35s/pipeline]Optimization Progress: 100%|██████████| 200/200 [00:31<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:32<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 [22:07:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 200/200 [00:34<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.05pipeline/s]                                                                              _pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 200/200 [00:38<00:00,  1.05pipeline/s]Optimization Progress:  68%|██████▊   | 204/300 [00:38<01:53,  1.18s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 204/300 [00:38<01:53,  1.18s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  68%|██████▊   | 205/300 [00:38<01:52,  1.18s/pipeline]Optimization Progress:  69%|██████▊   | 206/300 [00:49<01:51,  1.18s/pipeline]Optimization Progress:  69%|██████▉   | 207/300 [01:02<05:01,  3.24s/pipeline]Optimization Progress:  96%|█████████▌| 287/300 [01:07<00:29,  2.29s/pipeline]
Generation 2 - Current Pareto front scores:
-1	-1063519867.9114631	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:08<00:00,  2.29s/pipeline]Optimization Progress: 100%|██████████| 300/300 [01:08<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 300/300 [01:09<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:10<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 300/300 [01:11<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:11<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 300/300 [01:11<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 300/300 [01:11<00:00,  1.61s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 300/300 [01:12<00:00,  1.61s/pipeline]Optimization Progress:  76%|███████▌  | 304/400 [01:14<02:34,  1.61s/pipeline]Optimization Progress:  76%|███████▌  | 304/400 [01:30<02:34,  1.61s/pipeline]Optimization Progress:  76%|███████▋  | 305/400 [01:33<10:40,  6.75s/pipeline]Optimization Progress:  96%|█████████▋| 385/400 [01:38<01:11,  4.74s/pipeline]
Generation 3 - Current Pareto front scores:
-1	-1063519867.9114631	GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-1063083665.0668194	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=18), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-1040959336.3985523	RandomForestRegressor(Normalizer(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), Normalizer__norm=l1), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.55, RandomForestRegressor__min_samples_leaf=5, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 400/400 [01:42<00:00,  4.74s/pipeline]Optimization Progress: 100%|██████████| 400/400 [01:42<00:00,  3.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 400/400 [01:43<00:00,  3.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [22:09:00] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 400/400 [01:44<00:00,  3.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:45<00:00,  3.40s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 400/400 [01:45<00:00,  3.40s/pipeline]Optimization Progress:  80%|████████  | 402/500 [01:45<04:36,  2.82s/pipeline]Optimization Progress:  81%|████████  | 403/500 [02:10<15:13,  9.42s/pipeline]Optimization Progress:  97%|█████████▋| 483/500 [02:33<01:53,  6.68s/pipeline]
Generation 4 - Current Pareto front scores:
-1	-1063480236.7429711	GradientBoostingRegressor(CombineDFs(input_matrix, input_matrix), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=4, GradientBoostingRegressor__min_samples_split=3, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9000000000000001)
-2	-1063083665.0668194	GradientBoostingRegressor(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=9, DecisionTreeRegressor__min_samples_leaf=9, DecisionTreeRegressor__min_samples_split=18), GradientBoostingRegressor__alpha=0.8, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=lad, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.2, GradientBoostingRegressor__min_samples_leaf=1, GradientBoostingRegressor__min_samples_split=6, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.3)
-3	-1040959336.3985523	RandomForestRegressor(Normalizer(LassoLarsCV(input_matrix, LassoLarsCV__normalize=False), Normalizer__norm=l1), RandomForestRegressor__bootstrap=False, RandomForestRegressor__max_features=0.55, RandomForestRegressor__min_samples_leaf=5, RandomForestRegressor__min_samples_split=4, RandomForestRegressor__n_estimators=100)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [22:09:49] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 500/500 [02:33<00:00,  6.68s/pipeline]Optimization Progress: 100%|██████████| 500/500 [02:33<00:00,  4.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 500/500 [02:34<00:00,  4.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 500/500 [02:34<00:00,  4.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.00500.
Optimization Progress: 100%|██████████| 500/500 [02:36<00:00,  4.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 500/500 [02:39<00:00,  4.68s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 500/500 [02:39<00:00,  4.68s/pipeline]Optimization Progress:  83%|████████▎ | 500/600 [02:50<07:48,  4.68s/pipeline]Optimization Progress:  84%|████████▎ | 501/600 [03:39<38:11, 23.15s/pipeline]Optimization Progress:  97%|█████████▋| 581/600 [03:46<05:08, 16.23s/pipeline]
Generation 5 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [22:11:01] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 600/600 [03:46<00:00, 16.23s/pipeline]Optimization Progress: 100%|██████████| 600/600 [03:46<00:00, 11.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 600/600 [03:47<00:00, 11.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 600/600 [03:48<00:00, 11.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [22:11:06] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 600/600 [03:50<00:00, 11.36s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.
Optimization Progress: 100%|██████████| 600/600 [03:52<00:00, 11.36s/pipeline]Optimization Progress:  86%|████████▌ | 603/700 [04:00<18:21, 11.36s/pipeline]Optimization Progress:  86%|████████▋ | 604/700 [04:12<15:51,  9.92s/pipeline]Optimization Progress:  98%|█████████▊| 684/700 [04:50<01:53,  7.08s/pipeline]
Generation 6 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [04:51<00:00,  7.08s/pipeline]Optimization Progress: 100%|██████████| 700/700 [04:51<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [04:53<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:54<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 700/700 [04:54<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 700/700 [04:55<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 [22:12:13] ../src/learner.cc:543: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?
Stack trace:
  [bt] (0) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0xa5dc4) [0x7fe1c698adc4]
  [bt] (1) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1b6669) [0x7fe1c6a9b669]
  [bt] (2) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1c3f8e) [0x7fe1c6aa8f8e]
  [bt] (3) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x1aacbb) [0x7fe1c6a8fcbb]
  [bt] (4) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x55) [0x7fe1c697cf35]
  [bt] (5) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x69dd) [0x7fd7d47779dd]
  [bt] (6) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/../../libffi.so.7(+0x6067) [0x7fd7d4777067]
  [bt] (7) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fd7d478f27e]
  [bt] (8) /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12cb4) [0x7fd7d478fcb4]

.
Optimization Progress: 100%|██████████| 700/700 [04:57<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.
Optimization Progress: 100%|██████████| 700/700 [04:58<00:00,  4.97s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 700/700 [04:58<00:00,  4.97s/pipeline]                                                                              Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  88%|████████▊ | 700/800 [05:03<08:17,  4.97s/pipeline]Optimization Progress:  88%|████████▊ | 701/800 [05:03<11:55,  7.22s/pipeline]Optimization Progress:  88%|████████▊ | 702/800 [05:22<17:31, 10.73s/pipeline]Optimization Progress:  98%|█████████▊| 782/800 [05:28<02:15,  7.53s/pipeline]
Generation 7 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [05:28<00:00,  7.53s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 800/800 [05:30<00:00,  7.53s/pipeline]Optimization Progress: 100%|██████████| 800/800 [05:30<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [05:31<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 800/800 [05:34<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.
Optimization Progress: 100%|██████████| 800/800 [05:34<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.
Optimization Progress: 100%|██████████| 800/800 [05:37<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 800/800 [05:40<00:00,  5.31s/pipeline]                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.
Optimization Progress: 100%|██████████| 800/800 [05:42<00:00,  5.31s/pipeline]Optimization Progress:  89%|████████▉ | 802/900 [05:42<09:07,  5.59s/pipeline]                                                                              Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  89%|████████▉ | 802/900 [05:42<09:07,  5.59s/pipeline]Optimization Progress:  89%|████████▉ | 804/900 [05:52<08:33,  5.35s/pipeline]Optimization Progress:  98%|█████████▊| 884/900 [06:14<01:01,  3.83s/pipeline]
Generation 8 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                              _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 900/900 [06:17<00:00,  3.83s/pipeline]Optimization Progress: 100%|██████████| 900/900 [06:17<00:00,  2.73s/pipeline]Optimization Progress:  90%|█████████ | 902/1000 [06:31<06:34,  4.02s/pipeline]Optimization Progress:  90%|█████████ | 903/1000 [06:41<09:23,  5.81s/pipeline]Optimization Progress:  98%|█████████▊| 983/1000 [06:49<01:09,  4.10s/pipeline]
Generation 9 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                               _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 1000/1000 [06:49<00:00,  4.10s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [06:49<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1000/1000 [06:59<00:00,  2.87s/pipeline]Optimization Progress: 100%|██████████| 1000/1000 [07:00<00:00,  2.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.
Optimization Progress: 100%|██████████| 1000/1000 [07:05<00:00,  2.87s/pipeline]Optimization Progress:  91%|█████████ | 1002/1100 [07:06<07:23,  4.53s/pipeline]Optimization Progress:  91%|█████████ | 1003/1100 [07:16<10:11,  6.30s/pipeline]Optimization Progress:  98%|█████████▊| 1083/1100 [07:24<01:15,  4.44s/pipeline]
Generation 10 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:24<00:00,  4.44s/pipeline]Optimization Progress: 100%|██████████| 1100/1100 [07:24<00:00,  3.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:26<00:00,  3.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1100/1100 [07:29<00:00,  3.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1100/1100 [07:35<00:00,  3.12s/pipeline]Optimization Progress:  92%|█████████▏| 1103/1200 [07:40<06:06,  3.78s/pipeline]Optimization Progress:  92%|█████████▏| 1104/1200 [07:51<09:29,  5.93s/pipeline]Optimization Progress:  99%|█████████▊| 1184/1200 [08:07<01:07,  4.21s/pipeline]
Generation 11 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1200/1200 [08:10<00:00,  4.21s/pipeline]Optimization Progress: 100%|██████████| 1200/1200 [08:10<00:00,  3.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1200/1200 [08:13<00:00,  3.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  3.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  3.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  3.00s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=3 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 1200/1200 [08:17<00:00,  3.00s/pipeline]Optimization Progress:  93%|█████████▎| 1203/1300 [08:24<05:44,  3.55s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  93%|█████████▎| 1203/1300 [08:24<05:44,  3.55s/pipeline]Optimization Progress:  93%|█████████▎| 1205/1300 [08:49<09:51,  6.22s/pipeline]Optimization Progress:  99%|█████████▉| 1285/1300 [09:16<01:06,  4.46s/pipeline]
Generation 12 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:17<00:00,  4.46s/pipeline]Optimization Progress: 100%|██████████| 1300/1300 [09:17<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1300/1300 [09:21<00:00,  3.14s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1300/1300 [09:27<00:00,  3.14s/pipeline]Optimization Progress:  93%|█████████▎| 1301/1400 [10:38<44:09, 26.76s/pipeline]Optimization Progress:  99%|█████████▊| 1381/1400 [10:48<05:56, 18.77s/pipeline]
Generation 13 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 1400/1400 [10:54<00:00, 18.77s/pipeline]Optimization Progress: 100%|██████████| 1400/1400 [10:54<00:00, 13.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1400/1400 [10:56<00:00, 13.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1400/1400 [11:03<00:00, 13.24s/pipeline]Optimization Progress:  93%|█████████▎| 1401/1500 [11:04<20:04, 12.17s/pipeline]Optimization Progress:  93%|█████████▎| 1402/1500 [11:17<20:19, 12.44s/pipeline]Optimization Progress:  99%|█████████▉| 1482/1500 [11:25<02:37,  8.74s/pipeline]
Generation 14 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1500/1500 [11:26<00:00,  8.74s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [11:26<00:00,  6.13s/pipeline]Optimization Progress: 100%|██████████| 1500/1500 [11:40<00:00,  6.13s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  94%|█████████▍| 1500/1600 [11:42<10:12,  6.13s/pipeline]Optimization Progress:  94%|█████████▍| 1501/1600 [11:42<15:10,  9.20s/pipeline]Optimization Progress:  94%|█████████▍| 1502/1600 [11:57<17:49, 10.92s/pipeline]Optimization Progress:  99%|█████████▉| 1582/1600 [12:05<02:18,  7.67s/pipeline]
Generation 15 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [12:05<00:00,  7.67s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [12:05<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1600/1600 [12:06<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [12:10<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [12:17<00:00,  5.38s/pipeline]Optimization Progress: 100%|██████████| 1600/1600 [12:20<00:00,  5.38s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1600/1600 [12:31<00:00,  5.38s/pipeline]Optimization Progress:  94%|█████████▍| 1601/1700 [12:32<19:17, 11.69s/pipeline]Optimization Progress:  94%|█████████▍| 1602/1700 [13:38<45:44, 28.00s/pipeline]Optimization Progress:  99%|█████████▉| 1682/1700 [13:45<05:53, 19.63s/pipeline]
Generation 16 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.
Optimization Progress: 100%|██████████| 1700/1700 [13:50<00:00, 19.63s/pipeline]Optimization Progress: 100%|██████████| 1700/1700 [13:50<00:00, 13.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 1700/1700 [13:52<00:00, 13.83s/pipeline]Optimization Progress:  95%|█████████▍| 1703/1800 [14:04<17:56, 11.10s/pipeline]Optimization Progress:  95%|█████████▍| 1704/1800 [14:15<17:25, 10.89s/pipeline]Optimization Progress:  99%|█████████▉| 1784/1800 [14:22<02:02,  7.65s/pipeline]
Generation 17 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.
Optimization Progress: 100%|██████████| 1800/1800 [14:23<00:00,  7.65s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [14:23<00:00,  5.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.
Optimization Progress: 100%|██████████| 1800/1800 [14:23<00:00,  5.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:23<00:00,  5.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:26<00:00,  5.36s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 1800/1800 [14:34<00:00,  5.36s/pipeline]Optimization Progress: 100%|██████████| 1800/1800 [14:40<00:00,  5.36s/pipeline]Optimization Progress:  95%|█████████▍| 1802/1900 [14:48<12:13,  7.48s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  95%|█████████▍| 1802/1900 [14:48<12:13,  7.48s/pipeline]Optimization Progress:  95%|█████████▍| 1804/1900 [15:25<17:21, 10.85s/pipeline]Optimization Progress:  99%|█████████▉| 1884/1900 [15:34<02:01,  7.62s/pipeline]
Generation 18 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 1900/1900 [15:42<00:00,  7.62s/pipeline]Optimization Progress: 100%|██████████| 1900/1900 [15:42<00:00,  5.49s/pipeline]Optimization Progress:  95%|█████████▌| 1901/2000 [15:54<12:18,  7.46s/pipeline]Optimization Progress:  95%|█████████▌| 1902/2000 [17:50<1:05:17, 39.98s/pipeline]Optimization Progress:  99%|█████████▉| 1982/2000 [17:57<08:24, 28.01s/pipeline]  
Generation 19 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.
Optimization Progress: 100%|██████████| 2000/2000 [17:57<00:00, 28.01s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [17:57<00:00, 19.61s/pipeline]Optimization Progress: 100%|██████████| 2000/2000 [18:10<00:00, 19.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2000/2000 [18:12<00:00, 19.61s/pipeline]Optimization Progress:  95%|█████████▌| 2005/2100 [18:14<23:19, 14.73s/pipeline]Optimization Progress:  96%|█████████▌| 2006/2100 [18:29<23:24, 14.94s/pipeline]Optimization Progress:  99%|█████████▉| 2086/2100 [18:35<02:26, 10.48s/pipeline]
Generation 20 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [18:37<00:00, 10.48s/pipeline]Optimization Progress: 100%|██████████| 2100/2100 [18:37<00:00,  7.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:38<00:00,  7.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [18:39<00:00,  7.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2100/2100 [18:40<00:00,  7.37s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2100/2100 [18:48<00:00,  7.37s/pipeline]Optimization Progress:  96%|█████████▌| 2101/2200 [18:52<16:14,  9.85s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2101/2200 [18:52<16:14,  9.85s/pipeline]Optimization Progress:  96%|█████████▌| 2103/2200 [19:05<14:09,  8.75s/pipeline]Optimization Progress:  99%|█████████▉| 2183/2200 [19:11<01:44,  6.15s/pipeline]
Generation 21 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [19:11<00:00,  6.15s/pipeline]Optimization Progress: 100%|██████████| 2200/2200 [19:11<00:00,  4.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 2200/2200 [19:18<00:00,  4.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2200/2200 [19:24<00:00,  4.31s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2200/2200 [19:24<00:00,  4.31s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2201/2300 [19:28<07:06,  4.31s/pipeline]Optimization Progress:  96%|█████████▌| 2202/2300 [19:30<07:02,  4.31s/pipeline]Optimization Progress:  96%|█████████▌| 2203/2300 [20:11<14:36,  9.04s/pipeline]Optimization Progress:  99%|█████████▉| 2283/2300 [20:44<01:49,  6.45s/pipeline]
Generation 22 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2300/2300 [20:50<00:00,  6.45s/pipeline]Optimization Progress: 100%|██████████| 2300/2300 [20:50<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [20:51<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2300/2300 [20:52<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [20:58<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.
Optimization Progress: 100%|██████████| 2300/2300 [21:00<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2300/2300 [21:00<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [21:00<00:00,  4.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2300/2300 [21:01<00:00,  4.63s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  96%|█████████▌| 2300/2400 [21:02<07:42,  4.63s/pipeline]Optimization Progress:  96%|█████████▌| 2301/2400 [21:02<11:01,  6.68s/pipeline]Optimization Progress:  96%|█████████▌| 2302/2400 [24:58<2:03:26, 75.58s/pipeline]Optimization Progress:  99%|█████████▉| 2382/2400 [25:05<15:52, 52.93s/pipeline]  
Generation 23 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2400/2400 [25:14<00:00, 52.93s/pipeline]Optimization Progress: 100%|██████████| 2400/2400 [25:14<00:00, 37.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2400/2400 [25:15<00:00, 37.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 2400/2400 [25:22<00:00, 37.20s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 2400/2400 [25:22<00:00, 37.20s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2400/2500 [25:23<1:01:59, 37.20s/pipeline]Optimization Progress:  96%|█████████▌| 2401/2500 [25:23<47:17, 28.66s/pipeline]  Optimization Progress:  96%|█████████▌| 2402/2500 [25:40<41:10, 25.21s/pipeline]Optimization Progress:  99%|█████████▉| 2482/2500 [25:49<05:18, 17.68s/pipeline]
Generation 24 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:51<00:00, 17.68s/pipeline]Optimization Progress: 100%|██████████| 2500/2500 [25:51<00:00, 12.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:56<00:00, 12.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [25:58<00:00, 12.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.
Optimization Progress: 100%|██████████| 2500/2500 [25:59<00:00, 12.41s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2500/2500 [26:00<00:00, 12.41s/pipeline]Optimization Progress:  96%|█████████▌| 2501/2600 [26:06<21:46, 13.20s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  96%|█████████▌| 2501/2600 [26:06<21:46, 13.20s/pipeline]Optimization Progress:  96%|█████████▋| 2503/2600 [27:42<38:12, 23.63s/pipeline]Optimization Progress:  99%|█████████▉| 2583/2600 [27:50<04:41, 16.57s/pipeline]
Generation 25 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2600/2600 [27:50<00:00, 16.57s/pipeline]Optimization Progress: 100%|██████████| 2600/2600 [27:50<00:00, 11.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2600/2600 [27:51<00:00, 11.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 2600/2600 [27:58<00:00, 11.61s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 2600/2600 [28:04<00:00, 11.61s/pipeline]Optimization Progress:  96%|█████████▋| 2604/2700 [28:06<14:48,  9.26s/pipeline]Optimization Progress:  96%|█████████▋| 2605/2700 [29:45<57:26, 36.28s/pipeline]Optimization Progress:  99%|█████████▉| 2685/2700 [29:52<06:21, 25.42s/pipeline]
Generation 26 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.
Optimization Progress: 100%|██████████| 2700/2700 [29:55<00:00, 25.42s/pipeline]Optimization Progress: 100%|██████████| 2700/2700 [29:55<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2700/2700 [29:57<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [29:58<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [30:02<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.
Optimization Progress: 100%|██████████| 2700/2700 [30:03<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 2700/2700 [30:03<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.
Optimization Progress: 100%|██████████| 2700/2700 [30:03<00:00, 17.87s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2700/2700 [30:05<00:00, 17.87s/pipeline]Optimization Progress:  96%|█████████▋| 2702/2800 [30:06<22:59, 14.08s/pipeline]Optimization Progress:  97%|█████████▋| 2703/2800 [30:17<21:22, 13.22s/pipeline]Optimization Progress:  99%|█████████▉| 2783/2800 [30:29<02:38,  9.30s/pipeline]
Generation 27 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2800/2800 [30:36<00:00,  9.30s/pipeline]Optimization Progress: 100%|██████████| 2800/2800 [30:36<00:00,  6.64s/pipeline]Optimization Progress:  97%|█████████▋| 2801/2900 [30:43<11:23,  6.90s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 2801/2900 [30:43<11:23,  6.90s/pipeline]Optimization Progress:  97%|█████████▋| 2803/2900 [31:24<17:44, 10.97s/pipeline]Optimization Progress:  99%|█████████▉| 2883/2900 [31:37<02:11,  7.73s/pipeline]
Generation 28 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.
Optimization Progress: 100%|██████████| 2900/2900 [31:38<00:00,  7.73s/pipeline]Optimization Progress: 100%|██████████| 2900/2900 [31:38<00:00,  5.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 2900/2900 [31:39<00:00,  5.44s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 2900/2900 [31:39<00:00,  5.44s/pipeline]Optimization Progress:  97%|█████████▋| 2905/3000 [31:49<07:02,  4.44s/pipeline]Optimization Progress:  97%|█████████▋| 2906/3000 [32:57<36:49, 23.51s/pipeline]Optimization Progress: 100%|█████████▉| 2986/3000 [33:09<03:50, 16.50s/pipeline]
Generation 29 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [33:09<00:00, 16.50s/pipeline]Optimization Progress: 100%|██████████| 3000/3000 [33:09<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.
Optimization Progress: 100%|██████████| 3000/3000 [33:11<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.
Optimization Progress: 100%|██████████| 3000/3000 [33:13<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3000/3000 [33:17<00:00, 11.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3000/3000 [33:17<00:00, 11.57s/pipeline]Optimization Progress:  97%|█████████▋| 3002/3100 [33:22<16:12,  9.92s/pipeline]Optimization Progress:  97%|█████████▋| 3003/3100 [36:21<1:38:14, 60.77s/pipeline]Optimization Progress:  99%|█████████▉| 3083/3100 [36:35<12:04, 42.59s/pipeline]  
Generation 30 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 operands could not be broadcast together with shapes (3,) (2,) .
Optimization Progress: 100%|██████████| 3100/3100 [36:35<00:00, 42.59s/pipeline]Optimization Progress: 100%|██████████| 3100/3100 [36:35<00:00, 29.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3100/3100 [36:40<00:00, 29.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3100/3100 [36:41<00:00, 29.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 3100/3100 [36:43<00:00, 29.83s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3100/3100 [36:45<00:00, 29.83s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3101/3200 [36:48<49:12, 29.83s/pipeline]Optimization Progress:  97%|█████████▋| 3102/3200 [36:48<37:09, 22.75s/pipeline]Optimization Progress:  97%|█████████▋| 3103/3200 [38:09<1:05:03, 40.24s/pipeline]Optimization Progress:  99%|█████████▉| 3183/3200 [38:15<07:59, 28.20s/pipeline]  
Generation 31 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3200/3200 [38:28<00:00, 28.20s/pipeline]Optimization Progress: 100%|██████████| 3200/3200 [38:28<00:00, 19.95s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3200/3300 [38:29<33:15, 19.95s/pipeline]Optimization Progress:  97%|█████████▋| 3201/3300 [38:29<23:38, 14.33s/pipeline]Optimization Progress:  97%|█████████▋| 3202/3300 [39:48<55:09, 33.77s/pipeline]Optimization Progress:  99%|█████████▉| 3282/3300 [39:56<07:05, 23.67s/pipeline]
Generation 32 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [39:59<00:00, 23.67s/pipeline]Optimization Progress: 100%|██████████| 3300/3300 [39:59<00:00, 16.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3300/3300 [40:01<00:00, 16.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3300/3300 [40:01<00:00, 16.62s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.
Optimization Progress: 100%|██████████| 3300/3300 [40:07<00:00, 16.62s/pipeline]Optimization Progress:  97%|█████████▋| 3301/3400 [40:08<23:43, 14.38s/pipeline]Optimization Progress:  97%|█████████▋| 3302/3400 [40:44<33:48, 20.70s/pipeline]Optimization Progress:  99%|█████████▉| 3382/3400 [41:52<04:25, 14.74s/pipeline]
Generation 33 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3400/3400 [41:59<00:00, 14.74s/pipeline]Optimization Progress: 100%|██████████| 3400/3400 [41:59<00:00, 10.45s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.
Optimization Progress: 100%|██████████| 3400/3400 [41:59<00:00, 10.45s/pipeline]Optimization Progress:  97%|█████████▋| 3401/3500 [42:05<14:58,  9.08s/pipeline]                                                                                Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.
Optimization Progress:  97%|█████████▋| 3401/3500 [42:05<14:58,  9.08s/pipeline]Optimization Progress:  97%|█████████▋| 3403/3500 [45:07<54:20, 33.62s/pipeline]Optimization Progress: 100%|█████████▉| 3483/3500 [45:16<06:40, 23.57s/pipeline]
Generation 34 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.
Optimization Progress: 100%|██████████| 3500/3500 [45:24<00:00, 23.57s/pipeline]Optimization Progress: 100%|██████████| 3500/3500 [45:24<00:00, 16.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3500/3500 [45:26<00:00, 16.63s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.
Optimization Progress: 100%|██████████| 3500/3500 [45:27<00:00, 16.63s/pipeline]Optimization Progress:  97%|█████████▋| 3502/3600 [45:31<20:50, 12.76s/pipeline]Optimization Progress:  97%|█████████▋| 3503/3600 [45:51<24:09, 14.95s/pipeline]Optimization Progress: 100%|█████████▉| 3583/3600 [47:45<03:05, 10.89s/pipeline]
Generation 35 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.
Optimization Progress: 100%|██████████| 3600/3600 [47:48<00:00, 10.89s/pipeline]Optimization Progress: 100%|██████████| 3600/3600 [47:48<00:00,  7.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [47:54<00:00,  7.69s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3600/3600 [47:56<00:00,  7.69s/pipeline]Optimization Progress:  97%|█████████▋| 3601/3700 [47:57<13:21,  8.10s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  97%|█████████▋| 3601/3700 [47:57<13:21,  8.10s/pipeline]Optimization Progress:  97%|█████████▋| 3603/3700 [50:05<40:09, 24.84s/pipeline]Optimization Progress: 100%|█████████▉| 3683/3700 [50:14<04:56, 17.42s/pipeline]
Generation 36 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 3700/3700 [50:18<00:00, 17.42s/pipeline]Optimization Progress: 100%|██████████| 3700/3700 [50:18<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [50:18<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [50:19<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [50:19<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3700/3700 [50:23<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3700/3700 [50:24<00:00, 12.25s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3700/3700 [50:25<00:00, 12.25s/pipeline]Optimization Progress:  97%|█████████▋| 3701/3800 [50:28<19:22, 11.75s/pipeline]Optimization Progress:  97%|█████████▋| 3702/3800 [50:42<20:12, 12.37s/pipeline]Optimization Progress: 100%|█████████▉| 3782/3800 [50:52<02:36,  8.69s/pipeline]
Generation 37 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.
Optimization Progress: 100%|██████████| 3800/3800 [50:56<00:00,  8.69s/pipeline]Optimization Progress: 100%|██████████| 3800/3800 [50:56<00:00,  6.16s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.
Optimization Progress: 100%|██████████| 3800/3800 [50:58<00:00,  6.16s/pipeline]Optimization Progress:  97%|█████████▋| 3801/3900 [51:50<33:38, 20.39s/pipeline]Optimization Progress: 100%|█████████▉| 3881/3900 [53:19<04:37, 14.61s/pipeline]
Generation 38 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [53:19<00:00, 14.61s/pipeline]Optimization Progress: 100%|██████████| 3900/3900 [53:19<00:00, 10.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 3900/3900 [53:22<00:00, 10.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 3900/3900 [53:28<00:00, 10.24s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 3900/3900 [53:30<00:00, 10.24s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [53:31<00:00, 10.24s/pipeline]                                                                                _pre_test decorator: _mate_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 3900/3900 [53:31<00:00, 10.24s/pipeline]Optimization Progress:  98%|█████████▊| 3903/4000 [53:32<13:41,  8.47s/pipeline]Optimization Progress:  98%|█████████▊| 3904/4000 [56:16<1:27:56, 54.96s/pipeline]Optimization Progress: 100%|█████████▉| 3984/4000 [57:25<10:19, 38.73s/pipeline]  
Generation 39 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4000/4000 [57:26<00:00, 38.73s/pipeline]Optimization Progress: 100%|██████████| 4000/4000 [57:26<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..
Optimization Progress: 100%|██████████| 4000/4000 [57:26<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [57:26<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [57:27<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 No feature in X meets the variance threshold 0.05000.
Optimization Progress: 100%|██████████| 4000/4000 [57:27<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4000/4000 [57:29<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [57:29<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [57:30<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 1 feature(s) (shape=(50, 1)) while a minimum of 2 is required by FeatureAgglomeration..
Optimization Progress: 100%|██████████| 4000/4000 [57:30<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [57:30<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.
Optimization Progress: 100%|██████████| 4000/4000 [57:30<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..
Optimization Progress: 100%|██████████| 4000/4000 [57:31<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [57:32<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4000/4000 [57:35<00:00, 27.12s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.
Optimization Progress: 100%|██████████| 4000/4000 [57:36<00:00, 27.12s/pipeline]Optimization Progress:  98%|█████████▊| 4001/4100 [57:40<44:45, 27.12s/pipeline]Optimization Progress:  98%|█████████▊| 4002/4100 [59:03<54:55, 33.63s/pipeline]Optimization Progress: 100%|█████████▉| 4082/4100 [59:09<07:04, 23.56s/pipeline]
Generation 40 - Current Pareto front scores:
-1	-760294296.9739097	SGDRegressor(input_matrix, SGDRegressor__alpha=0.001, SGDRegressor__eta0=0.1, SGDRegressor__fit_intercept=True, SGDRegressor__l1_ratio=0.75, SGDRegressor__learning_rate=invscaling, SGDRegressor__loss=huber, SGDRegressor__penalty=elasticnet, SGDRegressor__power_t=0.0)                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..
Optimization Progress: 100%|██████████| 4100/4100 [59:13<00:00, 23.56s/pipeline]Optimization Progress: 100%|██████████| 4100/4100 [59:13<00:00, 16.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.
Optimization Progress: 100%|██████████| 4100/4100 [59:17<00:00, 16.57s/pipeline]                                                                                _pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.
Optimization Progress: 100%|██████████| 4100/4100 [59:18<00:00, 16.57s/pipeline]Optimization Progress:  98%|█████████▊| 4101/4200 [59:22<23:42, 14.37s/pipeline]                                                                                Invalid pipeline encountered. Skipping its evaluation.
Optimization Progress:  98%|█████████▊| 4101/4200 [59:22<23:42, 14.37s/pipeline]Optimization Progress:  98%|█████████▊| 4103/4200 [1:00:42<35:41, 22.07s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4182/4200 [1:00:42<06:37, 22.07s/pipeline]                                                                                  60.80 minutes have elapsed. TPOT will close down.
TPOT closed during evaluation in one generation.
WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.
Optimization Progress: 100%|█████████▉| 4182/4200 [1:00:42<06:37, 22.07s/pipeline]                                                                                  
Optimization Progress: 100%|█████████▉| 4182/4200 [1:00:42<06:37, 22.07s/pipeline]                                                                                  
TPOT closed prematurely. Will use the current best pipeline.
Optimization Progress: 100%|█████████▉| 4182/4200 [1:00:42<06:37, 22.07s/pipeline]                                                                                  /projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
/projappl/project_2003107/anaconda3/envs/tpot_automl/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.
  warnings.warn("Warning: optional dependency `torch` is not available. - skipping import of NN models.")
